{
    "version": "https://jsonfeed.org/version/1",
    "title": "Samir Paul • All posts by \"caching\" tag",
    "description": "Software Engineer",
    "home_page_url": "https://samirpaul.in",
    "items": [
        {
            "id": "https://samirpaul.in/posts/caching/",
            "url": "https://samirpaul.in/posts/caching/",
            "title": "Caching",
            "date_published": "2023-08-05T20:52:53.855Z",
            "content_html": "<p>Caching</p>\n<hr>\n<ul>\n<li>Take advantage of the locality of reference principle: recently requested data is likely to be requested again.</li>\n<li>Exist at all levels in architecture, but often found at the level nearest to the front end.</li>\n</ul>\n<h2 id=\"Application-server-cache\"><a href=\"#Application-server-cache\" class=\"headerlink\" title=\"Application server cache\"></a>Application server cache</h2><ul>\n<li>Cache placed on a request layer node.</li>\n<li>When a request layer node is expanded to many nodes<ul>\n<li>Load balancer randomly distributes requests across the nodes.</li>\n<li>The same request can go to different nodes.</li>\n<li>Increase cache misses.</li>\n<li>Solutions:<ul>\n<li>Global caches</li>\n<li>Distributed caches</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Distributed-cache\"><a href=\"#Distributed-cache\" class=\"headerlink\" title=\"Distributed cache\"></a>Distributed cache</h2><ul>\n<li>Each request layer node owns part of the cached data.</li>\n<li>Entire cache is divided up using a consistent hashing function.</li>\n<li>Pro<ul>\n<li>Cache space can be increased easily by adding more nodes to the request pool.</li>\n</ul>\n</li>\n<li>Con<ul>\n<li>A missing node leads to cache lost.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Global-cache\"><a href=\"#Global-cache\" class=\"headerlink\" title=\"Global cache\"></a>Global cache</h2><ul>\n<li>A server or file store that is faster than original store, and accessible by all request layer nodes.</li>\n<li>Two common forms<ul>\n<li>Cache server handles cache miss.<ul>\n<li>Used by most applications.</li>\n</ul>\n</li>\n<li>Request nodes handle cache miss.<ul>\n<li>Have a large percentage of the hot data set in the cache.</li>\n<li>An architecture where the files stored in the cache are static and shouldn’t be evicted.</li>\n<li>The application logic understands the eviction strategy or hot spots better than the cache</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Content-distributed-network-CDN\"><a href=\"#Content-distributed-network-CDN\" class=\"headerlink\" title=\"Content distributed network (CDN)\"></a>Content distributed network (CDN)</h2><ul>\n<li>For sites serving large amounts of static media.</li>\n<li>Process<ul>\n<li>A request first asks the CDN for a piece of static media.</li>\n<li>CDN serves that content if it has it locally available.</li>\n<li>If content isn’t available, CDN will query back-end servers for the file, cache it locally and serve it to the requesting user.</li>\n</ul>\n</li>\n<li>If the system is not large enough for CDN, it can be built like this:<ul>\n<li>Serving static media off a separate subdomain using lightweight HTTP server (e.g. Nginx).</li>\n<li>Cutover the DNS from this subdomain to a CDN later.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Cache-invalidation\"><a href=\"#Cache-invalidation\" class=\"headerlink\" title=\"Cache invalidation\"></a>Cache invalidation</h2><ul>\n<li>Keep cache coherent with the source of truth. Invalidate cache when source of truth has changed.</li>\n<li>Write-through cache<ul>\n<li>Data is written into the cache and permanent storage at the same time.</li>\n<li>Pro<ul>\n<li>Fast retrieval, complete data consistency, robust to system disruptions.</li>\n</ul>\n</li>\n<li>Con<ul>\n<li>Higher latency for write operations.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Write-around cache<ul>\n<li>Data is written to permanent storage, not cache.</li>\n<li>Pro<ul>\n<li>Reduce the cache that is no used.</li>\n</ul>\n</li>\n<li>Con<ul>\n<li>Query for recently written data creates a cache miss and higher latency.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Write-back cache<ul>\n<li>Data is only written to cache.</li>\n<li>Write to the permanent storage is done later on.</li>\n<li>Pro<ul>\n<li>Low latency, high throughput for write-intensive applications.</li>\n</ul>\n</li>\n<li>Con<ul>\n<li>Risk of data loss in case of system disruptions.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Cache-eviction-policies\"><a href=\"#Cache-eviction-policies\" class=\"headerlink\" title=\"Cache eviction policies\"></a>Cache eviction policies</h2><ul>\n<li>FIFO: first in first out</li>\n<li>LIFO: last in first out</li>\n<li>LRU: least recently used</li>\n<li>MRU: most recently used</li>\n<li>LFU: least frequently used</li>\n<li>RR: random replacement</li>\n</ul>\n",
            "tags": [
                "blog",
                "coding",
                "computer-science",
                "caching",
                "system-design",
                "design-interview"
            ]
        }
    ]
}