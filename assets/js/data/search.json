[ { "title": "Operating System Notes For Placement", "url": "/posts/operating-system-notes-for-placement/", "categories": "Computer Science, Operating System", "tags": "computer-science, Operating System", "date": "2023-06-11 00:00:00 +0530", "snippet": "Operating Systems OverviewDownload PDF Notes➥Operating Systems : Direct operational resources [CPU, memory, devices] Enforces working policies [Resource usage, access] Mitigates difficulty of co...", "content": "Operating Systems OverviewDownload PDF Notes➥Operating Systems : Direct operational resources [CPU, memory, devices] Enforces working policies [Resource usage, access] Mitigates difficulty of complex tasks [abstract hardware details (using system calls)]What is an Operating System? Intermediate between Hardware and Software applications Hides hardware complexity (Read/write file storage, send/receive socket network) Handles resource management (CPU scheduling, Memory management) Provide isolation and protection (allocate different parts of memory to different applications so that applications don’t overwrite other memory locations)Operating System definition:An Operating System is a layer of systems software that: directly has privileged access to the underlying hardware; hides the hardware complexity; manages hardware on behalf of one or more application according to some predifined policies. In addition, it ensures that applications are isolated and protected from one another.Operating System examples: Desktop Embedded devices Microsoft Windows Android OS MAC OS X (BSD) iOS LINUX Symbian … … OS Elements Abstractions (corresponds to applications that OS executes) process, thread, file, socket, memory page Mechanisms (on top of Abstractions) create, schedule, open, write, allocate Policies (how mechanisms are used to manage underlying hardware) Least Recently Used (LRU) , Earliest Deadline First (EDF), etc. Example :Memory Management: Abstractions: Memory page Mechanisms: Allocate, map to a process Policies: LRUOS Design Principles Seperation of mechanism and policy implement flexible mechanisms to support many policies e.g. LRU, LFU, random Optimize for common case Where will the OS be used? What will the user want to execute on that machine? What are the workload requirements? User/ Kernel Protection Boundary user-level =&gt; applications [underprivileged mode] kernel-level =&gt; OS Kernel [privileged access, hardware access] User-Kernel switch is supported by hardware. using trap instructions system calls like: \t- open (file) send (socket) malloc (memory) signals System call Flowcart To make a system call, an application must: write arguments save relevant data ast well defined location make system calls using system call number In synchronous mode : wait until system call completes.Basic OS services process management file management device management memory management storage management securityLinux System Calls Task Commands Process Control fork (); exit(); wait(); File Manipulation open(); read(); write(); Device Manipulation ioctl(); read(); write(); Information Maintenance getpid(); alarm(); sleep(); Communication pipe(); shmget(); mmap(); Protection chmod(); umask(); chown(); Linux ArchitectureProcess and Process ManagementProcess: Instance of an executing program. State of execution program counter, stack pointer Parts and temporary holding area data, register state, occupies state in memory May require special hardware I/O devices Process is a state of a program when executing and loaded in memory (active state) as opposed to application (static state).What does a process look like?Type of state Text and Data static state when process loads first Heap dynamically created during execution Stack grows and shrinks LIFO queue (used to store task checkpoints to resume the original process after switching from another.) How does the OS know what a process is doing?Using: Program counter CPU registers Stack pointerProcess Control Block (PCB) PCB created when process is created Certain fields are updated when process state change e.g. memory mapping or other fields that change very frequently e.g. Program CounterHow is PCB used ?Context Switch Mechanism used to switch from the context of one process to another in the CPU. They are expensive! direct costs: no of cycles for load and store instructions. indirect costs: COLD cache (read more here) Therefore limit frequency how context switching is done. When a cache is HOT, most process data is in the cache so the process performance will be at its best.Sometimes there are situations where we have to Context Switch (higher priority process, timesharing, etc.)Process LifecycleCPU is able to execute a process when the process is in Running or Ready state.Process CreationMechanisms: fork : copies the parent PCB into new child PCB child contains execution at instruction after fork exec : replace child image load new program and start from first instruction What is the role of CPU scheduler?CPU scheduler determines which one of the currently ready processes will be dispatched to the CPU to start running, and how long it should run for.OS must : preempt =&gt; interrupt and save current context schedule =&gt; run scheduler to choose next process dispatch =&gt; dispatch process 2 switch into its contextScheduling design decisions What are the appropriate timeslice values? Metrics to choose next process to run?I/OA process can make way in the ready queue in a number of ways.Can process interact?Inter Process communication:IPC mechanisms: transfer data/info between address space maintain protection and isolation provide flexibility and performanceTwo types of IPC models:1. Message Passing IPC OS provides communication channel line shared buffer Processes can write(send), read(receive) msg to/from channelAdvantages: OS manages the channelDisadvantages: Overheads2. Shared Memory IPC OS establishes a shared channel and maps it into each processes’ address space Processes directly write(send), read(receive) msg to/from this memoryAdvantages: OS is out of the way after establishing the shared channelDisadvantages: Re-implementing a lot of code that could have been done by the OSOverall, shared memory based communication is better if mapping memory between two processes is ammortized over a large number of messages.Threads and ConcurrencyThread: is an active entity executing unit of a process works simultaneously with others many threads execute together requires coordination sharing of I/O devices, CPUs, memory Process vs ThreadWhy are threads useful? Parallelization =&gt; Speedup Specialization =&gt; Hot cache Efficiency =&gt; lower memory requirement &amp; cheaper IPC Time for context switch in threads is less, since memory is shared, hence mapping is not required between virtual and physical memory. Therefore multithreading can be used to hide latency. Benefits to both applicatioons and OS code Multithreaded OS kernel threads working on behalf of applications OS level services like daemons and drivers What do we need to support threads? Threads data structure Identify threads, keep track of resource usage.. Mechanisms to create and manage threads Mechanisms to safely coordinate among threads running concurrently in the same address spaceConcurrency control and Coordination Mutual exclusion Exclusive access to only one thread at a time mutex Waiting on other threads Specific condition before proceeding condition variable Waking up other threads from wait stateThreads and Threads creation Thread data structure: Thread type, Thread ID, PC, SP, registers, stack, attributes. Fork(proc, args) create a thread not UNIX fork t1 = fork(proc, args) Join(thread) terminate a thread child_result = join(t1) Example:Thread t1;Shared_List list;t1 = fork(safe_insert, 4);safe_insert(6);join(t1); //OptionalThe list can be accessed by reading shared variable.Mutual Exclusion Mutex data structure: locked?, owner, blocked_threads lock(mutex){\t//Critical Section //Only one thread can access at a time}unlock(mutex)Producer Consumer problemWhat if the processing you wish to perform with mutual exclusion needs to occur under certai conditions?For e.g. The producer appends items to a list until the list is full, and the consumer has to print out all the items of the list once the list if full and then empty the list. Thus we have to execute the Consumer thread only under a certain condition (here- when the list becomes empty, print items).Solution: Use Condition Variables Wait(mutex, condition) mutex is automatically released and reaquired on wait The consumer applies Wait until the list is full Signal(condition) Notify only one thread waiting on condition The Producer applies Signal to the Consumer thread when the list is full Broadcast(condition) Notify all waiting threads Readers / Writer problem 0 or more readers can access a resource 0 or 1 writer can write the resource concurrently at the same time One solution: lock on resource \t- good for writer \t- too restrictive for readers Better solution:if ((read_count == 0) &amp; (read_count == 0))\tR okay, W okayif (read_count &gt; 0)\tR okay if (read_count == 1)\tR not-okay, W not-okay State of shared resource: free : resource_counter = 0 reading : resource_counter &gt; 0 writing : resource_counter = -1Thus essentially we can apply mutex on the new proxy ‘resource_counter’ variable that represents the state of the shared resource.Avoiding common mistakes keep track of mutex/lock variable used with a resource e.g. mutex_type m1; // mutex for file1 check that you are always and correctly using lock and unlock \t- Compilers can be used as they generate errors/warnings to correct this type of mistake Use a single mutex to access a single resource check that you are signalling correct condition check that you are not using signal when broadcast is needed signal : only 1 thread is will proceed, remaining threads will wait check thread execution order to be controlled by signals to condition variablesSpurious(Unnecessary) Wake upsWhen we wake up threads knowing they may not be able to proceed.DeadlocksTwo or more competing threads are said to be in a deadlock if they are waiting on each other to complete, but none of them ever do.Here T1 and T2 are in deadlock.How to avoid this? Unlock T1 before locking T2 Fine-grained locking but T1 nad T2 may both be required Use one mega lock, get all locks upfront, then release at end For some applications this may be ok. But generally its too restrictive and limits parallelism Maintain lock order first m_T1 then m_T2 \t- this will prevent cycles in wait graph A cycle in wait graph is necessary and sufficient for deadlock to occur. (thread-waiting-on-resource —edge—&gt; thread-owning-resource) Deadlock prevention =&gt; ExpensivePre-check for cycles and then delay process or change code Deadlock Detection and Recovery =&gt; Rollback Kernel vs User level ThreadsThree types of models:1. One to One model:Advantages: OS sees threads Synchronization BlockingDisadvantages: Must go to OS for all operations OS may have limits on policies, threads Portability2. Many to One model:Advantages: Totally Portable Doesn’t depend on OS limits and policiesDisadvantages: OS may block entire process if one user-level thread blocks on I/O3. Many to Many model:Advantages: Best of both worlds Can have bound or unbound threadsDisadvantages: Requires coordination between user and kernel level thread managersMultithreading patterns1. Boss-Workers pattern Boss- assigns work Workers- perform entire taskThroughput of system is limited by boss thread. Hence boss thread must be kept efficient.Throughput = 1/boss-time-ordersBoss assigns works by: Directly signalling specific works + workers don’t need to sync - boss must keep track of everyone Placing work in queue + boss doesn’t neeed to know details about workers - queue synchronization How many workers? on demand pool of workers static vs dynamic (i.e dynamically increasing size according to work)Advantages: SimplicityDisadvantages: Thread pool management Locality1B. Boss-Workers pattern variant Here workers are specialized for certain tasks opposite to the previous equally created workersAdvantages: Better locality Quality of Service managementDisadvantages: Load balancing2. Pipeline pattern Threads assigned one subtask in the system Entire task = Pipeline of threads Multiple tasks concurrently run in the system, in different pipeline stages Throughput depends on weakest link Shared buffer based communication between stages3. Layered pattern Layers of threads are assigned group of related subtasks End to end task must pass up and down through all layersAdvantages: Specialization Less fine-grained than pipelineDisadvantages: Not suitable for all applications SynchronizationExample:Q) For 6 step toy order application we have 2 solutions: Boss-workers solution Pipeline solutionBoth have 6 threads. In the boss-workers solution, a worker produces a toy order in 120 ms. In the pipeline solution, each of 6 stages take 20 ms.How long will it take for these solutions to complete 10 toy orders and 11 toy orders?A) 6 threads means for Boss-workers, 1 thread is for boss, 5 for workers. In pipeline 6 threads are equally used.For 10 toy orders:Boss-workers(10) = 120 + 120 = 240 msPipeline(10) = 120 + (9*20) = 300 msHere Boss-workers is better than Pipeline.For 11 toy orders:Boss-workers(11) = 120 + 120 + 120 = 360 msPipeline(11) = 120 + (10*20) = 320 msHere Pipeline is better than Boss-workers.This proves that choosing a better pattern depends on the number of threads and the work required to be done.PThreadsPThreads == POSIX ThreadsPOSIX = Portable OS interfaceCompiling PThreads #include in main file Compile source with -lpthread or -pthread gcc -o main main.c -lpthreadgcc -o main main.c -pthread Check return values of common examplesPThread mutexes to solve mutual exclusion problems among concurrent threadsSafety tips Shared data should always be accessed through single mutex Mutex scope must be visible to all Globally order locks for all threads, lock mutexes in order Always unlock a mutex (correctly)Thread Design ConsiderationsKernel vs User Level ThreadsThread related data structuresHard vs Light Process statesPCB is divided into multiple data structures classified as follows: Light Process states Signal mask System call args Heavy Process states virtual address mapping Rationale for Multiple Data Structures: Single PCB Multiple DS Large continuos DS Smaller DS Private for each entity Easier to share Saved and restored on each context switch Save and Restore only what needs to change on context switch Update for any changes User lever library need to only update portion of the state Thus the following disadvantages for single PCB become advantages for Multiple DS : Scalability Overheads Performance Flexibility Comparison of Interrupts and Signals Handled in specific ways - interrupt and signal handlers Can be ignored interrupt and signal mask Expected or unexpected appear synchronously or asynchronously Difference: Interrupts Signals Events generated externally by components other than CPU (I/O devices, timers, other CPUs) Events triggered by CPU and software running on it Determined based on physical platform Determined based on OS Appear asynchronously Appear synchronously or asynchronously Similarities: Have a unique ID depending on h/w or OS Can be masked and disabled/suspended via corresponding mask \t- per-CPU interrupt mask, preprocess signal mask if enabled, trigger corresponding to handler \t- interrupt handler set for entire system by OS signal handler set on per process basis by process An interrupt is like a snowstorm alarmA signal is like a low battery warningInterruptsSignalsHandlers / Actions Default actions Terminate, ignore Terminate and core dump Stop or continue Process Installs Handler signal(), sigaction() for most signals, some cannot be “caught” Synchronous SIGSEGV (access to protected memory) SIGFPE (divided by zero) SIGKILL (kill, id) \t- can be directed to a specific thread Asynchronous* SIGKILL (kill) SIGALARM Why disable Interrupts or Signals Here PC: First instruction in handlerSP : thread stackTo prevent deadlock, Keep handler code simple avoid mutex - too restrictive Control interruptions by handler code Use interrupt/signal masks 0011100110.. (0: disabled, 1: enabled) clear_field_in_mask(mask)lock(mutex){#disabled =&gt; remaining pending}unlock(mutex)reset_field_in_mask(mask)#enabled =&gt; execute handler code Interrupt masks are per CPU if mask disables interrupt, hardware interrupt rounting mechanism will not deliver interrupt Signal are per execution context (User-level thread on top of Kernel-level thread) if mask disables signal, kernel sees mask and will not interrupt corresponding thread Types of Signals One-shot Signals “n signals pending == 1 signal pending” : atleast once must be explicitly re-enabled Realtime Signals “if n signals raised, then handler is called n times” Handling interrupts as threadsbut dynamic thread creation is expensive! Dynamic decision if handler doesn’t lock \t- execute on interrupted threads stack if handler can block \t- turn into real thread Optimization pre-create and pre-initialize thread structure for interrupt routines Threads and Signal HandlingCase 1 : User-Level-Thread mask = 1 Kernel-Level-Thread mask = 1Case 2 : User-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 another User-Level-Thread mask = 1Case 3 : User-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 another User-Level-Thread mask = 1 another Kernel-Level-Thread mask = 1Case 4 : User-Level-Thread mask = 0 Kernel-Level-Thread mask = 1 all User-Level-Thread mask = 0Optimize common case signals less frequennt than signal mask updates system calls avoided cheaper to update user-level mask signal handling more expensiveMulti-processing vs Multi-threadingHow to best provide concurrency?Multi-Processing (MP)Advantages Simple programmingDisadvantages High memory usage Costs context switch costly to maintain shared state (tricky port setup)Multi-Threading (MP)Advantages Shared address space Shared state (no sys calls to other threads) Cheap context switchDisadvantages Complex implementation Requires synchronization Requires underlying support for threadsEvent Driven modelFeatures: Single address space Single process Single thread of controlDispatcher : acts as a state machine and accepts any external eventsWhen call handler =&gt; jump to codeThe handler: Runs to completion if they need to block initiate blocking operation and pass control to dispatch loop Concurrent execution in Event-driven models MP &amp; MT : 1 request per execution context (process/thread) Event Driven : Many requests interleaved in an execution context Single thread switches among processing of different requests Process requests until wait is necessary then switch to another request Advantages Single address space Single flow of control Smaller memory requirement Event Driven model requires less memory than Boss-workers/Pipeline model, where the extra memory is required for helper thread for concurrent blocking I/O not for all concurrent requests. No context switches No synchronizationDisadvantages A blocking request/handler will block entire processAsynchronous I/O operationsAsynchronous I/O operations fit well with Event-driven modelsSince asynchronous calls are not easily avalible, helpers can be used to implement the async call functionality: designated for blocking I/O operations only pipe/socket based communication with event dispatcher select()/ poll() still okay helper blocks, but main event loop (&amp; process) will notAsymmetric Multi-Process Event Driven model (AMPED &amp; AMTED)Advantages Resolve portability limitations of basic event driven model Smaller footprint than regular worker threadDisadvantages Applicability to certain classes of applications Event routing on multi CPU systemsEg Apache Web Server Core : basic server skeleton Modules : per functionality Flow of Control : Similar to Event Driven model But its an combination of MP + MT, each process = boss/worker with dynamic thread pool number of processes can also be dynamically adjusted SchedulingOperating System perform scheduling in the following simple ways: Dispatch orders immediately scheduling is simple FIFO (First-Come-First-Serve) Dispatch simple orders first maximize number of orders processed over time maximize throughput (SJF) Dispatch complex orders first maximize utilization of CPU, devices, memory CPU Scheduler Decides how and when process (and their threads) access shared CPUs Schedules tasks running at user level processes/threads as well as kernel level threads Chooses one of the ready tasks to run on CPU Runs when CPU becomes idle new task becomes ready timeslice expired timeout Context switch, enter user mode, set PC and go! &lt;= Thread is dispatched on CPU. Which task should be selected? Scheduling policy/algorithm How is this done? Depends on runqueue data structure “Run-to-completion” Scheduling Initial assumptions group of tasks/jobs known execution time no preemption single CPU Metrics throughput average job completion time average job wait time CPU utilization Scheduling algorithms:1. First Come First Serve (FCFS) Schedules tasks in order of arrivalrunqueue = queue(FIFO)If T1, T2, T3 arrive in the given order and T1 has execution time 1s, T2 10s and T3 1s then : Throughput = 3/(1+10+1) = 3/12 = 0.25s Average completion time = (1 + 11 + 12)/3 = 8s Average wait time = (1+1+11)/3 = 4s Starvation NOT possible2. Shortest Job First (SJF) Schedules tasks in order of execution time Therefore for the above example, T1(1s) &gt; T3(1s) &gt; T2(10s) Starvation possiblerunqueue = ordered(queue)//orrunqueue = tree()For SJF, Throughput = 3/(1+10+1) = 3/12 = 0.25s Average completion time = (1 + 2 + 12)/3 = 5s Average wait time = (0+1+2)/3 = 1sPreemptive Scheduling SJF + Preemption Starvation is possibleT2 arrives first.Priority Scheduling Tasks have different priority levels Run highest priority task next (preemption) Starvation is possiblerunqueue = per priority_queue()//or runqueue = tree() ordered on priority low priority task stuck in runqueue =&gt; starvation “priority aging” priority = f(actual priority, time spent in runqueue) eventually tasks will run prevents starvation 3. Round-Robin Scheduling Pick up the first task from queue (like FCFS) Task may yield to wait on I/O (unlike FCFCS) Starvation is NOT possible4. Shortest Remaining Time First (SRTF) Chooses the process with the shortest CPU burst remaining and executes that one. If processes come in during execution that have less remaining time, the current one is preempted and the new one executed. Therefore, it can lead to starvation.Timeslicing Timeslice = max amount of uninterrupted time given to a task task may run less than timeslice has to wait on I/O sync \t- will be placed on queue higher priority task becomes runnable using timeslice tasks are interleaved timesharing the CPU CPU bound tasks =&gt; preemption after timeslice Advantages Short tasks finish sooner More responsive Lengthy I/O operations initiated sooner best to keep timeslice &gt; context-switch-time Disdvantages OverheadsHow long should a timeslice be be? should balance benefits and overheadsFor CPU bound tasks: Hence, for CPU bound tasks, larger timeslice values are betterFor I/O bound tasks: Hence, for I/O bound tasks, smaller timeslice values are better Keeps CPU and I/P devices busy, I/O bound tasks run quickly, makes I/O requests responds to a user. Summary CPU bound tasks prefer longer timeslices limits context switching overheads keeps CPU utilization and throughput I/O bound tasks prefer smaller timeslices However, if all the tasks in contention are I/O bound, it may not make such a difference If a portion of them are I/O smaller timeslices keeps CPU and device utilization high Provides better user-perceived performance Memory ManagementOperating systems: uses intelligently size containers memory pages of segments Not all parts are needed at once tasks operate on subset of memory Optimized for performance reduce time to access state in memory \t- leads to better performance! Memory Management GoalsVirtual vs Physical memory Allocate allocation, replacement Arbitrate address translation and validation Page-based Memory Management Allocate =&gt; pages =&gt; page frames Arbitrate =&gt; page tablesSegment-based Memory Management Allocate =&gt; segments Arbitrate =&gt; segment registersHardware SupportMemory Management Unit (MMU) translate virtual to physical address reports faults (illegal access, permission, not present in memory)Registers pointers to page tables base and limit size, number of segmentsCache Translation lookaside buffer Valid VA-PA translations using TLBTranslation Actual PA generation done in hardwarePage Tables OS creates page table per process On context switch, switch to valid page table Updates register that points to correct page table. E.g CR3 on x86 architecturePage Table Entry (PTE)Flags Present (valid/invalid) Dirty (written to) Accessed (for read or write) Protection bits =&gt; RWXPage Table Entry on x86Flags Present Dirty Accessed R/W permission bit 0: R only, 1: R/W U/S permission bit 0: usermode, 1: superviser mode only others: caching related info (write through, caching disabled) unused: for future usePage faultsPage Table Size 32 bit architecture Page Table Entry (PTE) = 4 Bytes, including PFN + flags Virtual Page Number (VPN) = 2^32/page_size Page size = 4KB (…8KB, 2MB, 4MB, 1GB) Therefore Page Table Size = (2^32 * 2^12)*4B = 4MB (per process) for 64 bit architecture Page Table Entry (PTE) = 8 Bytes Page size = 4KB Page Table Size = (2^64 * 2^12)*8B = 32PB (per process!) processes don’t use entire address space even on 32 bit architecture, it will not always use all 4GBBut Page Table assumes an entry per VPN regardless, of whether corresponding virtual memory is needed or not.Hierarchical Page TablesOn malloc, a new internal page table may be allocated.Address split: Page Number offset P1 P2 d 12 10 10 inner table addresses =&gt; 2^10 * page_size = 2^10*2^10 = 1MB don’t need an inner table for each 1MB virtual memory gapAdditional Layers page table directory pointer (3rd level) page table directory map (4th level) Important on 64 bit architectures larger and more sparse =&gt; larger gaps would save more internal page table componentsTradeoffs of Multilevel Page TablesAdvantages Smaller internal page tables/directories Granularity of coverage Potentially reduced page table size Disadvantages More memory accesses required for translation increased translation latencyOverheads of Address TranslationFor each memory reference : Single level page table Four level page table x1 access to PTE x4 accesses to PTE x1 access to mem x1 access to mem which results in slowdown.Page Table CacheTranslation Lookaside Buffer MMU level address translation cache On TLB miss =&gt; page table access from memory has protection/validity bits small number of cached address =&gt; high TLB hit rate temporal and spatial locality Example x86 Core i7 \t- per core : 64-entry data TLB 128-entry instruction TLB 512-entry shared second-level TLB Inverted Page TablesHashing Page TablesSegmentationSegmentation is the process of mapping virtual to physical memory using segments. Segments: arbitrary granularity (size) e.g. code, heap, data, stack.. address = segment - selector + offset Segment contiguous physical memory segment size = segment base + limit registers Segmentation + PagingPage Size 10 bit offset =&gt; 1 KB page size [2^10] 12 bit offset =&gt; 4 KB page size [2^12]In real world examples, Linux/x86 : 4 KB, 2MB, 1GB Solaris/Sparse: 8kB, 4MB, 2GB   Large Huge page size 2 MB 1 GB offset bits 21 bits 30 bits reduction factor on page table size x512 x1024 Advantages larger pages fewer page table entries, smaller page tables, more TLB hits Disadvantages internal fragmentation =&gt; wastes memoryMemory Allocation Memory allocator determines VA to PA mapping address translation, page tables \t=&gt; simply determine PA from VA and check validity/permsissions Kernel Level Allocators kernel state, static process state User Level Allocators dynamic process state (heap), malloc/free e.g. d/malloc, jemalloc, Hoard, tcmalloc Demand Paging Virtual Memory » Physical Memory virtual memory page is not always in physical memory physical page frame saved and restored to/from secondary storage Demand paging: pages swapped in/out of memory &amp; a swap partition (e.g. on a disk) Original PA != PA after swapping if page is “pinned”, swapping is disabled When pages should be swapped? page(out) daemon when memory usage is above threshold when CPU usage is below thresholdWhich page should be swapped out? pages that won’t be used history based prediction Least Recently Used (LRU policy). Access bit tracks if page is referenced. page that don’t need to be written out Dirty bit to track if modified avoid non-swappable pagesCheckpointing Failure and Recovery management technique periodically save process state failure may be unavoidable but can restart from checkpoint, so recovery would be faster Simple Approach pause and saveBetter Approach write-protect and copy everything at once copy diffs of dirties pages for incremental checkpoints rebuild from multiple diffs, or in background Checkpointing can also be used in other services: Debugging Rewind-Replay rewind = restart from checkpoint gradually go back to earlier checkpoints until error is found Migration continue on another machine disaster recovery consolidation repeated checkpoints in a fast loop until pause and copy becomes acceptable (or unavoidable) Inter Process Communication Processes share memory data in shared messages Processes exchange messages message passing via sockets Requires synchronization mutex, waiting Inter Process Communication(IPC) is an OS supported mechanism for interaction among processes (coordination and communication) Message Passing e.g. sockets, pips, msgs, queues Memory based IPC shared memory, memory mapped files Higher level semantics files, RPC Synchronization primitivesMessage Passing Send/Receive messages OS creates and maintains a channel buffer, FIFO queue OS provides interfaces to processes a port processes send/write messages to this port processes receive/read messages from this port Kernel required to establish communication perform each IPC operation send: system call + data copy receive: system call + data copy Request-response: 4x user/ kernel crossings + 4x data copiesAdvantages simplicity : kernel does channel management and synchronizationDisadvantages OverheadsForms of Message Passing IPC1. Pipes Carry byte stream between 2 process e.g connect output from 1 process to input of another2. Message queues Carry “messages” among processes OS management includes priorities, scheduling of message delivery APIs : Sys-V and POSIX3. Sockets send() and recv() : pass message buffers socket() : create kernel level socket buffer associated neccessary kernel processing (TCP-IP,..) If different machines, channel between processes and network devices If same machine, bypass full protocol stackShared Memory IPC read and write to shared memory region OS establishes shared channel between the processes physical pages mapped into virtual address space VA(P1) and VA(P2) map to same physical address VA(P1) != VA(P2) physical mempry doesn’t need to be contiguous APIs : SysV, POSIX, memory mapped files, Android ashmemAdvantages System calls only for setup data copies potentially reduced (but not eliminated)Disdvantages explicit synchronization communication protocol, shared buffer management programmer’s responsibility Which is better?Overheads for Message Passing : must perform multiple copies Shared Memory : must establish all mappings among processes’ address space and shared memory pagesThus, it depends.Copy vs MapGoal for both is to transfer data from one into target saddress space Copy (Message Passing) Map (Shared Memory) CPU cycles to copy data to/from port CPU cycles to map memory into address space   CPU to copy data to channel   If channel setup once, use many times (good payoff)   Can perform well for 1 time use Large Data: t(Copy) » t(Map) e.g. tradeoff exercised in Window “Local” Procedure Calls (LPC) Shared Memory and SynchronizationUse threads accessing shared state in a single addressing space, but for processSynchronization method: mechanism supported by processing threading library (pthreads) OS supported IPC for syncEither method must coordinate no of concurrent access to shared segment when data is available and ready for consumptionIPC Synchronization Message Queues Semaphores Implement “mutual exclusion” via send/receive OS supported synchronization construct   binary construct (either allow process or not)   Like mutex, if value = 0, stop; if value = 1, decrement(lock) and proceed SynchronizationWaiting for other processes, so that they can continue working together may repeatedly check to continue sync using spinlocks may wait for a signal to continue sync using mutexes and condition vatiables waiting hurts performance CPUs wste cycles for checking; cache effects Limitation of mutextes and condition variables Error prone/correctness/ease of use unlock wrong mutex, signal wrong condition variable Lack of expressive power helper variables for access or priority control Low-level support: hardware atmoic instructionsSynchronization constructs Spinlocks (basic sync construct) Spinlock is like a mutex \t- mutual exclusion lock and unlock(free) but, lock == busy =&gt; spinning Semaphores common sync construct in OS kernels like a traffic light: Stop and Go like mutex, but more general Semaphore == integer value on init assigned a max value (positive int) =&gt; max count on try(wait) if non-zero, decrement and proceed =&gt; counting semaphore if initialized with 1 semaphore == mutex(binary semaphore) on exit(post) increment Syncing different types of accessesReader/Writer locksread (don't modify)write (always modify)shared accessexclusive access RW locks specify type of access, then lock behaves accordingly Monitors (highlevel construct) shared resource entry resource possible condition variables On entry: lock, check On exit: unlock, check, signal More synchroniaztion constructs serializers path expressions barriers rendezvous points optimistic wait-free sync (RCU) [Read Copy Update]All need hardware support.Need for hardware support Problem concurrent check/update on different CPUs can overlap Atomic instructionsCritical section with hardware supported synchronizationHardware specific test-and-set returns(tests) original values and sets new-value!= 1 (busy) automatically first thread: test-and-set(lock) =&gt; 0 : free next ones: test-and-set(lock) =&gt; 1 busy \t- reset lock to 1, but that’s okay + : Latency + : minimal (Atomic) + : Delay potentially min - : Contention processors go to memory on each spin - To reduce contention, introduce delay \t - Static(based on a fixed value) or Dynamic(backoff based, random delay) read-and-increment compare-and-swapGuarantees atomicity mutual exclusion queue all concurrent instructions but oneShared Memory MultiprocessorsAlso called symmetric multiprocessors (SMP) Caches hide memory latency, “memory” further away due to contention no-write, write-through, write-back Cache Coherence# I/O ManagementOperating system Has protocols Interfaces for device I/O Has dedicated handlers Device drivers, interrupt handlers Decouple I/O details from core processing abstract I/O device detail from applications I/O Device Features Control registers (accessed by CPU) Command Data Transfers Status Microcontroller : device’s CPU On device memory Other logic e.g. analog to digital Device drivers per each device type responsible for device access management and control provided by device manufacturers per OS /version each OS standardizes interfaces device independence device diversity Types of devices Block e.g. disk read/write blocks of data direct access to arbitrary block Character e.g. keyboard get/put character Network devicesOS representation of a device : special device fileUNIX like systems: /dev tmpfs devfsLinux supports a number of pseudo “virtual” devices that provide special functionality to a system.CPU device interactionsaccess device registers : memory load/store Memory mapped I/0 part of ‘host’ physical memory dedicated for device interactions Base Address Registers (BAR) I/O Port dedicated in low instructions for device access target device (I/0 port) and value in register Path from Device to CPU Interrupt Overhead: Interrupt handling steps +: Can be generated as soon as possible Polling Overhead: Delay or CPU overhead when convenient for OS Device access : Programmed I/O (PIO) No additional hardware support CPU “programs” the device via command registers data movement E.g. NIC(Network Interface Card) data = network packet Write command to request packet information Copy packet to data registers Repeat until packet sentE.g. 1500B packet; 8 byte registers or bus =&gt; 1(for bus command) + 188(for data) = 189 CPU store instructionsDirect Memory Access (DMA) Relies on DMA controller CPU “programs” the device via command registers via DMA controls E.g. NIC (data = network packet) Write command to request packet information Configure DMA controller with in memory address and size of packet bufferE.g. 1500B packet; 8 byte registers or bus =&gt; 1(for bus command) + 1(for DMA configuration) = total 2 CPU store instructions. Less steps, but DMA configuration is more complex.For DMAs data buffer must be in physical memory until transfer completes pinning regions (non-swappable)Typical Device Access System call In-kernel stack Driver Invocation Device request configuration Device performs requestOS bypass device registers/data directly available OS configures then gets out of the way “user level driver” in library OS retains coarse-grain control relies on device features sufficient registers demux capability What happens to a calling thread? Synchronous I/O operations process blocks Asynchronous I/O operations process continues Later, process checks and retrieves result OR process is notified that operation is completed and results are ready Block Device StackBlock device typical storage for files: processes use files =&gt; logical storage unit kernel file system (KFS) where how to find and access file OS specifies interface generic block layer OS standardized block interface Device driverVirtual File SystemVirtual File System Abstractions File : Elements on which the VFS operates File Descriptor : OS representation of file open, read, write, send file , lock, close inode : Persistent representation of file “index” list of all data blocks device, permissions, size dentry : Directory entry, corresponding to the single path component, dentry cache super block : file system specific information regarding the File System layoutVFS on disk File : data blocks on disk inode : track file blocks also resides on disk in some block super block : overall map of disk blocks inode blocks data blocks free blocks InodesIndex of all disk blocks corresponding to a file File : identified by inode inode : list of all blocks + other metadata+: Easy to perform sequential or random access-: Limit on file sizeInodes with indirect pointers Index of all disk blocks corresponding to a file Index contain: metadata pointers to blocks Direct pointer : Points to data block 1 KB per entry Indirect pointer : Points to block of pointers 256 KB per entry Double Indirect pointer : Points to block of block of pointers 64 MB per entry +: Small inode =&gt; large file size-: File access slowdownDisk access optimizationsReducing file access overheads Caching/buffering : reducenumber of disk accesses buffer cache in main menu read/write from cache periodically flush to disk - fsync() I/O scheduling : reduce disk head movement maximize sequential vs random access Prefetching : increases cache hits leverages locality Journaling/logging: reduce random access (ext3, ext4) “describe” write in log : block, offset, value.. periodically apply updates to proper disk locations # VirtualizationVirtualization allows concurrent execution of multiple OSs and their applications on the same physical machine. Virtual resources : each OS thinks that ot “owns” hardware resources Virtual machine (VM) : OS + applications + virtual resources (guest domain) Virtualization layer : management of physical hardware (virtual machine monitor, hypervisor)Defining Virtual MachineA Virtual Machine is an efficient, isolated duplicate of the real machine. Supported by a Virtual Machine Monitor (VMM): provides environment essentially identical with the original machine programs show only minor decrease in speed at worst VMM is in complete control of the system resources VMM goals Fidelity Performance Safety and IsolationVirtualization advantages consolidation decrease cost, improve manageability migration availibility, reliability security, debugging, support for legacy OSTwo main Virtualization Models:1. Bare-metal or Hypervisor based (Type 1) VMM (hypervisor) manages all hardware resources abd supports execution of VMs privileged, secure VM to deal with devices (and other configuration and management tasks) Adopted by Xen(Opensource or Citriol Xen Server) and ESX (VMware)1. Hosted (Type 2) Host owns all hardware Special VMM modle provides hardware interfaces to VMs and deals with VM context switchingVirtualization requirements Present virtual platform interface to VMs virtualize CPU, memory, devices Provide isolation across VMs preemption, MMU for address translation and validation Protect guest OS from applications can’t run guest OS and applications at same protection level Protect VMs from guest OS can’t run guest OS and VMMs at same protection level Hardware protection levelsCommodity hardware has more than two protection levels x86 has 4 protection levels (rings) ring 3 : lowest privilege (applications) ring 1 : OS ring 0 : highest privilege (hypervisor) and 2 protection modes non root : VMs \t- ring 3 : apps ring 0 : OS root : \t- ring 0 : hypervisor Process Virtualization (Trap-and-Emulate) Guest instruments executed directly by hardware for non-privileged operations : hardware speeds =&gt; efficiency for privileged operations : trap to hypervisor Hypervisor determines what needs to be done: if illegal operation : terminate VM if legal operation : emulate the behaviour the guest OS was expecting from the hardware Problems with Trap-and-Emulate 17 privileged information do not trao but fail silently Hypervisor doesn’t know, so it doesn’t try to change settings OS doesn’t know, so assumes change was successfulBinary TranslationGoal : Full Virtualization i.e. guest OS is not modifiedApproach : Dynamic Binary Translation Inspect code blocks to be executed If needed, translate to alternate instruction sequence e.g. to emulate desired behaviour, possibly avoid traps Otherwise run at hardware speeds cache translated blocks to ammortize translation costs ParavirtualizationGoal : Performance; give up on modified guest OSsApproach : Paravirtualization : modify guest OSs so that it knows it is running virtualized it makes explicit calls to hyperisor (hypercalls) hypercalls (~ system calls) package context information specify desired hypercall trap to VMM Xen : opensource hypervisorMemory virtualization Full virtualization all guests expect contiguous physical memory starting at 0 virtual vs physical vs machine addresses and page frame numbers still leverages hardware (MMU, TLB..) Option 1 guest page table : VA =&gt; PA hypervisor : PA =&gt; MA too expensive! Option 2 guest page tables : VA =&gt; PA hypervisor shadow PT : VA =&gt; MA hypervisor maintains consistence \t- e.g. invalidate on context switch, write protect guest PT to track new mappings Paravirtualized guest aware of virtualization no longer strict requirement on contiguous physical memory starting at 0 explicitly registers page tables with hypervisor can “batch” page tables updates to reduce VM exits other optimazations Overheads eliminated or reduced on newer platformsDevice Virtualization For CPUs and Memory less diversity, Intruction-Set-Architecture(ISA) level Standardization of interface For Devices high diversity lack of standard specification of device interface and behaviour 3 key models for Device Virtualization:1. Pass through modelApproach: VMM-level-driver configures device access permissionsAdvantages VM provided with exclusive and direct (VMM bypass) access to the deviceDisadvantages Device sharing difficult VMM must have exact type of device as what VM expects VM migration tricky2. Hypervisor - Direct modelApproach: VMM interrupts all device accesses Emulate device operations translate to generic I/O operations traverse VMM-resident I/O stack invoke VMM-resident driver Advantages VM decoupled from physical device Sharing, migration, dealing with device specificsDisadvantages Latency of device operations Device driver ecosystem complexities in Hypervisor3. Split Device-Driver modelApproach: Device access control split between Emulate device operations front-end driver in guest VM (device API) back-end driver in service VM (or Host) modified guest drivers \t- i.e. limited to paravirtualized guests Advantages Eliminate emulation overhead Allow for better management of shared devicesRemote Procedure CallsExample : GetFile App Client Server Create and init sockets Allocate and populate buffers Include ‘protocol’ info GetFile, size Copy data into buffers filename, file common steps related to remote IPCRemote Procedure Calls (RPC) Intended to simplify the development of cross address space and cross machine interactions+ Higher-level interface for data movement and communication+ Error handling+ Hiding complexities of cross machine interactionsRPC requirements Client/Server interactions Procedure Call Interface =&gt; RPC sync call semantics Type checking error handling packet bytes interpretation Cross machine conversion e.g. big/little endian Higher level protocol access control, fault tolerance, different transport protocols Structure of RPCRPC Steps:(-1.) register : server registers procedure, arg types, location(0.) bind : client finds and binds to desired server call : client make RPC call; control passed to stub, client code blocks marshal : client stub “marshals” args (serialize args into buffer) send : client sends message to server receive : server receives message; passes message to server stub; access control unmarshal : server stub “unmarshals” args (extract args from buffer) actual call : server stub calls local procedure implementation result : server performs operation and computes result of RPC operation(same on return &lt;=)Interface definition Language (IDL) Used to describe the interface the server expects procedure name, args, 2 result types version number RPC can use IDL that is Language agnostic XDR in SunRPC Language specific Java in JavaRMI MarshallingUnmarshallingMarshalling/Unmarshalling routines are provided by RPC system compiler.Binding and Registry Client determines which server to connect to? \t- service name. version number how to connect to that server? \t- IP address, network protocol Registry : database of available services search for service name to find server(which) and contact details(how) distributed \t- any RPC service can register machine-specific \t- for services running on same machine clients must know machine addresses registry provides port number needed for connection Who can provide a service? lookup registry for image processing What services do they provide? compress/filter.. version number =&gt; IDL How will they ship package? TCP / UDP -&gt; registry Pointers Procedure interface : foo(int,int) in Local Calls : foo(x,y) =&gt; okay in Remote Calls : foo(x,y) =&gt; ?here, y points to location in caller address space Solutions: No pointers Serialize pointers; copy referenced (“points to”) data structure to send buffer Handling Partial Failures Special RPC error notification (signal, exception..) Catch all possible ways in which RPC can (partially) fail RPC Design choice Binding =&gt; How to find the server IDL =&gt; How to talk to server; how to package data Pointers as args =&gt; Disallow or serialize pointer data Partial failures =&gt; Special error notificationsDistributed File Systems Accessed via well defined interface access via Virtual File Systems Focus on consistent state tracking state, file update, cache coherence Mixed distribution models possible replicates vs partitioned, peer-like systems DFS models Client Server on different machines File server distributed on multiple machines replicated (each server : all files) partitioned (each server : parts of files) both (files partitioned, each partition replicates) Files stored on and served from all machines (peers) blurred distinction between clients and servers Remote File Service : Extremes Extreme1 : Upload/Download like FTP, SVN + local read/writes at client - entire file download/upload evn for small accesses - server gives up contro; Extreme2 : True Remote File Access Every access to remote file, nothing done locally + file access centralized, easy to reason about consistency - every file operation pays network cost, limits server scalablity Remote File Service : A compromiseA more practical Remote File access (with Caching) Allow clients to store parts of files locally (blocks) + low latency on file operations + server load reduces =&gt; more scalable Force clients to interact with server (frequently) + server has insights into what clients are doing + server has control into which accesses can be permitted =&gt; easier to maintain consistency - server more complex, requires different file sharing semantics Stateless vs Stateful File server Stateless Stateful Keeps no state; Okay with extreme models, but can’t support ‘practical’ model Keeps client state needed for ‘practical’ model to track what is cached/accessed - Can’t support caching and consistency management + Can support locking, caching, incremental operations - Every request self-contained. =&gt; more bits transferred - Overheads to maintain state and consistency. Depends on caching mechanism and consistency protocol. + No resources are used on server side (CPU, MM). On failure just restart - On failure, need checkpoining and recovery mechanisms Caching state in a DFS Locally clients maintain portion of state (e.g. file blocks) Locally clients perform operations on cached state (e.g. open/read/write) requires coherent mechanisms System How When SMP Write-update/Write-invalidate On write DFS Client/Server-driven On demand, periodically, on open.. Files or File blocks can be (with 1 server and multiple clients) cached in: in client memory on client storage device (HDD/SDD) in buffer cache in memory on server \t- (usefulness will depend on client load, request interleaving) File Sharing Semantics in DFS Session semantics (between open-close =&gt; Session) write-back on close(), update on open() easy to reason, but may be insufficient Periodic updates client writes-back periodically \t- clients have a “lease” on cached data (not exclusively necessary) servers invalidates periodically =&gt; provides biunds on “inconsistency” augment with flush()/sync() API Immutable files =&gt; never modify, new files created Transactions =&gt; all changes atomicReplication vs PartitioningReplicationPartitioningEach machine holds all filesEach machine has subset of filesAdvantagesLoad balancing, availibility, fault tolerance Availibility vs single server DFS;Scalability with file system size;single file writes simplerDisadvantagesWrite becomes more complex- Synchronous to all- or, write to one, then propagate to othersreplicas must be reconciled e.g. VotingOn failure, lose portion of dataload balancing harder, if not balanced, then hot-spots possible Can combine both techniques Replicate each partition! Distributed Shared Memory Must decide placement place memory (pages) close to relevant processes Must decide migration when to copy memory (pages) from remote to local Must decide sharing rules ensure memory generations are properly ordered “Peer” Distribution Applications Each node “owns” state provide service all nodes are “peers”.Examples: Big-data analytics, web searches, context sharing or distributed shared memory (DSM)Distributed Shared Memory (DSM)DSM is a service that manages memory accross multiple nodes so that applications that are running on top will have an illusion that they are running on a shared memory. Each node “owns” state =&gt; memory provide service \t- memory read/writes from any nodes consistency protocols permits scaling beyond single machine memory limits \t- more “shared” memory at lower cost slower overall memory access commodity interconnect technologies support this RDMA(Remote Direct Memory Access) Hardware vs Software DSM Hardware-supported (expensive!) relies on interconnect OS manages larger physical memory NIC(Network Interface Cards) translate remote memory accesses to messages NICs involved in all aspects of memory management; support atomics.. Software supported everything done by software OS,or language runtime Hybrid (Software tasks in Hardware) DSM implementations prefetch pages address translation (easier done in hardware) triggering invalidations (easier done in hardware) DSM Design : Sharing Granularity cache line granularity? overheads too high for DSM variable granularity [N] page granularity [Y] (OS level) object granularity [Y] (Language runtime) beware of false sharing E.g. x and y shared on same page What types of applications use DSM?Application access algorithm Single reader/ single writer (SRSW) Multiple readers/ single writer (MRSW) Multiple reader/ Multiple writers (MRMW)Performance considerations DSM performance metric == access latency Achieving low latency through Migration \t- makes sense for SRSW requires data movement Replication (caching) \t- more general requires consistency management Hence, migration is okay for SRSW but not for all. Caching and Replication Copies of data to incerease data access for many concurrent writes, overheads too high but stil generally better than Migration Consistency Management In SMP write invalidate write update coherence operations triggered in each write overhead too high Push invalidations when data is written to Proactive Eager Pessimistic Pull modifications information periodically on demand (reactive) lazy optimistic when these methods get triggered depends on the consistency model for the shared stateDSM architecture (page-based, OS-supported) Page-based DSM architecture distributed nodes, each with own local memory contribution pool of pages from all nodes each page has IO (“home” node), page frame number if MRMW need local caches for performances (latency) “home” or “manager” node drives coherence operations all nodes responsible for part if distributed memory (state) management Home node keeps state: page accessed, modifications, caching enabled/disabled, locked.. Current owner owner may not be equal to home node Explicit replicas for load balancing, performance, or reliability \thome, manager node controls memory DSM metadataImplementing DSMs Problem : DSM must intercept access to DSM state to send remote messages requesting access to trigger coherence messages overheads should be avoided for local non-shared state (pages) dynamically engage and disengage DSM when necessary Solution : Use hardware MMU support! trap in OS if mapping invalid or access denied remote address mapping -&gt; trap and pass to DSM to send message cached content -&gt; trap and pass to DSM to perform memory coherence operations other MMU information useful (e.g. Dirty page) Consistency model Agreement between memory (state) and upper software layers Memory behaves correctly if and only if software follows specific rules Memory (state) guarantees to behave correctly access ordering propagation/ visibility of updates Our notation R_m1(X) =&gt; X was read from memory location m1 W_m1(Y) =&gt; Y was written to memory location m1Strict ConsistencyStrict Consistency =&gt; updates visible everywhere immediately In practice Even on single SMP no guarantees on order without extra locking and synchronization in DS, latency and message reorder make this even harder Hence almost impossible to guarantee strict consistency Sequential ConsistencySequential consistency =&gt; memory updates from different processors may be arbitrarily interleaved All processes will see the same interleaving Operations from the same process always appearin order they were issuedCausal Consistency For writes not causally related, “concurrent” writes doesnt gurantee. Don’t permit arbitrary ordering from same process writerWeak Consistency Use of synchronization Synchronization point =&gt; operations that are available (R,W,Sync) all updates prior to a sync point will be visible no guarantee what happens in between + limit data movement of coherence operations- maintain extra state for additional operations Variations: Single sync operation (sync) Seperate sync per surface of state (page) Seperate “entry/acquire” vs “exit/release” operations " }, { "title": "SQL Joins - Inner, Left, Right and Full Joins", "url": "/posts/sql-joins-inner-left-right-and-full-joins/", "categories": "Blog", "tags": "computer-science, sql", "date": "2023-03-25 00:00:00 +0530", "snippet": "SQL Join statement is used to combine data or rows from two or more tables based on a common field between them. Different types of Joins are as follows:  INNER JOIN LEFT JOIN RIGHT JOIN FULL JOIN", "content": "SQL Join statement is used to combine data or rows from two or more tables based on a common field between them. Different types of Joins are as follows:  INNER JOIN LEFT JOIN RIGHT JOIN FULL JOIN" }, { "title": "Python Cheat Sheet for Leetcode", "url": "/posts/python-cheat-sheet-for-leetcode/", "categories": "Blog", "tags": "blog, Python", "date": "2023-03-21 00:00:00 +0530", "snippet": "Basics Data Types Operators and it’s precendence Data StructuresImportant data structures for LeetcodeLists Lists are used to store multiple items in a single variable Op...", "content": "Basics Data Types Operators and it’s precendence Data StructuresImportant data structures for LeetcodeLists Lists are used to store multiple items in a single variable Operations Time Complexities nums = [1,2,3]nums.index(1) # returns indexnums.append(1) # appends 1nums.insert(0,10) # inserts 10 at 0th indexnums.remove(3) # removes all instances of 3nums.copy(1) # returns copy of the listnums.count(1) # returns no.of times '1' is present in the listnums.extend(someOtherList) # ...nums.pop() # pops last element [which element to pop can also be given as optional argument]nums.reverse() # reverses original list (nums in this case)nums.sort() # sorts list [does NOT return sorted list]#Python's default sort uses Tim Sort, which is a combination of both merge sort and insertion sort.It's pretty simple really:a[start:stop] # items start through stop-1a[start:] # items start through the rest of the arraya[:stop] # items from the beginning through stop-1a[:] # a copy of the whole arrayThere is also the step value, which can be used with any of the above:a[start:stop:step] # start through not past stop, by stepThe key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).The other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:a[-1] # last item in the arraya[-2:] # last two items in the arraya[:-2] # everything except the last two itemsSimilarly, step may be a negative number:a[::-1] # all items in the array, reverseda[1::-1] # the first two items, reverseda[:-3:-1] # the last two items, reverseda[-3::-1] # everything except the last two items, reversedPython is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.Relation to slice() objectThe slicing operator [] is actually being used in the above code with a slice() object using the : notation (which is only valid within []), i.e.:a[start:stop:step]is equivalent to:a[slice(start, stop, step)]Slice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported. To skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].While the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing.Dictionary Dictionaries are used to store data values in key:value pairs. Info about collections.Counter() available below. Operations Time Complexities dict = {'a':1,'b':2,'c':3}dict.keys() # returns list of keys of dictionarydict.values() # returns list of values of dictionarydict.get('a') # returns value for any corresponding keydict.items() # returns [('a',1),('b',2),('c',3)]dict.copy() # returns copy of the dictionary# NOTE : items() Returns view object that will be updated with any future changes to dictdict.pop(KEY) # pops key-value pair with that keydict.popitem() # removes most recent pair addeddict.setDefault(KEY,DEFAULT_VALUE) # returns value of key, if key exists, else default value returned# If the key exist, this parameter(DEFAULT_VALUE) has no effect.# If the key does not exist, DEFAULT_VALUE becomes the key's value. 2nd argument's default is None.dict.update({KEY:VALUE}) # inserts pair in dictionary if not present, if present, corresponding value is overriden (not key)# defaultdict ensures that if any element is accessed that is not present in the dictionary# it will be created and error will not be thrown (which happens in normal dictionary)# Also, the new element created will be of argument type, for example in the below line# an element of type 'list' will be made for a Key that does not existmyDictionary = defaultdict(list) Counter Python Counter is a container that will hold the count of each of the elements present in the container. The counter is a sub-class available inside the dictionary class. Specifically used for element frequenciesPretty similar to dictionary, infact I use defaultdict(int) most of the timefrom collections import Counter #(capital 'C')# can also be used as 'collections.Counter()' in codelist1 = ['x','y','z','x','x','x','y', 'z']# InitializationCounter(list1) # =&gt; Counter({'x': 4, 'y': 2, 'z': 2})Counter(\"Welcome to Guru99 Tutorials!\") # =&gt; Counter({'o': 3, ' ': 3, 'u': 3, 'e': 2.....})# UpdatingcounterObject = collections.Counter(list1)counterObject.keys() = [ 'x' , 'y' , 'z' ]most_common_element = counterObject.most_common(1) # [('x', 4)]counterObject.update(\"some string\") # =&gt; Counter({'o': 3, 'u': 3, 'e': 2, 's': 2})counterObject['s'] += 1 # Increase/Decrease frequency# Accessingfrequency_of_s = counterObject['s']# Deletingdel couterObject['s']Deque A double-ended queue, or deque, has the feature of adding and removing elements from either end. Operations Time Complexities from collections import dequequeue = deque(['name','age','DOB'])queue.append(\"append_from_right\") # Append from rightqueue.pop() # Pop from rightqueue.appendleft(\"fromLeft\") # Append from leftqueue.popleft() # Pop from leftqueue.index(element,begin_index,end_index) # Returns first index of element b/w the 2 indices.queue.insert(index,element)queue.remove() # removes first occurrancequeue.count() # obviousqueue.reverse() # reverses order of queue elementsHeapq As we know the Heap Data Structure is used to implement the Priority Queue ADT. In python we can directly access a Priority Queue implemented using a Heap by using the Heapq library/module. Operations Time Complexities import heapq # (minHeap by Default)nums = [5, 7, 9, 1, 3]heapq.heapify(nums) # converts list into heap. Can be converted back to list by list(nums).heapq.heappush(nums,element) # Push an element into the heapheapq.heappop(nums) # Pop an element from the heap#heappush(heap, ele) :- This function is used to insert the element mentioned in its arguments into heap. The order is adjusted, so as heap structure is maintained.#heappop(heap) :- This function is used to remove and return the smallest element from heap. The order is adjusted, so as heap structure is maintained.# Other Methods Available in the Library# Used to return the k largest elements from the iterable specified # The key is a function with that accepts single element from iterable,# and the returned value from that function is then used to rank that element in the heapheapq.nlargest(k, iterable, key = fun)heapq.nsmallest(k, iterable, key = fun)Sets A set is a collection which is unordered, immutable, unindexed, No Duplicates. Operations Time Complexities set = {1,2,3}set.add(item)set.remove(item)set.discard(item) | set.remove(item) # removes item | remove will throw error if item is not there, discard will notset.pop() # removes random item (since unordered)set.isdisjoint(anotherSet) # returns true if no common elementsset.issubset(anotherSet) # returns true if all elements from anotherSet is present in original setset.issuperset(anotherSet) # returns true if all elements from original set is present in anotherSetset.difference(anotherSet) # returns set containing items ONLY in first setset.difference_update(anotherSet) # removes common elements from first set [no new set is created or returned]set.intersection(anotherSet) # returns new set with common elementsset.intersection_update(anotherSet) # modifies first set keeping only common elementsset.symmetric_difference(anotherSet) # returns set containing all non-common elements of both setsset.symmetric_difference_update(anotherSet) # same as symmetric_difference but changes are made on original setset.union(anotherSet) # ...set.update(anotherSet) # adds anotherSet without duplicateTuples A tuple is a collection which is ordered, unchangeable and can contain duplicate values Operations Time Complexities Similar to list tuple = (1,2,3,1)tuple.count(1) # returns occurence of an itemtuple.index(1) # returns index of 1 in arrayStrings# ** split Function **#The split() method breaks up a string at the specified separator and returns a list of strings.text = 'Python is a fun programming language'# split the text from spaceprint(text.split(' '))#convert string to lists=\"abcd\"s=list(s)# Output: ['Python', 'is', 'a', 'fun', 'programming', 'language']# ** count Function **#The count() method returns the number of occurrences of a substring in the given string.#Examplemessage = 'python is popular programming language'# number of occurrence of 'p'print('Number of occurrence of p:', message.count('p')) # Output: Number of occurrence of p: 4#The isnumeric() method returns True if all characters in a string are numeric characters. If not, it returns False.s = '1242323'print(s.isnumeric()) #Output: True#The find() method returns the index of first occurrence of the substring (if found). If not found, it returns -1.# check the index of 'fun'print(message.find('fun')) # Output: 12#The isalnum() method returns True if all characters in the string are alphanumeric (either alphabets or numbers). If not, it returns False.name = \"M3onica Gell22er \"print(name.isalnum()) # Output : False#The isalpha() method returns True if all characters in the string are alphabets. If not, it returns Falsename = \"Monica\"print(name.isalpha()) #output true#other imp functionsstring.strip([chars]) #The strip() method returns a copy of the string by removing both the leading and the trailing characters (based on the string argument passed).string.upper() #he upper() method converts all lowercase characters in a string into uppercase characters and returns it.string.lower() #The lower() method converts all uppercase characters in a string into lowercase characters and returns it.string.islower()string.isdigit()string.isupper()Built-in or Library functions Functions to iterate over list / other iterable (tuple, dictionaries) ** map(fun, iter) ** #fun : It is a function to which map passes each element of given iterable. #iter : It is a iterable which is to be mapped. ** zip(list,list) ** for elem1,elem2 in zip(firstList,secondList): \t# will merge both lists and produce tuples with both elements \t# Tuples will stop at shortest list (in case of both lists having different len) #Example ''' a = (\"John\", \"Charles\", \"Mike\") b = (\"Jenny\", \"Christy\", \"Monica\") x = zip(a, b) #use the tuple() function to display a readable version of the result: print(tuple(x)) o/p: (('John', 'Jenny'), ('Charles', 'Christy'), ('Mike', 'Monica')) ''' ** any(list) ** [ OPPOSITE IS =&gt; ** all() ** ] any(someList) # returns true if ANY element in list is true [any string, all numbers except 0 also count as true] ** enumerate(list|tuple) ** # [when you need to attach indexes to lists or tuples ] enumerate(anyList) # ['a','b','c'] =&gt; [(0, 'a'), (1, 'b'), (2, 'c')] ** filter(function|list) ** filter(myFunction,list) # returns list with elements that returned true when passed in function ***************** import bisect *********************** ** bisect.bisect(list,number,begin,end) ** O(log(n)) # [ returns the index where the element should be inserted #\t\tsuch that sorting order is maintained ] a = [1,2,4] bisect.bisect(a,3,0,4) # [1,2,4] =&gt; 2 coz '3' should be inserted in 2nd index to maintain sorting order # Other variants of this functions are =&gt; bisect.bisect_left() | bisect.bisect_right() # they have same arguments. Suppose the element we want to insert is already present # in the sorting list, the bisect_left() will return index left of the existing number # and the bisect_right() or bisect() will return index right to the existing number # ** bisect.insort(list,number,begin,end) ** O(n) to insert # ** bisect.insort_right(list,number,begin,end) ** # ** bisect.insort_left(list,number,begin,end) ** The above 3 functions are exact same of bisect.bisect(), the only difference is that they return the sorted list after inserting and not the index. The left() right() logic is also same as above. Getting ASCII value of a character ** ord(str) ** # returns ascii value of the character , Example ord(\"a\") = 97 ** chr(int) ** #return character of given ascii value , Example chr(97) = \"a\" Clean Code Tips Doc Strings - Documentation for your functions in the interview to look slic 😎 A docstring is short for documentation string. Python docstrings (documentation strings) are the string literals that appear right after the definition of a function, method, class, or module. Triple quotes are used while writing docstrings. For example: def double(num): \"\"\"Function to double the value\"\"\" return 2*num Docstrings appear right after the definition of a function, class, or a module. This separates docstrings from multiline comments using triple quotes. The docstrings are associated with the object as their __doc__ attribute. So, we can access the docstrings of the above function with the following lines of code: def double(num): \"\"\"Function to double the value\"\"\" return 2*num print(double.__doc__) Output Function to double the value Use Assert keyword in python for testing edge cases. Looks more professional. ### Definition and Usage The assert keyword is used when debugging code. The assert keyword lets you test if a condition in your code returns True, if not, the program will raise an AssertionError. You can write a message to be written if the code returns False, check the example below. x = \"hello\" #if condition returns False, AssertionError is raised: assert x == \"goodbye\", \"x should be 'hello'\" ALWAYS be aware of any code snippet that is being REPEATED in your solution. MODULARITY #1 Priority. Refactoring is also an important part of interview. This is usually asked as a follow up after coding the solution. Are there any changes you want to make to this solution? Miscellaneous How to take multiple line input in python? Using split() method Using List comprehension Syntax : input().split(separator, maxsplit) ## Example # Python program showing how to # multiple input using split # taking two inputs at a time x, y = input(\"Enter a two value: \").split() print(\"Number of boys: \", x) print(\"Number of girls: \", y) print() # taking three inputs at a time x, y, z = input(\"Enter a three value: \").split() print(\"Total number of students: \", x) print(\"Number of boys is : \", y) print(\"Number of girls is : \", z) print() # taking two inputs at a time a, b = input(\"Enter a two value: \").split() print(\"First number is {} and second number is {}\".format(a, b)) print() # taking multiple inputs at a time # and type casting using list() function x = list(map(int, input(\"Enter a multiple value: \").split())) print(\"List of students: \", x) # Python program showing # how to take multiple input # using List comprehension # taking two input at a time x, y = [int(x) for x in input(\"Enter two value: \").split()] print(\"First Number is: \", x) print(\"Second Number is: \", y) print() # taking three input at a time x, y, z = [int(x) for x in input(\"Enter three value: \").split()] print(\"First Number is: \", x) print(\"Second Number is: \", y) print(\"Third Number is: \", z) print() # taking two inputs at a time x, y = [int(x) for x in input(\"Enter two value: \").split()] print(\"First number is {} and second number is {}\".format(x, y)) print() # taking multiple inputs at a time x = [int(x) for x in input(\"Enter multiple value: \").split()] print(\"Number of list is: \", x) # taking multiple inputs at a time separated by comma x = [int(x) for x in input(\"Enter multiple value: \").split(\",\")] print(\"Number of list is: \", x) Syntax : math.log(a,Base) Parameters :a : The numeric value Base : Base to which the logarithm has to be computed. Return Value : Returns natural log if 1 argument is passed and log with specified base if 2 arguments are passed. Exceptions : Raises ValueError is a negative no. is passed as argument. import math # Printing the log base e of 14 print (\"Natural logarithm of 14 is : \", end=\"\") print (math.log(14)) # Printing the log base 5 of 14 print (\"Logarithm base 5 of 14 is : \", end=\"\") print (math.log(14,5)) Finding the ceiling and the floor value Ceil value means the smallest integral value greater than the number and the floor value means the greatest integral value smaller than the number. This can be easily calculated using the ceil() and floor() method respectively. # Python code to demonstrate the working of # ceil() and floor() # importing \"math\" for mathematical operations import math a = 2.3 # returning the ceil of 2.3 (i.e 3) print (\"The ceil of 2.3 is : \", end=\"\") print (math.ceil(a)) # returning the floor of 2.3 (i.e 2) print (\"The floor of 2.3 is : \", end=\"\") print (math.floor(a)) Other Important functions #Constants # Print the value of Euler e (2.718281828459045) print (math.e) # Print the value of pi (3.141592653589793) print (math.pi) print (math.gcd(b, a)) print (pow(3,4)) # print the square root of 4 print(math.sqrt(4)) a = math.pi/6 b = 30 # returning the converted value from radians to degrees print (\"The converted value from radians to degrees is : \", end=\"\") print (math.degrees(a)) # returning the converted value from degrees to radians print (\"The converted value from degrees to radians is : \", end=\"\") print (math.radians(b)) ** bin(int) ** bin(anyNumber) # Returns binary version of number ** divmod(int,int) ** divmod(dividend,divisor) # returns tuple like (quotient, remainder) ## How the custom comparator works When providing a custom comparator, it should generally return an integer/float value that follows the following pattern (as with most other programming languages and frameworks): return a negative value (&lt; 0) when the left item should be sorted before the right item return a positive value (&gt; 0) when the left item should be sorted after the right item return 0 when both the left and the right item have the same weight and should be ordered “equally” without precedence from functools import cmp_to_key sorted(mylist, key=cmp_to_key(compare)) #Example def compare(item1, item2): if fitness(item1) &lt; fitness(item2): return -1 elif fitness(item1) &gt; fitness(item2): return 1 else: return 0 Python integer division behaves differently with -ve numbers ex: -3//2 will give -2 answer instead of -1 so always use int(-3/2) for integer division in problemsResourcesThe Modulo Operation (%) With Negative Numbers in PythonCheat Sheet PDFClick Here" }, { "title": "LeetCode Greedy for Beginners", "url": "/posts/leetcode-greedy-for-beginners/", "categories": "Problem Solving, LeetCode", "tags": "LeetCode, Greedy", "date": "2023-03-21 00:00:00 +0530", "snippet": "Greedy for practice:Sharing good Greedy problems for practice:List: https://leetcode.com/list/xyehq5j6Sort/Arrayhttps://leetcode.com/problems/jump-game/https://leetcode.com/problems/jump-game-ii/ht...", "content": "Greedy for practice:Sharing good Greedy problems for practice:List: https://leetcode.com/list/xyehq5j6Sort/Arrayhttps://leetcode.com/problems/jump-game/https://leetcode.com/problems/jump-game-ii/https://leetcode.com/problems/gas-station/https://leetcode.com/problems/candy/https://leetcode.com/problems/remove-k-digits/https://leetcode.com/problems/wiggle-subsequence/https://leetcode.com/problems/assign-cookies/https://leetcode.com/problems/boats-to-save-people/https://leetcode.com/problems/bag-of-tokens/https://leetcode.com/problems/number-of-burgers-with-no-waste-of-ingredients/https://leetcode.com/problems/queue-reconstruction-by-height/https://leetcode.com/problems/play-with-chips/https://leetcode.com/problems/previous-permutation-with-one-swap/https://leetcode.com/problems/lemonade-change/https://leetcode.com/problems/bag-of-tokens/Hash/Multi-set:https://leetcode.com/problems/task-scheduler/https://leetcode.com/problems/partition-labels/https://leetcode.com/problems/car-pooling/https://leetcode.com/problems/divide-array-in-sets-of-k-consecutive-numbers/https://leetcode.com/problems/group-the-people-given-the-group-size-they-belong-to/https://leetcode.com/problems/cinema-seat-allocation/https://leetcode.com/problems/construct-k-palindrome-strings/https://leetcode.com/problems/advantage-shuffle/Strings:https://leetcode.com/problems/reorganize-string/https://leetcode.com/problems/string-without-aaa-or-bbb/https://leetcode.com/problems/check-if-a-string-can-break-another-string/https://leetcode.com/problems/remove-duplicate-letters/Heap:https://leetcode.com/problems/last-stone-weight/https://leetcode.com/problems/reduce-array-size-to-the-half/Stack:https://leetcode.com/problems/minimum-add-to-make-parentheses-valid/Sharing solutions for little tricky problems:https://leetcode.com/problems/divide-array-in-sets-of-k-consecutive-numbers/class Solution {public:\tbool isPossibleDivide(vector&lt;int&gt;&amp; nums, int k) {\t\tint n = nums.size();\t\tif (n % k != 0) return false;\t\tint ssize = n/k;\t\tmap&lt;int, int&gt;hm;\t\tfor (int i = 0; i &lt; n; i++)\t\t\thm[nums[i]]++;\t\tfor (auto it = hm.begin(); it != hm.end(); it++) {\t\t\tif (hm[it-&gt;first] &gt; 0) {\t\t\t\tfor (int i = k-1; i &gt;= 0; i--) {\t\t\t\t\thm[it-&gt;first+i] -= hm[it-&gt;first];\t\t\t\t\tif (hm[it-&gt;first+i] &lt; 0)\t\t\t\t\t\treturn false;\t\t\t\t}\t\t\t}\t\t}\t\treturn true;\t}};https://leetcode.com/problems/car-pooling/class Solution {public:\tbool carPooling(vector&lt;vector&lt;int&gt;&gt;&amp; trips, int capacity) {\t\tint trip_len = 1001;\t\tvector&lt;int&gt;stops(trip_len, 0);\t\tfor (int i = 0; i &lt; trips.size(); i++) {\t\t\tstops[trips[i][1]] += trips[i][0];\t\t\tstops[trips[i][2]] -= trips[i][0];\t\t}\t\tfor (int i = 0; i &lt; trip_len; i++) {\t\t\tif (i != 0) stops[i] += stops[i-1];\t\t\tif (stops[i] &gt; capacity)\t\t\t\treturn false;\t\t}\t\treturn true;\t}};https://leetcode.com/problems/reorganize-string/class Solution {\tstatic bool compare(pair&lt;char, int&gt;p1, pair&lt;char, int&gt;p2) {\t\treturn p1.second &gt; p2.second;\t}public:\tstring reorganizeString(string S) {\t\tint n = S.length();\t\tunordered_map&lt;char, int&gt;m;\t\tvector&lt;pair&lt;char, int&gt;&gt;v;\t\tfor (int i = 0; i &lt; n; i++) \t\t\tm[S[i]]++;\t\tfor(auto it = m.begin(); it != m.end(); it++) {\t\t\tif (it-&gt;second &gt; (n+1)/2)\t\t\t\treturn \"\";\t\t\tv.push_back(make_pair(it-&gt;first, it-&gt;second));\t\t}\t\tsort(v.begin(), v.end(), compare);\t\tstring str;\t\tfor (int i = 0; i &lt; v.size(); i++) {\t\t\twhile (v[i].second--)\t\t\t\tstr += v[i].first;\t\t}\t\tstring ans;\t\tint size = str.size();\t\tint i = 0, j = (size-1)/2+1;\t\twhile (i &lt; (size-1)/2+1) {\t\t\tans += str[i];\t\t\tans += str[j];\t\t\ti++; j++;\t\t}\t\treturn ans;\t}};https://leetcode.com/problems/candy/class Solution {public:\tint candy(vector&lt;int&gt;&amp; ratings) {\t\tint n = ratings.size();\t\tvector&lt;int&gt;left(n, 1); \t\tfor (int i = 1; i &lt; n; i++) {\t\t\tif (ratings[i] &gt; ratings[i-1])\t\t\t\tleft[i] = left[i-1]+1;\t\t}\t\tint sum = left[n-1];\t\tfor (int i = n-2; i &gt;= 0; i--) {\t\t\tif (ratings[i] &gt; ratings[i+1])\t\t\t\tleft[i] = max(left[i], left[i+1]+1);\t\t\tsum += left[i];\t\t}\t\treturn sum;\t}};" }, { "title": "LeetCode all two pointers problems", "url": "/posts/leetcode-all-two-pointers-problems/", "categories": "Problem Solving, LeetCode", "tags": "LeetCode", "date": "2023-03-21 00:00:00 +0530", "snippet": "| 1. Running from both ends of an array || — |The first type of problems are, having two pointers at left and right end of array, then moving them to the center while processing something with them...", "content": "| 1. Running from both ends of an array || — |The first type of problems are, having two pointers at left and right end of array, then moving them to the center while processing something with them. 2 Sum problem (*) https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/ https://leetcode.com/problems/3sum/ https://leetcode.com/problems/4sum/ https://leetcode.com/problems/number-of-subsequences-that-satisfy-the-given-sum-condition/ https://leetcode.com/problems/two-sum-iv-input-is-a-bst/ https://leetcode.com/problems/sum-of-square-numbers/ https://leetcode.com/problems/boats-to-save-people/ https://leetcode.com/problems/minimize-maximum-pair-sum-in-array/ https://leetcode.com/problems/3sum-with-multiplicity/ Trapping Water (*) https://leetcode.com/problems/trapping-rain-water/ https://leetcode.com/problems/container-with-most-water/ Next Permutation (*) https://leetcode.com/problems/next-permutation/ https://leetcode.com/problems/next-greater-element-iii/ https://leetcode.com/problems/minimum-adjacent-swaps-to-reach-the-kth-smallest-number/ Reversing / Swapping https://leetcode.com/problems/valid-palindrome/ (*) https://leetcode.com/problems/reverse-string/ https://leetcode.com/problems/reverse-vowels-of-a-string/ https://leetcode.com/problems/valid-palindrome-ii/ https://leetcode.com/problems/reverse-only-letters/ https://leetcode.com/problems/remove-element/ https://leetcode.com/problems/sort-colors/ https://leetcode.com/problems/flipping-an-image/ https://leetcode.com/problems/squares-of-a-sorted-array/ https://leetcode.com/problems/sort-array-by-parity/ https://leetcode.com/problems/sort-array-by-parity-ii/ https://leetcode.com/problems/pancake-sorting/ https://leetcode.com/problems/reverse-prefix-of-word/ https://leetcode.com/problems/reverse-string-ii/ https://leetcode.com/problems/reverse-words-in-a-string/ https://leetcode.com/problems/reverse-words-in-a-string-iii/ Others https://leetcode.com/problems/bag-of-tokens/ https://leetcode.com/problems/di-string-match/ https://leetcode.com/problems/minimum-length-of-string-after-deleting-similar-ends/ https://leetcode.com/problems/sentence-similarity-iii/ https://leetcode.com/problems/find-k-closest-elements/ https://leetcode.com/problems/shortest-distance-to-a-character/ | 2.Slow &amp; Fast Pointers || — |Next type is using two pointers with different speed of movement. Typically they starts from the left end, then the first pointer advances fast and give some feedback to the slow pointer and do some calculation. Linked List Operations (*) https://leetcode.com/problems/linked-list-cycle/ https://leetcode.com/problems/linked-list-cycle-ii/ https://leetcode.com/problems/remove-nth-node-from-end-of-list/ https://leetcode.com/problems/rotate-list/ https://leetcode.com/problems/reorder-list/ https://leetcode.com/problems/palindrome-linked-list/ Cyclic Detection (*) https://leetcode.com/problems/find-the-duplicate-number/ https://leetcode.com/problems/circular-array-loop/ Sliding Window/Caterpillar Method (*) https://leetcode.com/problems/number-of-subarrays-with-bounded-maximum/ https://leetcode.com/problems/find-k-th-smallest-pair-distance/ https://leetcode.com/problems/moving-stones-until-consecutive-ii/ https://leetcode.com/problems/count-pairs-of-nodes/ https://leetcode.com/problems/count-binary-substrings/ https://leetcode.com/problems/k-diff-pairs-in-an-array/ Rotation (*) https://leetcode.com/problems/rotating-the-box/ https://leetcode.com/problems/rotate-array/ String (*) https://leetcode.com/problems/string-compression/ https://leetcode.com/problems/last-substring-in-lexicographical-order/ Remove Duplicate (*) https://leetcode.com/problems/remove-duplicates-from-sorted-array/ https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/ https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/ https://leetcode.com/problems/duplicate-zeros/ Others https://leetcode.com/problems/statistics-from-a-large-sample/ https://leetcode.com/problems/partition-labels/ https://leetcode.com/problems/magical-string/ https://leetcode.com/problems/friends-of-appropriate-ages/ https://leetcode.com/problems/longest-mountain-in-array/ https://leetcode.com/problems/shortest-subarray-to-be-removed-to-make-array-sorted/ | 3.Running from beginning of 2 arrays / Merging 2 arrays || — |In this category, you will be given 2 arrays or lists, then have to process them with individual pointers. Sorted arrays (*) https://leetcode.com/problems/merge-sorted-array/ https://leetcode.com/problems/heaters/ https://leetcode.com/problems/find-the-distance-value-between-two-arrays/ Intersections/LCA like (*) https://leetcode.com/problems/intersection-of-two-linked-lists/ https://leetcode.com/problems/intersection-of-two-arrays/ https://leetcode.com/problems/intersection-of-two-arrays-ii/ SubString (*) https://leetcode.com/problems/implement-strstr/ https://leetcode.com/problems/longest-word-in-dictionary-through-deleting/ https://leetcode.com/problems/long-pressed-name/ https://leetcode.com/problems/longest-uncommon-subsequence-ii/ https://leetcode.com/problems/compare-version-numbers/ https://leetcode.com/problems/camelcase-matching/ https://leetcode.com/problems/expressive-words/ Median Finder (*) https://leetcode.com/problems/find-median-from-data-stream/ Meet-in-the-middle / Binary Search (*) https://leetcode.com/problems/partition-array-into-two-arrays-to-minimize-sum-difference/ https://leetcode.com/problems/closest-subsequence-sum/ https://leetcode.com/problems/ways-to-split-array-into-three-subarrays/ https://leetcode.com/problems/3sum-closest/ https://leetcode.com/problems/valid-triangle-number/ Others https://leetcode.com/problems/shortest-unsorted-continuous-subarray/ https://leetcode.com/problems/most-profit-assigning-work/ https://leetcode.com/problems/largest-merge-of-two-strings/ https://leetcode.com/problems/swap-adjacent-in-lr-string/ | 4.Split &amp; Merge of an array / Divide &amp; Conquer || — |The last one is similiar to previous category but there is one thing is added. First, you need to split the given list into 2 separate lists and then do two pointers approach to merge or unify them. There aren’t many tasks here. Partition (*) https://leetcode.com/problems/partition-list/ Sorting (*) https://leetcode.com/problems/sort-list/ " }, { "title": "Graph For Beginners", "url": "/posts/graph-for-beginners/", "categories": "Computer Science", "tags": "computer-science, Graph", "date": "2023-03-21 00:00:00 +0530", "snippet": "Graph Problems For PracticeSharing some topic wise good Graph problems and sample solutions to observe on how to approach.List: https://leetcode.com/list/x1wy4de7 Union Find: Identify if pr...", "content": "Graph Problems For PracticeSharing some topic wise good Graph problems and sample solutions to observe on how to approach.List: https://leetcode.com/list/x1wy4de7 Union Find: Identify if problems talks about finding groups or components. https://leetcode.com/problems/friend-circles/ https://leetcode.com/problems/redundant-connection/ https://leetcode.com/problems/most-stones-removed-with-same-row-or-column/ https://leetcode.com/problems/number-of-operations-to-make-network-connected/ https://leetcode.com/problems/satisfiability-of-equality-equations/ https://leetcode.com/problems/accounts-merge/ All the above problems can be solved by Union Find algorithm with minor tweaks. Below is a standard template for union find problems. class Solution { \tvector&lt;int&gt;parent; \tint find(int x) { \t\treturn parent[x] == x ? x : find(parent[x]); \t} public: \tvector&lt;int&gt; findRedundantConnection(vector&lt;vector&lt;int&gt;&gt;&amp; edges) { \t\tint n = edges.size(); \t\tparent.resize(n+1, 0); \t\tfor (int i = 0; i &lt;= n; i++) \t\t\tparent[i] = i; \t\tvector&lt;int&gt;res(2, 0); \t\tfor (int i = 0; i &lt; n; i++) { \t\t\tint x = find(edges[i][0]); \t\t\tint y = find(edges[i][1]); \t\t\tif (x != y) \t\t\t\tparent[y] = x; \t\t\telse { \t\t\t\tres[0] = edges[i][0]; \t\t\t\tres[1] = edges[i][1]; \t\t\t} \t\t} \t\treturn res; \t} }; Depth First Search Start DFS from nodes at boundary: https://leetcode.com/problems/surrounded-regions/ https://leetcode.com/problems/number-of-enclaves/ class Solution { \tint rows, cols; \tvoid dfs(vector&lt;vector&lt;int&gt;&gt;&amp; A, int i, int j) { \t\tif (i &lt; 0 || j &lt; 0 || i &gt;= rows || j &gt;= cols) \t\t\treturn; \t\tif (A[i][j] != 1) \t\t\treturn; \t\tA[i][j] = -1; \t\tdfs(A, i+1, j); \t\tdfs(A, i-1, j); \t\tdfs(A, i, j+1); \t\tdfs(A, i, j-1); \t} public: \tint numEnclaves(vector&lt;vector&lt;int&gt;&gt;&amp; A) { \t\tif (A.empty()) return 0; \t\trows = A.size(); \t\tcols = A[0].size(); \t\tfor (int i = 0; i &lt; rows; i++) { \t\t\tfor (int j = 0; j &lt; cols; j++) { \t\t\t\tif (i == 0 || j == 0 || i == rows-1 || j == cols-1) \t\t\t\t\tdfs(A, i, j); \t\t\t} \t\t} \t\tint ans = 0; \t\tfor (int i = 0; i &lt; rows; i++) { \t\t\tfor (int j = 0; j &lt; cols; j++) { \t\t\t\tif (A[i][j] == 1) \t\t\t\t\tans++; \t\t\t} \t\t} \t\treturn ans; \t} }; Time taken to reach all nodes or share information to all graph nodes: https://leetcode.com/problems/time-needed-to-inform-all-employees/ class Solution { \tvoid dfs(unordered_map&lt;int, vector&lt;int&gt;&gt;&amp;hm, int i, vector&lt;int&gt;&amp; informTime, int &amp;res, int curr) { \t\tcurr += informTime[i]; \t\tres = max(res, curr); \t\tfor (auto it = hm[i].begin(); it != hm[i].end(); it++) \t\t\tdfs(hm, *it, informTime, res, curr); \t} public: \tint numOfMinutes(int n, int headID, vector&lt;int&gt;&amp; manager, vector&lt;int&gt;&amp; informTime) { \t\tunordered_map&lt;int, vector&lt;int&gt;&gt;hm; \t\tfor (int i = 0; i &lt; n; i++) \t\t\tif (manager[i] != -1) hm[manager[i]].push_back(i); \t\tint res = 0, curr = 0; \t\tdfs(hm, headID, informTime, res, curr); \t\treturn res; \t} }; DFS from each unvisited node/Island problems https://leetcode.com/problems/number-of-closed-islands/ https://leetcode.com/problems/number-of-islands/ https://leetcode.com/problems/keys-and-rooms/ https://leetcode.com/problems/max-area-of-island/ https://leetcode.com/problems/flood-fill/ class Solution { \tvoid dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, vector&lt;vector&lt;bool&gt;&gt;&amp; visited, int i, int j, int m, int n) { \t\tif (i &lt; 0 || i &gt;= m || j &lt; 0 || j &gt;= n) return; \t\tif (grid[i][j] == '0' || visited[i][j]) return; \t\tvisited[i][j] = true; \t\tdfs(grid, visited, i+1, j, m, n); \t\tdfs(grid, visited, i, j+1, m, n); \t\tdfs(grid, visited, i-1, j, m, n); \t\tdfs(grid, visited, i, j-1, m, n); \t} \tpublic: \tint numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) { \t\tif (grid.empty()) return 0; \t\tint m = grid.size(); \t\tint n = grid[0].size(); \t\tvector&lt;vector&lt;bool&gt;&gt;visited(m, vector&lt;bool&gt;(n, false)); \t\tint res = 0; \t\tfor (int i = 0; i &lt; m; i++) { \t\t\tfor (int j = 0; j &lt; n; j++) { \t\t\t\tif (grid[i][j] == '1' &amp;&amp; !visited[i][j]) { \t\t\t\t\tdfs(grid, visited, i, j, m, n); \t\t\t\t\tres++; \t\t\t\t} \t\t\t} \t\t} \t\treturn res; \t} \t}; Cycle Find: https://leetcode.com/problems/find-eventual-safe-states/ class Solution { \tbool dfs(vector&lt;vector&lt;int&gt;&gt;&amp; graph, int v, vector&lt;int&gt;&amp; dp) { \t\tif (dp[v]) \t\t\treturn dp[v] == 1; \t\tdp[v] = -1; \t\tfor (auto it = graph[v].begin(); it != graph[v].end(); it++) \t\t\tif (!dfs(graph, *it, dp)) \t\t\t\treturn false; \t\tdp[v] = 1; \t\treturn true; \t} public: \tvector&lt;int&gt; eventualSafeNodes(vector&lt;vector&lt;int&gt;&gt;&amp; graph) { \t\tint V = graph.size(); \t\tvector&lt;int&gt;res; \t\tvector&lt;int&gt;dp(V, 0); \t\tfor (int i = 0; i &lt; V; i++) { \t\t\tif (dfs(graph, i, dp)) \t\t\t\tres.push_back(i); \t\t} \t\treturn res; \t} }; Breadth First Search Shortest Path: https://leetcode.com/problems/01-matrix/ https://leetcode.com/problems/as-far-from-land-as-possible/ https://leetcode.com/problems/rotting-oranges/ https://leetcode.com/problems/shortest-path-in-binary-matrix/ Start BFS from nodes from which shortest path is asked for. Below is the sample BFS approach to find the path. class Solution { \tpublic: \tvector&lt;vector&lt;int&gt;&gt; updateMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) { \t\tif (matrix.empty()) return matrix; \t\tint rows = matrix.size(); \t\tint cols = matrix[0].size(); \t\tqueue&lt;pair&lt;int, int&gt;&gt;pq; \t\tfor (int i = 0; i &lt; rows; i++) { \t\t\tfor (int j = 0; j &lt; cols; j++) { \t\t\t\tif (matrix[i][j] == 0) { \t\t\t\t\tpq.push({i-1, j}), pq.push({i+1, j}), pq.push({i, j-1}), pq.push({i, j+1}); \t\t\t\t} \t\t\t} \t\t} \t\tvector&lt;vector&lt;bool&gt;&gt;visited(rows, vector&lt;bool&gt;(cols, false)); \t\tint steps = 0; \t\twhile (!pq.empty()) { \t\t\tsteps++; \t\t\tint size = pq.size(); \t\t\tfor (int i = 0; i &lt; size; i++) { \t\t\t\tauto front = pq.front(); \t\t\t\tint l = front.first; \t\t\t\tint r = front.second; \t\t\t\tpq.pop(); \t\t\t\tif (l &gt;= 0 &amp;&amp; r &gt;= 0 &amp;&amp; l &lt; rows &amp;&amp; r &lt; cols &amp;&amp; !visited[l][r] &amp;&amp; matrix[l][r] == 1) { \t\t\t\t\tvisited[l][r] = true; \t\t\t\t\tmatrix[l][r] = steps; \t\t\t\t\tpq.push({l-1, r}), pq.push({l+1, r}), pq.push({l, r-1}), pq.push({l, r+1}); \t\t\t\t} \t\t\t} \t\t} \t\treturn matrix; \t} }; Graph coloring/Bipartition https://leetcode.com/problems/possible-bipartition/ https://leetcode.com/problems/is-graph-bipartite/ Problems asks to check if its possible to divide the graph nodes into 2 groups Apply BFS for same. Below is a sample graph coloring approach. class Solution { \tpublic: \t\tbool isBipartite(vector&lt;vector&lt;int&gt;&gt;&amp; graph) { \t\t\tint n = graph.size(); \t\t\tvector&lt;int&gt;color(n, -1); \t\t\tfor (int i = 0; i &lt; n; i++) { \t\t\t\tif (color[i] != -1) continue; \t\t\t\tcolor[i] = 1; \t\t\t\tqueue&lt;int&gt;q; \t\t\t\tq.push(i); \t\t\t\twhile (!q.empty()) { \t\t\t\t\tint t = q.front(); \t\t\t\t\tq.pop(); \t\t\t\t\tfor (int j = 0; j &lt; graph[t].size(); j++) { \t\t\t\t\t\tif (color[graph[t][j]] == -1) { \t\t\t\t\t\t\tcolor[graph[t][j]] = 1-color[t]; \t\t\t\t\t\t\tq.push(graph[t][j]); \t\t\t\t\t\t} else if (color[graph[t][j]] == color[t]) { \t\t\t\t\t\t\treturn false; \t\t\t\t\t\t} \t\t\t\t\t} \t\t\t\t} \t\t\t} \t\t\treturn true; \t\t} \t}; Topological Sort: Check if its directed acyclic graph and we have to arrange the elements in an order in which we need to select the most independent node at first. Number of in-node 0 https://leetcode.com/problems/course-schedule/ https://leetcode.com/problems/course-schedule-ii/ Below is sample approach. Find if cycle is present, if not apply topological sort. class Solution { \tint V; \tlist&lt;int&gt;*adj; \t \tbool isCyclicUtil(int v, vector&lt;bool&gt;&amp;visited, vector&lt;bool&gt;&amp;recStack) { \t\t \t\tvisited[v] = true; \t\trecStack[v] = true; \t\t \t\tfor (auto it = adj[v].begin(); it != adj[v].end(); it++) { \t\t\tif (!visited[*it] &amp;&amp; isCyclicUtil(*it, visited, recStack)) \t\t\t\treturn true; \t\t\telse if (recStack[*it]) \t\t\t\treturn true; \t\t} \t\t \t\trecStack[v] = false; \t\treturn false; \t} \t \tbool isCyclic() { \t\tvector&lt;bool&gt;visited(V, false); \t\tvector&lt;bool&gt;recStack(V, false); \t\t \t\tfor (int i = 0; i &lt; V; i++) { \t\t\tif (isCyclicUtil(i, visited, recStack)) \t\t\t\treturn true; \t\t} \t\t \t\treturn false; \t} \t \tvoid topologicalSortUtil(int v, vector&lt;bool&gt;&amp;visited, vector&lt;int&gt;&amp; res) { \t\tvisited[v] = true; \t\t \t\tfor (auto it = adj[v].begin(); it != adj[v].end(); it++) \t\t\tif (!visited[*it]) \t\t\t\ttopologicalSortUtil(*it, visited, res); \t\t \t\tres.push_back(v); \t} \t \tvector&lt;int&gt;topologicalSort(int v) { \t\tvector&lt;int&gt;res; \t\t \t\tvector&lt;bool&gt;visited(V, false); \t\ttopologicalSortUtil(v, visited, res); \t\t \t\tfor (int i = 0; i &lt; V; i++) { \t\t\tif (!visited[i]) \t\t\t\ttopologicalSortUtil(i, visited, res); \t\t} \t\t \t\treturn res; \t} \t \tpublic: \tvector&lt;int&gt; findOrder(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) { \t\tV = numCourses; \t\tadj = new list&lt;int&gt;[V]; \t \t\tunordered_map&lt;int, vector&lt;int&gt;&gt;hm; \t\t \t\tfor (int i = 0; i &lt; prerequisites.size(); i++) { \t\t\tadj[prerequisites[i][0]].push_back(prerequisites[i][1]); \t\t\thm[prerequisites[i][1]].push_back(prerequisites[i][0]); \t\t} \t\t \t\tif (isCyclic()) return vector&lt;int&gt;(); \t\t \t\tint i = 0; \t\tfor (i = 0; i &lt; V; i++) { \t\t\tif (hm.find(i) == hm.end()) \t\t\t\tbreak; \t\t} \t\t \t\treturn topologicalSort(i); \t} }; Find Shortest Path (Dijkstra’s/Bellman Ford) https://leetcode.com/problems/network-delay-time/ Dijkstras and Bellman Ford: class Solution { \tpublic: \t\tint networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int N, int K) { \t\t\t \t\t\tpriority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt;pq; \t\t\tvector&lt;int&gt;dist(N+1, INT_MAX); \t\t\t \t\t\tpq.push(make_pair(0, K)); \t\t\tdist[K] = 0; \t\t\t \t\t\tunordered_map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt;hm; \t\t\tfor (int i = 0; i &lt; times.size(); i++) \t\t\t\thm[times[i][0]].push_back(make_pair(times[i][1], times[i][2])); \t\t\t \t\t\twhile (!pq.empty()) { \t\t\t\tpair&lt;int, int&gt;p = pq.top(); \t\t\t\tpq.pop(); \t\t\t\t \t\t\t\tint u = p.second; \t\t\t\tfor (auto it = hm[u].begin(); it != hm[u].end(); it++) { \t\t\t\t\tint v = it-&gt;first; \t\t\t\t\tint w = it-&gt;second; \t\t\t\t\t \t\t\t\t\tif (dist[v] &gt; dist[u] + w) { \t\t\t\t\t\tdist[v] = dist[u] + w; \t\t\t\t\t\tpq.push(make_pair(dist[v], v)); \t\t\t\t\t} \t\t\t\t} \t\t\t} \t\t\t \t\t\tint res = 0; \t\t\tfor (int i = 1; i &lt;= N; i++) \t\t\t\tres = max(res, dist[i]); \t\t\t \t\t\treturn res == INT_MAX ? -1 : res; \t\t} \t}; \t \tclass Solution { \tpublic: \t\tint networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int N, int K) { \t\t\t \t\t\tint n = times.size(); \t\t\tif (!n) return 0; \t\t\t \t\t\tvector&lt;int&gt;dist(N+1, INT_MAX); \t\t\tint res = 0; \t\t\t \t\t\tdist[K] = 0; \t\t\tfor (int i = 0; i &lt; N; i++) { \t\t\t\tfor (int j = 0; j &lt; n; j++) { \t\t\t\t\tint u = times[j][0]; \t\t\t\t\tint v = times[j][1]; \t\t\t\t\tint w = times[j][2]; \t\t\t\t\tif (dist[u] != INT_MAX &amp;&amp; dist[u] + w &lt; dist[v]) \t\t\t\t\t\tdist[v] = w + dist[u]; \t\t\t\t} \t\t\t} \t\t\t \t\t\tfor (int i = 1; i &lt;= N; i++) \t\t\t\tres = max(res, dist[i]); \t\t\treturn res == INT_MAX ? -1 : res; \t\t} \t} \t Complete List: Below are mostly list of problems (mostly medium level and may 1 or 2 easy) which are better to start practice with:(Updated on 14th June ‘20)Union Find: https://leetcode.com/problems/friend-circles/ https://leetcode.com/problems/redundant-connection/ https://leetcode.com/problems/most-stones-removed-with-same-row-or-column/ https://leetcode.com/problems/number-of-operations-to-make-network-connected/ https://leetcode.com/problems/satisfiability-of-equality-equations/ https://leetcode.com/problems/accounts-merge/ https://leetcode.com/problems/connecting-cities-with-minimum-cost/DFS:DFS from boundary: https://leetcode.com/problems/surrounded-regions/ https://leetcode.com/problems/number-of-enclaves/Shortest time: https://leetcode.com/problems/time-needed-to-inform-all-employees/Islands Variants https://leetcode.com/problems/number-of-closed-islands/ https://leetcode.com/problems/number-of-islands/ https://leetcode.com/problems/keys-and-rooms/ https://leetcode.com/problems/max-area-of-island/ https://leetcode.com/problems/flood-fill/ https://leetcode.com/problems/coloring-a-border/Hash/DFS: https://leetcode.com/problems/employee-importance/ https://leetcode.com/problems/find-the-town-judge/Cycle Find: https://leetcode.com/problems/find-eventual-safe-states/BFS:BFS for shortest path: https://leetcode.com/problems/01-matrix/ https://leetcode.com/problems/as-far-from-land-as-possible/ https://leetcode.com/problems/rotting-oranges/ https://leetcode.com/problems/shortest-path-in-binary-matrix/Graph coloring: https://leetcode.com/problems/possible-bipartition/ https://leetcode.com/problems/is-graph-bipartite/Topological Sort: https://leetcode.com/problems/course-schedule-ii/Shortest Path: https://leetcode.com/problems/network-delay-time/ https://leetcode.com/problems/find-the-city-with-the-smallest-number-of-neighbors-at-a-threshold-distance/ https://leetcode.com/problems/cheapest-flights-within-k-stops/" }, { "title": "Dynamic Programming Patterns", "url": "/posts/dynamic-programming-patterns/", "categories": "Computer Science", "tags": "Dynamic Programming, Patterns", "date": "2023-03-21 00:00:00 +0530", "snippet": "Before starting the topic let me introduce myself. I am a Mobile Developer currently working in Warsaw and spending my free time for interview preparations. I started to prepare for interviews two ...", "content": "Before starting the topic let me introduce myself. I am a Mobile Developer currently working in Warsaw and spending my free time for interview preparations. I started to prepare for interviews two years ago. At that time I should say I could not solve the two sum problem. Easy problems seemed to me like hard ones so most of the time I had to look at editorials and discuss section. Currently, I have solved ~800 problems and time to time participate in contests. I usually solve 3 problems in a contest and sometimes 4 problems. Ok, lets come back to the topic.Recently I have concentrated my attention on Dynamic Programming cause its one of the hardest topics in an interview prep. After solving ~140 problems in DP I have noticed that there are few patterns that can be found in different problems. So I did a research on that and find the following topics. I will not give complete ways how to solve problems but these patterns may be helpful in solving DP.PatternsMinimum (Maximum) Path to Reach a TargetDistinct WaysMerging IntervalsDP on StringsDecision MakingMinimum (Maximum) Path to Reach a TargetProblem list: https://leetcode.com/list/55ac4kucGenerate problem statement for this patternStatement Given a target find minimum (maximum) cost / path / sum to reach the target.Approach Choose minimum (maximum) path among all possible paths before the current state, then add value for the current state.routes[i] = min(routes[i-1], routes[i-2], ... , routes[i-k]) + cost[i]Generate optimal solutions for all values in the target and return the value for the target.Top-Downfor (int j = 0; j &lt; ways.size(); ++j) { result = min(result, topDown(target - ways[j]) + cost/ path / sum);}return memo[/*state parameters*/] = result;Bottom-Upfor (int i = 1; i &lt;= target; ++i) { for (int j = 0; j &lt; ways.size(); ++j) { if (ways[j] &lt;= i) { dp[i] = min(dp[i], dp[i - ways[j]] + cost / path / sum) ; } }} return dp[target]Similar Problems746. Min Cost Climbing Stairs EasyTop-Downint result = min(minCost(n-1, cost, memo), minCost(n-2, cost, memo)) + (n == cost.size() ? 0 : cost[n]);return memo[n] = result;Bottom-Upfor (int i = 2; i &lt;= n; ++i) { dp[i] = min(dp[i-1], dp[i-2]) + (i == n ? 0 : cost[i]);} return dp[n]64. Minimum Path Sum MediumTop-Downint result = min(pathSum(i+1, j, grid, memo), pathSum(i, j+1, grid, memo)) + grid[i][j]; return memo[i][j] = result;Bottom-Upfor (int i = 1; i &lt; n; ++i) { for (int j = 1; j &lt; m; ++j) { grid[i][j] = min(grid[i-1][j], grid[i][j-1]) + grid[i][j]; }} return grid[n-1][m-1]322. Coin Change MediumTop-Downfor (int i = 0; i &lt; coins.size(); ++i) { if (coins[i] &lt;= target) { // check validity of a sub-problem result = min(ans, CoinChange(target - coins[i], coins) + 1); }}return memo[target] = result;Bottom-Upfor (int j = 1; j &lt;= amount; ++j) { for (int i = 0; i &lt; coins.size(); ++i) { if (coins[i] &lt;= j) { dp[j] = min(dp[j], dp[j - coins[i]] + 1); } }}931. Minimum Falling Path Sum Medium983. Minimum Cost For Tickets Medium650. 2 Keys Keyboard Medium279. Perfect Squares Medium1049. Last Stone Weight II Medium120. Triangle Medium474. Ones and Zeroes Medium221. Maximal Square Medium322. Coin Change Medium1240. Tiling a Rectangle with the Fewest Squares Hard174. Dungeon Game Hard871. Minimum Number of Refueling Stops HardDistinct WaysProblem List: https://leetcode.com/list/55ajm50iGenerate problem statement for this patternStatement Given a target find a number of distinct ways to reach the target.Approach Sum all possible ways to reach the current state.routes[i] = routes[i-1] + routes[i-2], ... , + routes[i-k]Generate sum for all values in the target and return the value for the target.Top-Downfor (int j = 0; j &lt; ways.size(); ++j) { result += topDown(target - ways[j]);}return memo[/*state parameters*/] = result;Bottom-Upfor (int i = 1; i &lt;= target; ++i) { for (int j = 0; j &lt; ways.size(); ++j) { if (ways[j] &lt;= i) { dp[i] += dp[i - ways[j]]; } }} return dp[target]Similar Problems70. Climbing Stairs EasyTop-Downint result = climbStairs(n-1, memo) + climbStairs(n-2, memo); return memo[n] = result;Bottom-Upfor (int stair = 2; stair &lt;= n; ++stair) { for (int step = 1; step &lt;= 2; ++step) { dp[stair] += dp[stair-step]; }}62. Unique Paths MediumTop-Downint result = UniquePaths(x-1, y) + UniquePaths(x, y-1);return memo[x][y] = result;Bottom-Upfor (int i = 1; i &lt; m; ++i) { for (int j = 1; j &lt; n; ++j) { dp[i][j] = dp[i][j-1] + dp[i-1][j]; }}1155. Number of Dice Rolls With Target Sum Mediumfor (int rep = 1; rep &lt;= d; ++rep) { vector&lt;int&gt; new_ways(target+1); for (int already = 0; already &lt;= target; ++already) { for (int pipe = 1; pipe &lt;= f; ++pipe) { if (already - pipe &gt;= 0) { new_ways[already] += ways[already - pipe]; new_ways[already] %= mod; } } } ways = new_ways;}NoteSome questions point out the number of repetitions, in that case, add one more loop to simulate every repetition.688. Knight Probability in Chessboard Medium494. Target Sum Medium377. Combination Sum IV Medium935. Knight Dialer Medium1223. Dice Roll Simulation Medium416. Partition Equal Subset Sum Medium808. Soup Servings Medium790. Domino and Tromino Tiling Medium801. Minimum Swaps To Make Sequences Increasing673. Number of Longest Increasing Subsequence Medium63. Unique Paths II Medium576. Out of Boundary Paths Medium1269. Number of Ways to Stay in the Same Place After Some Steps Hard1220. Count Vowels Permutation HardMerging IntervalsProblem List: https://leetcode.com/list/55aj8s16Generate problem statement for this patternStatement Given a set of numbers find an optimal solution for a problem considering the current number and the best you can get from the left and right sides.Approach Find all optimal solutions for every interval and return the best possible answer.// from i to jdp[i][j] = dp[i][k] + result[k] + dp[k+1][j]Get the best from the left and right sides and add a solution for the current position.Top-Downfor (int k = i; k &lt;= j; ++k) { result = max(result, topDown(nums, i, k-1) + result[k] + topDown(nums, k+1, j));}return memo[/*state parameters*/] = result;Bottom-Upfor(int l = 1; l&lt;n; l++) { for(int i = 0; i&lt;n-l; i++) { int j = i+l; for(int k = i; k&lt;j; k++) { dp[i][j] = max(dp[i][j], dp[i][k] + result[k] + dp[k+1][j]); } }} return dp[0][n-1];for(int l = 1; l&lt;n; l++) { for(int i = 0; i&lt;n-l; i++) { int j = i+l; for(int k = i; k&lt;j; k++) { dp[i][j] = max(dp[i][j], dp[i][k] + result[k] + dp[k+1][j]); } }} return dp[0][n-1]Similar Problems1130. Minimum Cost Tree From Leaf Values Mediumfor (int l = 1; l &lt; n; ++l) { for (int i = 0; i &lt; n - l; ++i) { int j = i + l; dp[i][j] = INT_MAX; for (int k = i; k &lt; j; ++k) { dp[i][j] = min(dp[i][j], dp[i][k] + dp[k+1][j] + maxs[i][k] * maxs[k+1][j]); } }}96. Unique Binary Search Trees Medium1039. Minimum Score Triangulation of Polygon Medium546. Remove Boxes Medium1000. Minimum Cost to Merge Stones Medium312. Burst Balloons HardTop-Downfor (int k = i; k &lt;= j; ++k) { result = max(result, topDown(nums, i, k-1, memo) + (i-1 &gt;= 0 ? nums[i-1] : 1) * nums[k] * (j+1 &lt; nums.size() ? nums[j+1] : 1) + topDown(nums, k+1, j, memo));}return memo[i][j] = result;Bottom-Upfor(int l = 1; l &lt; n; l++) { for(int i = 0; i &lt; n-l; i++) { int j = i+l; for(int k = i; k &lt;= j; k++) { dp[i][j] = max(dp[i][j], (((k&gt;i &amp;&amp; k&gt;0) ? dp[i][k-1] : 0) + (i&gt;0 ? nums[i-1] : 1) * nums[k] * (j&lt;n-1 ? nums[j+1] : 1) + ((k&lt;j &amp;&amp; k&lt;n-1) ? dp[k+1][j] : 0))); } }}return dp[0][n-1];375. Guess Number Higher or Lower II MediumDP on StringsProblem List: https://leetcode.com/list/55afh7m7General problem statement for this pattern can vary but most of the time you are given two strings where lengths of those strings are not bigStatement Given two strings s1 and s2, return some result.Approach Most of the problems on this pattern requires a solution that can be accepted in O(n^2) complexity.// i - indexing string s1// j - indexing string s2for (int i = 1; i &lt;= n; ++i) { for (int j = 1; j &lt;= m; ++j) { if (s1[i-1] == s2[j-1]) { dp[i][j] = /*code*/; } else { dp[i][j] = /*code*/; } }} If you are given one string s the approach may little varyfor (int l = 1; l &lt; n; ++l) { for (int i = 0; i &lt; n-l; ++i) { int j = i + l; if (s[i] == s[j]) { dp[i][j] = /*code*/; } else { dp[i][j] = /*code*/; } }}1143. Longest Common Subsequence Mediumfor (int i = 1; i &lt;= n; ++i) { for (int j = 1; j &lt;= m; ++j) { if (text1[i-1] == text2[j-1]) { dp[i][j] = dp[i-1][j-1] + 1; } else { dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } }}647. Palindromic Substrings Mediumfor (int l = 1; l &lt; n; ++l) { for (int i = 0; i &lt; n-l; ++i) { int j = i + l; if (s[i] == s[j] &amp;&amp; dp[i+1][j-1] == j-i-1) { dp[i][j] = dp[i+1][j-1] + 2; } else { dp[i][j] = 0; } }}516. Longest Palindromic Subsequence Medium1092. Shortest Common Supersequence Medium72. Edit Distance Hard115. Distinct Subsequences Hard712. Minimum ASCII Delete Sum for Two Strings Medium5. Longest Palindromic Substring MediumDecision MakingProblem List: https://leetcode.com/list/55af7bu7The general problem statement for this pattern is forgiven situation decide whether to use or not to use the current state. So, the problem requires you to make a decision at a current state.Statement Given a set of values find an answer with an option to choose or ignore the current value.Approach If you decide to choose the current value use the previous result where the value was ignored; vice-versa, if you decide to ignore the current value use previous result where value was used.// i - indexing a set of values// j - options to ignore j valuesfor (int i = 1; i &lt; n; ++i) { for (int j = 1; j &lt;= k; ++j) { dp[i][j] = max({dp[i][j], dp[i-1][j] + arr[i], dp[i-1][j-1]}); dp[i][j-1] = max({dp[i][j-1], dp[i-1][j-1] + arr[i], arr[i]}); }}198. House Robber Easyfor (int i = 1; i &lt; n; ++i) { dp[i][1] = max(dp[i-1][0] + nums[i], dp[i-1][1]); dp[i][0] = dp[i-1][1];}121. Best Time to Buy and Sell Stock Easy714. Best Time to Buy and Sell Stock with Transaction Fee Medium309. Best Time to Buy and Sell Stock with Cooldown Medium123. Best Time to Buy and Sell Stock III Hard188. Best Time to Buy and Sell Stock IV HardI hope these tips will be helpful 😊" }, { "title": "DP for Beginners", "url": "/posts/dp-for-beginners/", "categories": "Computer Science", "tags": "computer-science, dsa", "date": "2023-03-21 00:00:00 +0530", "snippet": "Longest Increasing Subsequence variants:https://leetcode.com/problems/longest-increasing-subsequence/https://leetcode.com/problems/largest-divisible-subset/https://leetcode.com/problems/russian-dol...", "content": "Longest Increasing Subsequence variants:https://leetcode.com/problems/longest-increasing-subsequence/https://leetcode.com/problems/largest-divisible-subset/https://leetcode.com/problems/russian-doll-envelopes/https://leetcode.com/problems/maximum-length-of-pair-chain/https://leetcode.com/problems/number-of-longest-increasing-subsequence/https://leetcode.com/problems/delete-and-earn/https://leetcode.com/problems/longest-string-chain/Partition Subset:https://leetcode.com/problems/partition-equal-subset-sum/https://leetcode.com/problems/last-stone-weight-ii/BitMasking:https://leetcode.com/problems/partition-to-k-equal-sum-subsets/Longest Common Subsequence Variant:https://leetcode.com/problems/longest-common-subsequence/https://leetcode.com/problems/edit-distance/https://leetcode.com/problems/distinct-subsequences/https://leetcode.com/problems/minimum-ascii-delete-sum-for-two-strings/Palindrome:https://leetcode.com/problems/palindrome-partitioning-ii/https://leetcode.com/problems/palindromic-substrings/Coin Change variant:https://leetcode.com/problems/coin-change/https://leetcode.com/problems/coin-change-2/https://leetcode.com/problems/combination-sum-iv/https://leetcode.com/problems/perfect-squares/https://leetcode.com/problems/minimum-cost-for-tickets/Matrix multiplication variant:https://leetcode.com/problems/minimum-score-triangulation-of-polygon/https://leetcode.com/problems/minimum-cost-tree-from-leaf-values/https://leetcode.com/problems/burst-balloons/Matrix/2D Array:https://leetcode.com/problems/matrix-block-sum/https://leetcode.com/problems/range-sum-query-2d-immutable/https://leetcode.com/problems/dungeon-game/https://leetcode.com/problems/triangle/https://leetcode.com/problems/maximal-square/https://leetcode.com/problems/minimum-falling-path-sum/Hash + DP:https://leetcode.com/problems/target-sum/https://leetcode.com/problems/longest-arithmetic-sequence/https://leetcode.com/problems/longest-arithmetic-subsequence-of-given-difference/https://leetcode.com/problems/maximum-product-of-splitted-binary-tree/State machine:https://leetcode.com/problems/best-time-to-buy-and-sell-stock/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-ii/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/Depth First Search + DP:https://leetcode.com/problems/out-of-boundary-paths/https://leetcode.com/problems/knight-probability-in-chessboard/Minimax DP:https://leetcode.com/problems/predict-the-winner/https://leetcode.com/problems/stone-game/Misc:https://leetcode.com/problems/greatest-sum-divisible-by-three/https://leetcode.com/problems/decode-ways/https://leetcode.com/problems/perfect-squares/https://leetcode.com/problems/count-numbers-with-unique-digits/https://leetcode.com/problems/longest-turbulent-subarray/https://leetcode.com/problems/number-of-dice-rolls-with-target-sum/Sample solutions for each of above problem type:Longest Increasing Subsequencehttps://leetcode.com/problems/longest-increasing-subsequence/https://leetcode.com/problems/largest-divisible-subset/https://leetcode.com/problems/russian-doll-envelopes/https://leetcode.com/problems/maximum-length-of-pair-chain/https://leetcode.com/problems/number-of-longest-increasing-subsequence/https://leetcode.com/problems/delete-and-earn/https://leetcode.com/problems/longest-string-chain/class Solution {public:\tint lengthOfLIS(vector&lt;int&gt;&amp; nums) {\t\tint n = nums.size();\t\tvector&lt;int&gt;LIS(n+1, 1);\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tfor (int j = 0; j &lt; i; j++) {\t\t\t\tif (nums[i] &gt; nums[j])\t\t\t\t\tLIS[i] = max(LIS[i], 1 + LIS[j]);\t\t\t}\t\t}\t\tint ans = 0;\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tans = max(ans, LIS[i]);\t\t}\t\treturn ans;\t}};Partition Subset Sum:https://leetcode.com/problems/partition-equal-subset-sum/https://leetcode.com/problems/last-stone-weight-ii/class Solution {public:\tbool canPartition(vector&lt;int&gt;&amp; nums) {\t\tint n = nums.size();\t\tint sum = 0;\t\tfor (int i = 0; i &lt; n; i++)\t\t\tsum += nums[i];\t\tif (sum % 2 != 0) return false;\t\tint target = sum/2;\t\tvector&lt;bool&gt;dp(target+1, false);\t\tdp[0] = true;\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tfor (int j = target; j &gt;= nums[i]; j--) {\t\t\t\tdp[j] = dp[j] | dp[j - nums[i]];\t\t\t}\t\t}\t\treturn dp[target];\t}};BitMasking in DP:https://leetcode.com/problems/partition-to-k-equal-sum-subsets/class Solution {\tint dp[(1&lt;&lt;16) + 2];public:\tbool canPartitionKSubsets(vector&lt;int&gt;&amp; nums, int k) {\t\tint n = nums.size();\t\tfill(dp, dp+(1&lt;&lt;16)+2, -1);\t\tint sum = 0;\t\tfor (int i = 0; i &lt; n; i++)\t\t\tsum += nums[i];\t\tif (sum % k != 0) return false;\t\tint target = sum/k;\t\tdp[0] = 0;\t\tfor (int mask = 0; mask &lt; (1&lt;&lt;n); mask++) {\t\t\tif (dp[mask] == -1) continue;\t\t\tfor (int i = 0; i &lt; n; i++) {\t\t\t\tif (!(mask &amp; (1 &lt;&lt; i)) &amp;&amp; dp[mask] + nums[i] &lt;= target)\t\t\t\t\tdp[mask | (1 &lt;&lt; i)] = (dp[mask] + nums[i]) % target;\t\t\t}\t\t}\t\treturn dp[(1&lt;&lt;n)-1] == 0;\t}};Longest Common Subsequencehttps://leetcode.com/problems/longest-common-subsequence/https://leetcode.com/problems/edit-distance/https://leetcode.com/problems/distinct-subsequences/https://leetcode.com/problems/minimum-ascii-delete-sum-for-two-strings/class Solution {\tint longestCommonSubsequenceUtil(string text1, string text2, int n, int m) {\t\tif (n == 0 || m == 0)\t\t\treturn 0;\t\tvector&lt;vector&lt;int&gt;&gt;L(n+1, vector&lt;int&gt;(m+1, 0));\t\tfor (int i = 0; i &lt;= n; i++) {\t\t\tfor (int j = 0; j &lt;= m; j++) {\t\t\t\tif (i == 0 || j == 0)\t\t\t\t\tL[i][j] = 0;\t\t\t\telse if (text1[i-1] == text2[j-1])\t\t\t\t\tL[i][j] = 1 + L[i-1][j-1];\t\t\t\telse\t\t\t\t\tL[i][j] = max(L[i][j-1], L[i-1][j]);\t\t\t}\t\t}\t\treturn L[n][m];\t}public:\tint longestCommonSubsequence(string text1, string text2) {\t\tint n = text1.size();\t\tint m = text2.size();\t\treturn longestCommonSubsequenceUtil(text1, text2, n, m);\t}};Palindrome:https://leetcode.com/problems/palindrome-partitioning-ii/https://leetcode.com/problems/palindromic-substrings/class Solution {public:\tint minCut(string s) {\t\tint n = s.length();\t\tint res[n];\t\tbool P[n][n];\t\tfor (int i = 0; i &lt; n; i++)\t\t\tP[i][i] = true;\t\tfor (int L = 2; L &lt;= n; L++) {\t\t\tfor (int i = 0; i &lt; n-L+1; i++) {\t\t\t\tint j = i+L-1;\t\t\t\tif (L == 2) {\t\t\t\t\tP[i][j] = (s[i] == s[j]);\t\t\t\t} else {\t\t\t\t\tP[i][j] = (s[i] == s[j]) &amp;&amp; P[i+1][j-1];\t\t\t\t}\t\t\t}\t\t}\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tif (P[0][i])\t\t\t\tres[i] = 0;\t\t\telse {\t\t\t\tres[i] = INT_MAX;\t\t\t\tfor (int j = 0; j &lt; i; j++) {\t\t\t\t\tif (P[j+1][i] &amp;&amp; res[i] &gt; 1 + res[j])\t\t\t\t\t\tres[i] = 1+res[j];\t\t\t\t}\t\t\t}\t\t}\t\treturn res[n-1] == INT_MAX ? 1 : res[n-1];\t}};Coin Change:https://leetcode.com/problems/coin-change/https://leetcode.com/problems/coin-change-2/https://leetcode.com/problems/combination-sum-iv/https://leetcode.com/problems/perfect-squares/https://leetcode.com/problems/minimum-cost-for-tickets/class Solution {public:\tint coinChange(vector&lt;int&gt;&amp; coins, int amount) {\t\tint n = coins.size();\t\tif (n == 0) return 0;\t\tvector&lt;int&gt;res(amount+1, INT_MAX);\t\tres[0] = 0;\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tfor (int j = coins[i]; j &lt;= amount; j++) {\t\t\t\tif (res[j-coins[i]] != INT_MAX)\t\t\t\t\tres[j] = min(res[j], 1+res[j-coins[i]]);\t\t\t}\t\t}\t\treturn res[amount] != INT_MAX ? res[amount] : -1;\t}};Matrix multiplication:https://leetcode.com/problems/minimum-score-triangulation-of-polygon/https://leetcode.com/problems/minimum-cost-tree-from-leaf-values/https://leetcode.com/problems/burst-balloons/class Solution {public:\tint minScoreTriangulation(vector&lt;int&gt;&amp; A) {\t\tint n = A.size(); \t\tvector&lt;vector&lt;int&gt;&gt;dp(n, vector&lt;int&gt;(n, 0));\t\tfor (int L = 2; L &lt;= n; L++) {\t\t\tfor (int i = 0; i+L &lt; n; i++) {\t\t\t\tint j = i+L;\t\t\t\tdp[i][j] = INT_MAX;\t\t\t\tfor (int k = i+1; k &lt; j; k++) {\t\t\t\t\tdp[i][j] = min(dp[i][j], dp[i][k] + dp[k][j] + A[i]*A[k]*A[j]);\t\t\t\t}\t\t\t}\t\t}\t\treturn dp[0][n-1];\t}};Matrix/2D Array:https://leetcode.com/problems/matrix-block-sum/https://leetcode.com/problems/range-sum-query-2d-immutable/https://leetcode.com/problems/dungeon-game/https://leetcode.com/problems/triangle/https://leetcode.com/problems/maximal-square/https://leetcode.com/problems/minimum-falling-path-sum/class Solution {public:\tvector&lt;vector&lt;int&gt;&gt; matrixBlockSum(vector&lt;vector&lt;int&gt;&gt;&amp; mat, int K) {\t\tint m = mat.size();\t\tint n = mat[0].size();\t\tvector&lt;vector&lt;int&gt;&gt;sum(m+1, vector&lt;int&gt;(n+1, 0));\t\tfor (int i = 1; i &lt;= m; i++) {\t\t\tfor (int j = 1; j &lt;= n; j++) {\t\t\t\tsum[i][j] = sum[i-1][j] + sum[i][j-1] - sum[i-1][j-1] + mat[i-1][j-1];\t\t\t}\t\t}\t\tvector&lt;vector&lt;int&gt;&gt;res(m, vector&lt;int&gt;(n, 0));\t\tfor (int i = 0; i &lt; m; i++) {\t\t\tfor (int j = 0; j &lt; n; j++) {\t\t\t\tint r1 = max(0, i-K); int c1 = max(0, j-K);\t\t\t\tint r2 = min(m-1, i+K); int c2 = min(n-1, j+K);\t\t\t\tr1++; r2++;\t\t\t\tc1++; c2++;\t\t\t\tres[i][j] = sum[r2][c2] - (sum[r2][c1-1] + sum[r1-1][c2]- sum[r1-1][c1-1]);\t\t\t}\t\t}\t\treturn res;\t}};Hash + DP:https://leetcode.com/problems/target-sum/https://leetcode.com/problems/longest-arithmetic-sequence/https://leetcode.com/problems/longest-arithmetic-subsequence-of-given-difference/https://leetcode.com/problems/maximum-product-of-splitted-binary-tree/class Solution {public:\tint findTargetSumWays(vector&lt;int&gt;&amp; nums, int S) {\t\tint n = nums.size();\t\tunordered_map&lt;int, int&gt;hm;\t\thm[0] = 1;\t\tfor (int i = 0; i &lt; n; i++) {\t\t\tauto mp = hm;\t\t\thm.clear();\t\t\tfor (auto it = mp.begin(); it != mp.end(); it++) {\t\t\t\thm[it-&gt;first + nums[i]] += it-&gt;second;\t\t\t\thm[it-&gt;first - nums[i]] += it-&gt;second;\t\t\t}\t\t}\t\treturn hm[S];\t}};State machine:https://leetcode.com/problems/best-time-to-buy-and-sell-stock/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-ii/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/class Solution {public:\tint maxProfit(vector&lt;int&gt;&amp; prices, int fee) {\t\tint n = prices.size();\t\tvector&lt;int&gt;buy(n, 0);\t\tvector&lt;int&gt;sell(n, 0);\t\tbuy[0] = -prices[0], sell[0] = 0;\t\tfor (int i = 1; i &lt; n; i++) {\t\t\tbuy[i] = max(buy[i-1], sell[i-1]-prices[i]);\t\t\tsell[i] = max(sell[i-1], buy[i-1]+prices[i]-fee);\t\t}\t\treturn sell[n-1];\t}};Depth First Search +DP:https://leetcode.com/problems/out-of-boundary-paths/https://leetcode.com/problems/knight-probability-in-chessboard/class Solution {\tint mod = 1000000007;\tint dfs(int m, int n, int N, int r, int c, vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt;&amp; dp) {\t\tif (r &lt; 0 || c &lt; 0 || r &gt;= m || c &gt;= n) return 1;\t\tif (N == 0) return 0;\t\tif (dp[N][r][c] != -1) return dp[N][r][c]%mod;\t\tint moves = 0;\t\tmoves = (moves + dfs(m, n, N-1, r, c+1, dp))%mod;\t\tmoves = (moves + dfs(m, n, N-1, r, c-1, dp))%mod;\t\tmoves = (moves + dfs(m, n, N-1, r+1, c, dp))%mod;\t\tmoves = (moves + dfs(m, n, N-1, r-1, c, dp))%mod;\t\tdp[N][r][c] = moves%mod;\t\treturn dp[N][r][c];\t}public:\tint findPaths(int m, int n, int N, int i, int j) {\t\tvector&lt;vector&lt;vector&lt;int&gt;&gt;&gt;dp(N+1, vector&lt;vector&lt;int&gt;&gt;(m+1, vector&lt;int&gt;(n+1, -1)));\t\treturn dfs(m, n, N, i, j, dp);\t}};Minimax DP:https://leetcode.com/problems/predict-the-winner/https://leetcode.com/problems/stone-game/class Solution {public:\tbool PredictTheWinner(vector&lt;int&gt;&amp; nums) {\t\tint n = nums.size();\t\tint res[n][n];\t\tfor (int i = 0; i &lt; n; i++)\t\t\tres[i][i] = nums[i];\t\tfor (int l = 2; l &lt;= n; l++) {\t\t\tfor (int i = 0; i+l-1 &lt; n; i++) {\t\t\t\tint j = i+l-1;\t\t\t\tint a = (i+1 &lt;= j-1) ? res[i+1][j-1] : 0;\t\t\t\tint b = (i+2 &lt;= j) ? res[i+2][j] : 0;\t\t\t\tint c = (i &lt;= j-2) ? res[i][j-2] : 0;\t\t\t\tres[i][j] = max(nums[i] + min(a,b), nums[j] + min(a, c));\t\t\t}\t\t}\t\tint total = 0;\t\tfor (int i = 0; i &lt; n; i++)\t\t\ttotal += nums[i];\t\treturn res[0][n-1] &gt;= total - res[0][n-1];\t}};Miscellaneous:https://leetcode.com/problems/greatest-sum-divisible-by-three/https://leetcode.com/problems/decode-ways/https://leetcode.com/problems/count-numbers-with-unique-digits/https://leetcode.com/problems/longest-turbulent-subarray/https://leetcode.com/problems/number-of-dice-rolls-with-target-sum/" }, { "title": "Binary Search Template", "url": "/posts/binary-search-template/", "categories": "Computer Science", "tags": "computer-science", "date": "2023-03-21 00:00:00 +0530", "snippet": "Binary Search is quite easy to understand conceptually. Basically, it splits the search space into two halves and only keep the half that probably has the search target and throw away the other hal...", "content": "Binary Search is quite easy to understand conceptually. Basically, it splits the search space into two halves and only keep the half that probably has the search target and throw away the other half that would not possibly have the answer. In this manner, we reduce the search space to half the size at every step, until we find the target. Binary Search helps us reduce the search time from linear O(n) to logarithmic O(log n). But when it comes to implementation, it’s rather difficult to write a bug-free code in just a few minutes. Some of the most common problems include: When to exit the loop? Should we use left &lt; right or left &lt;= right as the while loop condition? How to initialize the boundary variable left and right? How to update the boundary? How to choose the appropriate combination from left = mid, left = mid + 1 and right = mid, right = mid - 1?A rather common misunderstanding of binary search is that people often think this technique could only be used in simple scenario like “Given a sorted array, find a specific value in it”. As a matter of fact, it can be applied to much more complicated situations.After a lot of practice in LeetCode, I’ve made a powerful binary search template and solved many Hard problems by just slightly twisting this template. I’ll share the template with you guys in this post. I don’t want to just show off the code and leave. Most importantly, I want to share the logical thinking: how to apply this general template to all sorts of problems. Hopefully, after reading this post, people wouldn’t be pissed off any more when LeetCoding, “This problem could be solved with binary search! Why didn’t I think of that before!”&gt;&gt; Most Generalized Binary SearchSuppose we have a search space. It could be an array, a range, etc. Usually it’s sorted in ascending order. For most tasks, we can transform the requirement into the following generalized form:Minimize k , s.t. condition(k) is TrueThe following code is the most generalized binary search template:def binary_search(array) -&gt; int: def condition(value) -&gt; bool: pass left, right = min(search_space), max(search_space) # could be [0, n], [1, n] etc. Depends on problem while left &lt; right: mid = left + (right - left) // 2 if condition(mid): right = mid else: left = mid + 1 return leftWhat’s really nice of this template is that, for most of the binary search problems, we only need to modify three parts after copy-pasting this template, and never need to worry about corner cases and bugs in code any more: Correctly initialize the boundary variables left and right to specify search space. Only one rule: set up the boundary to include all possible elements; Decide return value. Is it return left or return left - 1? Remember this: after exiting the while loop, left is the minimal k​ satisfying the condition function; Design the condition function. This is the most difficult and most beautiful part. Needs lots of practice.Below I’ll show you guys how to apply this powerful template to many LeetCode problems.&gt;&gt; Basic Application278. First Bad Version [Easy]You are a product manager and currently leading a team to develop a new product. Since each version is developed based on the previous version, all the versions after a bad version are also bad. Suppose you have n versions [1, 2, ..., n] and you want to find out the first bad one, which causes all the following ones to be bad. You are given an API bool isBadVersion(version) which will return whether version is bad.Example:Given n = 5, and version = 4 is the first bad version.call isBadVersion(3) -&gt; falsecall isBadVersion(5) -&gt; truecall isBadVersion(4) -&gt; trueThen 4 is the first bad version. First, we initialize left = 1 and right = n to include all possible values. Then we notice that we don’t even need to design the condition function. It’s already given by the isBadVersion API. Finding the first bad version is equivalent to finding the minimal k satisfying isBadVersion(k) is True. Our template can fit in very nicely:class Solution: def firstBadVersion(self, n) -&gt; int: left, right = 1, n while left &lt; right: mid = left + (right - left) // 2 if isBadVersion(mid): right = mid else: left = mid + 1 return left69. Sqrt(x) [Easy]Implement int sqrt(int x). Compute and return the square root of x, where x is guaranteed to be a non-negative integer. Since the return type is an integer, the decimal digits are truncated and only the integer part of the result is returned.Example:Input: 4Output: 2Input: 8Output: 2Easy one. First we need to search for minimal k satisfying condition k^2 &gt; x, then k - 1 is the answer to the question. We can easily come up with the solution. Notice that I set right = x + 1 instead of right = x to deal with special input cases like x = 0 and x = 1.def mySqrt(x: int) -&gt; int: left, right = 0, x + 1 while left &lt; right: mid = left + (right - left) // 2 if mid * mid &gt; x: right = mid else: left = mid + 1 return left - 1 # `left` is the minimum k value, `k - 1` is the answer35. Search Insert Position [Easy]Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order. You may assume no duplicates in the array.Example:Input: [1,3,5,6], 5Output: 2Input: [1,3,5,6], 2Output: 1Very classic application of binary search. We are looking for the minimal k value satisfying nums[k] &gt;= target, and we can just copy-paste our template. Notice that our solution is correct regardless of whether the input array nums has duplicates. Also notice that the input target might be larger than all elements in nums and therefore needs to placed at the end of the array. That’s why we should initialize right = len(nums) instead of right = len(nums) - 1.class Solution: def searchInsert(self, nums: List[int], target: int) -&gt; int: left, right = 0, len(nums) while left &lt; right: mid = left + (right - left) // 2 if nums[mid] &gt;= target: right = mid else: left = mid + 1 return left&gt;&gt; Advanced ApplicationThe above problems are quite easy to solve, because they already give us the array to be searched. We’d know that we should use binary search to solve them at first glance. However, more often are the situations where the search space and search target are not so readily available. Sometimes we won’t even realize that the problem should be solved with binary search – we might just turn to dynamic programming or DFS and get stuck for a very long time.As for the question “When can we use binary search?”, my answer is that, If we can discover some kind of monotonicity, for example, if condition(k) is True then condition(k + 1) is True, then we can consider binary search.1011. Capacity To Ship Packages Within D Days [Medium]A conveyor belt has packages that must be shipped from one port to another within D days. The i-th package on the conveyor belt has a weight of weights[i]. Each day, we load the ship with packages on the conveyor belt (in the order given by weights). We may not load more weight than the maximum weight capacity of the ship.Return the least weight capacity of the ship that will result in all the packages on the conveyor belt being shipped within D days.Example :Input: weights = [1,2,3,4,5,6,7,8,9,10], D = 5Output: 15Explanation: A ship capacity of 15 is the minimum to ship all the packages in 5 days like this:1st day: 1, 2, 3, 4, 52nd day: 6, 73rd day: 84th day: 95th day: 10Note that the cargo must be shipped in the order given, so using a ship of capacity 14 and splitting the packages into parts like (2, 3, 4, 5), (1, 6, 7), (8), (9), (10) is not allowed. Binary search probably would not come to our mind when we first meet this problem. We might automatically treat weights as search space and then realize we’ve entered a dead end after wasting lots of time. In fact, we are looking for the minimal one among all feasible capacities. We dig out the monotonicity of this problem: if we can successfully ship all packages within D days with capacity m, then we can definitely ship them all with any capacity larger than m. Now we can design a condition function, let’s call it feasible, given an input capacity, it returns whether it’s possible to ship all packages within D days. This can run in a greedy way: if there’s still room for the current package, we put this package onto the conveyor belt, otherwise we wait for the next day to place this package. If the total days needed exceeds D, we return False, otherwise we return True.Next, we need to initialize our boundary correctly. Obviously capacity should be at least max(weights), otherwise the conveyor belt couldn’t ship the heaviest package. On the other hand, capacity need not be more thansum(weights), because then we can ship all packages in just one day.Now we’ve got all we need to apply our binary search template:def shipWithinDays(weights: List[int], D: int) -&gt; int: def feasible(capacity) -&gt; bool: days = 1 total = 0 for weight in weights: total += weight if total &gt; capacity: # too heavy, wait for the next day total = weight days += 1 if days &gt; D: # cannot ship within D days return False return True left, right = max(weights), sum(weights) while left &lt; right: mid = left + (right - left) // 2 if feasible(mid): right = mid else: left = mid + 1 return left410. Split Array Largest Sum [Hard]Given an array which consists of non-negative integers and an integer m, you can split the array into m non-empty continuous subarrays. Write an algorithm to minimize the largest sum among these m subarrays.Example:Input:nums = [7,2,5,10,8]m = 2Output:18Explanation:There are four ways to split nums into two subarrays. The best way is to split it into [7,2,5] and [10,8], where the largest sum among the two subarrays is only 18.If you take a close look, you would probably see how similar this problem is with LC 1011 above. Similarly, we can design a feasible function: given an input threshold, then decide if we can split the array into several subarrays such that every subarray-sum is less than or equal to threshold. In this way, we discover the monotonicity of the problem: if feasible(m) is True, then all inputs larger than m can satisfy feasible function. You can see that the solution code is exactly the same as LC 1011.def splitArray(nums: List[int], m: int) -&gt; int: def feasible(threshold) -&gt; bool: count = 1 total = 0 for num in nums: total += num if total &gt; threshold: total = num count += 1 if count &gt; m: return False return True left, right = max(nums), sum(nums) while left &lt; right: mid = left + (right - left) // 2 if feasible(mid): right = mid else: left = mid + 1 return leftBut we probably would have doubts: It’s true that left returned by our solution is the minimal value satisfying feasible, but how can we know that we can split the original array to actually get this subarray-sum? For example, let’s say nums = [7,2,5,10,8] and m = 2. We have 4 different ways to split the array to get 4 different largest subarray-sum correspondingly: 25:[[7], [2,5,10,8]], 23:[[7,2], [5,10,8]], 18:[[7,2,5], [10,8]], 24:[[7,2,5,10], [8]]. Only 4 values. But our search space [max(nums), sum(nums)] = [10, 32] has much more that just 4 values. That is, no matter how we split the input array, we cannot get most of the values in our search space.Let’s say k is the minimal value satisfying feasible function. We can prove the correctness of our solution with proof by contradiction. Assume that no subarray’s sum is equal to k, that is, every subarray sum is less than k. The variable total inside feasible function keeps track of the total weights of current load. If our assumption is correct, then total would always be less than k. As a result, feasible(k - 1) must be True, because total would at most be equal to k - 1 and would never trigger the if-clause if total &gt; threshold, therefore feasible(k - 1) must have the same output as feasible(k), which is True. But we already know that k is the minimal value satisfying feasible function, so feasible(k - 1) has to be False, which is a contradiction. So our assumption is incorrect. Now we’ve proved that our algorithm is correct.875. Koko Eating Bananas [Medium]Koko loves to eat bananas. There are N piles of bananas, the i-th pile has piles[i] bananas. The guards have gone and will come back in H hours. Koko can decide her bananas-per-hour eating speed of K. Each hour, she chooses some pile of bananas, and eats K bananas from that pile. If the pile has less than K bananas, she eats all of them instead, and won’t eat any more bananas during this hour.Koko likes to eat slowly, but still wants to finish eating all the bananas before the guards come back. Return the minimum integer K such that she can eat all the bananas within H hours.Example :Input: piles = [3,6,7,11], H = 8Output: 4Input: piles = [30,11,23,4,20], H = 5Output: 30Input: piles = [30,11,23,4,20], H = 6Output: 23Very similar to LC 1011 and LC 410 mentioned above. Let’s design a feasible function, given an input speed, determine whether Koko can finish all bananas within H hours with hourly eating speed speed. Obviously, the lower bound of the search space is 1, and upper bound is max(piles), because Koko can only choose one pile of bananas to eat every hour.def minEatingSpeed(piles: List[int], H: int) -&gt; int: def feasible(speed) -&gt; bool: # return sum(math.ceil(pile / speed) for pile in piles) &lt;= H # slower return sum((pile - 1) // speed + 1 for pile in piles) &lt;= H # faster left, right = 1, max(piles) while left &lt; right: mid = left + (right - left) // 2 if feasible(mid): right = mid else: left = mid + 1 return left1482. Minimum Number of Days to Make m Bouquets [Medium]Given an integer array bloomDay, an integer m and an integer k. We need to make m bouquets. To make a bouquet, you need to use k adjacent flowers from the garden. The garden consists of n flowers, the ith flower will bloom in the bloomDay[i] and then can be used in exactly one bouquet. Return the minimum number of days you need to wait to be able to make m bouquets from the garden. If it is impossible to make m bouquets return -1.Examples:Input: bloomDay = [1,10,3,10,2], m = 3, k = 1Output: 3Explanation: Let's see what happened in the first three days. x means flower bloomed and _ means flower didn't bloom in the garden.We need 3 bouquets each should contain 1 flower.After day 1: [x, _, _, _, _] // we can only make one bouquet.After day 2: [x, _, _, _, x] // we can only make two bouquets.After day 3: [x, _, x, _, x] // we can make 3 bouquets. The answer is 3.Input: bloomDay = [1,10,3,10,2], m = 3, k = 2Output: -1Explanation: We need 3 bouquets each has 2 flowers, that means we need 6 flowers. We only have 5 flowers so it is impossible to get the needed bouquets and we return -1.Now that we’ve solved three advanced problems above, this one should be pretty easy to do. The monotonicity of this problem is very clear: if we can make m bouquets after waiting for d days, then we can definitely finish that as well if we wait for more than d days.def minDays(bloomDay: List[int], m: int, k: int) -&gt; int: def feasible(days) -&gt; bool: bonquets, flowers = 0, 0 for bloom in bloomDay: if bloom &gt; days: flowers = 0 else: bonquets += (flowers + 1) // k flowers = (flowers + 1) % k return bonquets &gt;= m if len(bloomDay) &lt; m * k: return -1 left, right = 1, max(bloomDay) while left &lt; right: mid = left + (right - left) // 2 if feasible(mid): right = mid else: left = mid + 1 return left668. Kth Smallest Number in Multiplication Table [Hard]Nearly every one have used the Multiplication Table. But could you find out the k-th smallest number quickly from the multiplication table? Given the height m and the length n of a m * n Multiplication Table, and a positive integer k, you need to return the k-th smallest number in this table.Example :Input: m = 3, n = 3, k = 5Output: 3Explanation: The Multiplication Table:1\t2\t32\t4\t63\t6\t9The 5-th smallest number is 3 (1, 2, 2, 3, 3).For Kth-Smallest problems like this, what comes to our mind first is Heap. Usually we can maintain a Min-Heap and just pop the top of the Heap for k times. However, that doesn’t work out in this problem. We don’t have every single number in the entire Multiplication Table, instead, we only have the height and the length of the table. If we are to apply Heap method, we need to explicitly calculate these m * n values and save them to a heap. The time complexity and space complexity of this process are both O(mn), which is quite inefficient. This is when binary search comes in. Remember we say that designing condition function is the most difficult part? In order to find the k-th smallest value in the table, we can design an enough function, given an input num, determine whether there’re at least k values less than or equal to num. The minimal num satisfying enough function is the answer we’re looking for. Recall that the key to binary search is discovering monotonicity. In this problem, if num satisfies enough, then of course any value larger than num can satisfy. This monotonicity is the fundament of our binary search algorithm.Let’s consider search space. Obviously the lower bound should be 1, and the upper bound should be the largest value in the Multiplication Table, which is m * n, then we have search space [1, m * n]. The overwhelming advantage of binary search solution to heap solution is that it doesn’t need to explicitly calculate all numbers in that table, all it needs is just picking up one value out of the search space and apply enough function to this value, to determine should we keep the left half or the right half of the search space. In this way, binary search solution only requires constant space complexity, much better than heap solution.Next let’s consider how to implement enough function. It can be observed that every row in the Multiplication Table is just multiples of its index. For example, all numbers in 3rd row [3,6,9,12,15...] are multiples of 3. Therefore, we can just go row by row to count the total number of entries less than or equal to input num. Following is the complete solution.def findKthNumber(m: int, n: int, k: int) -&gt; int: def enough(num) -&gt; bool: count = 0 for val in range(1, m + 1): # count row by row add = min(num // val, n) if add == 0: # early exit break count += add return count &gt;= k left, right = 1, n * m while left &lt; right: mid = left + (right - left) // 2 if enough(mid): right = mid else: left = mid + 1 return left In LC 410 above, we have doubt “Is the result from binary search actually a subarray sum?”. Here we have a similar doubt: “Is the result from binary search actually in the Multiplication Table?”. The answer is yes, and we also can apply proof by contradiction. Denote num as the minimal input that satisfies enough function. Let’s assume that num is not in the table, which means that num is not divisible by any val in [1, m], that is, num % val &gt; 0. Therefore, changing the input from num to num - 1 doesn’t have any effect on the expression add = min(num // val, n). So enough(num - 1) would also return True, same as enough(num). But we already know num is the minimal input satisfying enough function, so enough(num - 1) has to be False. Contradiction! The opposite of our original assumption is true: num is actually in the table.719. Find K-th Smallest Pair Distance [Hard]Given an integer array, return the k-th smallest distance among all the pairs. The distance of a pair (A, B) is defined as the absolute difference between A and B.Example :Input:nums = [1,3,1]k = 1Output: 0 Explanation:Following are all the pairs. The 1st smallest distance pair is (1,1), and its distance is 0.(1,3) -&gt; 2(1,1) -&gt; 0(3,1) -&gt; 2Very similar to LC 668 above, both are about finding Kth-Smallest. Just like LC 668, We can design an enough function, given an input distance, determine whether there’re at least k pairs whose distances are less than or equal to distance. We can sort the input array and use two pointers (fast pointer and slow pointer, pointed at a pair) to scan it. Both pointers go from leftmost end. If the current pair pointed at has a distance less than or equal to distance, all pairs between these pointers are valid (since the array is already sorted), we move forward the fast pointer. Otherwise, we move forward the slow pointer. By the time both pointers reach the rightmost end, we finish our scan and see if total counts exceed k. Here is the implementation:def enough(distance) -&gt; bool: # two pointers count, i, j = 0, 0, 0 while i &lt; n or j &lt; n: while j &lt; n and nums[j] - nums[i] &lt;= distance: # move fast pointer j += 1 count += j - i - 1 # count pairs i += 1 # move slow pointer return count &gt;= kObviously, our search space should be [0, max(nums) - min(nums)]. Now we are ready to copy-paste our template:def smallestDistancePair(nums: List[int], k: int) -&gt; int: nums.sort() n = len(nums) left, right = 0, nums[-1] - nums[0] while left &lt; right: mid = left + (right - left) // 2 if enough(mid): right = mid else: left = mid + 1 return left1201. Ugly Number III [Medium]Write a program to find the n-th ugly number. Ugly numbers are positive integers which are divisible by a or b or c.Example :Input: n = 3, a = 2, b = 3, c = 5Output: 4Explanation: The ugly numbers are 2, 3, 4, 5, 6, 8, 9, 10... The 3rd is 4.Input: n = 4, a = 2, b = 3, c = 4Output: 6Explanation: The ugly numbers are 2, 3, 4, 6, 8, 9, 10, 12... The 4th is 6.Nothing special. Still finding the Kth-Smallest. We need to design an enough function, given an input num, determine whether there are at least n ugly numbers less than or equal to num. Since a might be a multiple of b or c, or the other way round, we need the help of greatest common divisor to avoid counting duplicate numbers.def nthUglyNumber(n: int, a: int, b: int, c: int) -&gt; int: def enough(num) -&gt; bool: total = num//a + num//b + num//c - num//ab - num//ac - num//bc + num//abc return total &gt;= n ab = a * b // math.gcd(a, b) ac = a * c // math.gcd(a, c) bc = b * c // math.gcd(b, c) abc = a * bc // math.gcd(a, bc) left, right = 1, 10 ** 10 while left &lt; right: mid = left + (right - left) // 2 if enough(mid): right = mid else: left = mid + 1 return left1283. Find the Smallest Divisor Given a Threshold [Medium]Given an array of integers nums and an integer threshold, we will choose a positive integer divisor and divide all the array by it and sum the result of the division. Find the smallest divisor such that the result mentioned above is less than or equal to threshold.Each result of division is rounded to the nearest integer greater than or equal to that element. (For example: 7/3 = 3 and 10/2 = 5). It is guaranteed that there will be an answer.Example :Input: nums = [1,2,5,9], threshold = 6Output: 5Explanation: We can get a sum to 17 (1+2+5+9) if the divisor is 1. If the divisor is 4 we can get a sum to 7 (1+1+2+3) and if the divisor is 5 the sum will be 5 (1+1+1+2). After so many problems introduced above, this one should be a piece of cake. We don’t even need to bother to design a condition function, because the problem has already told us explicitly what condition we need to satisfy.def smallestDivisor(nums: List[int], threshold: int) -&gt; int: def condition(divisor) -&gt; bool: return sum((num - 1) // divisor + 1 for num in nums) &lt;= threshold left, right = 1, max(nums) while left &lt; right: mid = left + (right - left) // 2 if condition(mid): right = mid else: left = mid + 1 return leftEndWow, thank you so much for making it to the end! Really appreciate that. As you can see from the python codes above, they all look very similar to each other. That’s because I copy-pasted my own template all the time. No exception. This is the strong proof of my template’s powerfulness and adaptability. I believe everyone can acquire this binary search template to solve many problems. All we need is just more practice to build up our ability to discover the monotonicity of the problem and to design a beautiful condition function.Hope this helps.Reference [C++ / Fast / Very clear explanation / Clean Code] Solution with Greedy Algorithm and Binary Search Approach the problem using the “trial and error” algorithm Binary Search 101 The-Ultimate-Binary-Search-Handbook - LeetCode ugly-number-iii Binary Search with picture &amp; Binary Search Template - LeetCode" }, { "title": "Embed MusicApp", "url": "/posts/embed-music/", "categories": "Blog", "tags": "blog, music-player", "date": "2023-03-11 00:00:00 +0530", "snippet": "Embed samirpaul.in/music/embed music player(Lofi Study Music) to any website:Demo:Code:&lt;iframe src=\"https://samirpaul1.github.io/music/embed\" title=\"Embed MusicApp\"\tframeborder=\"0\"\tloading=\"laz...", "content": "Embed samirpaul.in/music/embed music player(Lofi Study Music) to any website:Demo:Code:&lt;iframe src=\"https://samirpaul1.github.io/music/embed\" title=\"Embed MusicApp\"\tframeborder=\"0\"\tloading=\"lazy\"\tmarginheight=\"0\"\tmarginwidth=\"0\"\twidth=\"100%\"\theight=\"223\"\tscrolling=\"no\"&gt;&lt;/iframe&gt;" }, { "title": "URL Shortening Service", "url": "/posts/url-shortening-service/", "categories": "System Design", "tags": "blog, url-shortner, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "URL Shortening ServiceSummaryRequirements Functional Requirements Given a URL, generate a shorter and unique alias (short link). When users access a short link, redirect to the origi...", "content": "URL Shortening ServiceSummaryRequirements Functional Requirements Given a URL, generate a shorter and unique alias (short link). When users access a short link, redirect to the original link. Users should optionally be able to pick a custom short link for their URL. Links will expire after a standard default timespan. Users should also be able to specify the expiration time. Non-Functional Requirements The system should be highly available. This is required because, if our service is down, all the URL redirections will start failing. URL redirection should happen in real-time with minimal latency. Shortened links should not be guessable (not predictable). Extended Requirements Analytics; e.g., how many times a redirection happened? Be accessible through REST APIs by other services. Capacity Estimation and Constraints Assumption Read-heavy. More redirection requests compared to new URL shortenings. Assume 100:1 ratio between read and write. Traffic estimates 500M new URL shortenings per month, 100 * 500M =&gt; 50B redirections per month. New URL shortenings per second 500 million / (30 days * 24 hours * 3600 seconds) = ~200 URLs/s URLs redirections per second 50 billion / (30 days * 24 hours * 3600 sec) = ~19K/s Storage estimates Assume storing every URL shortening request for 5 years, each object takes 500 bytes Total objects: 500 million * 5 years * 12 months = 30 billion Total storage: 30 billion * 500 bytes = 15 TB Bandwidth estimates Write: 200 URL/s * 500 bytes/URL = 100 KB/s Read: 19K URL/s * 500 bytes/URL = ~9 MB/s Cache memory estimates Follow the 80-20 rule, assuming 20% of URLs generate 80% of traffic, cache 20% hot URLs Requests per day: 19K * 3600 seconds * 24 hours = ~1.7 billion/day Cache 20%: 0.2 * 1.7 billion * 500 bytes = ~170GB Summary Assuming 500 million new URLs per month and 100:1 read:write ratio Category Calculation Estimate New URLs 500 million / (30 days * 24 hours * 3600 seconds) 200 /s URL redirections 500 million * 100 / (30 days * 24 hours * 3600 seconds) 19 K/s Incoming data 500 bytes/URL * 200 URL/s 100 KB/s Outgoing data 500 bytes/URL * 19K URL/s 9 MB/s Storage for 5 years 500 bytes/URL * 500 million * 60 months 15 TB Memory for cache 19K URL * 3600 seconds * 24 hours * 500 bytes * 20% 170 GB System APIscreateUrl ParametersName | Type | Note—- | —- | —-api_dev_key | string | The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.original_url | string | Original URL to be shortened.custom_alias | string | Optional custom key for the URL.user_name | string | Optional user name to be used in encoding.expire_date | string | Optional expiration date for the shortened URL. Return string A successful insertion returns the shortened URL; otherwise, it returns an error code. deleteUrl ParametersName | Type | Note—- | —- | —-api_dev_key | string | The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.url_key | string | Short URL. Return string A successful deletion returns ‘URL Removed’. Database design Observations Need to store billions of records. Each object is small (less than 1K). No relationships between records—other than storing which user created a URL. Read-heavy. A NoSQL choice would also be easier to scale. Comment: SQL with sharding should also work Schema URLColumn | Type—- | —-hash | varchar(16)original_url | varchar(512)creation_date | datetimeexpiration_date | datetimeuser_id | int UserColumn | Type—- | —-name | varchar(20)email | varchar(32)creation_date | datetimelast_login | datetime Basic System Design and AlgorithmEncoding actual URL Compute unique hash base64: A-Z, a-z, 0-9, -, . 6 letters: 64 ^ 6 = ~68.7 billion 8 letters: 64 ^ 8 = ~281 trillion Use 6 letters MD5 generates 128 bit hash value Each base64 character encodes 6 bits base64 encoding generates 22 characters Select 8 characters Issues with this approach Same URL from multiple users URL-encoded Workaround Append an increasing sequence number to each input URL, and generate a hash for it Append user id to input URL Generating keys offline Standalone Key Generation Service (KGS) Generate random 6 letter strings and store them in a database (key DB) When a short URL is needed, take one from the key DB Key DB size 6 characters/key * 68.7B unique keys = 412 GB Concurrency issue If there are multiple servers reading keys concurrently, two or more servers try to read the same key from the database. Workaround Servers can use KGS to read/mark keys in the database. KGS can use two tables to store keys: one for keys that are not used yet, and one for all the used keys. KGS can always keep some keys in memory so that it can quickly provide them whenever a server needs them. KGS needs to make sure not to give the same key to multiple servers. Comment: keys are sharded. Each KGS server only serves one application server. Key lookup When a key is found, issue an “HTTP 302 Redirect” status and passing the stored URL. When a key is not found, issue an “HTTP 404 Not Found”, or redirect to homepage. UUIDReplace KGS with UUID.Data Partitioning and Replication Range Based Partitioning Store URLs in separate partitions based on the first letter of the URL or the hash key. Combine certain less frequently occurring letters into one database partition. Problem with this approach Unbalanced servers. Hash-Based Partitioning Take a hash of the short URL we are storing, and calculate which partition to use based upon the hash. Use consistent hashing Cache Eviction policy LRU: discard the least recently used URL first Cache update Cache miss: hit backend database and pass new entry to all cache replicas Load Balancer (LB) LB locations Between Clients and Application servers Between Application Servers and database servers Between Application Servers and Cache servers DB SweepingA separate Cleanup service can run periodically to remove expired links from our storage and cache.TelemetryStatistics about the system: how many times a short URL has been usedSecurity and Permissions Store permission level (public/private) with each URL in the database Send an error (HTTP 401) for unauthorized access" }, { "title": "System design interview for IT companies", "url": "/posts/system-design-interview-for-it-companies/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": " How to prepare system design questions for an IT companyOriginal source and Credit: https://github.com/checkcheckzz/system-design-interviewSystem design is a very broad topic. Even a software eng...", "content": " How to prepare system design questions for an IT companyOriginal source and Credit: https://github.com/checkcheckzz/system-design-interviewSystem design is a very broad topic. Even a software engineer with many years of working experience at a top IT company may not be an expert on system design. If you want to become an expert, you need to read many books, articles, and solve real large scale system design problems.This repository only teaches you how to handle the system design interview with a systematic approach in a short time. You can dive into each topic if you have time. Of course, welcome to add your thoughts!Table of Contents System Design Interview Tips Basic Knowledge about System Design Company Engineering Blogs Products and Systems Hot Questions and Reference Good Books Object Oriented Design[⬆] System Design Interview Tips:Clarify the constraints and identify the user casesSpend a few minutes questioning the interviewer and agreeing on the scope of the system.Remember to make sure you know all the requirements the interviewer didn’t tell you about in the beginning.User cases indicate the main functions of the system, and constraints list the scale of the system such as requests per second, requests types, data written per second, data read per second.High-level architecture designSketch the important components and the connections between them, but don’t go into some details. Usually, a scalable system includes webserver (load balancer), service (service partition), database (primary/secondary database cluster plug cache).Component designFor each component, you need to write the specific APIs for each component. You may need to finishthe detailed OOD design for a particular function. You may also need to design the database schema for the database.[⬆] Basic Knowledge about System Design:Here are some articles about system design related topics. The Anatomy Of A System Design Interview How to Succeed in a System Design Interview How to Rock a Systems Design Interview System Interview Scalability for Dummies Scalable Web Architecture and Distributed Systems Numbers Everyone Should Know Fallacies of distributed systems Scalable System Design Patterns Introduction to Architecting Systems for Scale Transactions Across Datacenters A Plain English Introduction to CAP Theorem The CAP FAQ Paxos Made Simple Consistent Hashing NOSQL Patterns Scalability, Availability &amp; Stability PatternsOf course, if you want to dive into system related topics, here is a good collection of reading list about services-engineering, anda good collection of material about distributed systems.[⬆] Company Engineering Blogs:If you are going to have an onsite with a company, you should read their engineering blog. High Scalability The GitHub Blog Engineering at Quora Yelp Engineering Blog Twitter Engineering Facebook Engineering Yammer Engineering Etsy Code as Craft Foursquare Engineering Blog Airbnb Engineering WebEngage Engineering Blog LinkedIn Engineering The Netflix Tech Blog BankSimple Simple Blog Square The Corner SoundCloud Backstage Blog Flickr Code Instagram Engineering Dropbox Tech Blog Cloudera Developer Blog Bandcamp Tech Oyster Tech Blog THE REDDIT BLOG Groupon Engineering Blog Songkick Technology Blog Google AI Blog Google Developers Blog Pinterest Engineering Blog Twilio Engineering Blog Bitly Engineering Blog Uber Engineering Blog Godaddy Engineering Splunk Blog Coursera Engineering Blog PayPal Engineering Blog Nextdoor Engineering Blog Booking.com Development Blog Microsoft Engineering Blog Scalyr Engineering Blog Myntra Engineering Blog Fastly Blog AWS Architecture Blog Lyft Engineering Blog Wish Engineering Doordash Engineering SnowFlake Blog Palantir Blog[⬆] Products and Systems:The following papers/articles/slides can help you to understand the general design idea of different real products and systems. MapReduce: Simplified Data Processing on Large Clusters Bigtable: A Distributed Storage System for Structured Data The Google File System The Chubby lock service for loosely-coupled distributed systems Dynamo: Amazon’s Highly Available Key-value Store Introduction to Memcached Cassandra Introduction Features Introduction to HBase Introduction to MongoDB Introduction to Redis Storm Introduction to Zookeeper Kafka YouTube Architecture Scaling Pinterest Google Architecture Scaling Twitter The WhatsApp Architecture Flickr Architecture Amazon Architecture Stack Overflow Architecture Pinterest Architecture Tumblr Architecture Instagram Architecture TripAdvisor Architecture Scaling Mailbox Salesforce Architecture ESPN Architecture Uber Architecture DropBox Design Splunk Architecture[⬆] Hot Questions and Reference:There are some good references for each question. The references here are slides and articles.Design a CDN networkReference: Globally Distributed Content DeliveryDesign a Google document systemReference: google-mobwrite Differential SynchronizationDesign a random ID generation systemReference: Announcing Snowflake snowflakeDesign a key-value databaseReference: Introduction to RedisDesign the Facebook news feed function Reference: What are best practices for building something like a News Feed? What are the scaling issues to keep in mind while developing a social network feed? Activity Feeds ArchitectureDesign the Facebook timeline function Reference: Building Timeline Facebook TimelineDesign a function to return the top k requests during past time interval Reference: Efficient Computation of Frequent and Top-k Elements in Data Streams An Optimal Strategy for Monitoring Top-k Queries in Streaming WindowsDesign an online multiplayer card game Reference: How to Create an Asynchronous Multiplayer Game How to Create an Asynchronous Multiplayer Game Part 2: Saving the Game State to Online Database How to Create an Asynchronous Multiplayer Game Part 3: Loading Games from the Database How to Create an Asynchronous Multiplayer Game Part 4: Matchmaking Real Time Multiplayer in HTML5Design a graph search function Reference: Building out the infrastructure for Graph Search Indexing and ranking in Graph Search The natural language interface of Graph Search and Erlang at FacebookDesign a picture sharing system Reference: Flickr Architecture Instagram ArchitectureDesign a search engine Reference: How would you implement Google Search? Implementing Search EnginesDesign a recommendation systemReference: Hulu’s Recommendation System Recommender SystemsDesign a tinyurl system Reference: System Design for Big Data-tinyurl URL Shortener APIDesign a garbage collection system Reference: Baby’s First Garbage CollectorDesign a scalable web crawling system Reference: How can I build a web crawler from scratch?Design the Facebook chat function Reference: Erlang at Facebook Facebook ChatDesign a trending topic system Reference: Implementing Real-Time Trending Topics With a Distributed Rolling Count Algorithm in Storm Early detection of Twitter trends explainedDesign a cache system Reference: Introduction to Memcached[⬆] Good Books: Big Data: Principles and best practices of scalable realtime data systems Real-Time Analytics: Techniques to Analyze and Visualize Streaming Data Building Microservices: Designing Fine-Grained Systems Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems[⬆] Object Oriented Design:Tips for OOD InterviewClarify the scenario, write out user casesUse case is a description of sequences of events that, taken together, lead to a system doing something useful. Who is going to use it and how they are going to use it. The system may be very simple or very complicated.Special system requirements such as multi-threading, read or write oriented.Define objectsMap identity to class: one scenario for one class, each core object in this scenario for one class.Consider the relationships among classes: certain class must have unique instance, one object has many other objects (composition), one object is another object (inheritance).Identify attributes for each class: change noun to variable and action to methods.Use design patterns such that it can be reused in multiple applications.Useful Websites 101 Design Patterns &amp; Tips for Developers" }, { "title": "Steps how to approach the system design questions in interviews", "url": "/posts/steps-how-to-approach-the-system-design-questions-in-interviews/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "These are the steps to go through mentally in the interviews, followed by actual interview experiences: a) Be absolutely sure you understand the problem being asked, clarify on the onset rather th...", "content": "These are the steps to go through mentally in the interviews, followed by actual interview experiences: a) Be absolutely sure you understand the problem being asked, clarify on the onset rather than assuming anything b) Use-cases. This is critical, you MUST know what is the system going to be used for, what is the scale it is going to be used for. Also, constraints like requests per second, requests types, data written per second, data read per second. c) Solve the problem for a very small set, say, 100 users. This will broadly help you figure out the data structures, components, abstract design of the overall model. d) Write down the various components figured out so far and how will they interact with each other. e) As a rule of thumb remember at least these : processing and servers storage caching concurrency and communication security load balancing and proxy CDN Monetization: if relevant, how will you monetize? eg. What kind of DB (Is Postgres enough, if not why?), do you need caching and how much, is security a prime concern? f) Special cases for the question asked. Say designing a system for storing thumbnails, will a file system be enough? What if you have to scale for facebook or google? Will a nosql based database work? g) After I have my components in place, what I generally try to do is look for minor optimization in various places according to the use-cases, various tradeoffs that will help in better scaling in 99% cases. h) [Scaling out or up] (http://highscalability.com/blog/2014/5/12/4-architecture-issues-when-scaling-web-applications-bottlene.html) i) Check with the interviewer is there any other special case he is looking to solve? Also, it really helps if you know about the company you are interviewing with, what its architecture is, what will the interviewer have more interest in based on the company and what he works on?" }, { "title": "SQL vs. NoSQL", "url": "/posts/sql-vs-nosql/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "SQL vs. NoSQLCommon types of NoSQLKey-value stores Array of key-value pairs. The “key” is an attribute name. Redis, Vodemort, Dynamo.Document databases Data is stored in documents. Documents ar...", "content": "SQL vs. NoSQLCommon types of NoSQLKey-value stores Array of key-value pairs. The “key” is an attribute name. Redis, Vodemort, Dynamo.Document databases Data is stored in documents. Documents are grouped in collections. Each document can have an entirely different structure. CouchDB, MongoDB.Wide-column / columnar databases Column families - containers for rows. No need to know all the columns up front. Each row can have different number of columns. Cassandra, HBase.Graph database Data is stored in graph structures Nodes: entities Properties: information about the entities Lines: connections between the entities Neo4J, InfiniteGraphDifferences between SQL and NoSQLStorage SQL: store data in tables. NoSQL: have different data storage models.Schema SQL Each record conforms to a fixed schema. Schema can be altered, but it requires modifying the whole database. NoSQL: Schemas are dynamic. Querying SQL Use SQL (structured query language) for defining and manipulating the data. NoSQL Queries are focused on a collection of documents. UnQL (unstructured query language). Different databases have different syntax. Scalability SQL Vertically scalable (by increasing the horsepower: memory, CPU, etc) and expensive. Horizontally scalable (across multiple servers); but it can be challenging and time-consuming. NoSQL Horizontablly scalable (by adding more servers) and cheap. ACID Atomicity, consistency, isolation, durability SQL ACID compliant Data reliability Gurantee of transactions NoSQL Most sacrifice ACID compliance for performance and scalability. Which one to use?SQL Ensure ACID compliance. Reduce anomalies. Protect database integrity. Data is structured and unchanging.NoSQL Data has little or no structure. Make the most of cloud computing and storage. Cloud-based storage requires data to be easily spread across multiple servers to scale up. Rapid development. Frequent updates to the data structure. " }, { "title": "Sharding or Data Partitioning", "url": "/posts/sharding-or-data-partitioning/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "Sharding / Data PartitioningPartitioning methods Horizontal partitioning Range based sharding. Put different rows into different tables. Con If the value whose ...", "content": "Sharding / Data PartitioningPartitioning methods Horizontal partitioning Range based sharding. Put different rows into different tables. Con If the value whose range is used for sharding isn’t chosen carefully, the partitioning scheme will lead to unbalanced servers. Vertical partitioning Divide data for a specific feature to their own server. Pro Straightforward to implement. Low impact on the application. Con To support growth of the application, a database may need further partitioning. Directory-based partitioning A lookup service that knows the partitioning scheme and abstracts it away from the database access code. Allow addition of db servers or change of partitioning schema without impacting application. Con Can be a single point of failure. Partitioning criteria Key or hash-based partitioning Apply a hash function to some key attribute of the entry to get the partition number. Problem Adding new servers may require changing the hash function, which would need redistribution of data and downtime for the service. Workaround: consistent hashing. List partitioning Each partition is assigned a list of values. Round-robin partitioning With n partitions, the i tuple is assigned to partition i % n. Composite partitioning Combine any of above partitioning schemes to devise a new scheme. Consistent hashing is a composite of hash and list partitioning. Key -&gt; reduced key space through hash -&gt; list -&gt; partition. Common problems of shardingMost of the constraints are due to the fact that operations across multiple tables or multiple rows in the same table will no longer run on the same server. Joins and denormalization Joins will not be performance efficient since data has to be compiled from multiple servers. Workaround: denormalize the database so that queries can be performed from a single table. But this can lead to data inconsistency. Referential integrity Difficult to enforce data integrity constraints (e.g. foreign keys). Workaround Referential integrity is enforced by application code. Applications can run SQL jobs to clean up dangling references. Rebalancing Necessity of rebalancing Data distribution is not uniform. A lot of load on one shard. Create more db shards or rebalance existing shards changes partitioning scheme and requires data movement. " }, { "title": "PyShooter Python Game", "url": "/posts/pyshooter/", "categories": "Projects", "tags": "python, projects, pyshooter", "date": "2023-03-04 00:00:00 +0530", "snippet": "PyShooterPyShooter is a two-dimensional shooter game in which the player runs horizontally and fires at enemies.Repository: https://github.com/SamirPaul1/PyShooterDemo:Vimeo: https://vimeo.com/8097...", "content": "PyShooterPyShooter is a two-dimensional shooter game in which the player runs horizontally and fires at enemies.Repository: https://github.com/SamirPaul1/PyShooterDemo:Vimeo: https://vimeo.com/809728956How To Play If you don’t have Python or Pygame installed, you can simply double click the .exe file to play the game.Note: The .exe file needs to stay in the same directory as the sounds, images, and font folders.Install Pygame pip install pygame If you have the correct version of Python and Pygame installed, you can run the program in the command prompt / terminal.cd PyShooterpython main.pyCredits for assets used: https://erayzesen.itch.io/pixel-platformer https://secrethideout.itch.io/team-wars-platformer-battle https://soundimage.org/fantasywonder https://gushh.net/blog/free-game-sprites-explosion-3 https://mtk.itch.io/grenades-16x16" }, { "title": "Key Characteristics of Distributed Systems", "url": "/posts/key-characteristics-of-distributed-systems/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "Key Characteristics of Distributed SystemsScalability The capability of a system to grow and manage increased demand. A system that can continuously evolve to support growing amount of work is sc...", "content": "Key Characteristics of Distributed SystemsScalability The capability of a system to grow and manage increased demand. A system that can continuously evolve to support growing amount of work is scalable. Horizontal scaling: by adding more servers into the pool of resources. Vertical scaling: by adding more resource (CPU, RAM, storage, etc) to an existing server. This approach comes with downtime and an upper limit.Reliability Reliability is the probability that a system will fail in a given period. A distributed system is reliable if it keeps delivering its service even when one or multiple components fail. Reliability is achieved through redundancy of components and data (remove every single point of failure).Availability Availability is the time a system remains operational to perform its required function in a specific period. Measured by the percentage of time that a system remains operational under normal conditions. A reliable system is available. An available system is not necessarily reliable. A system with a security hole is available when there is no security attack. Efficiency Latency: response time, the delay to obtain the first piece of data. Bandwidth: throughput, amount of data delivered in a given time.Serviceability / Manageability Easiness to operate and maintain the system. Simplicity and spend with which a system can be repaired or maintained." }, { "title": "High-level design", "url": "/posts/high-level-design/", "categories": "System Design", "tags": "blog, system-design, design-interview, preparation", "date": "2023-03-04 00:00:00 +0530", "snippet": "High-level design (HLD)TicketmasterPastebinInstagramDropboxTwitterTwitter SearchYoutubeWeb CrawlerFacebook NewsfeedYelpUber Backend", "content": "High-level design (HLD)TicketmasterPastebinInstagramDropboxTwitterTwitter SearchYoutubeWeb CrawlerFacebook NewsfeedYelpUber Backend" }, { "title": "Consistent Hashing", "url": "/posts/consistent-hashing/", "categories": "System Design", "tags": "blog, system-design, design-interview, preparation", "date": "2023-03-04 00:00:00 +0530", "snippet": "Consistent HashingSimple hashingProblems of simple hashing function key % n (n is the number of servers): It is not horizontally scalable. Whenever a new cache host is added to the system, all exi...", "content": "Consistent HashingSimple hashingProblems of simple hashing function key % n (n is the number of servers): It is not horizontally scalable. Whenever a new cache host is added to the system, all existing mappings are broken. It may not be load balanced, especially for non-uniformly distributed data. Some servers will become hot spots.Consistent Hashing Consistent hashing maps a key to an integer. Imagine that the integers in the range are placed on a ring such that the values are wrapped around. Given a list of servers, hash them to integers in the range. To map a key to a server: Hash it to a single integer. Move clockwise on the ring until finding the first cache it encounters. When the hash table is resized (a server is added or deleted), only k/n keys need to be remapped (k is the total number of keys, and n is the total number of servers). To handle hot spots, add “virtual replicas” for caches. Instead of mapping each cache to a single point on the ring, map it to multiple points on the ring (replicas). This way, each cache is associated with multiple portions of the ring. If the hash function is “mixes well,” as the number of replicas increases, the keys will be more balanced. " }, { "title": "Company engineering blog links", "url": "/posts/company-engineering-blog-links/", "categories": "System Design", "tags": "blog, system-design, design-interview, preparation", "date": "2023-03-04 00:00:00 +0530", "snippet": "courtesy checkcheckzzDepending on where you are interviewing, go through the company blog. VERY USEFUL IN INTERVIEWS! It really helps if you have an idea of the architecture, as the questions asked...", "content": "courtesy checkcheckzzDepending on where you are interviewing, go through the company blog. VERY USEFUL IN INTERVIEWS! It really helps if you have an idea of the architecture, as the questions asked will generally be of that domain and your prior knowledge will help out here. Airbnb Engineering Amazon Amazon AWS Bandcamp Tech BankSimple Simple Blog Bitly Engineering Blog Cloudera Developer Blog Dropbox Tech Blog Engineering at Quora Etsy Code as Craft Facebook Engineering Flickr Code Foursquare Engineering Blog Google Research Blog Groupn Engineering Blog High Scalability Instagram Engineering LinkedIn Engineering Oyster Tech Blog Pinterest Engineering Blog Songkick Technology Blog SoundCloud Backstage Blog Square The Corner THE REDDIT BLOG The GitHub Blog The Netflix Tech Blog Twilio Engineering Blog Twitter Engineering Uber Engineering Walmart Labs Tech Blog WebEngage Engineering Blog Yammer Engineering Yelp Engineering Blog Smarkets Blog" }, { "title": "Common Design questions", "url": "/posts/common-design-questions/", "categories": "System Design", "tags": "blog, system-design, design-interview, preparation", "date": "2023-03-04 00:00:00 +0530", "snippet": "It generally depends what you are and you will be working on. Also what your level is but these are some of the more frequent interview questions. Design amazon’s frequently viewed product page (e...", "content": "It generally depends what you are and you will be working on. Also what your level is but these are some of the more frequent interview questions. Design amazon’s frequently viewed product page (eg. which shows the last 5 items you saw) Design an online poker game for multiplayer. Solve for persistence, concurrency, scale. Draw the ER diagram for this Design a [url compression system] (http://www.hiredintech.com/system-design/the-system-design-process/) Search engine (generally asked with people who have some domain knowledge): basic crawling, collection, hashing etc. Depends on your expertise on this topic Design dropbox’s architecture. good talk on this Design a picture sharing website. How will you store thumbnails, photos? Usage of CDNS? caching at various layers etc. Design a news feed (eg. Facebook , Twitter): news feed Design a product based on maps, eg hotel / ATM finder given a location. Design malloc, free and garbage collection system. What data structures to use? decorator pattern over malloc etc. Design a site like junglee.com i.e price comparision, availability on e-commerce websites. When and will you cache, how much to query, how to crawl efficiently over e-commerce sites, sharding of databases, basic database design A web application for instant messaging, eg whatsapp, facebook chat. Issues of each, scaling problems, status and availability notification etc. Design a system for collaborating over a document simultaneously (eg google docs) (very common:) top ‘n’ or most frequent items of a running stream of data Design election commission architecture : Let’s say we work with the Election Commission. On Counting day, we want to collate the votes received at the lakhs of voting booths all over the country. Each booth has a voting machine, which, when connected to the network, returns an array of the form {[party_id, num_votes],[party_id_2, num_votes_2],…}. We want to collect these and get the current scores in real time. The report we need continuously is how many seats is each party leading in. Please design a system for this. Design a logging system (For web applications, it is common to have a large number of servers running the same application, with a load balancer in front to distribute the incoming requests. In this scenario, we want to check and alarm in case an exception is thrown in any of the servers. We want a system that checks for the appearance of specific words, “Exception”, “Disk Full” etc. in the logs of any of the servers. How would you design this system?)" }, { "title": "Client-Server Communication", "url": "/posts/client-server-communication/", "categories": "System Design", "tags": "blog, system-design, design-interview, preparation", "date": "2023-03-04 00:00:00 +0530", "snippet": "Client-Server CommunicationStandard HTTP Web Request Client opens a connection and requests data from server. Server calculates the response. Server sends the response back to the client on the ...", "content": "Client-Server CommunicationStandard HTTP Web Request Client opens a connection and requests data from server. Server calculates the response. Server sends the response back to the client on the opened request.Ajax PollingThe client repeatedly polls (or requests) a server for data, and waits for the server to respond with data. If no data is available, an empty response is returned. Client opens a connection and requests data from the server using regular HTTP. The requested webpage sends requests to the server at regular intervals (e.g., 0.5 seconds). The server calculates the response and sends it back, like regular HTTP traffic. Client repeats the above three steps periodically to get updates from the server.Problems Client has to keep asking the server for any new data. A lot of responses are empty, creating HTTP overhead.HTTP Long-PollingThe client requests information from the server exactly as in normal polling, but with the expectation that the server may not respond immediately. The client makes an initial request using regular HTTP and then waits for a response. The server delays its response until an update is available, or until a timeout has occurred. When an update is available, the server sends a full response to the client. The client typically sends a new long-poll request, either immediately upon receiving a response or after a pause to allow an acceptable latency period.Each Long-Poll request has a timeout. The client has to reconnect periodically after the connection is closed, due to timeouts.WebSockets A persistent full duplex communication channels over a single TCP connection. Both server and client can send data at any time. A connection is established through WebSocket handshake. Low communication overhead. Real-time data transfer.Server-Sent Event (SSE) Client requests data from a server using regular HTTP. The requested webpage opens a connection to the server. Server sends the data to the client whenever there’s new information available. Use case: When real-time traffic from server to client is needed. When server generates data in a loop and sends multiple events to client. " }, { "title": "Caching", "url": "/posts/caching/", "categories": "System Design", "tags": "blog, caching, system-design", "date": "2023-03-04 00:00:00 +0530", "snippet": "Caching Take advantage of the locality of reference principle: recently requested data is likely to be requested again. Exist at all levels in architecture, but often found at the level nearest t...", "content": "Caching Take advantage of the locality of reference principle: recently requested data is likely to be requested again. Exist at all levels in architecture, but often found at the level nearest to the front end.Application server cache Cache placed on a request layer node. When a request layer node is expanded to many nodes Load balancer randomly distributes requests across the nodes. The same request can go to different nodes. Increase cache misses. Solutions: Global caches Distributed caches Distributed cache Each request layer node owns part of the cached data. Entire cache is divided up using a consistent hashing function. Pro Cache space can be increased easily by adding more nodes to the request pool. Con A missing node leads to cache lost. Global cache A server or file store that is faster than original store, and accessible by all request layer nodes. Two common forms Cache server handles cache miss. Used by most applications. Request nodes handle cache miss. Have a large percentage of the hot data set in the cache. An architecture where the files stored in the cache are static and shouldn’t be evicted. The application logic understands the eviction strategy or hot spots better than the cache Content distributed network (CDN) For sites serving large amounts of static media. Process A request first asks the CDN for a piece of static media. CDN serves that content if it has it locally available. If content isn’t available, CDN will query back-end servers for the file, cache it locally and serve it to the requesting user. If the system is not large enough for CDN, it can be built like this: Serving static media off a separate subdomain using lightweight HTTP server (e.g. Nginx). Cutover the DNS from this subdomain to a CDN later. Cache invalidation Keep cache coherent with the source of truth. Invalidate cache when source of truth has changed. Write-through cache Data is written into the cache and permanent storage at the same time. Pro Fast retrieval, complete data consistency, robust to system disruptions. Con Higher latency for write operations. Write-around cache Data is written to permanent storage, not cache. Pro Reduce the cache that is no used. Con Query for recently written data creates a cache miss and higher latency. Write-back cache Data is only written to cache. Write to the permanent storage is done later on. Pro Low latency, high throughput for write-intensive applications. Con Risk of data loss in case of system disruptions. Cache eviction policies FIFO: first in first out LIFO: last in first out LRU: least recently used MRU: most recently used LFU: least frequently used RR: random replacement" }, { "title": "Google Programmable Search Engine", "url": "/posts/google-programmable-search-engine/", "categories": "Blog", "tags": "blog, google-search, programmable-search-engine", "date": "2023-02-19 00:00:00 +0530", "snippet": "Google Programmable Search Engine lets you include a search engine on your website to help your visitors find the information they’re looking for. Because Programmable Search Engine is based on Goo...", "content": "Google Programmable Search Engine lets you include a search engine on your website to help your visitors find the information they’re looking for. Because Programmable Search Engine is based on Google’s core search technology, you can be confident that your users are getting high quality, relevant results. You can customize a lot of your search engine, including: Apply your site’s look and feel to the search box and results page Use search features such as refinements, autocomplete, and promotions to enhance your users’ search experience Understand your users’ behavior by linking your search engine with Google Analytics Make money from your search engine with Google AdSenseDemo:How is Programmable Search Engine different from Google Web Search?You have the option to set your custom search engine to search the entire web, similar to a normal search on Google.com. However, you might notice some differences. Your custom search engine: Emphasizes your results over anything else on the web Doesn’t include some Google Web Search features, such as personalized results May have a subset of results from the Google index if you include more than ten sites" }, { "title": "Why is System Design So Important?", "url": "/posts/why-is-system-design-so-important/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-02-10 00:00:00 +0530", "snippet": "System design is important for several reasons: Defining system requirements: System design helps to identify the requirements and constraints of the system being designed, and to prioritize t...", "content": "System design is important for several reasons: Defining system requirements: System design helps to identify the requirements and constraints of the system being designed, and to prioritize those requirements. This ensures that the final design meets the needs of the stakeholders and users. Improved efficiency: A well-designed system can improve efficiency by reducing the number of errors, reducing duplication of effort, and automating manual tasks. Improved scalability: System design helps to ensure that the system can accommodate future growth and change. A well-designed system is modular and scalable, making it easier to add new features or capabilities as needed. Better communication: System design helps to create a common understanding of the system among stakeholders, including developers, managers, and customers. A well-defined design makes it easier to communicate the system’s capabilities, constraints, and requirements. Improved maintainability: A well-designed system is easier to maintain and modify as needed. The design includes documentation and a clear understanding of the system’s components and interactions, making it easier for future developers to understand the system and make changes as needed. Overall, system design is an important step in the development of any system, as it helps to ensure that the final product meets the needs of stakeholders and users, is efficient, scalable, and maintainable, and facilitates communication and collaboration among team members." }, { "title": "Why Does The OSI Model Matter?", "url": "/posts/why-does-the-osi-model-matter/", "categories": "Blog", "tags": "blog, networking", "date": "2023-02-10 00:00:00 +0530", "snippet": "The OSI (Open Systems Interconnection) model matters because it provides a standard way of describing and understanding the different functions and components involved in a network communication. T...", "content": "The OSI (Open Systems Interconnection) model matters because it provides a standard way of describing and understanding the different functions and components involved in a network communication. The OSI model is a seven-layer abstraction of the network communication process, and it defines the tasks and responsibilities of each layer. Standardization: The OSI model provides a standard reference model that is widely used and accepted in the industry. This standardization helps to ensure that different systems and components can communicate with each other, even if they were developed by different vendors or organizations. Improved troubleshooting: The OSI model provides a systematic and organized approach to understanding network communication issues. By breaking down network communication into its component parts, it becomes easier to diagnose and fix problems. Design and development: The OSI model can help with the design and development of network systems by providing a common understanding of the different layers and their responsibilities. This can facilitate communication and collaboration between different teams and stakeholders. Education: The OSI model is a useful tool for teaching and learning about network communication. It provides a simple and visual way to understand the complex process of network communication. " }, { "title": "What is System Design?", "url": "/posts/what-is-system-design/", "categories": "System Design", "tags": "blog, system-design", "date": "2023-02-10 00:00:00 +0530", "snippet": "System design is a process of defining the architecture, modules, interfaces, data for a system to satisfy specified requirements. It can refer to the design of a complex system, such as a computer...", "content": "System design is a process of defining the architecture, modules, interfaces, data for a system to satisfy specified requirements. It can refer to the design of a complex system, such as a computer network, an aircraft, or a power plant, or it can refer to the design of a smaller system, such as a software application or a single computer program.The goal of system design is to produce a blueprint or plan that outlines how all the components of the system will work together to achieve the desired outcomes. This process typically involves analyzing the requirements of the system, defining the architecture, selecting appropriate technologies, and ensuring that the system is scalable, maintainable, and meets performance, reliability, and security requirements.In software engineering, system design is often used as a synonym for software design, which is the process of defining the architecture, modules, interfaces, and data for a software system to satisfy specified requirements." }, { "title": "Virtualization vs Containerization", "url": "/posts/virtualization-vs-containerization/", "categories": "Blog", "tags": "blog", "date": "2023-02-10 00:00:00 +0530", "snippet": "Virtualization and containerization are two different approaches to creating and managing virtual environments for software applications.Virtualization involves creating a virtual machine (VM) that...", "content": "Virtualization and containerization are two different approaches to creating and managing virtual environments for software applications.Virtualization involves creating a virtual machine (VM) that acts as a separate, self-contained operating system environment. Each VM runs its own operating system and applications, and has its own set of virtual hardware resources, such as CPU, memory, and storage. Virtualization allows multiple virtual machines to run on a single physical server, improving utilization and reducing costs. Examples of virtualization technology include VMware and Hyper-V.Containerization, on the other hand, is a newer approach to virtualization that is designed to be more lightweight and efficient. Containers are similar to virtual machines, in that they provide a self-contained environment for running applications. However, unlike virtual machines, containers do not include a full operating system. Instead, they share the host operating system and rely on the host for system services. This means that containers are much smaller and faster to start up than virtual machines, and can be run on a much larger scale. Examples of containerization technology include Docker and Kubernetes.In summary, virtualization and containerization are both ways to create virtual environments for software applications, but they differ in the level of abstraction and the resources they provide. Virtualization provides a full operating system environment, while containerization provides a lightweight, application-focused environment that relies on the host operating system. Both approaches have their own benefits and trade-offs, and the best choice will depend on the specific requirements of the application and the infrastructure." }, { "title": "TCP vs UDP", "url": "/posts/tcp-vs-udp/", "categories": "Blog", "tags": "blog", "date": "2023-02-10 00:00:00 +0530", "snippet": "TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are two of the most commonly used protocols for transmitting data over a network.TCP is a reliable and connection-oriented proto...", "content": "TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are two of the most commonly used protocols for transmitting data over a network.TCP is a reliable and connection-oriented protocol, meaning that a virtual connection must be established between the sender and the receiver before data can be transmitted. It ensures that data is delivered to the recipient in the same order it was sent, and that it is received without errors. If a packet of data is lost or corrupted during transmission, TCP will automatically retransmit the missing data until it is successfully received. This makes TCP a great choice for applications that require reliable data transfer, such as email and file transfers.UDP, on the other hand, is a connectionless and unreliable protocol. Unlike TCP, it does not establish a virtual connection between the sender and the receiver, and it does not guarantee that the data will be delivered in the same order it was sent. It is faster than TCP because it has less overhead, but it is less reliable. UDP is often used for applications that do not require reliable data transfer and can tolerate some lost or corrupted data, such as video or audio streaming, online gaming, and voice over IP (VoIP).In summary, TCP is best for applications that require reliable data transfer, while UDP is best for applications that can tolerate some loss and do not require reliable data transfer." }, { "title": "SSL TLS mTLS", "url": "/posts/ssl-tls-mtls/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "SSL (Secure Sockets Layer), TLS (Transport Layer Security), and mTLS (Mutual TLS) are all security protocols used to secure communications over the internet.SSL was the original protocol used to se...", "content": "SSL (Secure Sockets Layer), TLS (Transport Layer Security), and mTLS (Mutual TLS) are all security protocols used to secure communications over the internet.SSL was the original protocol used to secure internet communications, but it has been largely replaced by TLS, which is considered to be more secure. TLS is a cryptographic protocol that provides secure communication between two endpoints, such as a web server and a client browser. It ensures that the data transmitted between the endpoints is confidential and integrity protected.mTLS, also known as Mutual TLS, is an extension of TLS that adds an extra layer of security by requiring both the client and server to present a valid certificate to each other. This provides a stronger level of identity validation and protects against man-in-the-middle attacks. mTLS is used in situations where it is important to ensure the authenticity of both parties involved in a communication, such as in financial transactions or sensitive data transfers.In summary, SSL, TLS, and mTLS are all protocols used to secure internet communications, with TLS being the most widely used and considered to be the most secure. mTLS adds an extra layer of security by requiring both the client and server to present a valid certificate to each other, providing a stronger level of identity validation and protection against man-in-the-middle attacks." }, { "title": "SLO or Service Level Objective", "url": "/posts/slo-or-service-level-objective/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "A Service Level Objective (SLO) is a target or goal that a service provider sets for a specific service or service component, in terms of performance, availability, or some other quality metric. Th...", "content": "A Service Level Objective (SLO) is a target or goal that a service provider sets for a specific service or service component, in terms of performance, availability, or some other quality metric. The SLO defines what the service provider considers to be an acceptable level of service, and provides a clear and measurable way to track the performance of the service over time.An SLO is typically expressed as a specific, quantifiable target, such as “99.95% availability” or “mean response time of less than 500 milliseconds”. The SLO can be used to track the performance of the service, and to identify areas where improvements can be made.The SLO is often used in conjunction with a Service Level Agreement (SLA), which is a formal agreement between a service provider and a customer that outlines the level of service that will be delivered. The SLO forms the basis for the SLA, and provides a clear and measurable target for the service provider to meet.In summary, an SLO is a specific and measurable target that a service provider sets for a service or service component, in order to track and measure its performance over time. By setting clear and achievable SLOs, service providers can ensure that their services meet the needs and expectations of their customers." }, { "title": "SLA or Service Level Agreement", "url": "/posts/sla-or-service-level-agreement/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "A Service Level Agreement (SLA) is a contract between a service provider and a customer that outlines the level of service that the provider will deliver. The agreement is designed to ensure that t...", "content": "A Service Level Agreement (SLA) is a contract between a service provider and a customer that outlines the level of service that the provider will deliver. The agreement is designed to ensure that the customer is aware of what to expect from the service, and to hold the service provider accountable for meeting those expectations.SLAs typically cover a range of aspects, including:Availability: The percentage of time that the service will be available and accessible to the customer.Performance: The expected response times for the service, and any relevant performance metrics.Support: The hours of availability for customer support, and the response times for support requests.Maintenance: The scheduled maintenance windows for the service, and any expected downtime during these windows.Reporting: The frequency and format of performance reports that will be provided to the customer.Escalation: The procedures for escalation of issues, and the responsibility of the service provider in addressing them.Service credits: Financial compensation provided to the customer in the event that the service provider fails to meet the agreed-upon service levels.SLAs are common in many industries, including information technology, telecommunications, and cloud computing. By clearly defining the level of service that a customer can expect, SLAs help to build trust and ensure that the service provider and customer are aligned in their expectations." }, { "title": "Single Sign-On SSO", "url": "/posts/single-sign-on-sso/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "Single Sign-On (SSO) is a centralized authentication mechanism that allows users to access multiple applications or services with a single set of credentials. The idea behind SSO is to simplify the...", "content": "Single Sign-On (SSO) is a centralized authentication mechanism that allows users to access multiple applications or services with a single set of credentials. The idea behind SSO is to simplify the process of logging in to various systems, so that users only have to remember one username and password.With SSO, when a user logs in to one application or service, they are automatically logged in to all of the other systems and applications that are part of the SSO solution. This eliminates the need for the user to enter their credentials for each individual system, reducing the risk of forgotten passwords, password fatigue, and other security-related issues.There are different SSO technologies, including SAML (Security Assertion Markup Language), Kerberos, and OAuth/OpenID Connect. Each of these technologies has its own strengths and weaknesses, and the best choice depends on the specific requirements and constraints of the organization.In summary, SSO is a centralized authentication mechanism that allows users to access multiple applications and services with a single set of credentials, reducing the risk of forgotten passwords and improving security. SSO provides a convenient and secure way to manage access to resources, making it a popular choice for many organizations." }, { "title": "SAML vs OAuth 2.0 and OpenID Connect", "url": "/posts/saml-vs-oauth-2-dot-0-and-openid-connect/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "SAML (Security Assertion Markup Language), OAuth 2.0, and OpenID Connect are all protocols used for authentication and authorization on the web, but they each have different purposes and use cases....", "content": "SAML (Security Assertion Markup Language), OAuth 2.0, and OpenID Connect are all protocols used for authentication and authorization on the web, but they each have different purposes and use cases.SAML is an XML-based standard for exchanging authentication and authorization data between parties. It is primarily used for single sign-on (SSO) solutions, allowing users to log in to multiple applications and services with a single set of credentials. SAML is used by many organizations to provide a secure and seamless SSO experience for their users.OAuth 2.0 is an authorization framework that enables a third-party application to obtain limited access to an HTTP service on behalf of a resource owner, without requiring the resource owner to reveal its credentials. OAuth 2.0 provides a secure way for a user to grant access to their resources to a third-party application, without the need for the user to share their password with the application. OAuth 2.0 is used by many popular web applications, including Google, Facebook, and Twitter, to allow users to authenticate and authorize access to their resources.OpenID Connect is a simple identity layer built on top of OAuth 2.0. It provides a secure way to authenticate users and verify their identities, while also providing information about the user’s identity to the client. OpenID Connect enables the client to know that the user is who they claim to be, without having to manage passwords or other sensitive information. It provides a single sign-on solution, allowing users to authenticate once and then access multiple applications without having to log in again. OpenID Connect is used by many organizations to provide a secure and easy way for their users to authenticate and access resources.In summary, SAML is primarily used for SSO, allowing users to log in to multiple applications and services with a single set of credentials. OAuth 2.0 is an authorization framework used to control access to resources, while OpenID Connect is a simple identity layer built on top of OAuth 2.0 that provides a secure way to authenticate users and verify their identities. Both OAuth 2.0 and OpenID Connect are widely used and provide a secure and flexible way to control access to resources and authenticate users on the web." }, { "title": "Python vs R for data science", "url": "/posts/python-vs-r-for-data-science/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "Both Python and R are popular programming languages used in data science, but each has its own strengths and weaknesses.Python is a general-purpose programming language that has become a popular ch...", "content": "Both Python and R are popular programming languages used in data science, but each has its own strengths and weaknesses.Python is a general-purpose programming language that has become a popular choice for data science due to its simplicity, versatility, and large community of users. Python has a large number of libraries and packages specifically designed for data analysis and manipulation, such as NumPy, Pandas, and Matplotlib. It also has a rich ecosystem for machine learning, with libraries such as scikit-learn, TensorFlow, and PyTorch.On the other hand, R is a language specifically designed for data analysis and statistical computing. R has a strong focus on graphical representation of data and provides many built-in functions for statistical analysis, making it a popular choice for exploratory data analysis. R also has a vast library of packages for data analysis, machine learning, and visualization, such as ggplot2, dplyr, and caret.In conclusion, the choice between Python and R largely depends on the specific requirements of the project and personal preferences of the data scientist. Python is a good choice for a general-purpose programming language, while R is best suited for data analysis and statistical computing. Some data scientists prefer to use both languages, leveraging the strengths of each to get the job done." }, { "title": "Python libraries to automate web scraping", "url": "/posts/python-libraries-to-automate-web-scraping/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several libraries in Python for automating web scraping:BeautifulSoup: This is a popular library for web scraping and parsing HTML and XML documents. It provides a convenient way to extra...", "content": "There are several libraries in Python for automating web scraping:BeautifulSoup: This is a popular library for web scraping and parsing HTML and XML documents. It provides a convenient way to extract data from HTML and XML documents by searching and navigating the document tree.Scrapy: This is a full-featured web crawling and scraping framework for Python. It provides a comprehensive toolset for extracting data from websites, including features for handling common tasks like logging in, following links, and handling errors.Selenium: This is a browser automation library that can be used for web scraping as well. It allows you to control a web browser and interact with websites programmatically, making it useful for automating tasks that would otherwise require manual intervention.requests: This is a library for sending HTTP requests and processing HTTP responses. While it’s not specifically designed for web scraping, it can be used in combination with other libraries like BeautifulSoup to automate the process of sending requests to websites and extracting data from the responses.lxml: This is a library for parsing and manipulating XML and HTML documents. It provides an alternative to BeautifulSoup and can be used to extract data from HTML and XML documents in a more efficient and streamlined way.All of these libraries can be used to automate web scraping, but the best choice for your needs will depend on the specific requirements of your project. Some libraries may be more suited for large-scale web scraping, while others may be better suited for more targeted data extraction." }, { "title": "Python libraries for validating data. Used for forms in many cases", "url": "/posts/python-libraries-for-validating-data-used-for-forms-in-many-cases/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several Python libraries available for validating data, including:WTForms: WTForms is a flexible and powerful form handling library for Python. It provides a simple and intuitive interfac...", "content": "There are several Python libraries available for validating data, including:WTForms: WTForms is a flexible and powerful form handling library for Python. It provides a simple and intuitive interface for defining and validating forms, and it includes built-in support for a wide range of form fields, including text fields, checkboxes, and select fields.Django Forms: Django Forms is a form handling library built into the Django web framework. It provides a simple and flexible interface for defining and validating forms, and it includes support for a wide range of form fields, including text fields, checkboxes, and select fields.cerberus: Cerberus is a fast and lightweight data validation library for Python. It provides a simple and flexible interface for defining and validating data, and it includes support for a wide range of validation rules, including type checking, string formatting, and range checking.marshmallow: marshmallow is a data serialization and validation library for Python. It provides a simple and flexible interface for defining and validating data, and it includes support for a wide range of data types, including strings, integers, and dates.voluptuous: voluptuous is a data validation library for Python. It provides a simple and intuitive interface for defining and validating data, and it includes support for a wide range of validation rules, including type checking, string formatting, and range checking.These are just a few examples of the many data validation libraries available for Python. The best library for your needs will depend on the specific requirements of your project, as well as your personal preferences and experience." }, { "title": "Python libraries for parsing URLs", "url": "/posts/python-libraries-for-parsing-urls/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several libraries in Python for parsing URLs:urllib: This is a standard library in Python, and it includes several modules for working with URLs and HTTP requests, including urllib.parse ...", "content": "There are several libraries in Python for parsing URLs:urllib: This is a standard library in Python, and it includes several modules for working with URLs and HTTP requests, including urllib.parse which provides functions for parsing URLs.urlparse: This is another standard library in Python, and it provides similar functionality as urllib.parse.furl: This is a third-party library for parsing and manipulating URLs. It provides a more user-friendly interface than the standard libraries and supports features like query string parsing and modification.requests-furl: This library is an add-on for the requests library, and it provides URL parsing and manipulation functionality similar to furl.py-url-parse: This is another third-party library for parsing URLs, and it provides a simple and lightweight interface for parsing URLs into their constituent parts.All of these libraries can be used to parse URLs into their constituent parts, such as the scheme, host, path, query string, and fragment. You can choose the one that best fits your needs based on your requirements for features, ease of use, and performance." }, { "title": "Python libraries for manipulating audio and its metadata", "url": "/posts/python-libraries-for-manipulating-audio-and-its-metadata/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several Python libraries that can be used for manipulating audio and its metadata, including: pydub: pydub is a high-level library for audio manipulation. It allows you to load audio...", "content": "There are several Python libraries that can be used for manipulating audio and its metadata, including: pydub: pydub is a high-level library for audio manipulation. It allows you to load audio from a variety of sources (including MP3, WAV, and FLAC files), perform operations on the audio (such as slicing, concatenating, and exporting), and work with the metadata associated with the audio. librosa: librosa is a library for audio analysis and manipulation. It provides functions for loading audio from disk, computing features like Mel spectrograms and MFCCs, and manipulating the audio signal in various ways. It also includes functions for working with audio metadata, such as extracting song titles and artist information. audioread: audioread is a library for decoding audio files of various formats, including MP3, FLAC, and WAV. It provides a simple, unified interface for reading audio data from a variety of file formats, and it can also extract metadata from the audio files, such as the length of the audio, the sample rate, and the number of channels. mutagen: mutagen is a library for reading and writing metadata in a variety of audio file formats, including MP3, FLAC, and Ogg Vorbis. It provides a simple and flexible interface for working with audio metadata, and it supports a wide range of metadata fields, including album art, lyrics, and album and track information. soundfile: soundfile is a library for reading and writing audio files of various formats, including WAV, AIFF, and FLAC. It provides a simple and efficient interface for reading and writing audio data, and it includes support for working with the metadata associated with the audio files, such as the sample rate and number of channels. These are just a few examples of the many libraries available for working with audio and its metadata in Python. The best library for your needs will depend on the requirements of your specific project, as well as your personal preferences and experience." }, { "title": "Python libraries for implementing authentication schemes", "url": "/posts/python-libraries-for-implementing-authentication-schemes/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several Python libraries that can be used for implementing authentication schemes, including:Flask-Login: Flask-Login is a library for handling user authentication in Flask applications. ...", "content": "There are several Python libraries that can be used for implementing authentication schemes, including:Flask-Login: Flask-Login is a library for handling user authentication in Flask applications. It provides a simple and flexible interface for managing user accounts, including login and logout, as well as user session management.Django-Auth-LDAP: Django-Auth-LDAP is a library for authenticating against an LDAP directory in Django applications. It provides a simple and efficient way to authenticate users against an LDAP directory, and it includes support for user account management and session management.PyJWT: PyJWT is a library for encoding and decoding JSON Web Tokens (JWT) in Python. JWT is a popular format for transmitting information between parties, and PyJWT provides a simple and efficient way to encode and decode JWTs in Python.Passlib: Passlib is a library for handling password storage and verification in Python. It provides a simple and flexible interface for storing and verifying passwords, and it includes support for a wide range of password hashing algorithms, including bcrypt, scrypt, and Argon2.OAuthLib: OAuthLib is a library for implementing OAuth in Python. OAuth is a popular standard for authorization, and OAuthLib provides a simple and flexible way to implement OAuth in your Python applications.These are just a few examples of the many libraries available for implementing authentication schemes in Python. The best library for your needs will depend on the requirements of your specific project, as well as your personal preferences and experience." }, { "title": "Python libraries for caching data", "url": "/posts/python-libraries-for-caching-data/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several Python libraries available for caching data, including:Redis: Redis is an open-source, in-memory data store that supports a wide range of data structures, including hashes, lists,...", "content": "There are several Python libraries available for caching data, including:Redis: Redis is an open-source, in-memory data store that supports a wide range of data structures, including hashes, lists, sets, and sorted sets. Redis can be used as a caching layer for storing frequently-accessed data, and it provides fast and efficient access to cached data.Memcached: Memcached is a distributed memory caching system that is often used as a caching layer for storing frequently-accessed data. It provides fast and efficient access to cached data, and it can be easily integrated with Python applications.Flask-Cache: Flask-Cache is a caching extension for Flask applications. It provides a simple and flexible interface for caching data in Flask applications, and it supports a wide range of caching backends, including Redis and Memcached.Django Cache Framework: The Django Cache Framework is a caching system built into the Django web framework. It provides a simple and flexible interface for caching data in Django applications, and it supports a wide range of caching backends, including Redis and Memcached.pylibmc: pylibmc is a Python wrapper around the libmemcached library, which is a high-performance, distributed memory caching system. pylibmc provides a simple and efficient interface for working with Memcached in Python, and it is well-suited for use in high-performance, distributed caching systems.These are just a few examples of the many caching libraries available for Python. The best library for your needs will depend on the specific requirements of your project, as well as your personal preferences and experience." }, { "title": "Python libraries for administrative interfaces", "url": "/posts/python-libraries-for-administrative-interfaces/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several Python libraries that can be used to create administrative interfaces for web applications. Some popular ones include: Django Admin: Django is a high-level Python web framewo...", "content": "There are several Python libraries that can be used to create administrative interfaces for web applications. Some popular ones include: Django Admin: Django is a high-level Python web framework that includes a built-in administrative interface. The Django Admin interface is a powerful tool for managing the data and settings of a Django-powered website. It is designed to be easy to use and provides a range of functionality, including the ability to add, edit, and delete records, manage user accounts, and run custom actions on selected records. Flask-Admin: Flask is a lightweight Python web framework that can be used to create administrative interfaces. Flask-Admin is a popular third-party library that provides a simple and flexible way to create administrative interfaces for Flask applications. It supports a range of data types and includes features such as pagination, form validation, and support for custom views and actions. Pyrogram Admin: Pyrogram is a Telegram client library for Python that can be used to create administrative interfaces for Telegram bots. Pyrogram Admin provides an easy-to-use interface for managing the data and settings of a Telegram bot, and it supports a range of data types and actions, including message sending, user management, and custom commands. Sanic Admin: Sanic is an asynchronous Python web framework that can be used to create high-performance web applications. Sanic Admin is a third-party library that provides a simple and flexible way to create administrative interfaces for Sanic applications. It includes features such as pagination, form validation, and support for custom views and actions. These are just a few examples of the many libraries available for creating administrative interfaces in Python. The best library for your needs will depend on the requirements of your specific project, as well as your personal preferences and experience." }, { "title": "Python Content Management Systems", "url": "/posts/python-content-management-systems/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several content management systems (CMS) available in Python, including:Django CMS: Django CMS is a popular open-source CMS built using the Django web framework. It provides a flexible an...", "content": "There are several content management systems (CMS) available in Python, including:Django CMS: Django CMS is a popular open-source CMS built using the Django web framework. It provides a flexible and scalable platform for building complex and feature-rich websites, and it includes support for a wide range of content types, including text, images, and videos.Mezzanine: Mezzanine is a high-level Python CMS built on top of the Django web framework. It provides a user-friendly interface for managing content, and it includes a range of built-in features, including blog, gallery, and form builders.Plone: Plone is a powerful and flexible open-source CMS built using the Python programming language. It provides a range of features for building and managing websites, including a user-friendly interface, content versioning, and support for multiple languages.Wagtail: Wagtail is a CMS built using the Django web framework. It provides a flexible and intuitive interface for building and managing websites, and it includes a range of built-in features, including a WYSIWYG editor, document management, and support for multiple languages.Pyramid CMS: Pyramid CMS is a flexible and scalable CMS built using the Pyramid web framework. It provides a simple and efficient platform for building and managing websites, and it includes support for a wide range of content types, including text, images, and videos.These are just a few examples of the many Python CMS options available. The best CMS for your needs will depend on the specific requirements of your project, as well as your personal preferences and experience." }, { "title": "OAuth 2.0 and OpenID Connect", "url": "/posts/oauth-2-dot-0-and-openid-connect/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "OAuth 2.0 and OpenID Connect are both open standards for authorization and authentication on the web. They are used to control access to resources, such as APIs, and to verify the identity of users...", "content": "OAuth 2.0 and OpenID Connect are both open standards for authorization and authentication on the web. They are used to control access to resources, such as APIs, and to verify the identity of users.OAuth 2.0 is an authorization framework that enables a third-party application to obtain limited access to an HTTP service on behalf of a resource owner, without requiring the resource owner to reveal its credentials. OAuth 2.0 provides a secure way for a user to grant access to their resources to a third-party application, without the need for the user to share their password with the application. OAuth 2.0 is used by many popular web applications, including Google, Facebook, and Twitter, to allow users to authenticate and authorize access to their resources.OpenID Connect is a simple identity layer built on top of OAuth 2.0. It provides a secure way to authenticate users and verify their identities, while also providing information about the user’s identity to the client. OpenID Connect enables the client to know that the user is who they claim to be, without having to manage passwords or other sensitive information. It provides a single sign-on solution, allowing users to authenticate once and then access multiple applications without having to log in again. OpenID Connect is used by many organizations to provide a secure and easy way for their users to authenticate and access resources.In summary, OAuth 2.0 is an authorization framework used to control access to resources, while OpenID Connect is a simple identity layer built on top of OAuth 2.0 that provides a secure way to authenticate users and verify their identities. Both OAuth 2.0 and OpenID Connect are widely used and provide a secure and flexible way to control access to resources and authenticate users on the web." }, { "title": "Libraries for visualizing data", "url": "/posts/libraries-for-visualizing-data/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are many libraries available in Python for visualizing data, including:Matplotlib: Matplotlib is a plotting library for creating static, animated, and interactive visualizations in Python. It...", "content": "There are many libraries available in Python for visualizing data, including:Matplotlib: Matplotlib is a plotting library for creating static, animated, and interactive visualizations in Python. It provides a wide range of visualization options, including line charts, bar charts, scatter plots, and histograms, and it can be easily integrated with other data analysis libraries, such as NumPy and Pandas.Seaborn: Seaborn is a library for creating beautiful and informative statistical graphics in Python. It provides a high-level interface for creating a wide range of visualizations, including heat maps, violin plots, and regression plots, and it is built on top of Matplotlib.Plotly: Plotly is an open-source library for creating interactive, web-based visualizations in Python. It provides a wide range of visualization options, including bar charts, line charts, scatter plots, and 3D visualizations, and it includes support for streaming and real-time data.Bokeh: Bokeh is an interactive visualization library for Python that is optimized for large, real-time data sets. It provides a wide range of visualization options, including scatter plots, line charts, and bar charts, and it includes support for interactive tools, such as zooming and panning.ggplot: ggplot is a plotting library for Python that is inspired by the popular ggplot2 library in R. It provides a high-level interface for creating a wide range of visualizations, including scatter plots, bar charts, and histograms, and it is designed to work well with Pandas data frames.These are just a few examples of the many data visualization libraries available for Python. The best library for your needs will depend on the specific requirements of your project, as well as your personal preferences and experience." }, { "title": "how to learn object oriented programming in python", "url": "/posts/how-to-learn-object-oriented-programming-in-python/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "Learning object-oriented programming (OOP) in Python can be done by following these steps:Familiarize yourself with the basic syntax and features of Python: Before diving into OOP, it’s important t...", "content": "Learning object-oriented programming (OOP) in Python can be done by following these steps:Familiarize yourself with the basic syntax and features of Python: Before diving into OOP, it’s important to have a good understanding of the basic syntax and features of the language, such as variables, data types, functions, and control structures.Understand the basics of OOP: OOP is a programming paradigm that is based on the concept of “objects”. An object is a data structure that contains both data and the functions (methods) that operate on that data. OOP also involves the concepts of inheritance, encapsulation, and polymorphism.Study the class syntax in Python: In Python, a class is a blueprint for creating objects. It defines the attributes (data) and methods of an object. Classes are defined using the class keyword, and objects are created by calling the class as a function.Learn about inheritance and polymorphism: Inheritance allows you to create a new class based on an existing class, inheriting its attributes and methods. Polymorphism allows objects of different classes to be treated as objects of the same class.Practice creating classes and objects: To solidify your understanding of OOP in Python, try creating some classes and objects on your own. Start with simple classes that define basic data structures, and then move on to more complex classes that involve inheritance and polymorphism.Read and understand code written by others: One of the best ways to learn OOP is to read and understand code written by others. Look for open-source projects on GitHub that use OOP in Python and study their code.Build projects: Apply your OOP knowledge by building real-world projects. This could be anything from a simple game to a complex web application.Remember, the key to learning OOP is practice and repetition. Keep trying out new concepts and examples until you feel comfortable with the basics of OOP in Python." }, { "title": "How does SSO work?", "url": "/posts/how-does-sso-work/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "Single Sign-On (SSO) works by creating a central authentication service that is responsible for verifying the identity of a user. When a user attempts to access an application or service that is pa...", "content": "Single Sign-On (SSO) works by creating a central authentication service that is responsible for verifying the identity of a user. When a user attempts to access an application or service that is part of the SSO solution, they are redirected to the SSO service, which authenticates the user. If the user’s identity is verified, the SSO service generates a token that represents the user’s identity and includes information about the user’s session and the resources they are authorized to access.The token is then sent back to the application or service the user was trying to access, and the application uses the information in the token to determine whether the user is authorized to access the requested resources. If the user is authorized, the application grants access to the resources, and the user can perform the tasks they need to do.One of the key benefits of SSO is that once a user has logged in to the SSO service, they are automatically logged in to all of the other applications and services that are part of the SSO solution. This eliminates the need for the user to enter their credentials for each individual system, making it easier and more convenient for the user to access the resources they need.In summary, SSO works by creating a central authentication service that verifies the identity of a user and generates a token representing the user’s identity. The token is used by the applications and services to determine whether the user is authorized to access the requested resources, and the user is automatically logged in to all systems that are part of the SSO solution. This eliminates the need for the user to enter their credentials for each individual system, making it more convenient and secure for the user to access the resources they need." }, { "title": "gaming library in python", "url": "/posts/gaming-library-in-python/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several libraries in Python that can be used for game development, including:Pygame: This is a popular library for game development in Python. It provides a simple and easy-to-use set of ...", "content": "There are several libraries in Python that can be used for game development, including:Pygame: This is a popular library for game development in Python. It provides a simple and easy-to-use set of tools for creating 2D games and other types of interactive applications.Arcade: This is a library for creating 2D video games and other interactive applications in Python. It provides a high-level API for creating games and other interactive applications, making it a great choice for beginners.Pyglet: This is a cross-platform library for game and multimedia development in Python. It provides a powerful and flexible set of tools for creating games and other interactive applications, including support for 2D and 3D graphics.Kivy: This is an open-source library for developing mobile and desktop games in Python. It provides a high-level API for creating games and other interactive applications, and it supports multiple platforms, including Android, iOS, and Windows.PyOpenGL: This is a library for developing 3D games and other interactive applications in Python. It provides a low-level API for creating 3D graphics and animations, and it is often used in conjunction with other game development libraries, such as Pygame or Pyglet.All of these libraries have their own strengths and weaknesses, so it’s important to evaluate each one to see which one is the best fit for your needs. Consider factors such as the ease of use, available features, and overall performance when choosing a gaming library in Python." }, { "title": "Databases implemented in Python", "url": "/posts/databases-implemented-in-python/", "categories": "Blog", "tags": "blog, coding, computer-science", "date": "2023-02-10 00:00:00 +0530", "snippet": "There are several databases that have been implemented in Python, including:SQLite: SQLite is a lightweight, file-based database that is well-suited for small to medium-sized projects. It provides ...", "content": "There are several databases that have been implemented in Python, including:SQLite: SQLite is a lightweight, file-based database that is well-suited for small to medium-sized projects. It provides a simple and efficient SQL interface, and it is included as a standard library in many Python distributions.PostgreSQL: PostgreSQL is a powerful, open-source relational database that is well-suited for large, complex projects. It provides a rich set of features, including transactions, stored procedures, and advanced indexing, and it is widely used in a variety of applications, from web applications to scientific research.MySQL: MySQL is a widely-used, open-source relational database that is well-suited for small to medium-sized projects. It provides a simple and efficient SQL interface, and it is widely used for a variety of applications, from web applications to data warehousing.SQLAlchemy: SQLAlchemy is a SQL toolkit and Object-Relational Mapping (ORM) library for Python. It provides a high-level interface for working with databases, and it supports a wide range of databases, including SQLite, PostgreSQL, and MySQL.Django ORM: Django ORM is an Object-Relational Mapping (ORM) library that is built into the Django web framework. It provides a simple and intuitive interface for working with databases, and it supports a wide range of databases, including SQLite, PostgreSQL, and MySQL.These are just a few examples of the many databases that have been implemented in Python. The best database for your needs will depend on the specific requirements of your project, as well as your personal preferences and experience." }, { "title": "best static site generator for blog", "url": "/posts/best-static-site-generator-for-blog/", "categories": "Blog", "tags": "blog", "date": "2023-02-10 00:00:00 +0530", "snippet": "The best static site generator for a blog will depend on your specific needs and preferences. However, some of the most popular and well-regarded static site generators for blogs include:Jekyll: Th...", "content": "The best static site generator for a blog will depend on your specific needs and preferences. However, some of the most popular and well-regarded static site generators for blogs include:Jekyll: This is one of the most widely used static site generators and is well-suited for blogs and personal websites. Jekyll is built in Ruby and provides a simple and flexible way to create and manage a blog.Hugo: This is a fast and flexible static site generator that is well-suited for blogs and other types of websites. It is built in Go and provides a large number of features and customization options.Gatsby: This is a modern static site generator that is well-suited for creating fast and dynamic websites, including blogs. It is built with React and provides a powerful set of tools for creating and managing content.Hexo: This is a fast and simple static site generator that is well-suited for blogs and other types of websites. It is built in Node.js and provides a large number of plugins and themes for customizing your blog.Pelican: This is a static site generator that is well-suited for creating and managing blogs and other types of websites. It is built in Python and provides a simple and flexible way to create and manage content.All of these static site generators have their own strengths and weaknesses, so it’s important to evaluate each one to see which one is the best fit for your needs. Consider factors such as the ease of use, available themes and plugins, and overall performance when choosing a static site generator for your blog." }, { "title": "benefits of design patterns implementation", "url": "/posts/benefits-of-design-patterns-implementation/", "categories": "Blog", "tags": "blog", "date": "2023-02-10 00:00:00 +0530", "snippet": "Implementing design patterns in software development has several benefits, including:Reusability: Design patterns provide a common vocabulary and shared understanding for developers, allowing for m...", "content": "Implementing design patterns in software development has several benefits, including:Reusability: Design patterns provide a common vocabulary and shared understanding for developers, allowing for more efficient and effective communication about design decisions. Additionally, design patterns can be reused across multiple projects, reducing the amount of time and effort required to design and build new systems.Increased maintainability: Design patterns promote the separation of concerns, which makes the code easier to maintain and less prone to bugs. This also makes it easier for other developers to understand the code and make modifications, as they can easily identify which design pattern is being used and what it is intended to accomplish.Improved performance: Some design patterns are designed to improve performance in specific scenarios, such as the use of caching patterns to reduce the number of database lookups.Better scalability: Design patterns can help ensure that the code is scalable, making it easier to add new features and handle increasing amounts of data and user traffic.Reduced development time: By using proven design patterns, developers can focus on implementing business logic rather than figuring out how to structure the code. This can reduce the time it takes to develop and test software, leading to faster time-to-market.Overall, the use of design patterns can result in more robust, scalable, and maintainable code, which can lead to greater productivity and improved software quality." }, { "title": "Open External Links in a New Window Using JavaScript", "url": "/posts/open-external-links-in-a-new-window-using-javascript/", "categories": "Blog", "tags": "blog, external-links", "date": "2022-12-27 00:00:00 +0530", "snippet": "This is a quick post showing how to use JavaScript to make links to external websites open in a new window (or tab) instead of in the current window. This is useful for Jekyll blogs because the Mar...", "content": "This is a quick post showing how to use JavaScript to make links to external websites open in a new window (or tab) instead of in the current window. This is useful for Jekyll blogs because the Markdown converters don’t do this for you. I included two versions: one that uses straight JavaScript, and one that requires jQuery but is shorter.Both versions work basically the same way: grab all anchor tags &lt;a href=\"#\"&gt; that are linking to somewhere other than your development environment or a page on your site and then attribute target=\"_blank\" to those tags. Because this is JavaScript, users with JavaScript disabled will still experience the old behavior, but otherwise won’t be adversely affected.Straight JavaScriptThis version does not require any jQuery (or any other libraries):function ready(fn) { if (document.readyState != 'loading') { fn(); } else if (document.addEventListener) { document.addEventListener('DOMContentLoaded', fn); } else { document.attachEvent('onreadystatechange', function() { if (document.readyState != 'loading') fn(); }); }}ready(function() { var website = window.location.hostname; var internalLinkRegex = new RegExp('^((((http:\\\\/\\\\/|https:\\\\/\\\\/)(www\\\\.)?)?' + website + ')|(localhost:\\\\d{4})|(\\\\/.*))(\\\\/.*)?$', ''); var anchorEls = document.querySelectorAll('a'); var anchorElsLength = anchorEls.length; for (var i = 0; i &lt; anchorElsLength; i++) { var anchorEl = anchorEls[i]; var href = anchorEl.getAttribute('href'); if (!internalLinkRegex.test(href)) { anchorEl.setAttribute('target', '_blank'); } }});jQueryThis version requires jQuery in order to work, but if you’re using jQuery on your site anyway, it avoids reinventing the wheel:$(document).ready(function() { var website = window.location.hostname; var internalLinkRegex = new RegExp('^((((http:\\\\/\\\\/|https:\\\\/\\\\/)(www\\\\.)?)?' + website + ')|(localhost:\\\\d{4})|(\\\\/.*))(\\\\/.*)?$', ''); $('a').filter(function() { var href = $(this).attr('href'); return !internalLinkRegex.test(href); }) .each(function() { $(this).attr('target', '_blank'); });});My Implementation for Jekyll BlogI have created a file called external-links-new-window.html inside _includes directory and referred it from _layouts/default.html as ." }, { "title": "Text File Compressor De-compressor Web App", "url": "/posts/text-file-compressor-de-compressor-web-app/", "categories": "Projects", "tags": "project, txt-compressor", "date": "2022-12-25 00:00:00 +0530", "snippet": " This webapp uses Huffman Coding for Text Compression and De-compression. Made with JavaScript, HTML5 and CSS3. Live Demo: samirpaul1.github.io/txt-compressor Repository: github.com/SamirPaul1/...", "content": " This webapp uses Huffman Coding for Text Compression and De-compression. Made with JavaScript, HTML5 and CSS3. Live Demo: samirpaul1.github.io/txt-compressor Repository: github.com/SamirPaul1/txt-compressorAbout this application: An online text(.txt) file compressor, decompressor which uses Huffman Algorithm to encode/compress files by 35% and decode them back to the original size. This tool assigns a variable-length code to the characters of the uploaded file based on the frequency of occurrence. Then converts characters to that special code which takes less size than the original ASCII codes. Huffman code forms a binary tree assigning the most frequent characters with the smallest codes and longer codes for the least frequent characters. A Huffman code is a tree, built bottom up, starting with the list of different characters appearing in a text and their frequency. With this lossless data compression method, this tool can compress the file size by 35 to 40%. As file size gets reduced and original characters get changed to special characters so this encoding also improves security by encrypting the file during file sharing. With the decoding feature, the user can decode the encoded file and get back the original file of the previous size. I have used JavaScript to implement the algorithms so that browser can compile the code and HTML, CSS to make the website responsive. Additional instructions and warnings are provided if steps are not followed correctly. An Info page is added to give more information about tecnique of Lossless Data Compression with Huffman coding.Video Demo: Landing Page: Upload File Select Action (Compress / De-compress) Wait for File Download File gets downloaded automatically when selected process is complete. Compression - Compression Ratio is also displayed De-compression Additional Instructions and Warnings are provided if the above steps are not followed correctly About the tecnique of Lossless Data Compression with Huffman coding." }, { "title": "Some of My Online Courses Certificates", "url": "/posts/some-of-my-online-courses-certificates/", "categories": "Computer Science, Certifications", "tags": "certificates", "date": "2022-11-12 00:00:00 +0530", "snippet": "✅ Some of my verified skills and certifications:", "content": "✅ Some of my verified skills and certifications:" }, { "title": "Online PDF Compression Tool", "url": "/posts/online-pdf-compression-tool/", "categories": "Projects", "tags": "project, online-pdf-compressor", "date": "2022-10-29 00:00:00 +0530", "snippet": "About The Project:An online PDF file compression tool to reduce the size of a .pdf file. Python Flask is used to upload the file to a temporary location on the server. In the backend, using the PDF...", "content": "About The Project:An online PDF file compression tool to reduce the size of a .pdf file. Python Flask is used to upload the file to a temporary location on the server. In the backend, using the PDFNetPython library that file gets reduced and saved to its final location. After download, the files are automatically deleted from the server after 1 hour. Technologies used in this project: Python3, Flask, C, Shell, Nix, Replit, Git, HTML, CSS, JavaScript. Live Demo 🚀 Video Demo: Landing Page:Flask File Uploading:In HTML form, the enctype property is set to \"multipart/form-data\" to publish the file to the URL.The URL handler extracts the file from the request.files [] object and saves it to the required location. The path to the upload folder is defined as app.config['UPLOAD_FOLDER'] and maximum size (in bytes) asmaximum size (in bytes).The server-side flask script fetches the file from the request object using name = request.files['file'].filename.On successfully uploading the file, it is saved to the desired location on the server.Here’s the Python code for the Flask application.from flask import Flask, render_template, requestfrom werkzeug import secure_filenameapp = Flask(__name__)@app.route('/upload')def upload_file(): return render_template('upload.html')\t@app.route('/uploader', methods = ['GET', 'POST'])def upload_file(): if request.method == 'POST': f = request.files['file'] f.save(secure_filename(f.filename)) return 'file uploaded successfully'\t\tif __name__ == '__main__': app.run(debug = True)How PDF is compressed in backend:import osimport sysfrom PDFNetPython3.PDFNetPython import PDFDoc, Optimizer, SDFDoc, PDFNetdef compress_file(input_file: str, output_file: str): if not output_file: output_file = input_file try: PDFNet.Initialize() doc = PDFDoc(input_file) doc.InitSecurityHandler() Optimizer.Optimize(doc) doc.Save(output_file, SDFDoc.e_linearized) doc.Close() except Exception as e: doc.Close() return False return Trueif __name__ == \"__main__\": input_file = sys.argv[1] output_file = sys.argv[2] compress_file(input_file, output_file)File Download:function downloadFile(filename) {\tif(response !== null) {\t\tfname = response.filename;\t var url = \"static/resource/\" + fname.toString(2);\t console.log(url);\t fetch(url)\t .then(response =&gt; response.blob())\t .then(blob =&gt; {\t const link = document.createElement(\"a\");\t link.href = URL.createObjectURL(blob);\t link.download = fname;\t link.click();\t })\t .catch(console.error);\t}}🤔 How to contribute Fork this repository; Create a branch with your feature: git checkout -b my-feature; Commit your changes: git commit -m \"feat: my new feature\"; Push to your branch: git push origin my-feature." }, { "title": "Lists of Technical Interview Questions", "url": "/posts/lists-of-technical-interview-questions/", "categories": "Interview", "tags": "Interview", "date": "2022-10-26 00:00:00 +0530", "snippet": " A curated list of lists of technical interview questions.Table of Contents Programming Languages/Frameworks/Platforms Android AngularJS Angular BackboneJS C++ C...", "content": " A curated list of lists of technical interview questions.Table of Contents Programming Languages/Frameworks/Platforms Android AngularJS Angular BackboneJS C++ C C♯ .NET Clojure CSS Cucumber Django Docker Elastic EmberJS Erlang Golang GraphQl HTML Ionic iOS Java JavaScript jQuery Front-end build tools KnockoutJS Less Lisp NodeJS Objective-C PHP Python ReactJS Rails Ruby Rust Sass Scala Shell Spark Swift Vue.js Wordpress TypeScript Database technologies Cassandra Microsoft Access MongoDB MySQL Neo4j Oracle Postgres SQL SQL Lite Caching technologies Memcached Redis OS Linux Windows Algorithms Blockchain Coding exercises Comprehensive lists Design patterns Data structures Networks Security Data ScienceProgramming Languages/Frameworks/PlatformsAndroid 10 Android interview question answers for Freshers 20 Essential Android Interview Questions from Toptal 25 Essential Android Interview Questions from Adeva A couple of Android questions posted by Quora users A great list of Android interview questions covering all the aspects of this career Collection of Android and Java related questions and topics, including general developer questions, Java core, Data structures, Build Tools, Programming Paradigms, Core Android, Databases and etc Collection of Android and Java questions divided by experience RocketSkill App Android Interview Questions Android cheat sheet: Coding program, Data structure, Android and Java interview questions with answers and categorized by topics Android Interview Questions And Answers From Beginner To Advanced Interview Questions for Senior Android Developers 35+ Android Interview QuestionsAngularJS 12 Essential AngularJS Interview Questions from Toptal An AngularJS exam with questions from beginner to expert by @gdi2290 from @AngularClass 29 AngularJS Interview Questions – Can You Answer Them All? Great Article from Codementor AngularJS interview questions and answers for experienced developers AngularJS Interview Questions which have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of AngularJS This article discusses the top 50 Most occurred AngularJS interview question with answers Top 25 Angularjs Interview Questions and Quiz 100 AngularJS Interview Questions - Quick RefresherAngular A list of helpful Angular related questions you can use to interview potential candidates, test yourself or completely ignore Angular 2 Interview Questions List of 300 Angular Interview Questions and Answers Angular Interview Questions (2020) Top Angular Interview Questions and Answers in 2021BackboneJS 8 Essential Backbonejs Interview Questions from Toptal Backbonejs Interview Questions And Answers from web technology experts notes Top 25 Backbone.js interview questionsC++ 1000+ Multiple Choice Questions &amp; Answers in C++ with explanations 200 C++ interview questions and answers 24 Essential C++ Interview Questions from Toptal C++ Interview Questions from GeekInterview C++ Programming Q&amp;A and quizzes from computer science portal for geeks C++ Programming Questions and Answers related to such topics as OOPs concepts, Object and Classes, Functions, Constructors and Destructors, Inheritance and etc LeetCode Problems’ Solutions written in C++C Basic C language technical frequently asked interview questions and answers It includes data structures, pointers interview questions and answers for experienced C Programming Interview Questions and Answers for such topics as Bits and Bytes, Preprocessors, Functions, Strings, Language basics and etc C Programming Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of C Programming First set of commonly asked C programming interview questions from computer science portal for geeks Second set of commonly asked C programming interview questions from computer science portal for geeks 9 Essential C Interview Questions with answers Top C Interview Questions and AnswersC# 15 Essential C# Interview Question from Toptal C# interview questions from dotnetfunda.com Top 50 C# Interview Questions &amp; Answers 50 C# Coding Interview Questions and Answers 20 C# OOPS Interview Questions and Answers 30+ C# Interview Questions.NET 300 ASPNET interview questions and answers ASP.NET Core Interview Questions Great list of NET interview questions covering all the NET platform topics NET Interview Questions and Answers for Beginners which consists of the most frequently asked questions in NET This list of 100+ questions and answers gauge your familiarity with the NET platform Questions gathered by community of the StackOverflow What Great NET Developers Ought To Know (More NET Interview Questions)Clojure Classic ‘Fizz Buzz’ interview question for Clojure developers Clojure Interview Questions for experienced devs Coding exercises in Clojure, handy practice for technical interview questions Experience and questions from Clojure developer interview collected by Reddit users Interview cake Clojure solutionsCSS CSS interview questions and answers for freshers and experienced candidates Also there you can find CSS online practice tests to fight written tests and certification exams on CSS Development hiring managers and potential interviewees may find there sample CSS proficiency interview Q&amp;As and code snippets useful Interview Questions and Exercises About CSS Top 50 CSS(Cascading Style Sheet) Interview Questions covering the most of tricky CSS moments Front End Interview Handbook - CSS Questions and AnswersCucumber Cucumber Web Application BDD Sample Interview Questions Guide to building a simple Cucumber + Watir page object pattern frameworkDjango Some abstract interview questions for Python/Django developers Some Django basic interview questions to establish the basic level of the candidates Top 16 Django Interview Questions for both freshers and experienced developersDocker Docker Interview Questions Top Docker Interview Questions You Must Prepare In 2019 Top Docker Interview Questions And Answers DOCKER (SOFTWARE) INTERVIEW QUESTIONS &amp; ANSWERS 30 Docker Interview Questions and Answers in 2019 Docker Interview Questions &amp; Answers Top 50 Docker Interview Questions &amp; Answers Top 50+ Docker Interview Questions and Answers in 2021Elastic Top Elastic Stack Interview QuestionsEmberJS 8 Essential Emberjs Interview Questions from Toptal Top 25 Emberjs Interview Questions for both freshers and experienced developersErlang Top 22 Erlang Interview Questions for both freshers and experienced developersGolang Solutions for Elements of Programming Interviews problems written in Golang Solutions for some basic coding interview tasks written in Go Top 20 GO Programming Interview Questions for both freshers and experienced developersGraphQl 8 GraphQl Interview Questions To Know How to GraphQl - Common QuestionsHTML 10 Typical HTML Interview Exercises from SitePoint.com 16 Essential HTML5 Interview Questions from Toptal 40 important HTML 5 Interview questions with answers HTML interview questions and answers for freshers and experienced candidates Also find HTML online practice tests to fight written tests and certification exams on HTML Top 50 HTML Interview Questions for both freshers and experienced developers Common HTML interview questions for freshers Front End Interview Handbook - HTML Questions and Answers 30 HTML Interview Questions and Answers 30+ HTML Interview Questions (2021)Ionic 23 Beginner Level Ionic Framework Questions 12 Essential Ionic Interview Questions 45 Ionic Interview Questions Most Asked Ionic Interview QuestionsiOS 14 Essential iOS Interview Questions from Toptal 20 iOS Developer Interview Questions and Answers for getting you ready for your interview 25 Essential iOS Interview Questions from Adeva A small guide to help those looking to hire a developer or designer for iOS work While tailored for iOS, many questions could be used for Android developers or designers as well A great self-test if you’re looking to keep current or practice for your own interview All you need to know about iOS technical interview including some tips for preparing, questions and some coding exercises Interview Questions for iOS and Mac Developers from the CEO of Black Pixel iOS Interview Questions and Answers including such topics as Development Basics, App states and multitasking, App states, Core app objects iOS Interview Questions For Senior Developers 50 iOS Interview Questions And Answers 1 50 iOS Interview Questions And Answers Part 2 50 iOS Interview Questions And Answers Part 3 50 iOS Interview Questions And Answers Part 4 50 iOS Interview Questions And Answers Part 5 10 iOS interview questions and answers iOS Developer and Designer Interview Questions IOS Interview Questions and Answers iOS Interview Questions For Beginners Babylon iOS Interview Questions RocketSkill App iOS Interview Questions iOS Static vs Dynamic DispatchJava List of Java programs for interview Categoriwise 115 Java Interview Questions and Answers – The ULTIMATE List 37 Java Interview Questions to Practice With from Codementor 21 Essential Java Interview Questions Top 30 Core Java Interview Questions 29 Essential Java Interview Questions from Adeva A collection of Java interview questions and answers to them Data Structures and Algorithms in Java which can be useful in interview process Java Interview Questions: How to crack the TOP 15 questions 300 Core Java Interview Questions Top 10 Tricky Java interview questions and Answers Top 25 Most Frequently Asked Interview Core Java Interview Questions And Answers Top 40 Core Java Interview Questions Answers from Telephonic Round Top 50 Spring Interview Questions You Must Prepare For In 2020 Spring Interview Questions And Answers Interview Cake Java Interview Questions Java Interview Questions &amp; Quizzes Essetial Java Interview Questions Fundamental Java Interview QuestionsJavaScript Practice common algorithms using JavaScript 10 Interview Questions Every JavaScript Developer Should Know 21 Essential JavaScript Interview Questions from best mentors all over the world 20 Essential JavaScript Interview Questions from Adeva 37 Essential JavaScript Interview Questions from Toptal 5 More JavaScript Interview Exercises 5 Typical JavaScript Interview Exercises Development hiring managers and potential interviewees may find these sample JavaScript proficiency interview Q&amp;As and code snippets useful 123 Essential JavaScript Interview Question JavaScript Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of JavaScript JS: Basics and Tricky Questions JS: Interview Algorithm Some basic javascript coding challenges and interview questions Some JavaScript interview exercises Ten Questions I’ve Been Asked, Most More Than Once, Over Six Technical JavaScript / Front-End Engineer Job Interviews. Top 85 JavaScript Interview Questions Interview Cake JavaScript Interview Questions The Best Frontend JavaScript Interview Questions (written by a Frontend Engineer) 10 JavaScript Concepts You Need to Know for Interviews Front End Interview Handbook - JavaScript Questions and Answers JavaScript Interview Questions - Quick Refresher The MEGA Interview Guide Javascript Interview Questions and Answers (2020) JavaScript Modern Interview Code Challenges 2021 70 JavaScript Interview QuestionsjQuery Top 50 jquery interview questions 17 Essential jQuery Interview Questions From Toptal Top JQuery Interview Questions and AnswersFront-end build tools Webpack interview questions &amp; answers Gulp js interview questions Grunt js interview questions for beginners Grunt js interview questionsKnockoutJS 15 interview questions from CodeSample.com 20 questions you might be asked about KnockoutJS in an interview for both freshers and experienced developersLess Top 25 LESS Interview QuestionsLisp 10 LISP Questions &amp; Answers Top 18 Lisp Interview Questions from Career GuruNodeJS 25 Essential Node.js Interview Questions from Adeva 8 Essential Nodejs Interview Questions from Toptal Node.JS Interview Questions have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of Node.JS Node.js Interview Questions and Answers Top 25 Nodejs Interview Questions &amp; Answers from Career Guru Top 30 Node.Js Interview Questions With Answers Top Nodejs Interview Questions &amp; Answers Node.js Interview Questions in Chinese Node.js Interview Questions by learning-zoneObjective-C Interview Qs for Objective-C and Swift iOS Interview Questions For BeginnersPHP 100 PHP interview questions and answers from CareerRide.com 21 Essential PHP Interview Questions from Toptal 20 Common PHP Job Interview Questions and Answers 25 Essential PHP Interview Questions from Adeva PHP interview questions and answers for freshers Top 100 PHP Interview Questions &amp; Answers from CareerGuru 25 PHP Interview Questions 26 Essential PHP Interview Questions for 2018 Cracking PHP Interviews Questions ebook 300+ Q&amp;A PHP Interview Questions - Quick Refresher 30+ PHP Interview QuestionsPython 26 Essential Python Interview Questions from Adeva 20 Python interview questions and answers 11 Essential Python Interview Questions from Toptal A listing of questions that could potentially be asked for a python job listing Interview Questions for both beginners and experts Interview Cake Python Interview Questions Python Frequently Asked Questions (Programming) Python interview questions collected by Reddit users Top 25 Python Interview Questions from Career Guru Python Interview 10 questions from Corey Schafer Python interview questions. Part I. Junior Python interview questions. Part II. Middle Python interview questions. Part III. Senior Python Interview Questions and Answers (2019) 100 Python Interview Questions - Quick Refresher Top 100 Python Interview Questions from Edureka (2021)Ruby on Rails 20 Ruby on Rails interview questions and answers from CareerRide.com 9 Essential Ruby on Rails Interview Questions from Toptal High-level Ruby on Rails Interview Questions Ruby And Ruby On Rails interview Q&amp;A Some of the most frequently asked Ruby on Rails questions and how to answer them confidently 11 Ruby on Rails Interview Practice Questions Top 53 Ruby on Rails Interview Questions &amp; Answers 10 Ruby on Rails interview questions and answersReactJS Reddit users share their expectations from ReactJS interview 5 Essential React.js Interview Questions React Interview Questions Toptal’s 21 Essential React.js Interview Questions 19 Essential ReactJs Interview Questions React Interview Questions &amp; AnswersRuby 21 Essential Ruby Interview Questions from Toptal 15 Questions to Ask During a Ruby Interview A list of questions about Ruby programming you can use to quiz yourself The Art of Ruby Technical Interview Interview Cake Ruby Interview Questions Frequently Asked Ruby Interview QuestionsRust Top 250+ Rust Programming Language Interview Questions Rust Programming Interview Questions and Answers rust-exam: A set of questions about the Rust programming language Best Rust Programming Language Interview Questions and answersSass Top 17 Sass Interview Questions from Career Guru Top 10 Sass Interview Questions from educbaScala 4 Interview Questions for Scala Developers A list of Frequently Asked Questions and their answers, sorted by category A list of helpful Scala related questions you can use to interview potential candidates How Scala Developers Are Being Interviewed Top 25 Scala Interview Questions &amp; Answers from ToptalSharePoint Sharepoint Interview Question For Developer Top SharePoint Interview Questions and AnswersShell Top 50 Shell Scripting Interview Questions from Career GuruSpark Carefully Curated 70 Spark Questions with Additional Optimization Guides (First in the series)Swift 10 Essential Swift Interview Questions from Toptal Get prepared for your next iOS job interview by studying high quality LeetCode solutions in Swift 5 Swift Interview Questions and Answers Swift Programming Language Interview Questions And Answers from mycodetips.com Your top 10 Swift questions answered Swift interview questions and answers on Swift 5 by Raywenderlich Dynamic keyword in SwiftVue.js List of 300 VueJS Interview QuestionsWordPress Top 45 WordPress interview questions 10 Essential WordPress Interview QuestionsTypeScript Typescript Interview Questions Top 10 TypeScript Interview Questions and Answers for Beginner Web Developers 2019Database technologiesCassandra Top 23 Cassandra Interview Questions from Career GuruMicrosoft Access Top 16 Microsoft Access Database Interview Questions from Career GuruMongoDB 28 MongoDB NoSQL Database Interview Questions and Answers MongoDB frequently Asked Questions by expert members with experience in MongoDB These questions and answers will help you strengthen your technical skills, prepare for the new job test and quickly revise the concepts MongoDB Interview Questions from JavaTPointcom MongoDB Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of MongoDB Top 20 MongoDB interview questions from Career GuruMySQL 10 MySQL Database Interview Questions for Beginners and Intermediates 100 MySQL interview questions 15 Basic MySQL Interview Questions for Database Administrators 28 MySQL interview questions from JavaTPoint.com 40 Basic MySQL Interview Questions with Answers Top 50 MySQL Interview Questions &amp; Answers from Career GuruNeo4j Top 20 Neo4j Interview Questions from Career GuruOracle General Oracle Interview Questions &amp; AnswersPostgres 13 PostgreSQL Interview Q&amp;A Frequently Asked Basic PostgreSQL Interview Questions and Answers PostgreSQL Interview Preparation Guide PostgreSQL Interview Q&amp;A from CoolInterview.comSQL 10 Frequently asked SQL Query Interview Questions 45 Essential SQL Interview Questions from Toptal Common Interview Questions and Answers General Interview Questions and Answers Schema, Questions &amp; Solutions for SQL Exercising SQL Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of SQL SQL Interview Questions CHEAT SHEETSQLite Top 20 SQLITE Interview Questions from Career GuruCaching technologiesMemcached Memcached Interview Questions from Javapoint Memcached Interview Questions from WisdomjobsRedis Redis Interview Questions from Javapoint Redis Interview Questions from Wisdomjobs Redis Interview Questions from Career GuruOSLinux 10 Job Interview Questions for Linux System Administrators from Linux.com 10 Useful Random Linux Interview Questions and Answers 11 Basic Linux Interview Questions and Answers 11 Essential Linux Interview Questions from Toptal Top 30 Linux System Admin Interview Questions &amp; Answers Top 50 Linux Interview Questions from Career Guru 278 Test Questions and Answers for *nix System Administrators Linux Interview Questions - Quick RefresherWindows Top 10 Interview Questions for Windows Administrators Top 22 Windows Server Interview Questions from Career Guru Windows Admin Interview Questions &amp; AnswersDevOps Linux System Administrator/DevOps Interview Questions Top DevOps Interview Questions You Must Prepare In 2021 Top 60+ DevOps Interview Questions &amp; Answers in 2021 DevOps Interview Questions &amp; AnswersAlgorithms Comprehensive list of interview questions of top tech companies A great list of Java interview questions Algorithms playground for common interview questions written in Ruby EKAlgorithms contains some well known CS algorithms &amp; data structures Top 10 Algorithms for Coding Interview Top 15 Data Structures and Algorithm Interview Questions for Java programmer Tech Interview Handbook Best Practice Questions Daily Coding Interview PracticeBlockchain Top 55 Blockchain Interview Questions You Must Prepare In 2018 Blockchain Interview Questions Top Blockchain Interview Questions Blockchain Developer Interview Questions and Answers 10 Essential Blockchain Interview Questions Top 30 Blockchain Interview Questions – For Freshers to Experienced Most Frequently Asked Blockchain Interview QuestionsCoding exercises Common interview questions and puzzles solved in several languages Interactive, test-driven Python coding challenges (algorithms and data structures) typically found in coding interviews or coding competitions Interview questions solved in python 7 Swift Coding Challenges to Practice Your SkillsComprehensive lists A list of helpful front-end related questions you can use to interview potential candidates, test yourself or completely ignore Front End Developer Interview Questions Front End Interview Handbook Some simple questions to interview potential backend candidatesDesign Patterns Design Pattern Interview Questions that have been designed specially to get you acquainted with the nature of questions you may encounter during your interview for the subject of Design Pattern Design Patterns for Humans™ - An ultra-simplified explanation Design Patterns implemented in Java Design Patterns implemented in DotNetData structures Top 15 Data Structures and Algorithm Interview Questions for Java programmer Top 50 Data Structure Interview Questions from Career Guru [What is Data Structure? Top 40 Data Structure Interview Questions](https://www.interviewbit.com/data-structure-interview-questions/) Networks Top 100 Networking Interview Questions &amp; Answers from Career Guru Networking Interview QuestionsSecurity 101 IT Security Interview Questions How to prepare for an information security job interview? Information Security Interview Questions from Daniel Miessler Top 50 Information Security Interview Questions for freshers and expertsData Science Data Science Interview Questions for Top Tech Companies 66 Job Interview Questions for Data Scientists Top 45 Data Science Interview Questions You Must Prepare In 2021 Top 30 data science interview questions Top 100 Data science interview questions Data Science Interview Questions 160+ Data Science Interview Questions Top Data Science Interview Questions" }, { "title": "List of Python Frameworks Libraries Software and Resources", "url": "/posts/list-of-python-frameworks-libraries-software-and-resources/", "categories": "Python, Frameworks and Libraries", "tags": "python, python-frameworks-libraries", "date": "2022-10-26 00:00:00 +0530", "snippet": " A curated list of awesome Python frameworks, libraries, software and resources. Awesome Python Admin Panels Algorithms and Design Patterns ASGI Servers Asynchronous Progr...", "content": " A curated list of awesome Python frameworks, libraries, software and resources. Awesome Python Admin Panels Algorithms and Design Patterns ASGI Servers Asynchronous Programming Audio Authentication Build Tools Built-in Classes Enhancement Caching ChatOps Tools CMS Code Analysis Command-line Interface Development Command-line Tools Compatibility Computer Vision Concurrency and Parallelism Configuration Cryptography Data Analysis Data Validation Data Visualization Database Drivers Database Date and Time Debugging Tools Deep Learning DevOps Tools Distributed Computing Distribution Documentation Downloader E-commerce Editor Plugins and IDEs Email Enterprise Application Integrations Environment Management Files Foreign Function Interface Forms Functional Programming Game Development Geolocation GUI Development Hardware HTML Manipulation HTTP Clients Image Processing Implementations Interactive Interpreter Internationalization Job Scheduler Logging Machine Learning Miscellaneous Natural Language Processing Network Virtualization News Feed ORM Package Management Package Repositories Penetration testing Permissions Processes Recommender Systems Refactoring RESTful API Robotics RPC Servers Science Search Serialization Serverless Frameworks Shell Specific Formats Processing Static Site Generator Tagging Task Queues Template Engine Testing Text Processing Third-party APIs URL Manipulation Video Web Asset Management Web Content Extracting Web Crawling Web Frameworks WebSocket WSGI Servers Resources Books Newsletters Podcasts Websites ContributingAdmin PanelsLibraries for administrative interfaces. ajenti - The admin panel your servers deserve. django-grappelli - A jazzy skin for the Django Admin-Interface. django-jet - Modern responsive template for the Django admin interface with improved functionality. django-suit - Alternative Django Admin-Interface (free only for Non-commercial use). django-xadmin - Drop-in replacement of Django admin comes with lots of goodies. flask-admin - Simple and extensible administrative interface framework for Flask. flower - Real-time monitor and web admin for Celery. jet-bridge - Admin panel framework for any application with nice UI (ex Jet Django). wooey - A Django app which creates automatic web UIs for Python scripts.Algorithms and Design PatternsPython implementation of data structures, algorithms and design patterns. Also see awesome-algorithms. Algorithms algorithms - Minimal examples of data structures and algorithms. python-ds - A collection of data structure and algorithms for coding interviews. sortedcontainers - Fast and pure-Python implementation of sorted collections. TheAlgorithms - All Algorithms implemented in Python. Design Patterns PyPattyrn - A simple yet effective library for implementing common design patterns. python-patterns - A collection of design patterns in Python. transitions - A lightweight, object-oriented finite state machine implementation. ASGI ServersASGI-compatible web servers. daphne - A HTTP, HTTP2 and WebSocket protocol server for ASGI and ASGI-HTTP. uvicorn - A lightning-fast ASGI server implementation, using uvloop and httptools.Asynchronous Programming asyncio - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks. awesome-asyncio trio - A friendly library for async concurrency and I/O. Twisted - An event-driven networking engine. uvloop - Ultra fast asyncio event loop.AudioLibraries for manipulating audio and its metadata. Audio audioread - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding. dejavu - Audio fingerprinting and recognition. kapre - Keras Audio Preprocessors. librosa - Python library for audio and music analysis. matchering - A library for automated reference audio mastering. mingus - An advanced music theory and notation package with MIDI file and playback support. pyAudioAnalysis - Audio feature extraction, classification, segmentation and applications. pydub - Manipulate audio with a simple and easy high level interface. TimeSide - Open web audio processing framework. Metadata beets - A music library manager and MusicBrainz tagger. eyeD3 - A tool for working with audio files, specifically MP3 files containing ID3 metadata. mutagen - A Python module to handle audio metadata. tinytag - A library for reading music meta data of MP3, OGG, FLAC and Wave files. AuthenticationLibraries for implementing authentications schemes. OAuth authlib - JavaScript Object Signing and Encryption draft implementation. django-allauth - Authentication app for Django that “just works.” django-oauth-toolkit - OAuth 2 goodies for Django. oauthlib - A generic and thorough implementation of the OAuth request-signing logic. python-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers. python-social-auth - An easy-to-setup social authentication mechanism. JWT pyjwt - JSON Web Token implementation in Python. python-jose - A JOSE implementation in Python. python-jwt - A module for generating and verifying JSON Web Tokens. Build ToolsCompile software from source code. BitBake - A make-like build tool for embedded Linux. buildout - A build system for creating, assembling and deploying applications from multiple parts. PlatformIO - A console tool to build code with different development platforms. pybuilder - A continuous build tool written in pure Python. SCons - A software construction tool.Built-in Classes EnhancementLibraries for enhancing Python built-in classes. attrs - Replacement for __init__, __eq__, __repr__, etc. boilerplate in class definitions. bidict - Efficient, Pythonic bidirectional map data structures and related functionality.. Box - Python dictionaries with advanced dot notation access. dataclasses - (Python standard library) Data classes. DottedDict - A library that provides a method of accessing lists and dicts with a dotted path notation.CMSContent Management Systems. django-cms - An Open source enterprise CMS based on the Django. feincms - One of the most advanced Content Management Systems built on Django. indico - A feature-rich event management system, made @ CERN. Kotti - A high-level, Pythonic web application framework built on Pyramid. mezzanine - A powerful, consistent, and flexible content management platform. plone - A CMS built on top of the open source application server Zope. quokka - Flexible, extensible, small CMS powered by Flask and MongoDB. wagtail - A Django content management system.CachingLibraries for caching data. beaker - A WSGI middleware for sessions and caching. django-cache-machine - Automatic caching and invalidation for Django models. django-cacheops - A slick ORM cache with automatic granular event-driven invalidation. dogpile.cache - dogpile.cache is a next generation replacement for Beaker made by the same authors. HermesCache - Python caching library with tag-based invalidation and dogpile effect prevention. pylibmc - A Python wrapper around the libmemcached interface. python-diskcache - SQLite and file backed cache backend with faster lookups than memcached and redis.ChatOps ToolsLibraries for chatbot development. errbot - The easiest and most popular chatbot to implement ChatOps.Code AnalysisTools of static analysis, linters and code quality checkers. Also see awesome-static-analysis. Code Analysis coala - Language independent and easily extendable code analysis application. code2flow - Turn your Python and JavaScript code into DOT flowcharts. prospector - A tool to analyse Python code. pycallgraph - A library that visualises the flow (call graph) of your Python application. vulture - A tool for finding and analysing dead Python code. Code Linters flake8 - A wrapper around pycodestyle, pyflakes and McCabe. awesome-flake8-extensions pylama - A code audit tool for Python and JavaScript. pylint - A fully customizable source code analyzer. wemake-python-styleguide - The strictest and most opinionated python linter ever. Code Formatters black - The uncompromising Python code formatter. isort - A Python utility / library to sort imports. yapf - Yet another Python code formatter from Google. Static Type Checkers, also see awesome-python-typing mypy - Check variable types during compile time. pyre-check - Performant type checking. typeshed - Collection of library stubs for Python, with static types. Static Type Annotations Generators MonkeyType - A system for Python that generates static type annotations by collecting runtime types. pyannotate - Auto-generate PEP-484 annotations. pytype - Pytype checks and infers types for Python code - without requiring type annotations. Command-line Interface DevelopmentLibraries for building command-line applications. Command-line Application Development cement - CLI Application Framework for Python. click - A package for creating beautiful command line interfaces in a composable way. cliff - A framework for creating command-line programs with multi-level commands. docopt - Pythonic command line arguments parser. python-fire - A library for creating command line interfaces from absolutely any Python object. python-prompt-toolkit - A library for building powerful interactive command lines. Terminal Rendering alive-progress - A new kind of Progress Bar, with real-time throughput, eta and very cool animations. asciimatics - A package to create full-screen text UIs (from interactive forms to ASCII animations). bashplotlib - Making basic plots in the terminal. colorama - Cross-platform colored terminal text. rich - Python library for rich text and beautiful formatting in the terminal. Also provides a great RichHandler log handler. tqdm - Fast, extensible progress bar for loops and CLI. Command-line ToolsUseful CLI-based tools for productivity. Productivity Tools copier - A library and command-line utility for rendering projects templates. cookiecutter - A command-line utility that creates projects from cookiecutters (project templates). doitlive - A tool for live presentations in the terminal. howdoi - Instant coding answers via the command line. Invoke - A tool for managing shell-oriented subprocesses and organizing executable Python code into CLI-invokable tasks. PathPicker - Select files out of bash output. percol - Adds flavor of interactive selection to the traditional pipe concept on UNIX. thefuck - Correcting your previous console command. tmuxp - A tmux session manager. try - A dead simple CLI to try out python packages - it’s never been easier. CLI Enhancements httpie - A command line HTTP client, a user-friendly cURL replacement. iredis - Redis CLI with autocompletion and syntax highlighting. kube-shell - An integrated shell for working with the Kubernetes CLI. litecli - SQLite CLI with autocompletion and syntax highlighting. mycli - MySQL CLI with autocompletion and syntax highlighting. pgcli - PostgreSQL CLI with autocompletion and syntax highlighting. saws - A Supercharged aws-cli. CompatibilityLibraries for migrating from Python 2 to 3. python-future - The missing compatibility layer between Python 2 and Python 3. modernize - Modernizes Python code for eventual Python 3 migration. six - Python 2 and 3 compatibility utilities.Computer VisionLibraries for Computer Vision. EasyOCR - Ready-to-use OCR with 40+ languages supported. Face Recognition - Simple facial recognition library. Kornia - Open Source Differentiable Computer Vision Library for PyTorch. OpenCV - Open Source Computer Vision Library. pytesseract - A wrapper for Google Tesseract OCR. SimpleCV - An open source framework for building computer vision applications. tesserocr - Another simple, Pillow-friendly, wrapper around the tesseract-ocr API for OCR.Concurrency and ParallelismLibraries for concurrent and parallel execution. Also see awesome-asyncio. concurrent.futures - (Python standard library) A high-level interface for asynchronously executing callables. eventlet - Asynchronous framework with WSGI support. gevent - A coroutine-based Python networking library that uses greenlet. multiprocessing - (Python standard library) Process-based parallelism. scoop - Scalable Concurrent Operations in Python. uvloop - Ultra fast implementation of asyncio event loop on top of libuv.ConfigurationLibraries for storing and parsing configuration options. configobj - INI file parser with validation. configparser - (Python standard library) INI file parser. hydra - Hydra is a framework for elegantly configuring complex applications. profig - Config from multiple formats with value conversion. python-decouple - Strict separation of settings from code.Cryptography cryptography - A package designed to expose cryptographic primitives and recipes to Python developers. paramiko - The leading native Python SSHv2 protocol library. passlib - Secure password storage/hashing library, very high level. pynacl - Python binding to the Networking and Cryptography (NaCl) library.Data AnalysisLibraries for data analyzing. AWS Data Wrangler - Pandas on AWS. Blaze - NumPy and Pandas interface to Big Data. Open Mining - Business Intelligence (BI) in Pandas interface. Optimus - Agile Data Science Workflows made easy with PySpark. Orange - Data mining, data visualization, analysis and machine learning through visual programming or scripts. Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools.Data ValidationLibraries for validating data. Used for forms in many cases. Cerberus - A lightweight and extensible data validation library. colander - Validating and deserializing data obtained via XML, JSON, an HTML form post. jsonschema - An implementation of JSON Schema for Python. schema - A library for validating Python data structures. Schematics - Data Structure Validation. valideer - Lightweight extensible data validation and adaptation library. voluptuous - A Python data validation library.Data VisualizationLibraries for visualizing data. Also see awesome-javascript. Altair - Declarative statistical visualization library for Python. Bokeh - Interactive Web Plotting for Python. bqplot - Interactive Plotting Library for the Jupyter Notebook. Cartopy - A cartographic python library with matplotlib support. Dash - Built on top of Flask, React and Plotly aimed at analytical web applications. awesome-dash diagrams - Diagram as Code. Matplotlib - A Python 2D plotting library. plotnine - A grammar of graphics for Python based on ggplot2. Pygal - A Python SVG Charts Creator. PyGraphviz - Python interface to Graphviz. PyQtGraph - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets. Seaborn - Statistical data visualization using Matplotlib. VisPy - High-performance scientific visualization based on OpenGL.DatabaseDatabases implemented in Python. pickleDB - A simple and lightweight key-value store for Python. tinydb - A tiny, document-oriented database. ZODB - A native object database for Python. A key-value and object graph database.Database DriversLibraries for connecting and operating databases. MySQL - awesome-mysql mysqlclient - MySQL connector with Python 3 support (mysql-python fork). PyMySQL - A pure Python MySQL driver compatible to mysql-python. PostgreSQL - awesome-postgres psycopg2 - The most popular PostgreSQL adapter for Python. queries - A wrapper of the psycopg2 library for interacting with PostgreSQL. SQlite - awesome-sqlite sqlite3 - (Python standard library) SQlite interface compliant with DB-API 2.0 SuperSQLite - A supercharged SQLite library built on top of apsw. Other Relational Databases pymssql - A simple database interface to Microsoft SQL Server. clickhouse-driver - Python driver with native interface for ClickHouse. NoSQL Databases cassandra-driver - The Python Driver for Apache Cassandra. happybase - A developer-friendly library for Apache HBase. kafka-python - The Python client for Apache Kafka. py2neo - A client library and toolkit for working with Neo4j. pymongo - The official Python client for MongoDB. redis-py - The Python client for Redis. Asynchronous Clients motor - The async Python driver for MongoDB. Date and TimeLibraries for working with dates and times. Arrow - A Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps. Chronyk - A Python 3 library for parsing human-written times and dates. dateutil - Extensions to the standard Python datetime module. delorean - A library for clearing up the inconvenient truths that arise dealing with datetimes. maya - Datetimes for Humans. moment - A Python library for dealing with dates/times. Inspired by Moment.js. Pendulum - Python datetimes made easy. PyTime - An easy-to-use Python module which aims to operate date/time/datetime by string. pytz - World timezone definitions, modern and historical. Brings the tz database into Python. when.py - Providing user-friendly functions to help perform common date and time actions.Debugging ToolsLibraries for debugging code. pdb-like Debugger ipdb - IPython-enabled pdb. pdb++ - Another drop-in replacement for pdb. pudb - A full-screen, console-based Python debugger. wdb - An improbable web debugger through WebSockets. Tracing lptrace - strace for Python programs. manhole - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt. pyringe - Debugger capable of attaching to and injecting code into Python processes. python-hunter - A flexible code tracing toolkit. Profiler line_profiler - Line-by-line profiling. memory_profiler - Monitor Memory usage of Python code. py-spy - A sampling profiler for Python programs. Written in Rust. pyflame - A ptracing profiler For Python. vprof - Visual Python profiler. Others django-debug-toolbar - Display various debug information for Django. django-devserver - A drop-in replacement for Django’s runserver. flask-debugtoolbar - A port of the django-debug-toolbar to flask. icecream - Inspect variables, expressions, and program execution with a single, simple function call. pyelftools - Parsing and analyzing ELF files and DWARF debugging information. Deep LearningFrameworks for Neural Networks and Deep Learning. Also see awesome-deep-learning. caffe - A fast open framework for deep learning.. keras - A high-level neural networks library and capable of running on top of either TensorFlow or Theano. mxnet - A deep learning framework designed for both efficiency and flexibility. pytorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration. SerpentAI - Game agent framework. Use any video game as a deep learning sandbox. tensorflow - The most popular Deep Learning framework created by Google. Theano - A library for fast numerical computation.DevOps ToolsSoftware and libraries for DevOps. Configuration Management ansible - A radically simple IT automation platform. cloudinit - A multi-distribution package that handles early initialization of a cloud instance. OpenStack - Open source software for building private and public clouds. pyinfra - A versatile CLI tools and python libraries to automate infrastructure. saltstack - Infrastructure automation and management system. SSH-style Deployment cuisine - Chef-like functionality for Fabric. fabric - A simple, Pythonic tool for remote execution and deployment. fabtools - Tools for writing awesome Fabric files. Process Management honcho - A Python clone of Foreman, for managing Procfile-based applications. supervisor - Supervisor process control system for UNIX. Monitoring psutil - A cross-platform process and system utilities module. Backup BorgBackup - A deduplicating archiver with compression and encryption. Others docker-compose - Fast, isolated development environments using Docker. Distributed ComputingFrameworks and libraries for Distributed Computing. Batch Processing dask - A flexible parallel computing library for analytic computing. luigi - A module that helps you build complex pipelines of batch jobs. mrjob - Run MapReduce jobs on Hadoop or Amazon Web Services. PySpark - Apache Spark Python API. Ray - A system for parallel and distributed Python that unifies the machine learning ecosystem. Stream Processing faust - A stream processing library, porting the ideas from Kafka Streams to Python. streamparse - Run Python code against real-time streams of data via Apache Storm. DistributionLibraries to create packaged executables for release distribution. dh-virtualenv - Build and distribute a virtualenv as a Debian package. Nuitka - Compile scripts, modules, packages to an executable or extension module. py2app - Freezes Python scripts (Mac OS X). py2exe - Freezes Python scripts (Windows). pyarmor - A tool used to obfuscate python scripts, bind obfuscated scripts to fixed machine or expire obfuscated scripts. PyInstaller - Converts Python programs into stand-alone executables (cross-platform). pynsist - A tool to build Windows installers, installers bundle Python itself. shiv - A command line utility for building fully self-contained zipapps (PEP 441), but with all their dependencies included.DocumentationLibraries for generating project documentation. sphinx - Python Documentation generator. awesome-sphinxdoc pdoc - Epydoc replacement to auto generate API documentation for Python libraries. pycco - The literate-programming-style documentation generator.DownloaderLibraries for downloading. akshare - A financial data interface library, built for human beings! s3cmd - A command line tool for managing Amazon S3 and CloudFront. s4cmd - Super S3 command line tool, good for higher performance. you-get - A YouTube/Youku/Niconico video downloader written in Python 3. youtube-dl - A small command-line program to download videos from YouTube.E-commerceFrameworks and libraries for e-commerce and payments. alipay - Unofficial Alipay API for Python. Cartridge - A shopping cart app built using the Mezzanine. django-oscar - An open-source e-commerce framework for Django. django-shop - A Django based shop system. forex-python - Foreign exchange rates, Bitcoin price index and currency conversion. merchant - A Django app to accept payments from various payment processors. money - Money class with optional CLDR-backed locale-aware formatting and an extensible currency exchange. python-currencies - Display money format and its filthy currencies. saleor - An e-commerce storefront for Django. shoop - An open source E-Commerce platform based on Django.Editor Plugins and IDEs Emacs elpy - Emacs Python Development Environment. Sublime Text anaconda - Anaconda turns your Sublime Text 3 in a full featured Python development IDE. SublimeJEDI - A Sublime Text plugin to the awesome auto-complete library Jedi. Vim jedi-vim - Vim bindings for the Jedi auto-completion library for Python. python-mode - An all in one plugin for turning Vim into a Python IDE. YouCompleteMe - Includes Jedi-based completion engine for Python. Visual Studio PTVS - Python Tools for Visual Studio. Visual Studio Code Python - The official VSCode extension with rich support for Python. IDE PyCharm - Commercial Python IDE by JetBrains. Has free community edition available. spyder - Open Source Python IDE. EmailLibraries for sending and parsing email. Mail Servers modoboa - A mail hosting and management platform including a modern Web UI. salmon - A Python Mail Server. Clients imbox - Python IMAP for Humans. yagmail - Yet another Gmail/SMTP client. Others flanker - An email address and Mime parsing library. mailer - High-performance extensible mail delivery framework. Enterprise Application IntegrationsPlatforms and tools for systems integrations in enterprise environments Zato - ESB, SOA, REST, APIs and Cloud Integrations in Python.Environment ManagementLibraries for Python version and virtual environment management. pyenv - Simple Python version management. virtualenv - A tool to create isolated Python environments.FilesLibraries for file manipulation and MIME type detection. mimetypes - (Python standard library) Map filenames to MIME types. path.py - A module wrapper for os.path. pathlib - (Python standard library) An cross-platform, object-oriented path library. PyFilesystem2 - Python’s filesystem abstraction layer. python-magic - A Python interface to the libmagic file type identification library. Unipath - An object-oriented approach to file/directory operations. watchdog - API and shell utilities to monitor file system events.Foreign Function InterfaceLibraries for providing foreign function interface. cffi - Foreign Function Interface for Python calling C code. ctypes - (Python standard library) Foreign Function Interface for Python calling C code. PyCUDA - A Python wrapper for Nvidia’s CUDA API. SWIG - Simplified Wrapper and Interface Generator.FormsLibraries for working with forms. Deform - Python HTML form generation library influenced by the formish form generation library. django-bootstrap3 - Bootstrap 3 integration with Django. django-bootstrap4 - Bootstrap 4 integration with Django. django-crispy-forms - A Django app which lets you create beautiful forms in a very elegant and DRY way. django-remote-forms - A platform independent Django form serializer. WTForms - A flexible forms validation and rendering library.Functional ProgrammingFunctional Programming with Python. Coconut - A variant of Python built for simple, elegant, Pythonic functional programming. CyToolz - Cython implementation of Toolz: High performance functional utilities. fn.py - Functional programming in Python: implementation of missing features to enjoy FP. funcy - A fancy and practical functional tools. more-itertools - More routines for operating on iterables, beyond itertools. returns - A set of type-safe monads, transformers, and composition utilities. Toolz - A collection of functional utilities for iterators, functions, and dictionaries.GUI DevelopmentLibraries for working with graphical user interface applications. curses - Built-in wrapper for ncurses used to create terminal GUI applications. Eel - A library for making simple Electron-like offline HTML/JS GUI apps. enaml - Creating beautiful user-interfaces with Declarative Syntax like QML. Flexx - Flexx is a pure Python toolkit for creating GUI’s, that uses web technology for its rendering. Gooey - Turn command line programs into a full GUI application with one line. kivy - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS. pyglet - A cross-platform windowing and multimedia library for Python. PyGObject - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3). PyQt - Python bindings for the Qt cross-platform application and UI framework. PySimpleGUI - Wrapper for tkinter, Qt, WxPython and Remi. pywebview - A lightweight cross-platform native wrapper around a webview component. Tkinter - Tkinter is Python’s de-facto standard GUI package. Toga - A Python native, OS native GUI toolkit. urwid - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc. wxPython - A blending of the wxWidgets C++ class library with the Python. DearPyGui - A Simple GPU accelerated Python GUI frameworkGraphQLLibraries for working with GraphQL. graphene - GraphQL framework for Python. tartiflette-aiohttp - An aiohttp-based wrapper for Tartiflette to expose GraphQL APIs over HTTP. tartiflette-asgi - ASGI support for the Tartiflette GraphQL engine. tartiflette - SDL-first GraphQL engine implementation for Python 3.6+ and asyncio.Game DevelopmentAwesome game development libraries. Arcade - Arcade is a modern Python framework for crafting games with compelling graphics and sound. Cocos2d - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications. Harfang3D - Python framework for 3D, VR and game development. Panda3D - 3D game engine developed by Disney. Pygame - Pygame is a set of Python modules designed for writing games. PyOgre - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D. PyOpenGL - Python ctypes bindings for OpenGL and it’s related APIs. PySDL2 - A ctypes based wrapper for the SDL2 library. RenPy - A Visual Novel engine.GeolocationLibraries for geocoding addresses and working with latitudes and longitudes. django-countries - A Django app that provides a country field for models and forms. GeoDjango - A world-class geographic web framework. GeoIP - Python API for MaxMind GeoIP Legacy Database. geojson - Python bindings and utilities for GeoJSON. geopy - Python Geocoding Toolbox.HTML ManipulationLibraries for working with HTML and XML. BeautifulSoup - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML. bleach - A whitelist-based HTML sanitization and text linkification library. cssutils - A CSS library for Python. html5lib - A standards-compliant library for parsing and serializing HTML documents and fragments. lxml - A very fast, easy-to-use and versatile library for handling HTML and XML. MarkupSafe - Implements a XML/HTML/XHTML Markup safe string for Python. pyquery - A jQuery-like library for parsing HTML. untangle - Converts XML documents to Python objects for easy access. WeasyPrint - A visual rendering engine for HTML and CSS that can export to PDF. xmldataset - Simple XML Parsing. xmltodict - Working with XML feel like you are working with JSON.HTTP ClientsLibraries for working with HTTP. grequests - requests + gevent for asynchronous HTTP requests. httplib2 - Comprehensive HTTP client library. httpx - A next generation HTTP client for Python. requests - HTTP Requests for Humans. treq - Python requests like API built on top of Twisted’s HTTP client. urllib3 - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.HardwareLibraries for programming with hardware. ino - Command line toolkit for working with Arduino. keyboard - Hook and simulate global keyboard events on Windows and Linux. mouse - Hook and simulate global mouse events on Windows and Linux. Pingo - Pingo provides a uniform API to program devices like the Raspberry Pi, pcDuino, Intel Galileo, etc. PyUserInput - A module for cross-platform control of the mouse and keyboard. scapy - A brilliant packet manipulation library.Image ProcessingLibraries for manipulating images. hmap - Image histogram remapping. imgSeek - A project for searching a collection of images using visual similarity. nude.py - Nudity detection. pagan - Retro identicon (Avatar) generation based on input string and hash. pillow - Pillow is the friendly PIL fork. python-barcode - Create barcodes in Python with no extra dependencies. pygram - Instagram-like image filters. PyMatting - A library for alpha matting. python-qrcode - A pure Python QR Code generator. pywal - A tool that generates color schemes from images. pyvips - A fast image processing library with low memory needs. Quads - Computer art based on quadtrees. scikit-image - A Python library for (scientific) image processing. thumbor - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images. wand - Python bindings for MagickWand, C API for ImageMagick.ImplementationsImplementations of Python. CLPython - Implementation of the Python programming language written in Common Lisp. CPython - Default, most widely used implementation of the Python programming language written in C. Cython - Optimizing Static Compiler for Python. Grumpy - More compiler than interpreter as more powerful CPython2.7 replacement (alpha). IronPython - Implementation of the Python programming language written in C#. Jython - Implementation of Python programming language written in Java for the JVM. MicroPython - A lean and efficient Python programming language implementation. Numba - Python JIT compiler to LLVM aimed at scientific Python. PeachPy - x86-64 assembler embedded in Python. Pyjion - A JIT for Python based upon CoreCLR. PyPy - A very fast and compliant implementation of the Python language. Pyston - A Python implementation using JIT techniques. Stackless Python - An enhanced version of the Python programming language.Interactive InterpreterInteractive Python interpreters (REPL). bpython - A fancy interface to the Python interpreter. Jupyter Notebook (IPython) - A rich toolkit to help you make the most out of using Python interactively. awesome-jupyter ptpython - Advanced Python REPL built on top of the python-prompt-toolkit.InternationalizationLibraries for working with i18n. Babel - An internationalization library for Python. PyICU - A wrapper of International Components for Unicode C++ library (ICU).Job SchedulerLibraries for scheduling jobs. Airflow - Airflow is a platform to programmatically author, schedule and monitor workflows. APScheduler - A light but powerful in-process task scheduler that lets you schedule functions. django-schedule - A calendaring app for Django. doit - A task runner and build tool. gunnery - Multipurpose task execution tool for distributed systems with web-based interface. Joblib - A set of tools to provide lightweight pipelining in Python. Plan - Writing crontab file in Python like a charm. Prefect - A modern workflow orchestration framework that makes it easy to build, schedule and monitor robust data pipelines. schedule - Python job scheduling for humans. Spiff - A powerful workflow engine implemented in pure Python. TaskFlow - A Python library that helps to make task execution easy, consistent and reliable.LoggingLibraries for generating and working with logs. logbook - Logging replacement for Python. logging - (Python standard library) Logging facility for Python. loguru - Library which aims to bring enjoyable logging in Python. sentry-python - Sentry SDK for Python. structlog - Structured logging made easy.Machine LearningLibraries for Machine Learning. Also see awesome-machine-learning. gym - A toolkit for developing and comparing reinforcement learning algorithms. H2O - Open Source Fast Scalable Machine Learning Platform. Metrics - Machine learning evaluation metrics. NuPIC - Numenta Platform for Intelligent Computing. scikit-learn - The most popular Python library for Machine Learning. Spark ML - Apache Spark’s scalable Machine Learning library. vowpal_porpoise - A lightweight Python wrapper for Vowpal Wabbit. xgboost - A scalable, portable, and distributed gradient boosting library. MindsDB - MindsDB is an open source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using standard queries.Microsoft WindowsPython programming on Microsoft Windows. Python(x,y) - Scientific-applications-oriented Python Distribution based on Qt and Spyder. pythonlibs - Unofficial Windows binaries for Python extension packages. PythonNet - Python Integration with the .NET Common Language Runtime (CLR). PyWin32 - Python Extensions for Windows. WinPython - Portable development environment for Windows 7/8.MiscellaneousUseful libraries or tools that don’t fit in the categories above. blinker - A fast Python in-process signal/event dispatching system. boltons - A set of pure-Python utilities. itsdangerous - Various helpers to pass trusted data to untrusted environments. magenta - A tool to generate music and art using artificial intelligence. pluginbase - A simple but flexible plugin system for Python. tryton - A general purpose business framework.Natural Language ProcessingLibraries for working with human languages. General gensim - Topic Modeling for Humans. langid.py - Stand-alone language identification system. nltk - A leading platform for building Python programs to work with human language data. pattern - A web mining module. polyglot - Natural language pipeline supporting hundreds of languages. pytext - A natural language modeling framework based on PyTorch. PyTorch-NLP - A toolkit enabling rapid deep learning NLP prototyping for research. spacy - A library for industrial-strength natural language processing in Python and Cython. Stanza - The Stanford NLP Group’s official Python library, supporting 60+ languages. Chinese funNLP - A collection of tools and datasets for Chinese NLP. jieba - The most popular Chinese text segmentation library. pkuseg-python - A toolkit for Chinese word segmentation in various domains. snownlp - A library for processing Chinese text. Network VirtualizationTools and libraries for Virtual Networking and SDN (Software Defined Networking). mininet - A popular network emulator and API written in Python. napalm - Cross-vendor API to manipulate network devices. pox - A Python-based SDN control applications, such as OpenFlow SDN controllers.News FeedLibraries for building user’s activities. django-activity-stream - Generating generic activity streams from the actions on your site. Stream Framework - Building news feed and notification systems using Cassandra and Redis.ORMLibraries that implement Object-Relational Mapping or data mapping techniques. Relational Databases Django Models - The Django ORM. SQLAlchemy - The Python SQL Toolkit and Object Relational Mapper. awesome-sqlalchemy dataset - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL. orator - The Orator ORM provides a simple yet beautiful ActiveRecord implementation. orm - An async ORM. peewee - A small, expressive ORM. pony - ORM that provides a generator-oriented interface to SQL. pydal - A pure Python Database Abstraction Layer. NoSQL Databases hot-redis - Rich Python data types for Redis. mongoengine - A Python Object-Document-Mapper for working with MongoDB. PynamoDB - A Pythonic interface for Amazon DynamoDB. redisco - A Python Library for Simple Models and Containers Persisted in Redis. Package ManagementLibraries for package and dependency management. pip - The package installer for Python. pip-tools - A set of tools to keep your pinned Python dependencies fresh. PyPI conda - Cross-platform, Python-agnostic binary package manager. poetry - Python dependency management and packaging made easy.Package RepositoriesLocal PyPI repository server and proxies. bandersnatch - PyPI mirroring tool provided by Python Packaging Authority (PyPA). devpi - PyPI server and packaging/testing/release tool. localshop - Local PyPI server (custom packages and auto-mirroring of pypi). warehouse - Next generation Python Package Repository (PyPI).Penetration TestingFrameworks and tools for penetration testing. fsociety - A Penetration testing framework. setoolkit - A toolkit for social engineering. sqlmap - Automatic SQL injection and database takeover tool.PermissionsLibraries that allow or deny users access to data or functionality. django-guardian - Implementation of per object permissions for Django 1.2+ django-rules - A tiny but powerful app providing object-level permissions to Django, without requiring a database.ProcessesLibraries for starting and communicating with OS processes. delegator.py - Subprocesses for Humans 2.0. sarge - Yet another wrapper for subprocess. sh - A full-fledged subprocess replacement for Python.Recommender SystemsLibraries for building recommender systems. annoy - Approximate Nearest Neighbors in C++/Python optimized for memory usage. fastFM - A library for Factorization Machines. implicit - A fast Python implementation of collaborative filtering for implicit datasets. libffm - A library for Field-aware Factorization Machine (FFM). lightfm - A Python implementation of a number of popular recommendation algorithms. spotlight - Deep recommender models using PyTorch. Surprise - A scikit for building and analyzing recommender systems. tensorrec - A Recommendation Engine Framework in TensorFlow.RefactoringRefactoring tools and libraries for Python Bicycle Repair Man - Bicycle Repair Man, a refactoring tool for Python. Bowler - Safe code refactoring for modern Python. Rope - Rope is a python refactoring library.RESTful APILibraries for building RESTful APIs. Django django-rest-framework - A powerful and flexible toolkit to build web APIs. django-tastypie - Creating delicious APIs for Django apps. Flask eve - REST API framework powered by Flask, MongoDB and good intentions. flask-api - Browsable Web APIs for Flask. flask-restful - Quickly building REST APIs for Flask. Pyramid cornice - A RESTful framework for Pyramid. Framework agnostic apistar - A smart Web API framework, designed for Python 3. falcon - A high-performance framework for building cloud APIs and web app backends. fastapi - A modern, fast, web framework for building APIs with Python 3.6+ based on standard Python type hints. hug - A Python 3 framework for cleanly exposing APIs. sandman2 - Automated REST APIs for existing database-driven systems. sanic - A Python 3.6+ web server and web framework that’s written to go fast. vibora - Fast, efficient and asynchronous Web framework inspired by Flask. RoboticsLibraries for robotics. PythonRobotics - This is a compilation of various robotics algorithms with visualizations. rospy - This is a library for ROS (Robot Operating System).RPC ServersRPC-compatible servers. RPyC (Remote Python Call) - A transparent and symmetric RPC library for Python zeroRPC - zerorpc is a flexible RPC implementation based on ZeroMQ and MessagePack.ScienceLibraries for scientific computing. Also see Python-for-Scientists. astropy - A community Python library for Astronomy. bcbio-nextgen - Providing best-practice pipelines for fully automated high throughput sequencing analysis. bccb - Collection of useful code related to biological analysis. Biopython - Biopython is a set of freely available tools for biological computation. cclib - A library for parsing and interpreting the results of computational chemistry packages. Colour - Implementing a comprehensive number of colour theory transformations and algorithms. Karate Club - Unsupervised machine learning toolbox for graph structured data. NetworkX - A high-productivity software for complex networks. NIPY - A collection of neuroimaging toolkits. NumPy - A fundamental package for scientific computing with Python. ObsPy - A Python toolbox for seismology. Open Babel - A chemical toolbox designed to speak the many languages of chemical data. PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion. PyMC - Markov Chain Monte Carlo sampling toolkit. QuTiP - Quantum Toolbox in Python. RDKit - Cheminformatics and Machine Learning Software. SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering. SimPy - A process-based discrete-event simulation framework. statsmodels - Statistical modeling and econometrics in Python. SymPy - A Python library for symbolic mathematics. Zipline - A Pythonic algorithmic trading library.SearchLibraries and software for indexing and performing search queries on data. django-haystack - Modular search for Django. elasticsearch-dsl-py - The official high-level Python client for Elasticsearch. elasticsearch-py - The official low-level Python client for Elasticsearch. pysolr - A lightweight Python wrapper for Apache Solr. whoosh - A fast, pure Python search engine library.SerializationLibraries for serializing complex data types marshmallow - A lightweight library for converting complex objects to and from simple Python datatypes. pysimdjson - A Python bindings for simdjson. python-rapidjson - A Python wrapper around RapidJSON. ultrajson - A fast JSON decoder and encoder written in C with Python bindings.Serverless FrameworksFrameworks for developing serverless Python code. python-lambda - A toolkit for developing and deploying Python code in AWS Lambda. Zappa - A tool for deploying WSGI applications on AWS Lambda and API Gateway.ShellShells based on Python. xonsh - A Python-powered, cross-platform, Unix-gazing shell language and command prompt.Specific Formats ProcessingLibraries for parsing and manipulating specific text formats. General tablib - A module for Tabular Datasets in XLS, CSV, JSON, YAML. Office docxtpl - Editing a docx document by jinja2 template openpyxl - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files. pyexcel - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files. python-docx - Reads, queries and modifies Microsoft Word 2007/2008 docx files. python-pptx - Python library for creating and updating PowerPoint (.pptx) files. unoconv - Convert between any document format supported by LibreOffice/OpenOffice. XlsxWriter - A Python module for creating Excel .xlsx files. xlwings - A BSD-licensed library that makes it easy to call Python from Excel and vice versa. xlwt / xlrd - Writing and reading data and formatting information from Excel files. PDF PDFMiner - A tool for extracting information from PDF documents. PyPDF2 - A library capable of splitting, merging and transforming PDF pages. ReportLab - Allowing Rapid creation of rich PDF documents. Markdown Mistune - Fastest and full featured pure Python parsers of Markdown. Python-Markdown - A Python implementation of John Gruber’s Markdown. YAML PyYAML - YAML implementations for Python. CSV csvkit - Utilities for converting to and working with CSV. Archive unp - A command line tool that can unpack archives easily. Static Site GeneratorStatic site generator is a software that takes some text + templates as input and produces HTML files on the output. lektor - An easy to use static CMS and blog engine. mkdocs - Markdown friendly documentation generator. makesite - Simple, lightweight, and magic-free static site/blog generator (&lt; 130 lines). nikola - A static website and blog generator. pelican - Static site generator that supports Markdown and reST syntax.TaggingLibraries for tagging items. django-taggit - Simple tagging for Django.Task QueuesLibraries for working with task queues. celery - An asynchronous task queue/job queue based on distributed message passing. dramatiq - A fast and reliable background task processing library for Python 3. huey - Little multi-threaded task queue. mrq - A distributed worker task queue in Python using Redis &amp; gevent. rq - Simple job queues for Python.Template EngineLibraries and tools for templating and lexing. Genshi - Python templating toolkit for generation of web-aware output. Jinja2 - A modern and designer friendly templating language. Mako - Hyperfast and lightweight templating for the Python platform.TestingLibraries for testing codebases and generating test data. Testing Frameworks hypothesis - Hypothesis is an advanced Quickcheck style property based testing library. nose2 - The successor to nose, based on `unittest2. pytest - A mature full-featured Python testing tool. Robot Framework - A generic test automation framework. unittest - (Python standard library) Unit testing framework. Test Runners green - A clean, colorful test runner. mamba - The definitive testing tool for Python. Born under the banner of BDD. tox - Auto builds and tests distributions in multiple Python versions GUI / Web Testing locust - Scalable user load testing tool written in Python. PyAutoGUI - PyAutoGUI is a cross-platform GUI automation Python module for human beings. Schemathesis - A tool for automatic property-based testing of web applications built with Open API / Swagger specifications. Selenium - Python bindings for Selenium WebDriver. sixpack - A language-agnostic A/B Testing framework. splinter - Open source tool for testing web applications. Mock doublex - Powerful test doubles framework for Python. freezegun - Travel through time by mocking the datetime module. httmock - A mocking library for requests for Python 2.6+ and 3.2+. httpretty - HTTP request mock tool for Python. mock - (Python standard library) A mocking and patching library. mocket - A socket mock framework with gevent/asyncio/SSL support. responses - A utility library for mocking out the requests Python library. VCR.py - Record and replay HTTP interactions on your tests. Object Factories factory_boy - A test fixtures replacement for Python. mixer - Another fixtures replacement. Supports Django, Flask, SQLAlchemy, Peewee and etc. model_mommy - Creating random fixtures for testing in Django. Code Coverage coverage - Code coverage measurement. Fake Data fake2db - Fake database generator. faker - A Python package that generates fake data. mimesis - is a Python library that help you generate fake data. radar - Generate random datetime / time. Text ProcessingLibraries for parsing and manipulating plain texts. General chardet - Python 2/3 compatible character encoding detector. difflib - (Python standard library) Helpers for computing deltas. ftfy - Makes Unicode text less broken and more consistent automagically. fuzzywuzzy - Fuzzy String Matching. Levenshtein - Fast computation of Levenshtein distance and string similarity. pangu.py - Paranoid text spacing. pyfiglet - An implementation of figlet written in Python. pypinyin - Convert Chinese hanzi (漢字) to pinyin (拼音). textdistance - Compute distance between sequences with 30+ algorithms. unidecode - ASCII transliterations of Unicode text. Slugify awesome-slugify - A Python slugify library that can preserve unicode. python-slugify - A Python slugify library that translates unicode to ASCII. unicode-slugify - A slugifier that generates unicode slugs with Django as a dependency. Unique identifiers hashids - Implementation of hashids in Python. shortuuid - A generator library for concise, unambiguous and URL-safe UUIDs. Parser ply - Implementation of lex and yacc parsing tools for Python. pygments - A generic syntax highlighter. pyparsing - A general purpose framework for generating parsers. python-nameparser - Parsing human names into their individual components. python-phonenumbers - Parsing, formatting, storing and validating international phone numbers. python-user-agents - Browser user agent parser. sqlparse - A non-validating SQL parser. Third-party APIsLibraries for accessing third party services APIs. Also see List of Python API Wrappers and Libraries. apache-libcloud - One Python library for all clouds. boto3 - Python interface to Amazon Web Services. django-wordpress - WordPress models and views for Django. facebook-sdk - Facebook Platform Python SDK. google-api-python-client - Google APIs Client Library for Python. gspread - Google Spreadsheets Python API. twython - A Python wrapper for the Twitter API.URL ManipulationLibraries for parsing URLs. furl - A small Python library that makes parsing and manipulating URLs easy. purl - A simple, immutable URL class with a clean API for interrogation and manipulation. pyshorteners - A pure Python URL shortening lib. webargs - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.VideoLibraries for manipulating video and GIFs. moviepy - A module for script-based movie editing with many formats, including animated GIFs. scikit-video - Video processing routines for SciPy. vidgear - Most Powerful multi-threaded Video Processing framework.Web Asset ManagementTools for managing, compressing and minifying website assets. django-compressor - Compresses linked and inline JavaScript or CSS into a single cached file. django-pipeline - An asset packaging library for Django. django-storages - A collection of custom storage back ends for Django. fanstatic - Packages, optimizes, and serves static file dependencies as Python packages. fileconveyor - A daemon to detect and sync files to CDNs, S3 and FTP. flask-assets - Helps you integrate webassets into your Flask app. webassets - Bundles, optimizes, and manages unique cache-busting URLs for static resources.Web Content ExtractingLibraries for extracting web contents. html2text - Convert HTML to Markdown-formatted text. lassie - Web Content Retrieval for Humans. micawber - A small library for extracting rich content from URLs. newspaper - News extraction, article extraction and content curation in Python. python-readability - Fast Python port of arc90’s readability tool. requests-html - Pythonic HTML Parsing for Humans. sumy - A module for automatic summarization of text documents and HTML pages. textract - Extract text from any document, Word, PowerPoint, PDFs, etc. toapi - Every web site provides APIs.Web CrawlingLibraries to automate web scraping. cola - A distributed crawling framework. feedparser - Universal feed parser. grab - Site scraping framework. MechanicalSoup - A Python library for automating interaction with websites. portia - Visual scraping for Scrapy. pyspider - A powerful spider system. robobrowser - A simple, Pythonic library for browsing the web without a standalone web browser. scrapy - A fast high-level screen scraping and web crawling framework.Web FrameworksTraditional full stack web frameworks. Also see RESTful API. Synchronous Django - The most popular web framework in Python. awesome-django awesome-django Flask - A microframework for Python. awesome-flask Pyramid - A small, fast, down-to-earth, open source Python web framework. awesome-pyramid Masonite - The modern and developer centric Python web framework. Asynchronous Tornado - A web framework and asynchronous networking library. WebSocketLibraries for working with WebSocket. autobahn-python - WebSocket &amp; WAMP for Python on Twisted and asyncio. channels - Developer-friendly asynchrony for Django. websockets - A library for building WebSocket servers and clients with a focus on correctness and simplicity.WSGI ServersWSGI-compatible web servers. bjoern - Asynchronous, very fast and written in C. gunicorn - Pre-forked, ported from Ruby’s Unicorn project. uWSGI - A project aims at developing a full stack for building hosting services, written in C. waitress - Multi-threaded, powers Pyramid. werkzeug - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.ResourcesWhere to discover learning resources or new Python libraries.Books Fluent Python Think PythonWebsites Tutorials Full Stack Python Python Cheatsheet Real Python The Hitchhiker’s Guide to Python Ultimate Python study guide Libraries Awesome Python @LibHunt Others Python ZEEF Pythonic News What the f*ck Python! Newsletters Awesome Python Newsletter Pycoder’s Weekly Python Tricks Python WeeklyPodcasts Django Chat Podcast.__init__ Python Bytes Running in Production Talk Python To Me Test and Code The Real Python PodcastContributingYour contributions are always welcome! Please take a look at the contribution guidelines first.I will keep some pull requests open if I’m not sure whether those libraries are awesome, you could vote for them by adding :+1: to them. Pull requests will be merged when their votes reach 20.If you have any question about this opinionated list, do not hesitate to contact me @VintaChen on Twitter or open an issue on GitHub." }, { "title": "Leetcode Solutions Cheatsheet", "url": "/posts/leetcode-solutions-cheatsheet/", "categories": "Problem Solving, LeetCode", "tags": "leetcode, leetcode-solution", "date": "2022-10-26 00:00:00 +0530", "snippet": "Quick Access LinksLeetCode LeetCode - CheatSheet Getting Started Prerequisites Built With Authors Acknowledgments Quick Access Links ...", "content": "Quick Access LinksLeetCode LeetCode - CheatSheet Getting Started Prerequisites Built With Authors Acknowledgments Quick Access Links LeetCode 1-Two Sum Brute Force One Pass Hash Table 2-Add Two Numbers Elementary Math Solution 3-Substring No Repeat Brute Force Sliding Window Sliding Window Optimized 4-Median of Two Sorted Arrays Recursive Approach 5-Longest Palindromic Substring Longest Common Substring Brute Force Dynamic Programming Expand Around Center Manacher’s Algorithm 6-ZigZag Conversion Sort by Row Visit by Row 7-Reverse Integer Pop and Push Digits and Check Before Overflow 8-String to Integer (atoi) ASCII Conversion 9-Palindrome Number Revert Half of the Number 10-Regular Expression Matching Recursion Dynamic Programming Non-Recursive 11-Container with the Most Water Brute Force Two Pointer Approach 12-Integer To Roman String Array 13-Roman to Integer Character Array 14-Longest Common Prefix Horizontal Scanning Vertical Scanning Divide and Conquer Binary Search Further Thoughts 15-3Sum Sorted Array 16-3Sum Closest 3 Pointers 17-Letter Combinations of a Phone Number Backtracking First In First Out (FIFO) Queue 18-4Sum Sorted Array 19-Remove Nth Node From End of List Two Pass Algorithm One Pass Algorithm 20-Valid Parentheses Counting method Stacks 21-Merge Two Sorted Lists Recursive Non-Recursive 22-Generate Parentheses Brute Force Backtracking Closure Number 23-Merge k Sorted Lists Brute Force 146-LRU Cache1-Two SumGiven an array of integers, return indices of the two numbers such that they add up to a specific target.You may assume that each input would have exactly one solution, and you may not use the same element twice.Example:Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1].Brute Forcepublic int[] twoSum(int[] nums, int target) {\tfor (int i=0; i&lt;nums.size; i++){\t\tfor (int j=i+1;j&lt;nums.length;j++){\t\t\tif (nums[j]==target-nums[i]){\t\t\t\treturn new int[] {i,j};\t\t\t}\t\t}\t}\tthrow new IllegalArgumentException(\"No two sum solution\");} Complexity Analysis* Time complexity: O(n^2) we have a nested loop * Space complexity: O(1) \t we do not allocate any additional memoryOne Pass Hash Tablepublic int[] twoSum(int[] nums, int target) {\tMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();\tfor(int i=0; i&lt;nums.length; i++){\t\tint complement=target-nums[i];\t\tif (map.containsKey(complement)){\t\t\treturn new int[] {map.get(complement),i};\t\t}\t\tmap.put(nums[i],i);\t}\tthrow new IllegalArgumentException(\"No two sum solution\"); }Complexity Analysis* Time complexity: O(n)\t\teach lookup in the hash table only requires O(1) time* Space complexity: O(n)\t\twe require additional space for the hash table which stores at most n***2-Add Two NumbersGiven two non-empty linked lists representing two non-negative integers with the digits stored in reverse order and each node containing a single digit, add the two numbers and return as a linked listExample:Input (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) Output 7 -&gt; 0 -&gt; 8 342 + 465 = 807Elementary Math Solution/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead= new ListNode(0); ListNode p=l1, q=l2, curr=dummyHead; int carry=0; while (p!=null||q!=null){ int x= (p!=null) ? p.val :0; //if (p!=null) then x contains p.val int y= (q!=null) ? q.val :0; int sum=carry+x+y; carry=sum/10; curr.next=new ListNode(sum%10); curr=curr.next; if (p!=null) p=p.next; if (q!=null) q=q.next; } if (carry&gt;0){ curr.next= new ListNode(carry); } return dummyHead.next; }}Complexity analysis* Time Complexity: O(max(m,n)) depends on the lengths of the two linked lists * Space Complexity: O(max(m,n))\t\tthe maximum length of the new list is max(m,n)+1***3-Substring No RepeatLongest Substring Without Repeating CharactersGiven a string find the length of the longest substring without repeating characters.ExampleInput: \t\t\"abcabcbb\"Output:\t\t3Explanation:\tThe answer is \"abc\", with the length of 3Example 2Input:\t\t\"bbbbb\"Output:\t\t1Explanation:\tThe answer is \"b\", with the length of 1Example 3Input:\t\t\"pwwkew\"Output:\t\t3Explanation: \tThe answer is \"wke\", with the length of 3. Note that the answer must be a substring\t\t\"pwke\" is a subsequence and not a substring Brute ForceAlgorithmSuppose we have a function “boolean allUnique(String substring)” which returns true if all thecharacters in the substring are unique and false otherwise. We can iterate through all the possible substrings of the given string s and call the function allUnique. If it turns out to be true, then we update our answer of the maximum length of substring without duplicate characters.To enumerate all substrings of a given string we enumerate the start and end indices of them. Supposethe start and end indices are i and j respectively. Then we have 0 &lt;= i &lt;= j &lt;= n. Thus using two nested loops with i from 0 to n-1 and j from i+1 to n, we can enumerate all the substrings of sTo check if one string has duplicate characters we can use a set. We iterate through all the characters in the string and put them into the set one by one. Before putting one character, we checkif the set already contains it. If so we return false and after the loop we return true.public class Solution { public int lengthOfLongestSubstring(String s) { int n = s.length(); int ans = 0; for (int i = 0; i &lt; n; i++) for (int j = i + 1; j &lt;= n; j++) if (allUnique(s, i, j)) ans = Math.max(ans, j - i); return ans; } public boolean allUnique(String s, int start, int end) { Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int i = start; i &lt; end; i++) { Character ch = s.charAt(i); if (set.contains(ch)) return false; set.add(ch); } return true; }}Complexity Analysis* Time Complexity: O(n^3)\t\tVerifying if characters in [i,j) are unique requires us to scan all of\t\t\t\t\tthem which would cost O(j-i) time. \t\t\t\t\tFor a given i, the sum of time costed by each j -&gt; [i+1,n] is \t\t\t\t\t\"Summation from i+1 to n O(j-1)\"\t\t\t\t\tThus, the sum of all the time consumption is: \t\t\t\t\tO(summation from 0 to n-1(summation from j=i+1 to n (j-1))) \t\t\t\t\tO(summation from i=0 to n-1(1+n-i)(n-i)/2)) = O(n^3)\t\t\t\t\t*Note that the sum of all numbers up to n 1+2+3+...+n = n(n+1)/2* Space Complexity: O(min(n,m))\tWe require O(k) space for checking a substring has no duplicate \t\t\t\t\tcharacters, where k is the size of the set. The size of the Set is \t\t\t\t\tupper bounded by the size of the string n amd the size of the charset\t\t\t\t\tor alphabet m \t\t\t\t\t\t\t\tSliding WindowA sliding window is an abstract concept commonly used in array/string problems. A window is a range of elements in the array/string which usually defined by the start and end indicesEx. [i,j) left-closed, right-openA sliding window is a window that slides its two boundaries in a certain direction, for example if weslide [i,j) to the right by 1 element, then it becomes [i+1, j+1) - left closed, right open.Sliding Window approach, whenever we are looking at a section on an array usual to perform calculationswe don’t need to completely recalculate everything for every section of the array. Usually we can usethe value obtained from another section of the array to determine something about this section of the array. For example if we are calculating the sum of sections of an array we can use the previously calculated value of a section to determine the sum of an adjacent section in the array.Ex. 1 2 3 4 5 6 7 8 If we calculate the first section of four values we get 1+2+3+4 = 10 , then to calculate the next section2+3+4+5 we can just take our first section (window_sum) and perform the operation:window_sum-first entry + last entry = 10-1+5= 14So essentially for the window sliding technique we use what we know about an existing window to determine properties for another window.AlgorithmIn the brute force approach, we repeatedly check a substring to see if it has duplicate characters butthis is unnecessary. If a substring from index i to j-1 is already checked to have no duplicate characters we only need to check if s[j] is already in the substring.To check if a character is already in the substring we can scan the substring which leads to an O(n^2)algorithm but we can improve on this runtime using a HashSet as a sliding window to check if a character exists in the current set O(1).We use a HashSet to store the characters in the current window [i,j) and then we slide the index j tothe right, if it is not in the HashSet, we slide j further until s[j] is already in the HashSet. Atthis point we found the maximum size of substrings without duplicate characters starting with index i.If we do this for all i, then we obtain our answer.public class Solution { public int lengthOfLongestSubstring(String s) { int n = s.length(); Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int ans = 0, i = 0, j = 0; while (i &lt; n &amp;&amp; j &lt; n) { // try to extend the range [i, j] if (!set.contains(s.charAt(j))){ set.add(s.charAt(j++)); ans = Math.max(ans, j - i); } else { set.remove(s.charAt(i++)); } } return ans; }}Complexity AnalysisTime complexity:\tO(2n)=O(n)\tWorst case each character will be visited twice by i and jSpace complexity: \tO(min(m,n))\tSame as the brute force method, we need O(k) space for the \t\t\t\t\tsliding window where k is the size of the set. The size of the\t\t\t\t\tset is bounded by the size of the string n and the size of the\t\t\t\t\tcharset/alphabet mSliding Window OptimizedThe previously discussed sliding window approach requires at most 2n steps and this could in fact beoptimized even further to require only n steps. Instead of using a set to tell if a character exists ornot, we could define a mapping of the characters to its index. Then we can skip the characters immediately when we found a repeated characterIf s[j] has a duplicate in the range [i , j) with index j’, we don’t need to increase i little be littlewe can just skip all the elements in the range [i , j’] and let i be j’+1 directlypublic class Solution { public int lengthOfLongestSubstring(String s) { int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); // current index of character // try to extend the range [i, j] for (int j = 0, i = 0; j &lt; n; j++) { if (map.containsKey(s.charAt(j))) { i = Math.max(map.get(s.charAt(j)), i); } ans = Math.max(ans, j - i + 1); map.put(s.charAt(j), j + 1); } return ans; }}***4-Median of Two Sorted ArraysThere are two sorted arrays num1 and num2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2cannot be both empty.Example nums1 = [1, 3] nums2 = [2]The median is 2.0Example 2nums1= [1, 2] nums2= [3, 4] The median is (2+3)/2 = 2.5Recursive ApproachIn statistics the median is used for dividing a set into two equal length subsets with one set beingalways greater than the other set. To approach this problem first we cut A into two parts at a randomposition i: left_A | right_A A[0], A[1], ... , A[i-1] A[i], A[i+1], ... , A[m-1]Since A has m elements, there are m+1 kinds of cutting as i can range from 0-m. We can also see thatleft_A is empty when i is zero and right_A is empty when i=mlen(left_A) = i and len(right_A)= m-iWe can similarly cut B into two parts at a random position j:\tleft_B\t\t\t|\tright_B B[0], B[1], ... , B[j-1]\t B[j], B[j+1], ... , B[n-1]Now if we put left_A and left_B into one set and put right_A and right_B into another set and name them left_part and right_part, then we get\tleft_part\t\t|\tright_part A[0], A[1], ... , A[i-1]\t A[i], A[i+1], ... , A[m-1] B[0], B[1], ... , B[j-1]\t B[j], B[j+1], ... , B[n-1]If we can ensure that the len(left_part) = len(right_part) max(left_part) &lt;= min(right_part)then we divide all the elements in {A,B} into two parts with equal length and one part is alwaysgreater than the other. Thenmedian= (max(left_part)+min(right_part))/2To ensure these two conditions, we need to ensure: i+j= m-i+n-j (or: m-i+n-j+1) if n&gt;m, we just need to set i=0~m, j= (m+n+1)/2 - i B[j-1]&lt;=A[i] and A[i-1]&lt;=B[j]So, all we need to do is search for i in [0,m] to find an object i such that B[j-1]&lt;=A[i] and A[i-1]&lt;=B[j] where j=(m+n+1)/2 -iThen we perform a binary search following the steps described below:1) Set imin=0, imax=0, then start searching in [imin, imax]2) Set i=(imin+imax)/2 , j=(m+n+1)/2 - i3) Now we have len(left_part) = len(right_part) and there are only 3 more situations which we may encounter: - B[j-1] &lt;= A[i] and A[i-1]&lt;=B[j] This means that we have found the object i, so we can stop searching - B[j-1] &gt; A[i] Means A[i] is too small, we must adjust i to get B[j-1]&lt;=A[i] so we increase i because this will cuase j to be decreased. We cannot decrease i because when i is decreased, j will be increased so B[j-1] is increased and A[i] is decreased (B[j-1]&lt;= A[i] will never be satisfied) - A[i-1] &gt; B[j] Means A[i-1] is too big and thus we must decrease i to get A[i-1]&lt;=B[j]. In order to do that we must adjust the searching range to [imin, i-1] so we set imax=i-1 and go back to step 2When the object i is found, then the media is:max(A[i-1],B[j-1]), when m+n is odd(max(A[i-1],B[j-1])+min(A[i],B[j]))/2, when m+n is evenNext is to consider the edge values i=0, i=m, j=0, j=n where A[i-1], B[j-1], A[i], B[j] may not existclass Solution {\tpublic double findMedianSortedArrays(int[] A, int[] B) {\t\tint m=A.length;\t\tint n=B.length;\t\tif (m&gt;n) { \t//ensuring that m&lt;=n\t\t\tint[] temp=A; A=B; B=temp;\t\t\tint tmp=m; m=n; n=tmp;\t\t}\t\tint iMin=0, iMax=m, halfLen=(m+n+1)/2;\t\twhile (iMin&lt;=iMax) {\t\t\tint i=(iMin+iMax)/2\t\t\tint j= halfLen - i;\t\t\tif (i&lt;iMax &amp;&amp; B[j-1] &gt; A[i]){\t\t\t\tiMin=i+1; //i is too small\t\t\t}\t\t\telse if (i&gt;iMin &amp;&amp; A[i-1]&gt;B[j]) {\t\t\t\tiMax=i-1; //i is too big\t\t\t}\t\t\telse{ //we have found the object i \t\t\t\tint maxLeft=0; \t\t\t\tif (i==0) {\t\t\t\t\tmaxLeft=B[j-1];\t\t\t\t}\t\t\t\telse if (j==0){\t\t\t\t\tmaxLeft=A[i-1];\t\t\t\t}\t\t\t\telse{\t\t\t\t\tmaxLeft=Math.max(A[i-1], B[j-1]);\t\t\t\t}\t\t\t\tif ((m+n)%2 ==1) {\t\t\t\t\treturn maxLeft;\t\t\t\t}\t\t\t\tint minRIght=0;\t\t\t\tif (i==m) {\t\t\t\t\tminRight=B[j];\t\t\t\t}\t\t\t\telse if (j==n) {\t\t\t\t\tminRight=A[i];\t\t\t\t}\t\t\t\telse {\t\t\t\t\tminRight=Math.min(B[j], A[i]);\t\t\t\t}\t\t\t\treturn (maxLeft+minRight)/2.0;\t\t\t}\t\t}\t\treturn 0.0;\t}}Complexity AnalysisTime Complexity: O(log(min(m,n)))\tAt first the searching range is [0,m] and the length of this \t\t\t\t\tsearching range will be reduced by half after each loop so we\t\t\t\t\tonly need log(m) loops. Since we do constant operations in \t\t\t\t\teach loop the time complexity is O(log(m) and since m&lt;=n the\t\t\t\t\ttime complexity is O(log(min(m,n))Space Complexity: O(1)\t\t\tWe only need constant memory to store 9 local variables so the\t\t\t\t\tspace complexity is O(1)***5-Longest Palindromic SubstringGiven a string s, find the longest palindromic substring in s. You may assume that the maximum lengthof s is 1000.Example 1: Input: \"babad\" Output: \"bab\" Note: \"aba\" is also a valid answer Example 2: Input: \"cbbd\"Output: \"bb\" Longest Common SubstringSome people will be tempted to come up with this quick solution which is unforunately flawed, “reverseS and become S’. Find the longest common substring between S and S’ and that will be the longestpalindromic substring.” This will work with some examples but there are some cases where the longestcommon substring is not a valid palindrome.Ex. S=\"abacdfgdcaba\", S'=\"abacdgfdcaba\" \tThe longest common substring between S and S’ is “abacd” and clearly this is not a valid \tpalindromeWe can solve this problem however by checking if the substring’s indices are the same as the reversedsubstring’s original indices each time we find a longest common substring. If it is, then we attemptto update the longest palindrome found so far, if not we skip this and find the next candidateComplexity AnalysisTime Complexity: O(n^2) Space Complexity: O(n^2) Brute ForceThe obvious brute force solution is to pick all possible starting and ending position for a substring and verify if it is a palindromeComplexity AnalysisTime Complexity: O(n^3)\t\tIf n is the length of the input string, there are a total of \t\t\t\t(n 2) = n(n-1)/2 substrings and since verifying each substring takes \t\t\t\tO(n) time, the run time complexity is O(n^3)Space Complexity: O(1) Dynamic ProgrammingWe can improve on the brute force solution by avoid some unnecessary re-computation while validating palidromes. Consider the word “ababa”, if we already know that “bab” is a palindrome then we can determine that ababa is a palindrome by noticing that the two left and right letters connected to babare the same.This yields a straight forward dynamic programming solution where we initialize the one and two letterspalindromes and then work our way up finding all three letters palindromes and so on.Complexity AnalysisTime Complexity: \tO(n^2)\tSpace Complexity: \tO(n^2)\tUsing O(n^2) space to store the table Expand Around CenterThis approach allows us to solve this problem in O(n^2) time using only constant space complexity. Weobserve that a palindrome mirrors around its enter and therefore a palindrome can be expanded from itscenter and there are only 2n-1 such centers (for palindromes with an even number of letters like “abba” its center is in between two letters).public String longestPalindrome(String s) {\tif (s==null || s.length() &lt; 1) return \"\"; //edge case \tint start=0, end=0;\tfor (int i=0; i&lt;s.length(); i++) {\t\tint len1=expandAroundCenter(s,i,i);\t\tint len2=expandAroundCenter(s,i,i+1);\t\tint len=Math.max(len1,len2);\t\tif (len&gt;end-start) {\t\t\tstart= i-(len-1)/2;\t\t\tend=i+len/2\t\t}\t}\treturn s.substring(start,end+1);}private int expandAroundCenter(String s, int left, int right) {\tint L=left, R=right;\twhile(L&gt;=0 &amp;&amp; R&lt;s.length() &amp;&amp; s.charAt(L)==s.charAt(R)) {\t\tL--;\t\tR++;\t}\treturn R-L-1;}Manacher’s AlgorithmThere is an O(n) algorithm called Manacher’s algorithm, however, it is a non-trivial algorithm and no one would expect you to come up with this algorithm in a 45 minute coding session***6-ZigZag ConversionThe string “PAYPALISHIRING” is written in a zigzag pattern on a given number of rows like this:P A H NA P L S I I GY I RAnd then read line by line: “PAHNAPLSIIGYIR”. Write a code that will take a string and make this conversion given a number of rows:string convert(string s, int numRows);Example 1: Input: s=\"PAYPALISHIRING\", numRows=3Output: \"PAHNAPLSIIGYIR\"Example 2:Input: s=\"PAYPALISHIRING\", numRows=4Output: \"PINALSIGYAHRPI\"Explanation:P I NA L S I GY A H RP ISort by RowBy iterating through the string from left to right we can easily determine which row in the Zig-Zagpattern that a character belongs toAlgorithmWe can use min(numRows,len(s)) lists to represent the non-empty rows of the Zig-Zag Pattern. Iterate through s from left to right appending each character to the appropriate row. The appropriaterow can be tracked using two variables: the current row and the current direction.The current direction only changes when we moved to the topmost row or moved down to the bottommost rowclass Solution {\tpublic String convert(String s, int numRows) {\t\tif (numRows==1) return s;\t\t//if there is only one row return string\t\tList&lt;StringBuilder&gt; rows=new ArrayList&lt;&gt;();\t\tfor (int i=0; i&lt;Math.min(numRows, s.length()); i++){\t\t\trows.add(new StringBuilder());\t\t}\t\tint curRow=0;\t\tboolean goingDown=false;\t\tfor(char c: s.toCharArray()) {\t\t\trows.get(curRow).append(c);\t\t\tif (curRow==0 || curRow==numRows-1) {\t\t\t\tgoingDown=!goingDown;\t\t\t}\t\t\tcurRow+=goingDown ? 1 : -1;\t\t}\t\t\tStringBuilder ret= new StringBuilder();\t\tfor(StringBuilder row:rows) {\t\t\tret.append(row);\t\t}\t\treturn ret.toString();\t}}Complexity AnalysisTime Complexity: O(n)\twhere n==len(s)Space Complexity: O(n)Visit by RowVisit the characters in the same order as reading the Zig-Zag pattern line by lineAlgorithmVisit all characters in row 0 first, then row 1, then row 2, and so on.For all whole numbers k, \t* characters in row 0 are located at indexes k*(2*numRows-2)\t* characters in row numRows -1 are located at indexes k*(2*numRows-2)+ numRows -1 \t* characters in inner row i are located at indexes k*(2*numRows-2)+i and (k+1)(2*numRows-2)-iclass Solution {\tpublic String convert(String s, int numRows) {\t\tif (numRows==1) return s; \t\tStringBuilder ret=new StringBuilder();\t\tint n=s.length();\t\tint cycleLen= 2* numRows -2;\t\tfor (int i=0; i&lt;numRows; i++) {\t\t\tfor (int j=0; j+1&lt;n; j+= cycleLen) {\t\t\t\tret.append(s.charAt(j+i));\t\t\t\tif (i!=0 &amp;&amp; i!=numROws-1 &amp;&amp; j+cycleLen-i&lt;n) {\t\t\t\t\tret.append(s.charAt(j+cycleLen-i));\t\t\t\t}\t\t\t}\t\t\treturn ret.toString();\t\t}\t}}Complexity AnalysisTime Complexity: O(n)\twhere n==len(s) Each index is visited onceSpace Complexity: O(n) \tC++ implementation can achieve O(1) if the return string is not considered \t\t\textra space***7-Reverse IntegerGiven a 32- bit signed integer, reverse digits of an integer.Example 1: Input: 123Output: 321Example 2: Input: -123Output: -321Example 3: Input: 120 Output: 21For the purpose of this problem assume that your function returns 0 when the reversed integer overflowsPop and Push Digits and Check Before OverflowWe can build up the reverse integer one digit at and time and before doing so we can check whether ornot appedning another digit would cause overflowAlgorithmReversing an integer can be done similarly to reversing a string. We want to repeatedly “pop” the lastdigit off of x and push it to the back of the rev so that in the end rev is the reverse of x.To push and pop digits without the help of some auxiliar stack/array we can use math//pop operation: pop = x%10; x/=10;//push operation:temp=rev*10+pop;rev =temp;This statement is dangerous however as the statement temp=rev*10+pop may cause an overflow and luckilyit is easy to check beforehand whether or not this statement would cause an overflow. If temp=rev*10+pop causes an overflow, then rev&gt;=INTMAX/10 If rev&gt; INTMAX/10, then temp=rev*10+pop is guaranteed to overflow if rev==INTMAX/10, then temp=rev*10 + pop will overflow if an only if pop&gt;7class Solution {\tpublic int reverse(int x) {\t\tint rev=0; \t\twhile (x!=0) {\t\t\tint pop=x%10;\t\t\tx/=10;\t\t\tif (rev&gt;Integer.MAX_VALUE/10||(rev==Integer.MAX_VALUE/10 &amp;&amp; pop&gt;7)) return 0;\t\t\tif (rev&lt;Integer.MIN_VALUE/10||(rev==Integer.MIN_VALUE/10 &amp;&amp; pop&lt;-8)) return 0;\t\t\trev=rev*10 +pop;\t\t}\t\treturn rev;\t}}Complexity AnalysisTime Complexity: O(log(x))\tThere are roughly log10(x) digits in x Space Complexity: O(1)***8-String to Integer (atoi)Implement atoi which converts a string to an integerThe function first discards as many whitespace characters as necessary until the first non-whitespacecharacter is found. Then, starting from this character, takes an optional initial plus or minus signfollowed by as many numerical digits as possible and interprets them as a numerical value.The string can contain additional characters after those that form the integral number, which are ignored and have no effect on the behavior of this function.If the first sequence of non-whitespace characters in str is not a valid integral number, or if no suchsequence exits because either str is empty or it contains only whitespace characters, no conversion isperformed.If no valid conversion could be performed a zero value is returnedNote: only the space character ‘ ‘ is considered as whitespace character assume we are dealing with an environment which could only store integers within the 32-bit signed integer range: [-2^31, 2^31-1]. If the numerical value is out of the range of representable values, INT_MAX (2^31-1) or INT_MIN (-2^31) is returned\tExample 1: \tInput: \"42\"\tOutput: 42\tExample 2: \tInput: \" -42\" \tOutput: -42\tExample 3:\tInput: \"4193 with words \"\tOutput: 4193\tExample 4: \t\tInput: \"words and 987\"\tOutput: 0\tExample 5:\t\tInput: \"-91283472332\"\tOutput: -2147483648 \t//out of the range of a 32-bit signed integer so INT_MIN is returnedASCII ConversionRecognize that ASCII characters are actually numbers and 0-9 digits are numbers starting from decimal48 (0x30 hexadecimal)\t'0' is 48\t'1' is 49\t...\t'9' is 57So to get the value of any character digit you can just remove the ‘0’\t'1' - '0' =&gt; 1\t49 - 48 =&gt; 1public int myAtoi(String str) {\tint index=0, sign=1, total=0;\t\t//1. Empty string \tif (str.length() ==0) return 0;\t//2. Remove Spaces \twhile(str.charAt(index)==' ' &amp;&amp; index &lt; str.length())\t\tindex++;\t\t//3. Handle signs \tif (str.charAt(index)=='+' || str.charAt(index)=='-'){\t\tsign= str.charAt(index) == '+' ? 1:-1;\t\tindex++;\t}\t//4. COnvert number and avoid overflow\twhile(index&lt;str.length()){\t\tint digit= str.charAt(index) - '0'; \t\tif (digit&lt;0||digit&gt;9) break;\t\t//check if total will overflow after 10 times and add digit\t\tif (Integer.MAX_VALUE/10 &lt; total || Integer.MAX_VALUE/10 == total \t\t &amp;&amp; Integer.MAX_VALUE%10&lt;digit) { \t\t return sign==1 ? Integer.MAX_VALUE : Integer.MIN_VALUE;\t\t}\t\ttotal= 10* total+digit;\t\tindex++;\t}\treturn total*sign;}***9-Palindrome NumberDetermines whether an interger is a palindrome. An integer is a palindrome when it reads the same backward as forward.Example 1: Input: 121Output: trueExample 2: Input: -121Output: false Explanation: \tFrom left to right, it reads -121, meanwhile from right to left it becomes 121- . \t\tTherefore it is not a palindromeExample 3: Input: 10 Output: false Explanation: \tReads 01 from right to left. Therefore it is not a palindromeRevert Half of the NumberA first idea which may come to mind is to convert the number into a string and check if the string is apalindrome but this would require extra non-constant space for creating the string not allowed by the problem descriptionSecond idea would be reverting the number itself and comparing the number with the original number, ifthey are the same then the number is a palindrome, however if the reversed number is larger than int.MAX we will hit integer overflow problem.To avoid the overflow issue of the reverted number, what if we only revert half of the int number? Thereverse of the last half of the palindrome should be the same as the first half of the number if the number is a palindrome.If the input is 1221, if we can revert the last part of the number “1221” from “21” to “12” and compareit with the first half of the number “12”, since 12 is the same as 12, we know that the number is a palindrome.AlgorithmAt the very beginning we can deal with some edge cases. All negative numbers are not palindrome and numbers ending in zero can only be a palindrome if the first digit is also 0 (only 0 satisfies this property)Now let’s think about how to revert the last half of the number. For the number 1221 if we do 1221%10 we get the last digit 1. To get the second last digit we divide the number by 10 1221/10=122 and thenwe can get the last digit again by doing a modulus by 10, 122%10=2. If we multiply the last digit by 10 and add the second last digit 1*10+2=12 which gives us the reverted number we want. COntinuing thisprocess would give us the reverted number with more digits.Next is how do we know that we’ve reached the half of the number? Since we divided the number by 10 and multiplied the reversed number by 10 when the original number isless than the reversed number, it means we’ve gone through half of the number digits.class Solution { public boolean isPalindrome(int x) { if (x&lt;0 || (x%10==0 &amp;&amp; x!=0)) { return false; } int revertedNumber=0; while (x&gt;revertedNumber){ revertedNumber=x%10+revertedNumber*10; x/=10; } //when the length is an odd number, we can get rid of the middle digit by //revertedNumber/10 //For example when the input is 12321, at the end of the while loop we get x=12, //revertedNumber=123, since the middle digit doesn't matter in a palindrome we can //simply get rid of it return x==revertedNumber||x==revertedNumber/10; }}***10-Regular Expression MatchingGiven an input string (s) and a pattern (p), implement regular expression matching with support for ‘.’and ‘*’\t'.' Matches any single character\t'*' Matches zero or more of the preceding element The matching should cover the entire input string (not partial)Note: s could be empty and contains only lower case letters a-z p could be empty and contains only lower case letters a-z and characters like . or *Example 1: Input:\ts=\"aa\" \tp=\"a\" \tOutput: false \tExplanation: \t\"a\" does not match the entire string \"aa\" Example 2: Input: \ts=\"aa\"\tp=\"a*\" \tOutput: true \tExplanation: \t'*' means zero of more of the preceding element, 'a'. Therefore, by repeating\t\t\t'a' once it becomes \"aa\"Example 3: Input: \ts=\"ab\" \tp=\".*\" \tOutput: true \tExplanation: \t'.*' means \"zero or more (*) of any character (.)\"Example 4: Input: \ts=\"aab\" \tp=\"c*a*b\" \tOutput: true\tExplanation: \tc can be repeated 0 times, a can be repeated 1 time. Therefore it matches \t\t\t\"aab\" Example 5: Input: \ts=\"mississippi\" \tp=\"mis*is*p*.\"\tOutput: false RecursionIf there were no Kleene stars (the * wildcard characters for regular expressions), the problem would be easier- we simply check from left to right if each character of the text matches the pattern. Whena star is present we may need to check for may different suffixes of the text and see if they matchthe rest of the pattern. A recursive solution is a straightforward way to represent this relationshipclass Solution {\tpublic boolean isMatch(String text, String pattern) {\t\tif (pattern.isEmpty()) return text.isEmpty(); \t\t\t\tboolean first_match=(!text.isEmpty() &amp;&amp; \t\t\t\t (pattern.charAt(0)==text.charAt(0) || pattern.charAt(0)=='.'));\t\tif (pattern.length()&gt;=2 &amp;&amp; pattern.charAt(1) =='*'){\t\t\treturn (isMatch(text,pattern.substring(2))||\t\t\t (first_match &amp;&amp; isMatch(text.substring(1),pattern)));\t\t\t\t//note: pattern.substring(2) returns all of the characters after index 2 of pattern\t\t}\t\telse {\t\t\treturn first_match &amp;&amp; isMatch(text.substring(1), pattern.substring(1));\t\t}\t\t\t}}Complexity AnalysisTime Complexity: \tLet T, P be the lengths of the text and the pattern respectively. In the worst\t\t\tcase, a call to match(text[i:],pattern[2j:]) will be made (i+j i) times, and \t\t\tstrings of the order O(T-i) and O(P-2*j) will be made. Thus the complexity has\t\t\tthe order: \t\t\tsummation from i=0 to T * summation from j=0 to P/2 * (i+j i) O(T+P-i-2j).\t\t\tWe can show that this is bounded by O((T+P)2^(T+P/2))Space Complexity:\tFor every call to match, we will create those strings as described above \t\t\tpossibly creating duplicates. If memory is not freed, this will also take a\t\t\ttotal of O((T+P)2^(T+P/2)) space even though there are only order O(T^2+P^2) \t\t\tunique suffixes of P and T that are actually required Dynamic ProgrammingAs the problem has an optimal substructure, it is natural to cache intermediate results. We ask the question dp(i,j): does text[i:] and pattern[j:] match? We can describe our answer in terms of answersto questions involving smaller stringsAlgorithmWe proceed with the same recursion as in Approach 1, except because calls will only ever be made to match(text[i:], pattern[j:]), we use dp(i,j) to handle those calls instead, saving us expensive string-building operations and allowing us to cache the intermediate resultsJava Top-Down Variationenum Result {\tTRUE, FALSE\t}class Solution {\tResult[][] memo; \tpublic boolean isMatch(String text, String pattern) { \t\tmemo=new Result[text.length() +1][pattern.length() +1];\t\treturn dp(0,0,text,pattern);\t}\tpublic boolean dp(int i, int j, String text, String pattern) {\t\tif (memo[i][j]!=null) {\t\t\treturn memo[i][j]==Result.TRUE;\t\t}\t\tboolean ans; \t\tif (j==pattern.length()){\t\t\tans=i==text.length();\t\t}\t\telse {\t\t\tboolean first_match=(i&lt;text.length() &amp;&amp; (pattern.charAt(j) == text.charAt(i) ||\t\t\t\t\t patter.charAt(j) == '.'));\t\t\tif (j+1&lt;pattern.length() &amp;&amp; pattern.charAt(j+1)=='*'){\t\t\t\tans=(dp(i,j+1,text,pattern)||first_match&amp;&amp; dp(i+1,j,text,pattern));\t\t\t}\t\t\telse {\t\t\t\tans=first_match &amp;&amp; dp(i+1, j+1, text, pattern); \t\t\t}\t\t}\t\tmemo[i][j]=ans? Result.TRUE: Result.FALSE; \t\treturn ans; \t}}Complexity AnalysisTime Complexity: \tLet T, P be the lengths of the text and the pattern respectively. The work \t\t\tfor every call to dp(i,j) for i=0,...,T; j=0,...,P is done once and it is O(1) \t\t\t\twork. Hence the time complexity is O(TP)Space Complexity:\tThe only memory we use is the O(TP) boolean entries in our cache. Hence, the \t\t\tspace complexity is O(TP) Non-RecursiveThe recursive programming solutions are pretty confusing so this implementation uses 2D arrays and Dynamic ProgrammingThe logic works as follows:1. If p.charAt(j) == s.charAt(i) : dp[i][j] = dp[i-1][j-1]; 2. If p.charAt(j) == '.' : dp[i][j] = dp[i-1][j-1]; 3. If p.charAt(j) == '*': \t\tSubconditions\t1. If p.charAt(j-1)!= s.charAt(i):dp[i][j]=dp[i][j-2] \t//in this case a* only counts as empty\t2. If p.charAt(i-1)== s.charAt(i) or p.charAt(i-1) == '.': \t\t\t\tdp[i][j] = dp[i-1][j]\t//in this case a* counts as multiple a \t or dp[i][j] = dp[i][j-1]\t//in this case a* counts as single a \t or dp[i][j] = dp[i][j-2]\t//in this case a* counts as empty public boolean isMatch(String s, String p) {\tif (s==null || p==null){\t\treturn false;\t}\tboolean[][] dp=new boolean[s.length()+1][p.length()+1];\tdp[0][0]=true; \tfor (int i=0;i&lt;p.length(); i++){\t\tif (p.charAt(i)=='*' &amp;&amp; dp[0][i-1]){\t\t\tdp[0][i+1]=true; \t\t}\t}\tfor (int i=0;i&lt;s.length();i++){\t\tfor (int j=0;j&lt;p.length();j++){\t\t\tif (p.charAt(j)=='.'){\t\t\t\tdp[i+1][j+1]=dp[i][j];\t\t\t}\t\t\tif (p.charAt(j)==s.charAt(i)){\t\t\t\tdp[i+1][j+1]=dp[i][j];\t\t\t}\t\t\tif (p.charAt(j)=='*'){\t\t\t\tif (p.charAt(j-1)!=s.charAt(i) &amp;&amp; p.charAt(j-1) !='.'){\t\t\t\t\tdp[i+1][j+1]=dp[i+1][j-1];\t\t\t\t}\t\t\t\telse{\t\t\t\t\tdp[i+1][j+1]=(dp[i+1][j] || dp[i][j+1] || dp[i+1][j-1]);\t\t\t\t}\t\t\t}\t\t}\t}\treturn dp[s.length()][p.length()];}***11-Container with the Most WaterGiven n non negative integers a1,a2, … , an where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forns a container such that the container contains the most water.```Example: The array [1,8,6,2,5,4,8,3,7] would have a max area of water which is 49.\t ^\t\t ^ These two values form the container which could hold water at a max height of 7, these values are also 7 array indexes apart from each other so it could hold water at a max width of 7. The area of water which could be held is thus 7 x 7 = 49 ```Brute ForceIn this case we simply consider the area for every possible pair of the lines and find out the maximumarea out of those.public class Solution {\tpublic int maxArea(int[] height) {\t\tint maxarea=0; \t\tfor (int i=0; i&lt;height.length; i++){\t\t\tfor (int j=i+1;j&lt;height.length;j++){\t\t\t\tmaxarea=Math.max(maxarea, Math.min(height[i],height[j])*(j-i));\t\t\t}\t\t}\t\treturn maxarea;\t}}Complexity AnalysisTime complexity: \tO(n^2) \tCalculating the area for all n(n-1)/2 height pairs Space complexity: \tO(1) \tConstant extra space is used Two Pointer ApproachThe intuition behind this approach is that the area formed between the lines will always be limited by the height of the shorter line. Further, the farther the lines, the more will be the area obtained.We take two pointers, one at the beginning and one at the end of the array constituting the length of the lines. Further, we maintain a variable maxarea to store the maximum area obtained till now. At every step, we find out the area formed between them, update maxarea and move the pointer pointing to the shorter line towards the other end by one step.Initially we consider the area constituting the exterior most lines. Now to maximize the area we needto consider the area between the lines of larger lengths. If we try to move the pointer at the longerline inwards, we won’t gain any increase in area, since it is limited by the shorter line. But movingthe shorter line’s pointer could turn out to be benefical, as per the same argument, despite the reduction in width. This is done since a relatively longer line obtained by moving the shorter line’s pointer might overcome the reduction in area caused by the width reduction.public class Solution {\tpublic int maxArea(int[] height) {\t\tint maxarea=0, l=0, r=height.length-1; \t\twhile (l&lt;r){\t\t\tmaxarea=Math.max(maxarea,Math.min(height[l],height[r])*(r-l));\t\t\tif (height[l]&lt;height[r]){\t\t\t\tl++;\t\t\t}\t\t\telse{\t\t\t\tr--;\t\t\t}\t\t}\t\treturn maxarea; \t}}Complexity AnalysisTime complexity: \tO(n) \tSingle passSpace complexity: \tO(1) \tConstant space is used ***12-Integer To RomanRoman numerals are represented by seven different symbols: I, V, X, L, C, D and MSymbol\t\tValue I\t\t1V\t\t5X\t\t10L\t\t50C\t\t100D\t\t500M\t\t1000For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written asXII which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II.Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9 X can be placed before L (50) and C(100) to make 40 and 90 C can be placed before D (500) and M(1000) to make 400 and 900Given an integer, convert it to a roman numeral, input is guaranteed to be within the range from 1 to 3999Example 1: Input: 3 Output: \"III\" Example 2: Input: 4Output: \"IV\" Example 3: Input: 9 Output: \"IX\" Example 4: Input: 58 Output: \"LVIII\" Explanation: L=50, V=5, III=3Example 5: Input: 1994Output: \"MCMXCIV\"Explanation: M=1000, CM=900, XC=90 and IV=4 String Arraypublic static String intToRoman(int num) { \t\tString M[]={\"\", \"M\", \"MM\", \"MMM\"};\t//represents 1000, 2000, and 3000 since we know the number is in the range 1 to 3999\t\tString C[]={\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"};\t//represents 0, 100, 200, 300, 400, 500, 600, 700, 800, 900\tString X[]={\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"};\t//represents 0, 10, 20, 30, 40, 50, 60, 70, 80, 90\tString I[]={\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"}; \t//represents 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\treturn M[num/1000] + C[(num%1000)/100] + X[(num%100)/10] + I[num%10]; } ***13-Roman to IntegerRoman numerals are represented by seven different symbols I, V, X, L, C, D and MSymbol \t\tValue I\t\t1V\t\t5X\t\t10 L\t\t50C\t\t100D\t\t500M\t\t1000For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written asXII which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II.Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine which is written as IX. There are six instances where subtraction is used: I can be placed before V (5) and X (10) to make 4 and 9 X can be placed before L (50) and C(100) to make 40 and 90 C can be placed before D (500) and M(1000) to make 400 and 900Given an integer, convert it to a roman numeral, Input is guaranteed to be within the range from 1 to 3999Example 1: \tInput: \"III\" Output: 3 Example 2: Input: \"IV\" Output: 4Example 3: Input: \"IX\" Output: 9 Example 4: Input: \"LVIII\" Output: 58 Explanation: L=50, V=5, III=3Example 5: Input: \"MCMXCIV\" Output: 1994Explanation: M=1000, CM=900, XC=90 and IV=4Character Arrayclass Solution {\tpublic int romanToInt(String s) {\t\tMap&lt;Character, Integer&gt; map = new HashMap(); \t\tmap.put('I', 1); \t\tmap.put('V', 5); \t\tmap.put('X', 10); \t\tmap.put('L', 50); \t\tmap.put('C', 100); \t\tmap.put('D', 500); \t\tmap.put('M', 1000); \t\tchar[] sc= s.toCharArray(); \t\tint total= map.get(sc[0]); \t\tint pre=map.get(sc[0]); \t\tfor (int i=1; i&lt;sc.length; i++) {\t\t\tint curr=map.get(sc[i]); \t\t\tif (curr&lt;=pre) {\t\t\t\ttotal= total + curr; \t\t\t}\t\t\telse {\t\t\t\ttotal=total+curr -2*pre; \t\t\t}\t\t\tpre=curr; \t\t}\t\treturn total; \t}}***14-Longest Common PrefixWrite a function to find the longest common prefix string amongst an array of strings. If there is no common prefix, return an empty string “”Example 1: Input: [\"flower\", \"flow\", \"flight\"]Output: \"fl\"Example 2: Input: [\"dog\", \"racecar\", \"car\"] Output: \"\"Explanation: There is no common prefix among the input strings Note: All given inputs are in lowercase letters a-zHorizontal ScanningIntuition:For a start we will describe a simple way of find the longest prefix shared by a set of strings LCP(S1 … Sn).We will use the observation that:LCP(S1 ... Sn) = LCP(LCP(LCP(S1, S2), S3), ... Sn) Algorithm:To employ this idea, the algorithm iterates through the strings [S1 … Sn]. finding at each iterationi the longest common prefix of strings LCP(S1 … Si). When LCP(S1 … Si) is an empty string, the algorithm ends. Otherwise after n iterations, the algorithm returns LCP(S1 … Sn)Example: {leets, leetcode, leet, leeds} \\ / LCP{1,2} = leets \t leetcode\t leet \t \t\\\t{leets, leetcode, leet, leeds}\t\t \\ \t\t\t /\t\t LCP{1,3} = leet\t\t \t leet\t\t\t leet\t\t\t \\ {leets, leetcode, leet, leeds}\t\t\t \\ \t\t\t\t /\t\t\t LCP{1,4} leet\t\t\t \t\t leeds\t\t\t\t\t lee\t\t\t\tLCP{1,4} = \"lee\"public String longestCommon Prefix(String[] strs){\tif (strs.length==0){\t\treturn \"\"; \t}\tString prefix=strs[0]; \tfor (int i=1; i&lt;strs.length; i++) {\t\twhile (strs[i].indexOf(prefix) != 0) {\t\t\tprefix=prefix.substring(0, prefix.length() -1);\t\t\tif (prefix.isEmpty()) {\t\t\t\treturn \"\";\t\t\t}\t\t}\t\treturn prefix; \t}}Complexity AnalysisTime complexity: \tO(S)\tWhere S is the sum of all characters in all strings. In the worse case\t\t\t\tall n strings are the same. The algorithm compares the string S1 with \t\t\t\tthe other strings [S2 ... Sn]. There are S character comparisons where\t\t\t\tS is the sum of all characters in the input array Space complexity: \tO(1) \tWe only used constant extra space Vertical ScanningImagine a very short string is at the end of the array. The above approach will still do S comparisons.One way to optimize this case is to do vertical scanning. We compare characters from top to bottom onthe same column (same character index of the strings) before moving on to the next column.public String longestCommonPrefix(String[] strs) {\tif (strs==null || strs.length==) return \"\"; \tfor (int i=0; i&lt;strs[0].length(); i++){\t\tchar c=strs[0].charAt(i); \t\tfor (int j=1; j&lt;strs.length; j++) {\t\t\tif (i==strs[j].length() || strs[j].charAt(i)!=c){\t\t\t\treturn strs[0].substring(0,i);\t\t\t}\t\t}\t}\treturn strs[0]; }Complexity AnalysisTime complexity: \tO(S) \tWhere S is the sum of all characters in all strings. In the worst case\t\t\t\tthere will be n equal strings with length m and the algorithm performs\t\t\t\tS=n*m character comparisons. Even the worst case is still the same as \t\t\t\tApproach 1, in the best case there are at most n*minLen comparisons \t\t\t\twhere minLen is the length of the shortest string in the array. Space complexity: \tO(1)\tWe only used constant extra spaceDivide and ConquerThe idea of the algorithm comes from the associative property of LCP operation. We notice that: LCP(S1 … Sn) = LCP(LCP(S1 … Sk), LCP(Sk+1 … Sn)), where LCP(S1 … Sn) is the longest commonprefix in a set of strings [S1 … Sn], 1&lt;k&lt;nAlgorithmTo apply the previous observation, we use the divide and conquer technique, where we split the LCP(Si … Sj) problem into two subproblems LCP(Si … Smid) and LCP(Smid+1 … Sj), where mid is (i+j)/2. We use their solutions lcpLeft and lcpRight to construct the solution of the main problem LCP(Si … Sj). To accomplish this we compare one by one the characters of lcpLeft and lcpRight till there is no character match. The found common prefix of lcpLeft and lcpRight is the solution of the LCP(Si … Sj)\t\t\t\t{leetcode, leet, lee, le} \t\t\t\t / \\ Divide \t\t\t{leetcode, leet} {lee, le} Conquer\t\t\t\t|\t\t\t | \t\t\t {leet} \t\t {le} \t\t\t \\ /\t\t\t\t \t {le} \tSearching for the longest common prefix (LCP) in dataset {leetcode, leet, lee, le} public String longestCommonPrefix(String[] strs) { \tif (strs == null || strs.length ==0) return \"\";\t\treturn longestCommonPrefix(strs, 0, strs.length-1); }private String longestCommonPrefix(String[] strs, int l, int r) { \tif (l==r) {\t\treturn strs[l];\t}\telse {\t\tint mid=(l+r)/2; \t\tString lcpLeft= longestCommonPrefix(strs,l, mid); \t\tString lcpRight= longestCommonPrefix(strs,mid+1;r); \t\treturn commonPrefix(lcpLeft,lcpRight);\t}}String commonPrefix(String left, String right) {\tint min=Math.min(left.length(), right.length()); \tfor (int i=0; i&lt;min; i++) {\t\tif (left.charAt(i) !=right.charAt(i) ){\t\t\treturn left.substring(0, i);\t\t}\t}\treturn left.substring(0, min);}Complexity AnalysisIn the worst case we have n equal strings with length mTime Complexity: O(S)\t\twhere S is the number of all characters in the array, S=m*n so time\t\t\t\tcomplexity is 2*T(n/2)+O(m). Therefore time complexity is O(S). In the\t\t\t\tbest case the algorithm performs O(minLen * n) comparisons, where\t\t\t\tminLen is the shortest string of the array Space Complexity: O(m*log(n))\tThere is a memory overhead since we sotre recursive call in the \t\t\t\texecution stack. There are log(n) recursive calls, each store needs m\t\t\t\tspace to store the result so space complexity is O(m*log(n))Binary SearchThe idea is to apply binary search method to find the string with maximum value L, which is common prefix of all the strings. The algorithm searches the space in the interval (0 … minLen), where minLen is minimum string length and the maximum possible common prefix. Each time search space is divided in two equal parts, one of them is discarded because it is sure that it doesn’t contain the solution. There are two possible cases: S[1…mid] is not a common string. This means that for each j&gt;i, S[1…j] is not a common string and we discard the second half of the search space S [1…mid] is common string. This means that for each i&lt;j, S[1…i] is a common string and we discard the first half of the search space, because we try to find longer common prefix \t\t\t\t{leets, leetcode, leetc, leeds} \t\t\t\t\t\t|\t\t\t\t\t \t\t\t\t\t \"leets\"\t\t\t\t\t / \\\t\t\t\t\t \"lee\" \"ts\"\t\t\t\t\t midpoint \t\t\t\t\t\t\t\t\"lee\" in \"leetcode\" : yes\t\t\t\t\"lee\" in \"leetc\" : yes\t\t\t\t\"lee\" in \"leeds\" : yes\t\t\t\t\t\t|\t\t\t\t\t \"leets\"\t\t\t\t\t / \\\t\t\t\t\t \"lee\" \"ts\"\t\t\t\t\t | / \\\t\t\t\t\t \"lee\" \"t\" \"s\"\t\t\t\t\t \t\t\t\t\t\t midpoint\t\t\t\t\t\t \"leet\" in \"leetcode\" : yes\t\t\t\t\t\t \"leet\" in \"leetc\" : yes \t\t\t\t\t\t \"leet\" in \"leeds\" : no\t\t\t\t\t\t LCP= \"lee\" public String longestCommonPrefix(String[] strs) {\tif (strs==null || strs.length==0)\t\treturn \"\";\tint minLen=Integer.MAX_VALUE; \tfor (String str: strs)\t\tminLen=Math.min(minLen, str.length());\tint low=1; \tint high=min Len; \twhile (low&lt;=high) {\t\tint middle=(low+high)/2;\t\tif (isCommonPrefix(strs, middle)\t\t\tlow=middle+1;\t\telse \t\t\thigh=middle-1;\t}\treturn strs[0].substring(0, (low + high)/2);} private boolean isCommonPrefix(String[] strs, int len) {\tString str1=strs[0].substring(0,len);\tfor (int i=1; i&lt;strs.length; i++)\t\tif (!strs[i].startsWith(str1))\t\t\treturn false;\treturn true;}**Complexity AnalysisIn the worst case we have n equal strings with length m\tTime complexity: \tO(S * log(n)), where S is the sum of all characters in all strings. The\t\t\t\talgorithm makes log(n) iterations, for each of them there are S=m*n \t\t\t\tcomparisons, which gives in total O(S * log(n)) time complexity\tSpace complexity: \tO(1). We only used constant extra space Further ThoughtsConsidering a slightly different problem:\tGiven a set of keys S= [S1, S2 ... Sn], find the longest common prefix among a string q and S.\tThis LCP query will be called frequentlyWe coule optimize LCP queries by storing the set of keys S in a Trie. See this for Trie implementation. In a Trie, each node descending from the root represents a common prefix of some keys. But we need to find the longest common prefix of a string q and all key strings. This means that we have to find thedeepest path from the root, which satisfies the following conditions it is a prefix of query string q each node along the path must contain only one child element. Otherwise the found path will not be acommon prefix among all strings the path doesn’t comprise of nodes which are marked as end of key. Otherwise the path couldn’t be aprefix of a key which is shorter than itselfAlgorithmThe only question left is how to find the deepest path in the Trie, that fulfills the requirements above. The most effective way is to build a trie from {S1 … Sn] strings. Then find the prefix of query string q in the Trie. We traverse the Trie from the root, till it is impossible to continue thepath in the Trie because one of the conditions above is not satisfied.Searching for the longest common prefix of string \"le\" in a Trie from dataset {lead, leet}\t\t\tRoot\t\t\t 1\tl ===========&gt; \\ l\t\t\t 2\te ===============&gt; \\ eLCP \"le\" FOUND\t=============&gt; 3 \t\t\t a\t/ \\ e End of Key \"lee\" \t\t\t\t \t\t\t 6 4\t\t\t d /\t \\ t\t\t\t\t END OF KEY \"lead\"\t 7\t\t 5 End of key \"leet\"public String longestCommonPrefix(String q, String[] strs) { if (strs == null || strs.length == 0) return \"\"; if (strs.length == 1) return strs[0]; Trie trie = new Trie(); for (int i = 1; i &lt; strs.length ; i++) { trie.insert(strs[i]); } return trie.searchLongestPrefix(q);}class TrieNode { // R links to node children private TrieNode[] links; private final int R = 26; private boolean isEnd; // number of children non null links private int size; public void put(char ch, TrieNode node) { links[ch -'a'] = node; size++; } public int getLinks() { return size; } //assume methods containsKey, isEnd, get, put are implemented as it is described //in https://leetcode.com/articles/implement-trie-prefix-tree/)}public class Trie { private TrieNode root; public Trie() { root = new TrieNode(); }//assume methods insert, search, searchPrefix are implemented private String searchLongestPrefix(String word) { TrieNode node = root; StringBuilder prefix = new StringBuilder(); for (int i = 0; i &lt; word.length(); i++) { char curLetter = word.charAt(i); if (node.containsKey(curLetter) &amp;&amp; (node.getLinks() == 1) &amp;&amp; (!node.isEnd())) { prefix.append(curLetter); node = node.get(curLetter); } else return prefix.toString(); } return prefix.toString(); }}Complexity AnalysisIn the worst case query q has length m and is equal to all n strings of the array Time Complexity: O(S) where S is the number of all characters in the array, LCP query O(m) \t\t\t Trie build has O(S) time complexity. To find the common prefix of q \t\t\t in the Trie takes in the worst O(m). Space complexity: O(S) we only used additional S extra space for the Trie. ***15-3SumGiven an array “nums” of n integers, are there elements a, b, c in nums such that a+b+c=0? Find all unique triplets in the array which gives the sum of zero.Note:The solution set must not contain duplicate tripletsExample: Given array nums = [-1, 0, 1, 2, -1, -4]. A solution set is: [ [-1, 0, 1], [-1, -1, 2]]Sorted ArrayThe method is to sort an input array and then run through all indices of a possible first element of atriplet. For each element we make another 2Sum sweep of the remaining part of the array. Also we wantto skip elements to avoid duplicates in the answer without expending extra memory.public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] num) { //Arrays.sort re-arranges the array of integers in ascending order //ex. [1, 2, 3, 4] Arrays.sort(num); List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; num.length-2; i++) { if (i == 0 || (i &gt; 0 &amp;&amp; num[i] != num[i-1])) { \t //This lets us skip some of the duplicate entries in the array\t \t int lo = i+1, hi = num.length-1, sum = 0 - num[i];\t //This is for the 2 Sum sweep while (lo &lt; hi) { if (num[lo] + num[hi] == sum) { res.add(Arrays.asList(num[i], num[lo], num[hi])); while (lo &lt; hi &amp;&amp; num[lo] == num[lo+1]) lo++; while (lo &lt; hi &amp;&amp; num[hi] == num[hi-1]) hi--;\t\t //This lets us skip some of the duplicate entries in the array lo++; hi--; } else if (num[lo] + num[hi] &lt; sum) lo++; else hi--;\t\t//This allows us to optimize slightly since we know that the array is sorted } } } return res;}Complexity AnalysisTime Complexity: O(n^2) We go through a maximum of n elements for the first element of a triplet, \t\t\t and then when making a bi-directional 2Sum sweep of the remaining part of \t\t\t the array we also go through a maxiumum of n elements. Space Complexity: O(1)\t If we assume the return linked list is not extra space, then we do not \t\t\t allocate any significant extra space***16-3Sum ClosestGiven an array nums of n integers and an integer target, find three integers in nums such that the sumis closest to target. Return the sum of the three integers. You may assume that each input would haveexactly one solution.Example:Given array nums=[-1, 2, 1, -4], and target=1.The sum that is closest to the target is 2. (-1+2+1=2)3 PointersSimilar to the previous 3Sum problem, we use three pointers to point to the current element, next element and the last element. If the sum is less than the target, it means that we need to add a largerelement so next element move to the next. If the sum is greater, it means we have to add a smaller element so last element move to the second last element. Keep doing this until the end. Each time compare the difference between sum and target, if it is less than minimum difference so far, then replace result with it, otherwise continue iterating.public class Solution {\t\tpublic int threeSumClosest(int[] num, int target) {\t\tint result=num[0] + num[1] + num[num.length-1];\t\tArrays.sort(num);\t\tfor (int i=0; i&lt;num.length -2; i++) {\t\t\tint start= i+1, end = num.length -1;\t\t\twhile (start &lt; end) {\t\t\t\tint sum = num[i] + num[start] + num[end];\t\t\t\tif (sum &gt; target) {\t\t\t\t\tend--;\t\t\t\t} else {\t\t\t\t\tstart++;\t\t\t\t}\t\t\t\tif (Math.abs(sum-target) &lt; Math.abs(result-target)) {\t\t\t\t\tresult=sum;\t\t\t\t}\t\t\t}\t\t}\t\treturn result;\t}}***17-Letter Combinations of a Phone NumberGiven a string contianing digits from 2-9 inclusive, return all possible letter combinations that the number could represent.A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does notmap to any letters.2 - abc \t3 - def \t4 - ghi\t\t5 - jkl\t\t6 - mno\t\t7 - pqrs \t8 - tuv\t\t\t\t\t\t\t\t\t\t9 - wxyzExample: Input: \"23\" Output: [\"ad\", \"ae\", \"af\", \"bd\", \"be\", \"bf\", \"cd\", \"ce\", \"cf\"]. Note: The above answer is in lexicographical order but the answer can be in any orderBacktrackingBacktracking is an algorithm for finding all solutions by exploring all potential candidates. If the solution candidate turns to not be a solution (or at least not the last one), backtracking algorithm discards it by making some changes on the previous step, ie backtracks and then tries again.Here is a backtrack function backtrack(combination, next_digits) which takes as arguments an ongoing letter combination and the next digits to check. If there are no more digits to check that means the current combination is done If there are still digits to check: Iterate over the letters mapping to the next available digit Append the current letter to the current combination and proceed to check next digits: \t combination = combination + letter\t backtrack(combination + letter, next_digits[1:]).Visual RepresentationComplexity AnalysisTime Complexity: \tO(3^N * 4^M) \twhere N is the number of digits in the input that maps to 3\t\t\t\t\tletters (eg. 2, 3, 4, 5, 6, 8) and M is the number of digits \t\t\t\t\tin the input that maps to 4 letters (eg. 7, 9) and N+M is the \t\t\t\t\ttotal number digits in the input Space Complexity: \tO(3^N * 4^M)\tsince one has to keep 3^N * 4^M solutions First In First Out (FIFO) QueueThis solution utilizes the Single Queue Breadth First Search (BFS) which is an algorithm for traversingor searching tree or graph data structures. It starts at the tree root and explores all of the neighbornodes.public List&lt;String&gt; letterCombinations(String digits) {\t\tLinkedList&lt;String&gt; ans = new LinkedList&lt;String&gt;();\tif (digits.isEmpty()) return ans; \tString[] mapping = new String[] {\"0\", \"1\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", {wxyz\"};\tans.add(\"\"); \tfor (int i = 0; i&lt;digits.length(); i++) {\t\tint x = Character.getNumericValue(digits.charAt(i)); \t\t\t\t//we terminate the while loop when we encounter a new-formed string which is more than\t\t//the current level i \t\t\t\t//peek retrieves the first value of the linked list\t\twhile (ans.peek().length==i){\t\t\t\t\t\t//removes the head or the first value in the linkedlist\t\t\tString t = ans.remove(); \t\t\tfor (char s : mapping[x].toCharArray()) {\t\t\t\tans.add(t+s);\t\t\t\t//this works because add appends to the end of the list\t\t\t}\t\t}\t\treturn ans; \t}}Complexity AnalysisTime Complexity: \tO(3^N * 4^M) \twhere N is the number of digits in the input that maps to 3\t\t\t\t\tletters (eg. 2, 3, 4, 5, 6, 8) and M is the number of digits \t\t\t\t\tin the input that maps to 4 letters (eg. 7, 9) and N+M is the \t\t\t\t\ttotal number digits in the input Space Complexity: \tO(3^N * 4^M)\tsince one has to keep 3^N * 4^M solutions ***18-4SumGiven an array nums of n integers and an integer target, are there elements a, b, c, and d in nums suchthat a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of targetNote:The solution set must not contain duplicate quadrupletsExample: Given array nums = [1, 0, -1, 0, -2, 2], and target = 0A solution set is: [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]]Sorted ArrayThe idea is the same as the other numbered sum problems like 2sum and 3sum. We sort the array and thenproceed to interate through the values until we end up with a result that we are looking for.public class Solution {\tpublic List&lt;List&lt;Integer&gt;&gt; fourSum(int[] num, int target) {\t\t\t\tArrayList&lt;List&lt;Integer&gt;&gt; ans = new ArrayList&lt;&gt;();\t\t\t\tif (num.length&lt;4) {\t\t\t\t\t\treturn ans;\t\t}\t\tArrays.sort(num); \t\t\t\tfor (int i=0; i&lt;num.length-3; i++) { //picking the first candidate must leave room\t\t\t\t\t\t //for the other values \t\t\t\t\t\tif (num[i]+num[i+1]+num[i+2]+num[i+3]&gt;target) {\t\t\t\t\t\t\t\tbreak;\t\t\t\t//first candidate too large, search finished\t\t\t}\t\t\tif (num[i]+num[num.length-1]+num[num.length-2]+num[num.length-3]&lt;target) {\t\t\t\t\t\t\t\tcontinue;\t\t\t\t//first candidate too small \t\t\t}\t\t\tif(i&gt;0 &amp;&amp; num[i]==num[i-1]) {\t\t\t\t\t\t\t\tcontinue;\t\t\t\t//prevents duplicate in ans list\t\t\t}\t\t\t\t\t\tfor (int j=i+1; j&lt;num.length-2; j++) { //picking the second candidate must\t\t\t\t\t\t\t\t //leave room for other values \t\t\t\t\t\t\t\tif (num[i]+num[j]+num[j+1]+num[j+2]&gt;target) {\t\t\t\t\t\t\t\t\t\tbreak;\t\t\t\t\t//second candidate too large\t\t\t\t}\t\t\t\tif (num[i]+num[j]+num[num.length-1]+num[num.length-2]&lt;target) {\t\t\t\t\t\t\t\t\tcontinue;\t\t\t\t\t//second candidate too small\t\t\t\t}\t\t\t\tif(j&gt;i+1 &amp;&amp; num[j]==num[j-1]) {\t\t\t\t\t\t\t\t\t\tcontinue;\t\t\t\t\t//prevents duplicate results in ans list\t\t\t\t}\t\t\t\tint low=j+1, high=num.length-1;\t\t\t\t\t\t\t\t//two pointer search\t\t\t\twhile(low&lt;high) {\t\t\t\t\t\t\t\t\t\tint sum=num[i]+num[j]+num[low]+num[high];\t\t\t\t\tif (sum==target) {\t\t\t\t\t\t\t\t\t\t\t\tans.add(Arrays.asList(num[i],num[j],num[low],num[high]));\t\t\t\t\t\twhile(low&lt;high&amp;&amp;num[low]==num[low+1]) {\t\t\t\t\t\t\tlow++; //skipping over duplicates\t\t\t\t\t\t}\t\t\t\t\t\twhile(low&lt;high &amp;&amp; num[high]==num[high-1] {\t\t\t\t\t\t\thigh--; //skipping over duplicates \t\t\t\t\t\t}\t\t\t\t\t\tlow++;\t\t\t\t\t\thigh--;\t\t\t\t\t}\t\t\t\t\t//moving window\t\t\t\t\telse if (sum&lt;target) {\t\t\t\t\t\tlow++;\t\t\t\t\t}\t\t\t\t\telse {\t\t\t\t\t\thigh--;\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}\t\treturn ans;\t}}***19-Remove Nth Node From End of ListGiven a linked list, remove the n-th node from the end of the list and return its headExample: Given linked list: 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5, and n=2 After removing the second node from the end, the linked list becomes \t\t \t\t 1 -&gt; 2 -&gt; 3 -&gt; 5Note:Given n will always be validFollow up:Could you do this in one pass?Two Pass AlgorithmIntuitionWe notice that the problem could be simply reduced to another one: Remove the (L-n+1)th node from thebeginning of the list, where L is the list length. This problem is easy to solve once we found the list length L.AlgorithmFirst we will add an auxiliary “dummy” node, which points to the list head. The “dummy” node is used tosimplify some corner cases such as a list with only one node or removing the head of the list. On the first pass, find the list length L. Then we set a pointer to the dummy node and start to move it through the list till it comes to the (L-n)th node. We relink next pointer of the (L-n)th node to the(L-n+2)th node and we are done.\tD -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; NULL\t\t |\t\t v\tD -&gt; 1 -&gt; 2 -&gt; 4 -&gt; NULLpublic ListNode removeNthFromEnd(ListNode head, int n) {\t\tListNode dummy = new ListNode(0); \tdummy.next = head; \tint length =0; \tListNode first = head; \t\twhile (first!=null) {\t\t\t\tlength++;\t\tfirst=first.next;\t}\tlength -= n; \tfirst = dummy;\twhile (length&gt;0) {\t\t\t\tlength--;\t\tfirst=first.next;\t}\tfirst.next=first.next.next;\treturn dummy.next; }Complexity AnalysisTime Complexity: \tO(L) \tThe algorithm makes two traversals of the list, first to calculate the \t\t\t\tlist length L and second to find the (L-n)th node. There are 2L-n \t\t\t\toperations and time complexity is O(L)Space Complexity: \tO(1) \tWe only used constant extra spaceOne Pass AlgorithmThe previous algorithm could be optimized to one pass. Instead of one pointer, we could use two pointers. The first pointer advances the list by n+1 steps from the beginning, while the second pointerstarts from the beginning of the list. Now, both pointers are separated by exactly n nodes. We maintainthis constant gap by advancing both pointers together until the first pointer arrives past the last node. The second pointer will be pointing at the nth node counting from the last. We relink the nextpointer of the node referenced by the second pointer to point to the node’s next next node.Maintaining N=2 nodes apart between the first and second pointer \tD\t-&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; NULL first \t Head second \t\t\t Move the first pointer N+1 steps \t\t\t |\t\t\t v\tD\t-&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; NULL second Head FirstMove the first and second pointers together until the first pointer arrives past the last node \t\t\t |\t\t\t v\tD\t-&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; NULL\t\t\t\t Head Second FirstSecond pointer points to the nth node counting from last so link node to the node's next next node \t\t\t\t |\t\t\t\t v\tD\t-&gt; 1 -&gt; 2 -&gt; 3 -&gt; -&gt; 5 -&gt; NULL\t \t\t Head Second Firstpublic ListNode removeNthFromEnd(ListNode head, int n) {\t\tListNode dummy = new ListNode(0);\tdummy.next = head; \tListNode first = dummy; \tListNode second = dummy;\t\t//Moves the first pointer so that the first and second nodes are separated by n nodes\t\tfor (int i=1; i&lt;=n+1; i++) {\t\t\t\tfirst = first.next;\t}\t//Move first to the end, maintaining the gap\twhile (first!=null) {\t\tfirst=first.next;\t\tsecond=second.next;\t}\tsecond.next=second.next.next;\treturn dummy.next;}Complexity AnalysisTime Complexity: \tO(L) \tThe algorithm makes one traversal of the list of L nodes. Therefore\t\t\t\ttime complexity is O(L)Space Complexity: \tO(1)\tOnly constant extra space was used ***20-Valid ParenthesesGiven a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[’, ‘]’, determine if the input string is validAn input string is valid if: Open brackets must be closed by the same type of brackets Open brackets must be closed in the correct orderNote that an empty string is also considered validExample 1: Input: \"()\"Output: trueExample 2: Input: \"()[]{}\"Output: true Example 3: Input: \"(]\"Output: falseExample 4: Input: \"([)]\"Output: falseExample 5: Input: \"{[]}\"Output: trueCounting methodIntuitionImagine you are writing a small compiler for your college project and one of the tasks or sub-tasks forthe compiler would be to detect if the parenthesis are in place or not.The algorithm we will look at in this article can be then used to process all the parenthesis in the program your compiler is compiling and checking if all the parenthesis are in place. This makes checking if a given string of parenthesis is valid or not, an important programming problem.The expressions that we will deal with in this problem can consist of three different types of parenthesis: () {} []Before looking at how we can check if a given expression consisting of thes parenthesis is valid or not, let us look at a simpler version of the problem that consists of just one type of parenthesis. So,the expressions we can encounter in this simplified version of the problem are:(((((()))))) -- VALID()()()() -- VALID(((((((() -- INVALID((()(()))) -- VALIDLet’s look at a simple algorithm to deal with this problem We process the expression one bracket at a time starting from the left Suppose we encounter an opening bracket ie. (, it may or may not be an invalid expression becausethere can be a matching ending bracket somewhere in the remaining part of the expression. Here, we simply increment the counter keeping track of the left parenthesis till now. left += 1 If we encounter a closing bracket, this has two meanings: There was no matching opening bracket for this closing bracket and in that case we have an invalidexpression. This is the case when left==0 ie. when there are no unmatched left brackets available We had some unmatched opening bracket available to match this closing bracket. This is the case when left&gt;0 ie. we have unmatched left brackets available If we encounter a closing bracket ie. ) when left==0, then we have an invalid expression on our hands. Else, we decrement left thus reducing the number of unmatched left parenthesis available. Continue processing the string until all parenthesis have been processed If in the end we still have an unmatched left parenthesis available, this implies an invalid expressionThe reason we discussed this particular algorithm here is because the approach for the approach for the original problem derives its inspiration from this very solution.If we try and follow the same approach for our original problem, then it simply won’t work. The reasona simple counter based approach works above is because all the parenthesis are of the same type. So when we encounter a closing bracket, we simply assume a corresponding opening matching bracket to be available ie. if left&gt;0But in our problem, if we encounter say ], we don’t really know if there is a corresponding opening[ available or not. You could say: Why not maintain a separate counter for the different types of parenthesis?This doesn’t work because the relative placement of the parenthesis also matters here eg: [{]If we simply keep counters here, then as soon as we encounter the closing square bracket, we would know there is an unmatched opening square bracket available as well. But, the **closest unmatched opening bracket available is a curly bracket and not a square bracket and hence the counting approachbreaks here.StacksAn interesting property about a valid parenthesis expression is that a sub-expression. (Not every sub-expression) eg.\t{ [ [ ] { } ] } ( ) ( ) \t ^ ^\t | |The entire expression is valid, but sub portions of it are also valid in themselves. This lends a sort of a recursive structure to the problem. For example consider the expression enclosed within the marked parenthesis in the diagram above. The opening bracket is at index 1 and the corresponding closing bracket is at index 6. What if whenever we encounter a matching pair of parenthesis in the expression we simply remove itfrom the expression?Let’s have a look at this idea below where we remove the smaller expressions one at a time from the overall expression and since this is a valid expression, we would be left with an empty string in theend.The stack data structure can come in handy here in representing this recursive structure of the problem. We can't really process this from the inside out because we don't have an idea about the overall structure. But, the stack can help us process this recursively ie. from outside to inwards.Lets take a look at the algorithm for this problem using stacks as the intermediate data structure.Algorithm Initialize a stack S. Process each bracket of the expression one at a time If we encounter an opening bracket, we simply push it onto the stack. This means we will process itlater, let us simply move onto the sub-expression ahead If encounter a closing bracket, then we check the element on top of the stack. If the element at thetop of the stack is an opening bracket of the same type, then we pop it off the stack and continueprocessing. Else, this implies an invalid expression In the end, if we are left with a stack still having elements, then this implies an invalid expressionLets take a look at the implementation for this algorithmclass Solution {\t\t//Hash table that takes care of the mappings\tprivate HashMap&lt;Character, Character&gt; mappings; \t//Initialize the hash map with mappings. This simply makes the code easier to read \tpublic Solution() {\t\t\t\tthis.mappings = new HashMap&lt;Character, Character&gt;(); \t\tthis.mappings.put(')', '(');\t\tthis.mappings.put('}', '{');\t\tthis.mappings.put(']', '[');\t}\tpublic boolean isValid(String s) { \t\t\t\t// Initialize a stack to be used in the algorithm\t\tStack&lt;Character&gt; stack = new Stack&lt;Character&gt;();\t\tfor (int i=0; i&lt; s.length(); i++) {\t\t\t\t\t\tchar c = s.charAt(i);\t\t\t// If the current character is a closing bracket \t\t\tif (this.mappings.containsKey(c)) {\t\t\t\t\t\t\t\t// Get the top element of the stack. If the stack is empty, set a dummy value of '#' \t\t\t\tchar topElement = stack.empty() ? '#' : stack.pop();\t\t\t\t// If the mapping for this bracket doesn't match the stack's top element, return false. \t\t\t\tif (topElement != this.mappings.get(c)) {\t\t\t\t\treturn false;\t\t\t\t}\t\t\t} else {\t\t\t\t\t\t\t\t//If it was an opening bracket, push to the stack \t\t\t\t\t\t\t\tstack.push(c);\t\t\t}\t\t}\t\t//If the stack still contains elements, then it is an invalid expression. \t\treturn stack.isEmpty();\t}}Complexity AnalysisTime Complexity: \tO(n)\tWe simply traverse the given string one character at a time and push \t\t\t\tand pop operations on a stack take O(1) time Space Complexity: \tO(n)\tIn the worst case, when we push all opening brackets onto the stack, we\t\t\t\twill end up pushing all the brackets onto the stack eg (((((((((((***21-Merge Two Sorted ListsMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.Example: Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4Recursiveclass solution {\tpublic ListNode mergeTwoLists(ListNode l1, ListNode l2) {\t\t\t\tif (l1 == null) return l2; \t\tif (l2 == null) return l1;\t\tif (l1.val &lt; l2.val) {\t\t\t\t\t\tl1.next = mergeTwoLists(l1.next, l2);\t\t\treturn l1;\t\t} else {\t\t\t\t\t\tl2.next = mergeTwoLists(l1, l2.next);\t\t\treturn l2;\t\t}\t}\t}Non-RecursiveSimilar approach and implemenation to the recursive solution above but a little more intuitive and does not require memory being held on the stack (as the recursive program runs it has to store variables on the stack so that when the program jumps back it is able to continue)As with most other linked list solutions, a dummy node is utilized and two pointers are used to keeptrack of where we are in the the two linked lists.class solution {\tpublic ListNode mergeTwoLists(ListNode l1, ListNode l2) {\t\t\t\tListNode returnNode = new ListNode(-1); \t\tListNode headNode = returnNode; \t\t\t\twhile (l1 != null &amp;&amp; l2 != null) {\t\t\tif (l1.val &lt;= l2.val) {\t\t\t\treturnNode.next = l1;\t\t\t\tl1 = l1.next;\t\t\t} else {\t\t\t\treturnNode.next = l2;\t\t\t\tl2 = l2.next; \t\t\t}\t\t\treturnNode = returnNode.next;\t\t}\t\tif (l1 == null) {\t\t\treturnNode.next = l2;\t\t} else if (l2 == null) {\t\t\treturnNode.next = l1; \t\t}\t\treturn headNode.next; \t}}***22-Generate ParenthesesGiven n pairs of parentheses, write a function to generate all combinations of well-formed parentheses.For example: Given n=3, a solution set is: [ \"((()))\", \"(()())\". \"(())()\", \"()(())\", \"()()()\"]Brute ForceIntuitionWe can generate all 2^(2n) sequences of ( and ) characters. Then we can check if each one is validAlgorithmTo generate all sequences, we use recursion. All sequences of length n is just ( plus all sequencesof length n-1, and then ) plus all sequences of length n-1.To check whether a sequence is valid, we keep track of balance, the net number of opening brackets minuts closing brackets. If it falls below zero at any time, or doesn’t end in zero, the sequence is invalid - otherwise it is valid.class Solution {\t\tpublic List&lt;String&gt; generateParenthesis(int n) {\t\t\t\tList&lt;String&gt; combinations = new ArrayList(); \t\tgenerateAll(new char[2*n], 0, combinations);\t\treturn combinations;\t}\tpublic void generateAll(char[] current, int pos, List&lt;String&gt; result) {\t\t\t\tif(pos == current.length) {\t\t\t\t\t\tif (valid(current)) {\t\t\t\tresult.add(new String(current));\t\t\t} \t\t} else {\t\t\tcurrent[pos] = '(';\t\t\tgenerateAll(current, pos+1, result);\t\t\tcurrent[pos] = ')';\t\t\tgenerateAll(current, pos+1, result);\t\t\t\t}\t}\tpublic boolean valid(char[] current) {\t\t\t\tint balance = 0; \t\tfor (char c : current) {\t\t\t\t\t\tif(c == '(') {\t\t\t\tbalance++;\t\t\t} else {\t\t\t\tbalance--;\t\t\t}\t\t\tif(balance &lt; 0) {\t\t\t\treturn false; \t\t\t}\t\t}\t\treturn (balance == 0);\t}}Complexity AnalysisTime Complexity: \tO(2^2n * n)\tFor each of 2^2n sequences, we need to create an validate the \t\t\t\t\tsequence, which takes O(n) work in the worst case Space Complexity: \tO(2^2n * n) \tNaively, every sequence could be valid, see Closure number for\t\t\t\t\ta tighter asymptotic bound BacktrackingIntuition and AlgorithmInstead of adding ( or ) every time as we do in the Brute Force algorithm, let’s only add them when we know it will remain a valid sequence. We can do this by keeping track of the number of openingand closing brackets we have placed so far.We can start an opening bracket if we still have one (of n) left to place. And we can start a closingbracket if it would not exceed the number of opening bracketsclass Solution {\t\tpublic List&lt;String&gt; generateParenthesis(int n) {\t\t\t\tList&lt;String&gt; ans = new ArrayList(); \t\tbacktrack(ans, \"\", 0, 0, n);\t\treturn ans; \t}\tpublic void backtrack(List&lt;String&gt; ans, String cur, int open, int close, int max){\t\t\t\tif (cur.length() == max*2) {\t\t\tans.add(cur);\t\t\treturn;\t\t}\t\tif(open &lt; max) {\t\t\tbacktrack(ans, cur + \"(\", open + 1, close, max);\t\t} \t\t\t\tif (close &lt; open) {\t\t\tbacktrack(ans, cur + \")\", open, close +1, max);\t\t}\t}}Complexity AnalysisOur complexity analysis rests on understanding how many elements there are in generateParenthesis(n).This analysis is outside the scope of this article, but it turns out this is the nth Catalan number 1/(n+1) (2n choose n), which is bounded asymptotically by 4^n/(n* sqrt(n)).Time Complexity: \tO((4^n)/sqrt(n))\tEach valid sequence has at most n steps during the \t\t\t\t\t\tbacktracking procedureSpace Complexity: \tO((4^n)/sqrt(n))\tAs described above and using O(n) space to store the\t\t\t\t\t\tsequenceAnother way to think about the runtime of backtracking algorithms on interviewers is O(b^d), where b isthe branching factor and d is the maximum depth of recursion.Backtracking is characterized by a number of decisions b that can be made at each level of recursion. If you visualize the recursion tree, this is the number of children each internal node has. You canalso think of b as standing for “base”, which helps us remember that b is the base of the exponential.If we make b decisions at each level of recursion, and we expand the recursion tree to d levels (ie. each path has a length of d), then we get b^d nodes. Since backtracking is exhaustive and must visit each of these nodes, the runtime is O(b^d)Closure NumberTo enumerate something, generally we would like to express it as a sum of disjoint subsets that are easier to count.Consider the closure number of a valid parentheses sequence s: the least index &gt;= 0 so that `S[0], S[1], … , S[2 * index + 1] is valid. Clearly, every parentheses sequence has a unique closurenumber. We can try to enumerate them individually.AlgorithmFor each closure number c, we know the starting and ending brackets must be at index 0 and 2 * c + 1. Then, the 2 * c elements between must be a valid sequence, plus the rest of the elementsmust be a valid sequence.This is just some minor improvement to the backtracking solution using the fact that for all valid solutions the first char is always ‘(‘ and the lat char is always ‘)’. We initialize the starting string to ‘(‘ and set the recursion bottom condition to string reaching length of 2 * n - 1 - we knowthat we need to append a bracket at the end. There will not be much of an improvement in the runtimehowever.class Solution {\tpublic List&lt;String&gt; generateParenthesis(int n) {\t\tList&lt;String&gt; ans = new ArrayList(); \t\tif (n==0) {\t\t\tans.add(\"\");\t\t} else {\t\t\tfor (int c=0; c&lt;n; ++c)\t\t\t\tfor (String left: generateParenthesis(c))\t\t\t\t\tfor (String right: generateParenthesis(n-1-c))\t\t\t\t\t\tans.add(\"(\" + left + \")\" + right);\t\t}\t\treturn ans;\t}}Complexity AnalysisTime Complexity: \tO((4^n)/sqrt(n))Space Complexity: \tO((4^n)/sqrt(n))***23-Merge k Sorted ListsMerge k sorted linked lists and return it as one sorted list. Analyze and descibe its complexity:Example: Input: [\t1 -&gt; 4 -&gt; 5,\t1 -&gt; 3 -&gt; 4,\t2 -&gt; 6]Output: 1 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 4 -&gt; 5 -&gt; 6Brute ForceIntuition and Algorithm Traverse all the linked lists and collect the values of the nodes into an array Sort and iterate over this array to get the proper value of nodes Create a new sorted linked list and extend it with the new nodesAs for sorting you can refer to the Algorithms/Data Structures CheatSheet for more about sorting algorithms.***146-LRU CacheDesign and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations: get and put.get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1put(key, value) - Set or insert the value if the key is not already present. When the cache reached its capacity, it should invalidate the least recently used item before inserting a new item.Follow up:Could both of these operations be done in O(1) time complexity?Example:LRUCache cache = new LRUCache(2 /* capacity */);cache.put(1, 1);cache.put(2, 2);cache.get(1); \t\t\t// returns 1 cache.put(3, 3); \t\t// evicts key 2cache.get(2);\t\t\t// returns -1 (not found)\tIndex Lowest Common Ancestor Count And Say Maximum SubArray Plus One Sqrt of X Climbing Stairs Remove Duplicates from sorted list Same Tree Symmetric Tree Max Depth of Binary Tree Convert Sorted Array to Binary Search Tree Balanced Binary Tree Minimum Depth of Binary Tree Path Sum Pascal’s Triangle Valid Palindrome Pascal’s Triangle II Best Time to Buy and Sell Stock Best Time to Buy and Sell Stock II Single Number Linked List Cycle Min Stack Intersection of Two Linked Lists Two Sum II - Input array is sorted Excel Sheet Column Title Majority Element Excel Sheet Column Number Factorial Trailing Zeroes Combine Two Tables Second Highest Salary Employees Earning More Than Their Managers Duplicate Emails Customers Who Never Order Rotate Array Delete Duplicate Emails Rising Temperature X of a Kind in a Deck of Cards Reverse Integer Add Two Numbers Longest Substring Without Repeating Characters House Robber Happy Number Remove Linked List Elements Count Primes Isomorphic Strings Reverse LinkedList Contains Duplicate Contains Duplicate II Implement Stack Using Queues Invert Binary Tree Fibonacci Number kth Largest Element Power Of Two Valid Sudoku Implement Queue Using Stack Palindrome LinkedList Delete Node in a Linked List Is Anagram Binary Tree Paths Add Digits Largest Perimeter Triangle Ugly Number Missing Number Is Bad Version Move Zeroes Word Pattern Can Win Nim Power Of Three Power of Four Reverse String Implement strStr() Reverse Vowels of a String Intersection of two arrays Is Perfect Square Sum of Two Integers Guess Number Higher or Lower Ransom Note First Unique Character in a String Find the Difference Nth Digit Sum of Left Leaves Longest Palindrome Fizz Buzz Third maximum Number Add Two Strings Construct Quad Tree N-ary Tree Level Order Traversal Number of Segments in a String Binary Tree Level Order Traversal Path Sum III Find All Anagrams in a String Arranging Coins Hamming Distance String Compression Number of Boomerangs Find All Numbers Disappeared in an Array Assign Cookies Poor Pigs Find Pivot Index Squares of a Sorted Array Repeated Substring Pattern Island Perimeter Number Complement Binary Watch Minimum Moves to Equal Array Elements License Key Formatting Max Consecutive Ones Permutations Construct the Rectangle Merge Intervals Merged sorted lists Next Greater Element I String Without AAA or BBB Keyboard Row Find Mode in Binary Search Tree Base 7 Relative Ranks Perfect Number Detect Capital Longest Uncommon Subsequence I Course Schedule II Letter Combinations of a Phone Number Sudoku Solver Bulls and Cows N-Queens 1 K-diff pairs in an Array Is Subsequence Minimum Absolute Difference in BST BST Tree to Greater Tree Student Attendance Record I Reverse Words in String III Quad Tree Intersection Long Pressed Name Binary Tree Zigag Level Order Traversal Array Partition I Reshape the matrix Swap Nodes in Pairs Generate Parentheses Distribute Candies Maximum Subproduct Subarray Binary Tree Right Side View Find Minimum in Rotated Sorted Array Binary Search Tree Iterator Find Peak Element Next Permutation Search in Rotated Sorted Array Transpose Matrix Merge K sorted listsLowest Common Ancestorpublic TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { TreeNode current = root; while (current != null){ if (p.val &lt; current.val &amp;&amp; q.val &lt; current.val)\t\t// Both located in left side. current = current.left; else if (p.val &gt; current.val &amp;&amp; q.val &gt; current.val)\t// Both located in right side current = current.right; else return current;\t\t// Seperate branches, therefore current is lca. } return null;}Count And SayThe updated version runs in 2ms and passes 96.85% submissions.public String countAndSay(int n) { String result = \"1\";\t\t// initial result StringBuilder temp;\t\t\t// to create intermediate strings efficiently. int len;\t\t\t\t\t// length of the result string. for (int i = 1; i &lt; n; ++i){\t// We need to iterate n-1 times, because 1st result is 1 int startIndex = 0;\t\t\t// we will look at each index of result temp = new StringBuilder();\t// and store freq,char in the builder len = result.length(); while (startIndex &lt; len){ char ch = result.charAt(startIndex++);\t// get the char at startIndex, and increment it, because we also want to look at the next character int count = 1;\t\t\t\t\t// intialize it's count to 1, we just saw it. while (startIndex &lt; len &amp;&amp; ch == result.charAt(startIndex)){ count++;\t\t\t// If next also matches, increment count and startIndex startIndex++; } temp.append(count).append(ch);\t// No more match, Add the freq and the char } result = temp.toString();\t// Update result to generate the next cound-and-say } return result;}Maximum SubArraypublic int maxSubArray(int[] nums) { int localMax = nums[0];\t\t// keeps track of max sum between the previous and current int globalMax = nums[0];\t// keeps track of global max sum. /* The idea is as follows: If the current element is greater than the previous local max, then we found an element that is a better option then before. Then, if that localmax changed and is greater than our global max, update our global max. */ for (int i = 1; i &lt; nums.length; i++){ localMax = Math.max(localMax + nums[i], nums[i]); globalMax = Math.max(localMax, globalMax); } return globalMax;}Plus Onepublic int[] plusOne(int[] digits){ digits[digits.length-1]++;\t\t\t// Add one to the last place. if (digits[digits.length-1] == 10)\t// If it became 10, { for (int i = digits.length-1; i &gt; 0; i--)\t// Then add one to its previous place { if (digits[i] == 10){\t// If that also results in 10, keep propogating that 1 digits[i-1]++;\t\t// upstream digits[i] = 0; } } if (digits[0] == 10){\t// If the index 0 is 10, then the number is a multiple of 10. digits = new int[digits.length+1]; digits[0] = 1;\t\t// So increase length by 1 and set index 0 to 1. } } return digits;}Sqrt of Xpublic int mySqrt(int x) { long x1 = 10 - (100 - x)/20;\t\t// Using Newton's method of computing square roots. boolean done = false; while (!done) { long x2 = x1 - (x1*x1 - x)/(2*x1); if (x2 == x1) done = true; else x1 = x2; } return (int)x1-1;}Climbing Stairspublic int climbStairs(int n) { if (n &lt; 4)\t\t// I chose n &lt; 4 because climbStairs(0 &lt;= n &lt;= 3) = n return n; int[] dp = new int[n+1]; for (int i = 0; i &lt; 4; i++) dp[i] = i; //return naiveDP(n, dp); return efficientDP(n);}public int naiveDP(int n, int dp[]){ if (dp[n] != 0)\t\t// If already computed, return it. return dp[n]; int ways = naiveDP(n-1, dp) + naiveDP(n-2, dp);\t// Just like Fibonacci. dp[n] = ways;\t\t// Save it. return ways;}public int efficientDP(int n){ if (n &lt; 4) return n; int[] dp = new int[n+1];\t\t// Initialize dp of length n+1 to store n'th way. for (int i = 0; i &lt; 4; i++) dp[i] = i;\t\t\t\t\t// climbStairs(0 &lt;= n &lt;= 3) = n for (int i = 3; i &lt;= n; i++)\t// climbStairs(n) = climbStairs(n-1) + climbstairs(n-2); dp[i] = dp[i-1] + dp[i-2]; // So fetch those values from the dp array. return dp[n];}Remove Duplicates from sorted listpublic ListNode deleteDuplicates(ListNode head){ ListNode current = head; // while we haven't reached the tail while (current != null &amp;&amp; current.next != null) { // if current's next is the same as current, skip and update its next while (current.next != null &amp;&amp; current.val == current.next.val) current.next = current.next.next; current = current.next; } return head;}Same Treepublic boolean isSameTree(TreeNode p, TreeNode q){ if (p == null &amp;&amp; q == null)\t\t// Two empty trees return true; // If one of the node is null, the two trees can't be equal. if ((p == null &amp;&amp; q != null) || (p != null &amp;&amp; q == null)) return false; // If the values in the two nodes are same, compare its's left and right sub-tree. if (p.val == q.val) return isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right); return false;\t\t// If nothing worked out, they can't be same.}Symmetric Treepublic boolean isSymmetric(TreeNode root){ return isSymmetricIterative(root);}public boolean isSymmetricIterative(TreeNode root){ Queue&lt;TreeNode&gt; track = new LinkedList&lt;&gt;(); track.add(root);\t\t// Add the root twice so we can compare its left and right track.add(root); while (!track.isEmpty()) { TreeNode x = track.poll();\t\t// Remove 2 nodes TreeNode y = track.poll(); if (x == null &amp;&amp; y == null)\t\t// If they are both null, skip it. continue; if (x == null || y == null || x.val != y.val) return false;\t\t\t\t// If values don't match or one is null track.add(x.left);\t\t// Otherwise add them in this order -&gt; LRRL track.add(y.right);\t\t// because we need to compare left most with the track.add(x.right);\t\t// right most, then inner left with inner right. track.add(y.left); } return true;\t\t// Everything's all right, so they must be symmetric.}public boolean isSymmetricRecursive(TreeNode root){ return helperRecursive(root, root);}private boolean helperRecursive(TreeNode x, TreeNode y){ if (x == null || y == null)\t\t// Base Case: Both or one is null, so true return true; return (x.val == y.val &amp;&amp; helperRecursive(x.left, y.right) &amp;&amp; helperRecursive(x.right, y.left)); // Check if values match and 1.left matches with the 2.right and 1.right matches with 2.left}Max Depth of Binary Tree/*If root is null, height is 0 else add 1 and find if the left or the right has a greater depth.*/public int maxDepth(TreeNode root) { return root == null ? 0 : 1 + Math.max(maxDepth(root.left), maxDepth(root.right));}Convert Sorted Array to Binary Search Treepublic TreeNode sortedArrayToBST(int[] nums){ return aux(nums, 0, nums.length-1);}private TreeNode aux(int[] n, int left, int right){ if (left &gt; right)\t\t\t\t\t// Either empty, or return a null node return null; int mid = (left+right+1)/2;\t\t\t// Create a node with the middle value TreeNode root = new TreeNode(n[mid]); root.left = aux(n, left, mid-1);\t// Compute the left (which is the mid in left side) root.right = aux(n, mid+1, right);\t// Compute the right (which is the mid in right side) return root;}Balanced Binary Treepublic boolean isBalanced(TreeNode root){ return isBalancedBottomUp(root);}public boolean isBalancedTopDown(TreeNode root){ if (root == null) return true; // if difference between root's left and right is &gt; 1, they're not balanced if (Math.abs((getHeight(root.left) - getHeight(root.right))) &gt; 1) return false; // otherwise, we need to check if the left and right subtree are also balanced. return isBalanced(root.left) &amp;&amp; isBalanced(root.right);}private int getHeight(TreeNode node){ // Standard height of a binary tree calculator if (node == null) return 0; return 1 + Math.max(getHeight(node.left), getHeight(node.right));}public boolean isBalancedBottomUp(TreeNode root){ return getHeight2(root) != -1;\t// -1 means not balanced.}private int getHeight2(TreeNode node){ if (node == null) return 0; int lHeight = getHeight2(node.left);\t// Get the height of left and right tree int rHeight = getHeight2(node.right); // If at any point there was a height difference of more than 1 or previous node's leftheight || rightheight returned -1, return -1 to let the next node know there was an imbalance. if ((Math.abs(lHeight-rHeight) &gt; 1) || lHeight == -1 || rHeight == -1) return -1; return 1 + Math.max(lHeight, rHeight); // Else carry on with the normal procedure}Minimum Depth of Binary Treepublic int minDepth(TreeNode root) { // Base case if (root == null) return 0; // Left is null, find minheight from right side if (root.left == null) return 1 + minDepth(root.right); // Right is null, find minheight from left side if (root.right == null) return 1 + minDepth(root.left); // Else, both are not null, so compute min height from the two sides. return 1 + Math.min(minDepth(root.left), minDepth(root.right));}Path Sumpublic boolean hasPathSum(TreeNode root, int sum) { if (root == null) return false;\t// No sum exist sum -= root.val;\t// Sum decreases if (root.left == null &amp;&amp; root.right == null)\t// If we are at a leaf return sum == 0;\t// Check if the sum is 0. return hasPathSum(root.left, sum) || hasPathSum(root.right, sum); // Otherwise look if you can make sum = 0 by exploring the left or right side.}Pascal’s Trianglepublic List&lt;List&lt;Integer&gt;&gt; generate(int numRows) { List&lt;List&lt;Integer&gt;&gt; pt = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; numRows; i++)\t// Need to add all n rows { List&lt;Integer&gt; temp = new ArrayList&lt;&gt;();\t\t// temp list to store values for (int j = 0; j &lt;= i; j++) { if (j == 0 || i == j)\t\t// First and last values are always 1. temp.add(1); else\t// Else, get the previous row and surrounding two values and add them temp.add(pt.get(i-1).get(j-1) + pt.get(i-1).get(j)); } pt.add(temp);\t\t// Add it to pt. } return pt;}Valid Palindromepublic boolean isPalindrome(String s) { if (s.length() &gt; 0){\t\t// Only do this is s is not empty s = s.toLowerCase();\t// Convert it to lowercase int left = 0;\t\t\t// Initialize left and right pointers int right = s.length()-1; while (left &lt; right)\t// continue while we haven't hit the middle of the string { // If char at left is not a letter or a number, skip it. if (!Character.isLetter(s.charAt(left)) &amp;&amp; !Character.isDigit(s.charAt(left))) left++; // Same with char at right. else if (!Character.isLetter(s.charAt(right)) &amp;&amp; !Character.isDigit(s.charAt(right))) right--; //Char's are now alphanumeric. else if (s.charAt(left) != s.charAt(right))\t// If they don't match return false;\t// return false else\t// They matched, so try to match the inner string { left++; right--; } } } return true;\t// No mismatch found, return true.}Pascal’s Triangle IIpublic List&lt;Integer&gt; getRow(int rowIndex){ ArrayList&lt;Integer&gt; row = new ArrayList&lt;&gt;(); row.add(1);\t// First is always 1.\t// Using the nth row formula to compute the coeeficients. You can google \"nth row Pascal\" for (int i = 0; i &lt; rowIndex; i++) row.add((int)(1.0*row.get(i)*(rowIndex-i)/(i+1))); return row;}Best Time to Buy and Sell Stock/*The general idea is that if the price you are looking at right now in the array minus the minimum observed so far is greater than the maximum profit you recorded, update the max.*/public int maxProfit(int[] prices) { if (prices.length == 0)\t\t// Empty array return 0; int min = prices[0]; int max = 0; for (int i = 1; i &lt; prices.length; i++) { if (prices[i] &lt; min) min = prices[i]; else if (prices[i] - min &gt; max) max = prices[i]-min; } return max;}Best Time to Buy and Sell Stock II/*The general idea is that the moment you observe a valley and consecutive peak, make the trade by buying the stock on the valley day and selling it on the peak day.*/public int maxProfit(int[] prices) { int sum = 0; for (int i = 0; i &lt; prices.length-1; i++) if (prices[i+1] &gt; prices[i]) sum += (prices[i+1] - prices[i]); return sum;}Single Number/*The general idea is that XOR of two same numbers returns 0 and XOR with 0 returns the same number. So if there is only one element that doesn't have a pair, all the remaining will XOR with themselves at one point and give 0 but not the singleton element.*/public int singleNumber(int[] nums) { int num = nums[0]; for (int i = 1; i &lt; nums.length; i++) num ^= nums[i]; return num;}Linked List Cycle// Using the slow-fast runner technique.public boolean hasCycle(ListNode head) { if (head == null) return false; ListNode first = head;\t// Slow runner ListNode second = first.next;\t\t// Fast Runner // while second is not at the end or it isn't the tail while (second != null &amp;&amp; second.next != null) { if (second == first)\t// If fast made a full loop and met up with slow return true;\t\t// We got a cycle first = first.next;\t\t// Slow moves one step second = second.next.next;\t// Second advances two. } return false;\t\t// We don't have a cycle}Min Stackclass MinStack { int min; Stack&lt;Integer&gt; stack; public MinStack() { min = Integer.MAX_VALUE; stack = new Stack&lt;&gt;(); } public void push(int x) { stack.push(x);\t\t// Push the value if (x &lt; min)\t\t// If that value is minimum than we have, update min min = x; stack.push(min);\t// Push the minimum on top of the stack for constant time }\t\t\t\t\t\t// minimum retrieval. public void pop() { stack.pop();\t\t// Pop the minimum. stack.pop();\t\t// Pop the actual element meant to be popped if (stack.isEmpty())\t// If empty, min is Max int value min = Integer.MAX_VALUE; else min = stack.peek();\t// Otherwise, min would be the top most element since we }\t\t\t\t\t\t\t// always push the minimum on top of any element we push. public int top() { return stack.elementAt(stack.size()-2);\t// Top element is actually at second last }\t\t\t\t// index since the last element is the minimum. public int getMin() { return min; }}Intersection of Two Linked Lists/*The general idea is that if you are done traversing any of the lists, make it's pointer point to the head of the other list and start iterating. The reasoning is that the second time they iterate, they will have traversed exactly the same distance (it's length plus the other list's head to the intersecting node) and will meet at the intersecting node.*/public ListNode getIntersectionNode(ListNode headA, ListNode headB) { int count = 0; ListNode pA = headA; ListNode pB = headB; while (pA != pB){ pA = pA == null ? headB : pA.next; pB = pB == null ? headA : pB.next; } return pA;}Two Sum II - Input array is sortedpublic int[] twoSum(int[] numbers, int target) { int left = 0, right = numbers.length-1; while (left &lt; right)\t// Narrow down the window from both sides until they add up. { int sum = numbers[left] + numbers[right]; if (sum &gt; target)\t// We overshot, so decrease the window from right right--; else if (sum &lt; target)\t// Undershot, increase windows from left so next sum is more left++; else break;\t\t\t\t// Found the two numbers } return new int[] {left+1, right+1};\t// +1 because LeetCode followed 1-n indexing.}Excel Sheet Column Titlepublic String convertToTitle(int n) { String res = \"\"; while (n &gt; 0) { /* 1 is A and 26 is Z, so n-1 to change it to 0-25 scheme. Then, % 26 to find how much it is off on a full alphabet cycle, add 65 (ASCII for A) and convert it to char */ res = String.valueOf((char)(65+((n-1)%26))) + res; n = (n-1) / 26;\t// Subtract 1 and divide by 26 to get prepare for the next character } return res;}Majority ElementUses Moore’s Algorithm// This is the implementation of Moore's Algorithm for O(n) complexity.public int majorityElement(int[] nums) { int major = nums[0]; int count = 1; for (int i = 0; i &lt; nums.length; i++){ if (major == nums[i]) count++; else count--; if (count == 0){ major = nums[i]; count = 1; } } return major;}Excel Sheet Column Number/*Start from the end of String s, compute the ASCII for the char, +1 for 1-26 Alphabet-Scheme (hence -64 instead of -65) and multiply it to 26^{distance from the end of the string}*/public int titleToNumber(String s) { int length = s.length()-1; int total = 0; for (int i = length; i &gt; -1; i--) total += (int)(s.charAt(i)-64) * Math.pow(26,length-i); return total;}Factorial Trailing Zeroes/*The general idea is that every factorial that has 5 as a multiple also has 2 to multiply to 10. So if we can count the number of times we can divide n by 5, should gives us the number of trailing zeroes. O(log(n) base 5) complexity.*/public int trailingZeroes(int n) { int res = 0; while (n &gt; 4) { res += n / 5; n /= 5; } return res;}Combine Two Tablesselect FirstName, LastName, City, Statefrom Person left join Address on Address.personId = person.personId;Second Highest Salaryselect max(salary) as SecondHighestSalaryfrom Employeewhere salary not in (select max(salary) from employee);Employees Earning More Than Their Managersselect emp.Name as Employeefrom Employee emp, Employee manwhere emp.managerId = man.Id and emp.salary &gt; man.salary;Duplicate Emailsselect emailfrom persongroup by (email)having count(*) &gt; 1;Customers Who Never Orderselect name as Customersfrom Customerswhere customers.id not in (select customerId from orders);Rotate Arraypublic void rotate(int[] nums, int k) { k %= nums.length;\t\t// k == nums.length ? Then it's a full rotation and no change if (k == 0) return; reverse(nums, 0 , nums.length-1);\t// First reverse the full array reverse(nums, 0, k-1);\t\t\t\t// Then reverse element from index 0 to k-1 reverse(nums, k, nums.length-1);\t// Then reverse all elements from k to end of Array}// Reverse function that reverses the array from specified indices.public void reverse(int[] nums, int start, int end){ while (start &lt; end){ int temp = nums[start]; nums[start] = nums[end]; nums[end] = temp; start++; end--; }}Delete Duplicate Emailsdelete from Personwhere Id not in (select min_id from(select min(Id) as min_id from Person group by Email) as a)Rising Temperatureselect w2.idfrom weather w1, weather w2where Datediff(w2.recorddate, w1.recorddate) = 1 and w2.temperature &gt; w1.temperature;X of a Kind in a Deck of Cardspublic boolean hasGroupsSizeX(int[] deck) { HashMap&lt;Integer, Integer&gt; freq = new HashMap&lt;&gt;(); for (int i = 0; i &lt; deck.length; i++)\t\t// Record the frequencies freq.put(deck[i],freq.getOrDefault(deck[i],0)+1);/*deck = [1,1,2,2,2,2,3,3,3,3,3,3]number 1 has len of 2, number 2 has len of 4, number 3 has len of 6, they share a Greatest common divisor of 2, which means diving them into group of size X = 2, will be valid. Thus we just have to ensure each length (of a number) shares a Greatest Common Divisor that's &gt;= 2.*/ int hcf = 0; for (int i: freq.keySet()) hcf = gcd(hcf, freq.get(i)); return hcf &gt; 1;}private static int gcd(int x, int y){ int temp = 0; while (y != 0){ temp = y; y = x % y; x = temp; } return x;}Reverse Integerpublic int reverse(int x) { int sign = x &lt; 0 ? -1 : 1; x = x * sign;\t\t\t\t\t\t\t// Make x positive long n = 0; while (x &gt; 0){ n = n * 10 + x % 10;\t\t\t\t// Start adding from the end. x /= 10; } return (int)n == n ? (int)n*sign : 0;\t// Try converting to int from long, if no change,}\t\t\t\t\t\t\t\t\t\t\t// Return n * sign, else 0 cause overflow.Add Two Numberspublic ListNode addTwoNumbers(ListNode l1, ListNode l2) { int carry = 0;\t\t\t\t\t\t\t// To record the carry int sum = 0;\t\t\t\t\t\t\t// To record the total of two vals ListNode dummy = new ListNode(0);\t\t// Dummy's next is the actual head ListNode curr = dummy; do{ if (l1 == null)\t\t\t\t\t\t// If one of the node is null, we set it to a l1 = new ListNode(0);\t\t\t// dummy value of 0 so we can adjust for if (l2 == null)\t\t\t\t\t\t// different length of the two lists. l2 = new ListNode(0); sum = l1.val + l2.val + carry;\t\t// Add the two vals and the carry. carry = sum &lt; 10 ? 0 : 1;\t\t\t// Record the carry for the next iteration curr.next = new ListNode(sum % 10);\t// next node's value is sum % 10. curr = curr.next;\t\t\t\t\t// advance current, l1 and l2. l1 = l1.next; l2 = l2.next; } while(l1 != null || l2 != null); if (carry == 1)\t\t\t\t\t\t\t// In the end, if carry is 1, it was from curr.next = new ListNode(carry);\t// from adding last terms, so make next node 1 return dummy.next;\t\t\t\t\t\t// Return the actual head.}Longest Substring Without Repeating Characterspublic int lengthOfLongestSubstring(String s) { if (s == null || s.length() == 0) return 0; int[] hash = new int[128];\t\t\t\t\t// To store the occurence of characters int maxLength = 0; for (int i = 0, j = 0; j &lt; s.length(); j++){ i = Math.max(hash[s.charAt(j)], i);\t\t// Check the most recent index of character. maxLength = Math.max(maxLength, j-i+1);\t// That minus current pointer gives length hash[s.charAt(j)] = j+1;\t\t\t\t// Record the index of the next character. } return maxLength;}House Robber/*The basic idea is that if you are robbing house i, the maximum loot may come from by robbing the i-2th house or by robbing the i-3th house. Therefore rob both and then find the path that gave the maximum profit.Example: loot = [1,9,3,8,4,3,6,4,3,5,7,6]Profit DP = [1,9,4,17,13,20,23,24,26,29,33,35]Here,\tdp[2] = loot[2] + loot[1]\tdp[4] = loot[4] + max(dp[2], dp[1])\tdp[5] = loot[5] + max(dp[3], dp[2]) and so on.In the end, just compare the last two elements to check which path gave us the maximum profit.Some people might not prefer modifying the original nums array. In that case, you can initialize another dp array of same length, initialize the first two elements as dp[0] = nums[0] and dp[1] = nums[1] and dp[3] = nums[0] + nums[2] and then performing the same loop. In that case, you would be using O(n) space.*/public int rob(int[] nums) { if (nums.length == 0 || nums == null)\t\t\t// 3 Base Case return 0; if (nums.length == 1) return nums[0]; else if (nums.length == 2) return Math.max(nums[0], nums[1]); else{ nums[2] = nums[0] + nums[2];\t\t\t\t// House 3 profit is rob House 1 and 3. for (int i = 3; i &lt; nums.length; i++) nums[i] = nums[i] + Math.max(nums[i-2], nums[i-3]); return Math.max(nums[nums.length-1], nums[nums.length-2]); }}Happy Numberpublic boolean isHappy(int n) { return isHappyConstantSpace(n);\t\t// Much faster than set method //return isHappySet(n); } private boolean isHappyConstantSpace(int n){ int numSeenLessThan10 = 0;\t\t// If I see 10 single digits, then it means that I am while (n != 1){\t\t\t\t\t// now starting to see repititions. if (n &lt; 10)\t\t\t\t\t// Each time I see a num &lt; 10, increment the counter numSeenLessThan10++; if (numSeenLessThan10 &gt; 9) return false; n = getSquare(n);\t\t\t// Get the total of square of its digits. } return true; }/*The general idea is that the moment you see a repition, it can't be a happy number, so keep track of digit square obtained so far. If they hit 1, well and good, otherwise there will be some repition, so return false.*/ private boolean isHappySet(int n){ HashSet&lt;Integer&gt; seen = new HashSet&lt;&gt;();\t\t// Keep track of numbers while (true){ n = getSquare(n);\t\t\t\t\t\t\t// Get the sum of digits square if (n == 1)\t\t\t\t\t\t\t\t\t// If it's 1, it's a happy number return true; else if (seen.contains(n))\t\t\t\t\t// If it's a repition of something return false;\t\t\t\t\t\t\t// seen before, it's not a happy no. else seen.add(n);\t\t\t\t\t\t\t// If not seen, add it. } } private int getSquare(int n){\t\t// Add the squares of the digits. int total = 0; while (n != 0){ int digit = n % 10; total += digit * digit; n /= 10; } return total; }}Remove Linked List Elementspublic ListNode removeElements(ListNode head, int val) { while (head != null &amp;&amp; head.val == val)\t\t\t\t// While head contains the val, skip head = head.next;\t\t\t\t\t\t\t\t// the head ListNode current = head; while (current != null &amp;&amp; current.next != null){\t// While we have something to iterate if (current.next.val == val)\t\t\t\t\t// If current's val match, skip the current.next = current.next.next;\t\t\t// next node. else current = current.next;\t\t\t\t\t\t// Else advance to the next node. } return head;}Count Primespublic int countPrimes(int n) { if (n &lt; 2) return 0;\t\t\t\t\t\t\t// No prime numbers for numbers &lt; 2 boolean[] store = new boolean[n];\t\t// Using Sieve of Eratosthenes for (int i = 2; i*i &lt;= n; i++)\t\t\t// Start from i = 2 to sqrt(n) if (!store[i])\t\t\t\t\t\t// If store[i] = false, then mark all its for (int j = i*i; j &lt; n; j += i)// multiples in the store as true store[j] = true;\t\t\t// True = not a prime, false = prime int count = 0; for (int i = 2; i &lt; n; i++)\t\t\t\t// Loop through the array, count if (!store[i]) count++; return count;}Isomorphic Stringspublic boolean isIsomorphic(String s, String t) { if (s.length() != t.length())\t\t\t// Can't be isomorphic is string lengths do not return false;\t\t\t\t\t\t// match char[] hashS = new char[128];\t\t\t// To store String s' match char[] hashT = new char[128];\t\t\t// To store String t's match for (int i = 0; i &lt; s.length(); i++){ char charS = s.charAt(i), charT = t.charAt(i); if (hashS[charS] != hashT[charT])\t// If the values at respective characters index return false;\t\t\t\t\t// do not match, return false hashS[charS] = (char)(i+1);\t\t\t// Otherwise, mark those index with the same hashT[charT] = (char)(i+1);\t\t\t// arbitrary value. I chose a simple (i+1) to }\t\t\t\t\t\t\t\t\t\t// to mark both the hash with the same value. return true;\t\t\t\t\t\t\t// Everything worked out, return true;}Reverse LinkedList// Recursivepublic ListNode reverseList(ListNode head) {\t// Very tricky. Refer to the demo below if (head == null || head.next == null) return head; ListNode node = reverseList(head.next); head.next.next = head; head.next = null; return node;}//Iterativepublic ListNode reverseList(ListNode head) { if (head == null || head.next == null) return head;\t\t\t\t\t\t// No point in reversing empty or 1-sized list ListNode curr = head, prev = null; ListNode nextNode; while (curr != null){\t\t\t\t\t// While we haven't reached the tail nextNode = curr.next;\t\t\t\t// Store the next node curr.next = prev;\t\t\t\t\t// Current's next becomes it's previous prev = curr;\t\t\t\t\t\t// Advance previous to current. curr = nextNode;\t\t\t\t\t// Make current the actual next node } return prev;\t\t\t\t\t\t\t// Current is at null, so it's previous is the}\t\t\t\t\t\t\t\t\t\t\t// new head.Contains Duplicatepublic boolean containsDuplicate(int[] nums) { if (nums.length &lt; 2) return false;\t\t\t\t\t\t\t// There can't be any duplicates. HashSet&lt;Integer&gt; store = new HashSet&lt;&gt;();\t// Store unique values. for (int n: nums){ if (!store.add(n))\t\t\t\t\t\t// Add func returns true if n was'nt present, return true;\t\t\t\t\t\t// false if duplicate. Therefore if it was a }\t\t\t\t\t\t\t\t\t\t\t// duplicate, return true. return false;\t\t\t\t\t\t\t\t// No duplicates, so return false}Contains Duplicate IIpublic boolean containsNearbyDuplicate(int[] nums, int k) { if (nums.length &lt; 2) return false; int left = 0, right = 0; HashSet&lt;Integer&gt; store = new HashSet&lt;&gt;();\t// Use a rotating window of size k while (right &lt; nums.length){\t\t\t\t// While we haven't processed everything if (store.contains(nums[right]))\t\t// If our current window contains duplicate return true; store.add(nums[right]);\t\t\t\t\t// No duplicates in the window right++;\t\t\t\t\t\t\t\t// Increase right to visit the new element if (right - left &gt; k){\t\t\t\t\t// If window becomes &gt; k store.remove(nums[left]);\t\t\t// remove the number on the left side of left++;\t\t\t\t\t\t\t\t// the window and increase the left counter }\t\t\t\t\t\t\t\t\t\t// for new window from the next index } return false;\t\t\t\t\t\t\t\t// No duplicates found in any window.}Implement Stack Using Queuesclass MyStack { Deque&lt;Integer&gt; stack; /** Initialize your data structure here. */ public MyStack() { stack = new ArrayDeque&lt;&gt;(); } /** Push element x onto stack. */ public void push(int x) { stack.add(x); } /** Removes the element on top of the stack and returns that element. */ public int pop() { return stack.removeLast(); } /** Get the top element. */ public int top() { return stack.peekLast(); } /** Returns whether the stack is empty. */ public boolean empty() { return stack.isEmpty(); }}Invert Binary Treepublic TreeNode invertTree(TreeNode root) { if (root == null) return null; TreeNode temp = root.left;\t\t// Swap the left and right nodes root.left = root.right; root.right = temp; invertTree(root.left);\t\t\t// Then swap the subsequent trees of those nodes. invertTree(root.right); return root;\t\t\t\t\t// Return the original root.}Fibonacci Number// Iterativepublic int fib(int N) { if (N &lt; 2)\t\t\t\t\t\t// fib(0) = 0; fib(1) = 1 return N; int f0 = 0, f1 = 1, fn = 0; for (int i = 2; i &lt;= N; i++){ fn = f0 + f1;\t\t\t\t// fib(n) = fib(n-1) + fib(n-2) f0 = f1;\t\t\t\t\t// f0 becomes f1 f1 = fn;\t\t\t\t\t// f1 becomes fn } return f1;}// Dynamic Programmingprivate int fibDP(int N){ if (N &lt; 2) return N; int[] dp = new int[N+1];\t\t// To store intermediate result dp[1] = 1;\t\t\t\t\t\t// fib(0) = 0; fib(1) = 1 for (int i = 2; i &lt;= N; i++) dp[i] = dp[i-1]+dp[i-2];\t// fib(i) = fib(i-1) + fib(i-2) return dp[N];\t\t\t\t\t// Return the last number in the array}kth Largest Element The minheap algorithm has $O(n lg n) $ complexity and $O(1)$ space. The idea here is that we use a minheap to keep only the k greatest elements. If size becomes more than k, we remove the smallest element at the top of the heap. Thereby, at the end, our kth largest element will be at the top. QuickSelect Algorithm performs in $O(n)$ best case, $O(n^2)$ worst case when the pivot chosen is always the largest, so we use a random pivot.// MinHeap Algorithmpublic int kthLargest(int[] nums, int k){ PriorityQueue&lt;Integer&gt; q = new PriorityQueue&lt;&gt;((n1,n2) -&gt; n1 - n2);\t// Initialize minheap for (int n: nums){ q.add(n);\t\t\t\t// Add number one by one if (q.size() &gt; k)\t\t// If size is greater than k q.poll();\t\t\t// Remove the topmost element } return q.poll();\t\t\t// The topmost element is our answer}// QuickSelect Algorithm - Hoare's Partition Schemeprivate int[] arr;public int kthLargest(int[] nums, int k){\tarr = nums;\treturn quickselect(0, nums.length-1, nums.length-k);// kth largest is (n-k)th largest}private int quickselect(int left, int right, int k){\tif (left == right)\t\t\t\t\t// Array contains only 1 element, that's the answer \t\treturn arr[left];\tRandom rand = new Random();\t\t\t\t// Choose a random pivot between left and right\tint pivotIndex = left + rand.nextInt(right-left);\t// but not left\tpivotIndex = partition(left, right, pivotIndex);\t// Partition, and find it's correct index\tif (k == pivotIndex)\t\t\t\t\t// That index is equal to kth statistic \t\treturn arr[pivotIndex];\telse if (k &lt; pivotIndex)\t\t\t// If it's less than the index, our ans lies in the \t\treturn quickselect(left, pivotIndex-1, k);\t// left side\telse \t\treturn quickselect(pivotIndex+1, right, k);\t// Otherwise, it's on the right side.}private int partition(int left, int right, int pivotIndex){\tint pivot = arr[pivotIndex];\t\t\t// Partition element\tswap(pivotIndex, right);\t\t\t\t// Move that element to the end\tint wall = left - 1;\t\t\t\t\t// wall is initially before everything\tfor (int i = left; i &lt; right; i++){ \t\tif (arr[i] &lt; pivot)\t\t\t\t// If the current element is &lt; than the pivot, then \t\tswap(i, ++wall);\t\t\t// we need to swap it with the element next to wall.\t}\tswap(right, ++wall);\t\t\t\t\t// Lastly, swap the element at wall and the end.\treturn wall;}private void swap(int i, int j){\tint temp = arr[i];\tarr[i] = arr[j];\tarr[j] = temp;}Power Of Twopublic boolean isPowerOfTwo(int n) { if (n &lt; 1) return false;\t\t// n &lt; 0 cannot be powers of 2 while (n &gt; 2){ if (n % 2 != 0)\t\t// If n is odd, it can't be a power of 2. return false; n = n / 2;\t\t\t// It is a multiple of 2, so divide it by 2. } return true;\t\t\t// n came out to be 1 which is a power of 2, so return true.}Valid Sudokuprivate char[][] board;public boolean isValidSudoku(char[][] board){this.board = board;return rowCheck() &amp;&amp; colCheck() &amp;&amp; boxCheck();\t// Check row first, then column and at}\t\t\t\t\t\t\t\t\t\t\t\t// last, boxes because they are time // consuming. private boolean onePassCheck(){ HashSet&lt;Integer&gt;[] rows = new HashSet[9];\t\t// 1 HashSet for each row HashSet&lt;Integer&gt;[] columns = new HashSet[9];\t// 1 HashSet for each column HashSet&lt;Integer&gt;[] boxes = new HashSet[9];\t// 1 HashSet for each box. for (int i = 0; i &lt; 9; i++){ rows[i] = new HashSet&lt;&gt;(); columns[i] = new HashSet&lt;&gt;(); boxes[i] = new HashSet&lt;&gt;(); } for (int i = 0; i &lt; 9; i++){ for (int j = 0; j &lt; 9; j++){ int n = (int)(board[i][j]); if (n != -2){\t\t\t\t\t\t\t// -2 = '.'\t\t int boxIndex = (i/3) * 3 + j/3;\t// Calculate which box we are in. if (!rows[i].add(n) || !columns[j].add(n) || !boxes[boxIndex].add(n)) return false;\t\t\t\t\t// If the row set or the column set or the }\t\t\t\t\t\t\t\t\t\t// box set contains that val, return false. } } return true;}private boolean rowCheck(){\t\t\t\t\t\t// Horizontal check boolean[] arr; for (char[] row: board){ arr = new boolean[9]; for (char c: row){ int val = c-'0'; if (val != -2){\t\t\t\t\t\t\t\t// val = -2 means '.' in the board if (arr[val-1])\t\t\t\t\t\t\t// If val already seen, invalid sudoku return false; arr[val-1] = true;\t\t\t\t\t\t// else, Mark that index as seen. } } } return true; } private boolean colCheck(){\t\t\t\t\t\t// Vertical Check. boolean[] arr; for (int col = 0; col &lt; board.length; col++){ arr = new boolean[9]; for (int row = 0; row &lt; board[0].length; row++){ int val = board[row][col]-'0'; if (val != -2){ if (arr[val-1]) return false; arr[val-1] = true; } } } return true; } private boolean boxCheck(){\t\t\t\t\t// For the 9 sub boxes, let the single for (int i = 0; i &lt; 9; i+=3){\t\t\t\t// box checker check it's validity. for (int j = 0; j &lt; 9; j+=3)\t\t\t\t// If any of the subbox was invalid, if (!singleBoxCheck(i,j))\t\t\t\t// we abort and return false. return false; } return true; } private boolean singleBoxCheck(int topRightRow, int topRightCol){ boolean[] arr = new boolean[9]; for (int i = 0; i &lt; 3; i++){\t\t\t\t// Each sub box has 3 rows and 3 columns for (int j = 0; j &lt; 3; j++){ int val = board[topRightRow+i][topRightCol+j]-'0';\t// This gives us the value at if (val != -2){\t\t\t\t\t\t\t// each cell in the sub box and we fill the if (arr[val-1])\t\t\t\t\t\t// arr with all values that are seen. return false;\t\t\t\t\t\t// If seen twice, return false; arr[val-1] = true; } } } return true; }}Implement Queue Using Stack/*Since we reverse stack1 into stack2, stack2 is basically our queue, so if stack2 isn't empty, then the topmost element is what we need when we pop or peek. If it is empty, then again fill it with whatever's there is stack1, and it again becomes the correct queue.*/Stack&lt;Integer&gt; stack1;Stack&lt;Integer&gt; stack2;public MyQueue() { stack1 = new Stack&lt;&gt;(); stack2 = new Stack&lt;&gt;();}public void push(int x) { stack1.push(x);\t\t\t// Push onto stack1}public int pop() { peek();\t\t\t\t\t// First call the peek function, to make sure stack 2 isn't return stack2.pop();\t// empty. Then, the topmost element of stack2 is what we want}/** Get the front element. */public int peek() { if (stack2.isEmpty()){\t\t\t while (!stack1.isEmpty()) stack2.push(stack1.pop()); } return stack2.peek();\t// stack2 is basically the queue, so return whatever's on the top}/** Returns whether the queue is empty. */public boolean empty() { return stack1.isEmpty() &amp;&amp; stack2.isEmpty();}Palindrome LinkedListpublic boolean isPalindrome(ListNode head) { if (head == null || head.next == null)\t\t// Size 0 or 1 list, must be unique. return true; if (head.next.next == null)\t\t\t\t\t// Size 2 list, compare the head and tail return head.val == head.next.val;\t\t// values ListNode middleNode = head;\t\t\t\t\t// Standard Rabbit-Tortoise pointers. ListNode fastPointer = head;\t\t\t\t// Fast pointer jumps twice so by the time\t\t\t\t\t\t\t\t\t\t\t\t// it reaches the end of the list, middlenode ListNode curr = head;\t\t\t\t\t\t// is at the middle of the linkedlist. ListNode prev = null; ListNode nextNode;\t\t\t\t\t\t\t// These three nodes are for reversing the \t\t\t\t\t\t\t\t\t\t\t\t// first half of the list while (fastPointer != null &amp;&amp; fastPointer.next != null){ middleNode = middleNode.next;\t\t\t// Advance middle once, fastpointer twice fastPointer = fastPointer.next.next; nextNode = curr.next;\t\t\t\t\t// Reverse the curr node, but first store the curr.next = prev;\t\t\t\t\t\t// next newNode. By doing this, we would have prev = curr;\t\t\t\t\t\t\t// reversed exactly half of the list because curr = nextNode;\t\t\t\t\t\t// fastpointer advacnes at double the speed. } if (fastPointer != null)\t\t\t\t\t// If faspointer isn't null, then we have an middleNode = middleNode.next;\t\t\t// odd length list, so advance middle once,\t\t\t\t\t\t\t\t\t\t\t\t// List looks like 1-&gt;2-&gt;3-&gt;2-&gt;1 instead of while (middleNode != null){\t\t\t\t\t// 1-&gt;2-&gt;3-&gt;3-&gt;2-&gt;1 if (middleNode.val != prev.val)\t\t\t// While middle isn't null, check middlenode return false;\t\t\t\t\t\t// val and prev val. Prev is basically the middleNode = middleNode.next;\t\t\t// the point where the list reverses. prev = prev.next;\t\t\t\t\t\t// Advance middle and next. } return true;\t\t\t\t\t\t\t\t// Values matched, so return true.}\t\t\t\t\t\t\t\t\t\t\t\t// Reversed list looks like this:\t\t\t\t\t\t\t\t\t\t\t\t// 1&lt;-2&lt;-3&lt;-prev middle-&gt;3-&gt;2-&gt;1 in even len\t\t\t\t\t\t\t\t\t\t\t\t// 1&lt;-2&lt;-prev middle-&gt;2-&gt;1 in odd lengths.Delete Node in a Linked Listpublic void deleteNode(ListNode node) { node.val = node.next.val;\t\t// Node's value becomes its next node's value node.next = node.next.next; \t// Node's next is it's next's next.}Is Anagrampublic boolean isAnagram(String s, String t) { if (s.length() != t.length())\t\t\t// Can't be anagram if size aren't the same return false; int[] store = new int[26];\t\t\t\t// Acts like a hashmap for (int i = 0; i &lt; s.length(); i++)\t// Increment the count by 1 in the store for the store[s.charAt(i)-'a']++;\t\t\t// index = position of char in the alphabet for (int i = 0; i &lt; t.length(); i++){\t// Loop throught the second string, decrement if (--store[t.charAt(i)-'a'] &lt; 0)\t// count of each character in store by 1, but if return false;\t\t\t\t\t// it goes below 0, then it means that character }\t\t\t\t\t\t\t\t\t\t// occurred more than it did in s. So false. return true;\t\t\t\t\t\t\t// Everything matched, so return true.}Binary Tree PathsList&lt;String&gt; paths = new ArrayList&lt;&gt;();public List&lt;String&gt; binaryTreePaths(TreeNode root) { if (root == null)\t\t\t\t\t// No paths return paths; String rootval = root.val + \"\";\t\t// Converting int to string. traverse(root, rootval); return paths;}private void traverse(TreeNode root, String s){ if (root.left == null &amp;&amp; root.right == null)\t\t// It's a leaf, and you found a path paths.add(s);\t\t\t\t\t\t\t\t\t// so add it to the list if (root.left != null)\t\t\t\t\t\t\t\t// Left side is traversable, so traverse(root.left, s + \"-&gt;\" + root.left.val);\t// visit it and record its value. if (root.right != null)\t\t\t\t\t\t\t\t// Same as above, but for right side. traverse(root.right, s + \"-&gt;\" + root.right.val);}Add Digitsprivate int constantTime(int n){ if (n &lt; 10) return n;\t\t\t// Already a single digit int result = n % 9; if (result == 0)\t\t// If perfectly divisible by 9, then sum will be 9. return 9; return result;\t\t\t// Otherwise, the result is going to be n % 9.}private int iterative(int num){ while (num &gt; 9){\t\t\t\t// While number isn't between 2-9 num = sumOfDigits(num);\t\t// make num = sum of it's digits. } return num;}private int sumOfDigits(int n){\t\t// Standard method to add the digits of a number. int sum = 0; while (n != 0){ sum += n % 10;\t\t\t\t// Extract the last digit, add it to sum. n /= 10;\t\t\t\t\t// Divide the num by 10. } return sum;}Largest Perimeter Trianglepublic int largestPerimeter(int[] A) { Arrays.sort(A);\t\t\t\t\t\t\t// Sort so the largest sides are at the end. for (int i = A.length-3; i &gt;= 0; --i)\t// Triangle inequality Theorem : a + b &gt; c if (A[i] + A[i+1] &gt; A[i+2])\t\t\t// If sum of last two is greater than the last return A[i] + A[i+1] + A[i+2];\t// we found out max perimeter, otherwise return 0;\t\t\t\t\t\t\t\t// decrease i by i, then check the next three}\t\t\t\t\t\t\t\t\t\t\t// triplets\t\t\t\t\t\t\t\t\t\t\t// In the end if nothing works out, we return 0.Ugly Numberpublic boolean isUgly(int num) { if (num &lt; 1) return false;\t\t// Negative numbers are automatically non ugly while (num % 2 == 0)\t// Keep dividing number by 2 till it is divisible num /= 2; while (num % 3 == 0)\t// Keep dividing by 3 num /= 3; while (num % 5 == 0)\t// and 5 num /= 5; return num == 1;\t\t// If num isn't 1, that means that there are other prime factors}\t\t\t\t\t\t\t// except 2,3 and 5.Missing Numberpublic int missingNumber(int[] nums) {\t\t\t// Since it's given that the array contains int nsum = (nums.length*(nums.length+1))/2;\t// all numbers from 0-n, we use the formula int arraySum = nums[0];\t\t\t\t\t\t// to compute sum of n numbers. for (int i = 1; i &lt; nums.length; i++)\t\t// Then we loop through the array to compute arraySum += nums[i];\t\t\t\t\t// the sum of the array. return nsum - arraySum;\t\t\t\t\t\t// Subtract the array sum from the required}\t\t\t\t\t\t\t\t\t\t\t\t// sum, and that gives us the missing numberIs Bad Versionpublic int firstBadVersion(int n) {\t\t// Basic Binary Search Algorithm int low = 1, high = n; int mid; while (low &lt; high){ mid = low + (high - low)/2;\t\t// high - low to prefent integer overflow. if (isBadVersion(mid))\t\t\t// if the model at mid was bad version, then we high = mid;\t\t\t\t\t// could possibly have a bad version before it else low = mid+1;\t\t\t\t// If it wasn't, then our first bad version lies }\t\t\t\t\t\t\t\t\t// beyond the middle element. return low;}Move Zeroes/*The general idea is that we know the end of the array is going to contain zeroes. So first, iterate over the array, if you find any non-zero value, copy it down to the front of the array. Then we you are done, length of the array minus the last index where you copied the non-zero element is the number of zeroes you need to fill in. So iterate from that last non-zero index to the end of the array and fill in zeroes.*/public void moveZeroes(int[] nums) { int lastNonZeroIndex = 0; for (int i = 0; i &lt; nums.length; i++) if (nums[i] != 0) nums[lastNonZeroIndex++] = nums[i]; for (int i = lastNonZeroIndex; i &lt; nums.length; i++) nums[i] = 0;}/*This solution is an extension of the above, but a better one because we only swap elements when needed and do not do any unnecessary writes. Start from the beginning of the array, maintain the last position of non-zero value you saw, and the current element. If you see a non-zero value, swap the current value with the index just after the last non-zero index you have, and then increment the non-zero index by 1 because you just found a new non-zero value. This helps us prepare for the next non-zero value we find and copy it at this index+1. By doing so, we are basically partitioning the array into non-zeroes and zero values.*/public void moveZeroes(int[] nums) { for (int lastNonZeroIndex = 0, i = 0; i &lt; nums.length; i++){ if (nums[i] != 0) swap(nums, i , lastNonZeroIndex++); }}private void swap(int[] a, int i, int j){ int temp = a[i]; a[i] = a[j]; a[j] = temp;}Word Patternpublic boolean wordPattern(String pattern, String str) { String[] words = str.split(\" \");\t\t// Split str into words if (pattern.length() != words.length)\t// If length of pattern and words mismatch return false;\t\t\t\t\t\t// then pattern do not match HashMap&lt;Character, String&gt; patternStore = new HashMap&lt;&gt;();\t// Map pattern char to word HashMap&lt;String, Character&gt; wordMap = new HashMap&lt;&gt;();\t\t// Map word to pattern char for (int i = 0; i &lt; words.length; i++){ char c = pattern.charAt(i);\t\t\t\t\t// Get the char patternStore.putIfAbsent(c, words[i]);\t\t// Put it in patternStore if absent if (!patternStore.get(c).equals(words[i]))\t// If it was already there and it doesn't return false;\t\t\t\t\t\t\t// map to words[i], we have a violation wordMap.putIfAbsent(words[i], c);\t\t\t// Now check the other way around. If if (wordMap.get(words[i]) != c)\t\t\t\t// words is absent in the map, map it to return false;\t\t\t\t\t\t\t// the char. If present, then fetch it's }\t\t\t\t\t\t\t\t\t\t\t\t// mapping and check if both match to c. return true;\t\t\t\t\t\t\t// No violation, so return true}Can Win Nimpublic boolean canWinNim(int n) { return n % 4 != 0;\t\t\t// You can always win the game if n is not divisible by 4.}Power Of Threepublic boolean isPowerOfThree(int n) { if (n &lt; 1)\t\t\t\t// If negative, it can't be a power of 3. return false; while (n % 3 == 0)\t\t// While n is divisible by 3, keep dividing it. n /= 3; return n == 1;\t\t\t// In the end, if it was a power of 3, then n should be 1.}Power of Four/*You can also use the iterative method that I have used in Power of Two and Power of Three problems. I just wanted to try a different approach here. This is a constant time function.*/public boolean isPowerOfFour(int num) { double pow = Math.log(num)/Math.log(4);\t// Calculate x in 4^x = num using logs. return pow == (int)pow;\t\t\t\t\t// Making sure that x is an integer and not a}\t\t\t\t\t\t\t\t\t\t\t// fractional exponent.Reverse String/*1 Liner solution. Basically, create a StringBuilder of the string, the builder already has a reverse method, so reverse it and then return it's toString.*/public String reverseString(String s) { return new StringBuilder(s).reverse().toString();}/*Golfing aside, here is how one is expected to solve it in an interview.*/public String reverseString(String s) {\tchar[] array = s.toCharArray();\t\t// Create a char array of the string\tint len = array.length;\t\t\t\t// length of the array\tfor (int i = 0; i &lt; len/2; i++){\t// We only need to iterate over half the array.\t\tchar temp = array[i];\t\t\t// Swap the 0th index element with (len-1)th,\t\tarray[i] = array[len-i-1];\t\t// 1st index element with (len-2)th, until you get\t\tarray[len-i-1] = temp;\t\t\t// to the middle element.\t}\treturn new String(array);\t\t\t// Return a new string with the reversed array.}Implement strStr()/*The basic idea here is that you only need to iterate haystack length - needle length, and then check the substring of size = needle length in haystack from each index. If you are successfully able to match each character of the needle in the corresponding substring in haystack, return the index you start from. */public int strStr(String haystack, String needle) { if (needle.length() &gt; haystack.length())\t// Needle length can't be &gt; than haystack return -1; int hl = haystack.length(); int nl = needle.length(); if (nl == 0)\t\t\t\t\t\t\t\t// Empty strings are always a match starting return 0;\t\t\t\t\t\t\t\t// from 0. for (int i = 0; i &lt;= hl-nl; i++){\t\t\t// Iterate haystack length - needle length. for (int j = 0; j &lt; nl &amp;&amp; haystack.charAt(i+j) == needle.charAt(j); ++j)} if (j == nl-1)\t\t\t\t\t\t// We are checking how far from i can we return i;\t\t\t\t\t\t// match. If i matched with j, increment j }\t\t\t\t\t\t\t\t\t\t// and then match the character i+1 to j. }\t\t\t\t\t\t\t\t\t\t\t// If that matches, increment j and match i+2 return -1;\t\t\t\t\t\t\t\t\t// j == n-1 checked wether or not if we were}\t\t\t\t\t\t\t\t\t\t\t\t// able to match the full needle string, if\t\t\t\t\t\t\t\t\t\t\t\t// yes, then i is our index\t\t\t\t\t\t\t\t\t\t\t\t// in the end, nothing matched, so return -1Reverse Vowels of a Stringpublic String reverseVowels(String s) { if (s.length() &lt; 2) return s;\t\t\t\t\t// No need to reverse a string of length 0 or 1 char[] str = s.toCharArray();\t// Get the char array int left = 0; int right = str.length-1; while (left &lt; right){ while (left &lt; right &amp;&amp; !isVowel(str[left]))\t\t// While left is pointing to a left++;\t\t\t\t\t\t\t\t\t\t// consonant, increment it/ while (left &lt; right &amp;&amp; !isVowel(str[right]))\t// While right is pointing to a right--;\t\t\t\t\t\t\t\t\t// consonant, decrement it. char temp = str[left];\t\t\t\t\t\t\t// Left and right are now pointing str[left] = str[right];\t\t\t\t\t\t\t// to vowels, so swap it. str[right] = temp;\t\t\t\t\t\t\t\t// And then increment left and left++;\t\t\t\t\t\t\t\t\t\t\t// decrement right to process the right--;\t\t\t\t\t\t\t\t\t\t// inner string } return new String(str);\t\t\t// Return a string from the reveresed array.}private boolean isVowel(char c){\t// Function to check if a character is a vowel. switch (c) { case 'a': case 'e': case 'i': case 'o': case 'u': case 'A': case 'E': case 'I': case 'O': case 'U': return true; default: return false; }}Intersection of two arrayspublic int[] intersection(int[] nums1, int[] nums2) { Set&lt;Integer&gt; set1 = new HashSet&lt;Integer&gt;();\t\t// Record all unique values in set 1 for (int i: nums1) set1.add(i); Set&lt;Integer&gt; intersect = new HashSet&lt;&gt;();\t\t// We will use it to record intersection for (int i: nums2)\t\t\t\t\t\t\t\t// For each value in nums2 array if (set1.contains(i))\t\t\t\t\t\t// If set1 contains it, we found an intersect.add(i);\t\t\t\t\t\t// intersecting element, so add it. int[] res = new int[intersect.size()];\t\t\t// We will now convert the set to an int i = 0;\t\t\t\t\t\t\t\t\t\t// array and then return the array. for (int n: intersect) res[i++] = n; return res;}Is Perfect Square/**The basic idea here is to close in on the square root using binary search algorithm. I handle 4 seperately because it's root is the only one where 4/3 &lt; it's square root. All other numbers square root is greater than its value/3.So we create a lowerBound of 1 and an upperBound of num/3. Then if the middle value's squareovershoots, we make upperBound = mid-1, otherwise increment lowerBound to mid+1. This way, weclose on the square root from both sides, and if the middle values is the square root, it'ssquare will yield num.*/public boolean isPerfectSquare(int num) { if (num &lt; 2 || num == 4) return true; long lowerBound = 1; long upperBound = num/3; long mid; long square; while (lowerBound &lt;= upperBound){ mid = lowerBound + (upperBound-lowerBound)/2; square = mid*mid; if (square == num) return true; if (square &gt; num) upperBound = mid-1; else lowerBound = mid+1; } return false;}Sum of Two IntegersI cannot explain it better than this post.public int getSum(int a, int b) { if (a == 0) return b; if (b == 0) return a; int sum = a ^ b; int carry = a &amp; b; if (carry == 0) return sum; return getSum(sum, carry &lt;&lt; 1);}Guess Number Higher or Lowerpublic int guessNumber(int n) {\t\t\t\t// Standard binary search algorithm int low = 1, high = n, result = -2;\t\t// Arbitrary result, but not 0 int mid = 0; while (result != 0){ mid = low + (high-low)/2;\t\t\t// Check the mid. result = guess(mid);\t\t\t\t// Check if our guess is correct if (result == -1)\t\t\t\t\t// If result == -1, then we overshot high = mid-1;\t\t\t\t\t// So we can discard all values &gt; mid else if (result == 1)\t\t\t\t// If result == 1, we undershot low = mid+1;\t\t\t\t\t// Need to discard all the values &lt; mid } return mid;\t\t\t\t\t\t\t\t// Result == 0, so return the mid.}Ransom Notepublic boolean canConstruct(String ransomNote, String magazine) { int[] store = new int[26]; for (char c: magazine.toCharArray())\t\t// First, fill the store with available store[c-'a']++;\t\t\t\t\t\t\t// characters from the magazine for (char c: ransomNote.toCharArray())\t\t// Then, scan through the note, decrement if (--store[c-'a'] &lt; 0)\t\t\t\t\t// each char's index by 1 because we used return false;\t\t\t\t\t\t// it. If it's frequency drops below 0, return true;\t\t\t\t\t\t\t\t// then it means that we need more chars}\t\t\t\t\t\t\t\t\t\t\t\t// than available. In the end, return\t\t\t\t\t\t\t\t\t\t\t\t// true if everything worked out.First Unique Character in a Stringpublic int firstUniqChar(String s) { int[] freq = new int[26];\t\t\t// Preprocess freq array to maintain freq of each char[] chars = s.toCharArray();\t\t// character in the string s for (char c: chars) ++freq[c-'a']; for (int i = 0; i &lt; chars.length; i++)\t// Make a second pass through the chars of the if (freq[chars[i]-'a'] == 1)\t\t// string in order, and if any of the char's return i;\t\t\t\t\t\t// frequency is 1, that's our unique char return -1;\t\t\t\t\t\t\t\t// Otherwise, no unique character}Find the Difference/**The general idea here is same as the problem where we are required to find a unique intin an array containing duplicates except one. We use the xor operator between each characterof the string s and t, and the ones that are duplicate will xor to give 0. XOR of any elementwith 0 is the element itself, and XOR of two same elements gives 0. This way, since string sand t basically has pairs of repeating characters except one, the unique element will XORwith 0 and give us it's ASCII code. The only thing we need to take care of is to now shift itup by 26, so we add 'a' and convert it to char.*/public char findTheDifference(String s, String t) { int xor = 0; for (char c: s.toCharArray()) xor ^= c-'a'; for (char c: t.toCharArray()) xor ^= c-'a'; return (char)(xor+'a');}Nth Digit/**Notice that # of digits between 0-9 is 1*9, 10-99 is 2*90, 100-999 is 3*900. If we generalizeit, it is exactly equal to 9 * (num of digits in the number) * 10^{# of digits - 1}.*/public int findNthDigit(int n) { if (n &lt; 10) return n; int pow = 1;\t\t\t\t// First we need to figure out how many digits there are long upperBound = 9;\t\t// in the number. while (n &gt; upperBound){ n -= upperBound;\t\t// If n is a two digit number, subtract the 9 single digit ++pow;\t\t\t\t\t// numbers, if 3 digit, subtract the first 189 digits. upperBound = (long)Math.pow(10, pow-1) * pow * 9; }\t\t\t\t\t\t\t// pow allows us to track how many digits there are in num. int num = (int)Math.pow(10,pow-1) + (n-1)/pow;\t\t// Calculate which number we want int position = pow - 1 - (n-1) % pow;\t\t\t\t// Calculate which index we want for (int i = 0; i &lt; position; i++)\t\t\t\t\t// Divide num that many times num /= 10; return num % 10;\t\t\t\t\t\t\t\t\t// num % 10 gives us that digit.}Sum of Left Leavespublic int sumOfLeftLeaves(TreeNode root) { if (root == null)\t\t// Empty tree, therefore total is 0. return 0; int sum = 0;\t\t\t// Initialize sum. // Look ahead and check. If left is not null but left is a leaf, then sum is the value of the left leaf. // But if left is null or left is an inner node, then we need to explore it, so sum is whatever the subtree from the left node returns. if (root.left != null &amp;&amp; root.left.left == null &amp;&amp; root.left.right == null) sum = root.left.val; else sum = sumOfLeftLeaves(root.left); // We computed the sum of the left side. Now we need to traverse the right side and fetch // the sum, so total sum is sum of the left side as computed above + sum returned by // traversing the right side. return sum + sumOfLeftLeaves(root.right);}Longest Palindromepublic int longestPalindrome(String s) { int[] freq = new int[128];\t\t// To record the frequency of each char for (char c: s.toCharArray()) freq[c]++;\t\t\t\t\t// Increment count by 1 for each character observed int len = 0;\t\t\t\t\t// length of the longest palindrome boolean isOdd = false;\t\t\t// Check if our palindrome length is odd for (int i = 0; i &lt; 128; i++){\t// Go through each character's index if (freq[i] != 0){\t\t\t// Only if it has been observed atleast once int val = freq[i];\t\t// Store it's frequency int used;\t\t\t\t// Record how many of it's occurrences we will use if (val % 2 == 0)\t\t// If a perfect multiple of 2, we will use all used = val; else{ used = val-1;\t\t// If odd occurrences, then the max we can use to form a isOdd = true;\t\t// valid palindrome is val-1. It also tells us that the }\t\t\t\t\t\t// palindrome is going to be of odd length. len += used;\t\t\t// Finally, increment length by the number of chars used } } if (isOdd)\t\t\t\t\t\t// If length is odd, we can always insert any single return len+1;\t\t\t\t// character in the middle to keep the palindrome valid. return len;\t\t\t\t\t\t// If the length is even, then we can't do anything.}Fizz Buzzpublic List&lt;String&gt; fizzBuzz(int n) { List&lt;String&gt; nums = new ArrayList&lt;String&gt;(); for (int i = 1; i &lt;= n; ++i){\t\t\t\t// Loop from 1 to n if (i % 15 == 0)\t\t\t\t\t\t// If i divisible by 15, add \"FizzBuzz\" nums.add(\"FizzBuzz\"); else if (i % 5 == 0)\t\t\t\t\t// i's not a multiple of 15, check if it's a nums.add(\"Buzz\");\t\t\t\t\t// multiple of 5. If so, add \"Buzz\" else if (i % 3 == 0)\t\t\t\t\t// i's not a multiple of 5, check if it's a nums.add(\"Fizz\");\t\t\t\t\t// multiple of 3, if so, add \"Fizz\" else nums.add(i+\"\");\t\t\t\t\t\t// Otherwise, just add the String type of the }\t\t\t\t\t\t\t\t\t\t\t// number return nums;}Third maximum Numberpublic int thirdMax(int[] nums) { if (nums.length == 0)\t\t// Empty array return 0; if (nums.length == 1)\t\t// Size 1 array return nums[0]; if (nums.length == 2)\t\t// Size 2 array, check between 0th element or 1st element return nums[0] &gt; nums[1] ? nums[0] : nums[1]; long firstMax = Long.MIN_VALUE;\t\t// Lowest values for all three long secondMax = Long.MIN_VALUE; long thirdMax = Long.MIN_VALUE; for (int i: nums){\t\t\t\t\t// For each number in the array if (i &gt; firstMax){\t\t\t\t// If num &gt; than the largest, then old largest thirdMax = secondMax;\t\t// becomes second largest and second largest becomes secondMax = firstMax;\t\t// first largest, then update the largest. firstMax = i; } else if (i &gt; secondMax &amp;&amp; i != firstMax){\t// If num &gt; second and num is not is the thirdMax = secondMax;\t\t\t\t\t// same as first, first largets becomes secondMax = i;\t\t\t\t\t\t\t// second largest and update the second } else if (i &gt; thirdMax &amp;&amp; i != secondMax &amp;&amp; i != firstMax) // // If num &gt; third, we \tthirdMax = i;\t\t\t\t\t\t// need to check that it is not the same }\t\t\t\t\t\t\t\t\t\t\t\t// as the first and second largest. if (thirdMax == Long.MIN_VALUE)\t\t\t\t\t// This check allows us to make sure that return (int)firstMax;\t\t\t\t\t\t// we do indeed have a third max and is return (int)thirdMax;\t\t\t\t\t\t\t// not what we initialized initially.}Add Two Stringspublic String addStrings(String num1, String num2) { if (num1.equals(\"0\")) return num2; if (num2.equals(\"0\")) return num1; /** We use a char array to maintain the digit at each index. We want the array to be of the size of the largest string + 1 to handle carry bit if any at the end. We start adding each digit of the string from the end, and place it in it's correct index at the end of the sum array. This way, we avoid reversing it and return the answer in constant time. Take care to convert the digit you compute by adding '0'. Lastly, if the carry bit is 1, we need to make the 0th index as 1, and return the string by using the sum array. If it's not 1, then the sum array has a leading 0 which we don't want. So we use Java's String constructor that takes in the char array, startingIndex in that array and the number of elements of that array we want. So if the carry isn't 1, we technically want everything from index 1 and # of elements = sum.length - 1 because we discard 0 index. */ char[] sum = new char[1 + Math.max(num1.length(), num2.length())]; int index = sum.length-1, idx1 = num1.length()-1, idx2 = num2.length()-1, carry = 0, total = 0; int n1, n2; while (idx1 &gt;= 0 || idx2 &gt;= 0){ n1 = idx1 &lt; 0 ? 0 : num1.charAt(idx1--)-'0'; n2 = idx2 &lt; 0 ? 0 : num2.charAt(idx2--)-'0'; total = n1 + n2 + carry; carry = total/10; sum[index--] = (char)(total % 10 + '0'); } if (carry == 1){ sum[0] = '1'; return new String(sum); } return new String(sum, 1, sum.length-1);}Construct Quad Treeprivate int[][] grid;\t\t\t\t\t// Store it once, instead of passing it over &amp; over.public Node construct(int[][] _grid) { grid = _grid; return helper(0,0,grid.length);\t\t// Ask helper to build the tree.}private Node helper(int top, int left, int len){ if (len &lt;= 0)\t\t\t\t\t\t// Base case: if empty grid or if we are done return null;\t\t\t\t\t// checking the full grid, return null int key = grid[top][left];\t\t\t// Get the topleft value, and start checking the box for (int i = 0; i &lt; len; ++i){\t\t// of len*len. If at any point, the value doesn't for (int j = 0; j &lt; len; ++j){\t// match the key, we have found a breakpoint from if (grid[top+i][left+j] != key){\t// where we need to break the grid into four int offset = len/2;\t\t// grids, each of len = len/2. The topleft grid has return new Node(true, false, \t// the same top and left point, the topright helper(top,left, offset),\t// grid has left point shifted to helper(top, left + offset, offset),\t// the right by offset. helper(top+offset, left, offset),\t// The bottom left grid helper(top+offset, left+offset, offset));\t// is shifted }\t// downwards by offset with the same left point. The bottom right grid will }\t\t// have an index where it's top is shifted down by len/2 and left by left/2. }\t\t\t// We know that the node will have a value = true if 1 else false and it won't be a leaf, so true, false, topleft, topright, bottomleft, bottomright. return new Node(key == 1, true, null, null, null, null);\t// Everything passed, so we return a new Node whose value is true if key is 1, else false and it will be a leaf, with// no children, so 4 nulls.}N-ary Tree Level Order Traversalpublic List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();\t// Result list if (root == null)\t\t\t\t\t\t\t\t// If root is null, return empty list. return res; Queue&lt;Node&gt; q = new LinkedList&lt;&gt;();\t\t\t\t// BFS Queue. Add the root. q.add(root); while (!q.isEmpty()){\t\t\t\t\t\t\t// While q isn't empty int size = q.size();\t\t\t\t\t\t// Check how many elements in that level List&lt;Integer&gt; level = new ArrayList&lt;&gt;(size);// level list to store elements. for (int i = 0; i &lt; size; i++){\t\t\t\t// Remove each node for whatever the size Node n = q.poll();\t\t\t\t\t\t// Add that node's value and add all of level.add(n.val);\t\t\t\t\t\t// its children to the queue. for (Node child: n.children) q.add(child); } res.add(level);\t\t\t\t\t\t\t\t// Add the level array to the result } return res;\t\t\t\t\t\t\t\t\t\t// Return the result list.}Number of Segments in a Stringpublic int countSegments(String s) { if (s.length() == 0)\t\t\t\t\t// Empty String return 0; int segments = 0;\t\t\t\t\t\t// Record segments char prev = s.charAt(0);\t\t\t\t// We will compare adjacent characters. for (int i = 1; i &lt; s.length(); ++i){\t// Start looking at chars from index 0 char curr = s.charAt(i);\t\t\t// Get the current char if (prev != ' ' &amp;&amp; curr == ' ')\t\t// If previous char wasn't a space but the ++segments;\t\t\t\t\t\t// current char is, we found a segment. prev = curr;\t\t\t\t\t\t// Make previous = current for next iteration }/**This line is important. If prev was an empty space, that means that all we have been lookingat was empty spaces towards the end. So return whatever segments we found in the beginningof the string. But if prev wasn't a space, that means the char next to prev might have beenan empty space or just a normal character. In any case, we would want to include that lastsegment, so we return segment+1.*/ return prev == ' ' ? segments : segments+1;}Binary Tree Level Order Traversalpublic List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null)\t\t\t\t\t\t// Empty Tree return result; Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;();\t// BFS Queue q.add(root); while (!q.isEmpty()){\t\t\t\t\t// While we have something to process List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); int size = q.size();\t\t\t\t// Check how many elements at the current level for (int i = 0; i &lt; size; i++){ TreeNode node = q.poll();\t\t// Remove one element each time if (node != null){\t\t\t\t// If not null, add it's val to the level list, level.add(node.val);\t\t// and it's left and right children to the queue q.add(node.left);\t\t\t// to process in order q.add(node.right); } } if (!level.isEmpty())\t\t\t\t// If level list wasn't empty, result.add(level);\t\t\t\t// add it to the result list. } return result;}Path Sum IIIHashMap&lt;Integer, Integer&gt; sumToWays;\t\t\t// Record how many ways there are to form sumint ways;\t\t\t\t\t\t\t\t\t\t// Total number of ways.public int pathSum(TreeNode root, int sum) { sumToWays = new HashMap&lt;&gt;(); ways = 0; sumToWays.put(0,1);\t\t\t\t\t\t\t// 1 way to form a sum of 0. helper(root, 0, sum); return ways;}/**The idea here is as follows. Start with the root node, and keep a running total. We maintainhow many ways there to form a running sum. Then we check how many ways there are to form(running sum) - (sum we are looking for). If there is a way to form it, then we increase thenumber of ways to form sum. We then have to update the map to record how many ways can therunning sum be formed. If it's something we could form before, increment it, or else set itto 1. Now, traverse the left side and then the right side. In the end, for each time weincremented the count for a running sum, we need to decrement it because we are backtracking.We are first going down, incrementing the count for runningSum, then we move up and decrementit by 1 for each time we observed it. This is to maintain the Pre-Order traversal.*/private void helper(TreeNode node, int runningSum, int sum){ if (node == null) return; runningSum += node.val; ways += sumToWays.getOrDefault(runningSum-sum, 0); sumToWays.put(runningSum, sumToWays.getOrDefault(runningSum, 0)+1); helper(node.left, runningSum, sum); helper(node.right, runningSum, sum); sumToWays.put(runningSum, sumToWays.get(runningSum)-1);}Find All Anagrams in a Stringpublic List&lt;Integer&gt; findAnagrams(String s, String p) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); int start = 0, end = 0, slen = s.length(), plen = p.length(); if (slen == 0 || slen &lt; plen || plen == 0) return result; int[] freq = new int[26];\t\t\t\t// Store the freq of chars in p for (char c: p.toCharArray()) freq[c-'a']++; char[] sArr = s.toCharArray();\t\t\t// Get the chars of the string s as an array while (end &lt; slen){\t\t\t\t\t\t// While everything is not processed if (--freq[sArr[end]-'a'] &gt;= 0)\t\t// decrease the freq of the char at index end plen--;\t\t\t\t\t\t\t// if it's &gt; 0, then we matched something in p\t\t\t\t\t\t\t\t\t\t\t// so decrease plen by 1. while (plen == 0){\t\t\t\t\t// If plen goes to 0, we were able to match all if (end-start+1 == p.length())\t// chars of p. If length of the matched chars is result.add(start);\t\t\t// equal to length p, we found a start point. if (freq[sArr[start]-'a'] &gt;= 0)\t// Check if the freq of char at start index is plen++;\t\t\t\t\t\t// &gt;= 0. If it is, shift the window to the right ++freq[sArr[start++]-'a'];\t\t// but first restore the frequency of the char }\t\t\t\t\t\t\t\t\t// at the index start. end++;\t\t\t\t\t\t\t\t// Get ready to inspect the new element } return result;\t\t\t\t\t\t\t// Return the answer.}Arranging CoinsThe idea is as follows. Sum of first n numbers is given by $\\frac{n^2+n}{2}$. We need to find $n$ such that sum of $n$ numbers is closest to the number of coins we have. That is, $\\frac{n^2+n}{2} = k$ where $k$ is the number of coins we have. So, everything boils down to solving the quadratic equation $n^2 + n - 2k = 0$. We use the quadratic formula where for any quadratic equation $ax^2 -bx + c$ is solved substituting for $a$, $b$ and $c$ in $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2}$. Here, $a$ and $b$ are always going to be 1, while $c$ is always going to be $2k$. Substitute those, and solve the equation.public int arrangeCoins(int n) { // return solveQuadratic(n); return iterative(n);}private int solveQuadratic(int n){ return (int)(Math.sqrt(1 + 8*(long)n)-1)/2;}private int iterative(int n){ int used = 1, level = 0;\t\t// Coins used, and level completed. while (n &gt; 0){\t\t\t\t\t// While coins left are greater than 0. n-=used;\t\t\t\t\t// Calculcate remaining coins. if (n &gt; -1)\t\t\t\t\t// If there are still some coins left, ++level;\t\t\t\t// we were able to fill the level. ++used;\t\t\t\t\t\t// Prepare used for the next level, which is plus 1. } return level;\t\t\t\t\t// Return level}Hamming Distancepublic int hammingDistance(int x, int y) { int diff = 0;\t\t\t\t// Track differences while (x != 0 || y != 0) {\t// While both of them aren't 0 if (x % 2 != y % 2)\t\t// Check the bit of x and y by mod 2. If they are unequal diff++;\t\t\t\t// increment difference. x /= 2;\t\t\t\t\t// Divide x and y by 2. y /= 2; } return diff;}String Compressionpublic int compress(char[] chars) { int len = chars.length;\t\t\t// No need to reverse array of length 0 or 1 if (len &lt; 2) return len; int arrayIndex = 0;\t\t\t\t// To maintain the length of new array. int start = 0;\t\t\t\t\t// start index int end = 0;\t\t\t\t\t// end index while (end &lt; len){ char first = chars[start];\t// Record the char we are looking at. int count = 0;\t\t\t\t// count is 0. while (end &lt; len &amp;&amp; chars[end] == first){\t// while the char is the same ++end;\t\t\t\t\t// increment end to check next char ++count;\t\t\t\t// and increment the count. } start = end;\t\t\t\t// shift start to end to check next sequence of chars chars[arrayIndex++] = first;\t// our arrayIndex points to to the new array's if (count != 1){\t\t\t\t// indices. So copy the first char to arrayIndex. if (count &gt; 1 &amp;&amp; count &lt; 10)\t//Only if count isn't 1, if count is less than 10 chars[arrayIndex++] = (char)(count+'0');\t// then we simply convert count to char and write it next to the char we just overwrote. else\t\t\t\t\t\t// Otherwise, it has many digits. So convert it to for (char c: String.valueOf(count).toCharArray()){\t// string and add all it's digit to the array one by one while increment arrayIndex. chars[arrayIndex++] = c; } } } return arrayIndex;\t\t\t// Wherever arrayIndex is, is the new length for the array.}Number of Boomerangspublic int numberOfBoomerangs(int[][] points) { int boomerangs = 0; HashMap&lt;Double, Integer&gt; map = new HashMap&lt;&gt;();\t// To record points with same dist for (int[] i: points){\t\t// Compute distance between one point and every other. map.clear()\t\t\t\t// clear map before each relative distance computation for (int[] j: points){\t// Compute distance with other points if (i == j)\t\t\t// Don't compare the same two points. continue; double dist = Math.sqrt(Math.pow(i[0]-j[0],2) + Math.pow(i[1]-j[1],2)); int prevCount = map.getOrDefault(dist, 0);\t// Check how many points are equidistant from point i. boomerangs += prevCount * 2;\t// Number of boomerangs = whatever pairs there were before times 2, because you can form twice the number of different orders. map.put(dist, prevCount+1);\t// Increase the count of points observed for that distance. } } return boomerangs;\t// return number of boomerangs}Find All Numbers Disappeared in an Array/**The idea is simple. For each number in the array, since it's gauranteed that that the valueslie are inclusive [1,n], we can look at the index value-1. So check that index, and markthat value as negative. That is why I take the absolute value. Check value at that index, ifnegative, it means we have visited it via some other duplicate value. But if it's positive,then we are seeing it for the first time, so make it's value negative. Make a second pass.For values that are still positive, that means those indices were never visited, hence leftpositive. So add 1 to them and add it to the set. Eg:\tGiven array a = [4,3,2,7,8,2,3,1],1.\tval = 4 =&gt; idx = 3 &amp; a[3] &gt; 0, therefore, a[3] *= -1\ta = [4,3,2,-7,8,2,3,1]2.\tval = 3 =&gt; idx = 2 &amp; a[2] &gt; 0, therefore a[2] *= -1\ta = [4,3,-2,-7,8,2,3,1]3.\tval = -2 =&gt; idx = abs(-2)-1 = 1 &amp; a[1] &gt; 0, therefore a[1] *= -1\ta = [4,-3,-2,-7,8,2,3,1]4.\tval = -7 =&gt; idx = abs(-7)-1 = 6 &amp; a[6] &gt; 0, therfore a[6] *= -1\ta = [4,-3,-2,-7,8,2,-3,1]5.\tval = 8 =&gt; idx = abs(8)-1 = 7 &amp; a[7] &gt; 0, therfore a[7] *= -1\ta = [4,-3,-2,-7,8,2,-3,-1]6.\tval = 2 =&gt; idx = 1 but a[2] &lt; 0. No change.7.\tval = -3 =&gt; idx = abs(-3)-1 = 2 but a[2] &lt; 0. No change.8.\tval = -1 =&gt; idx = abs(-1)-1 = 0 &amp; a[0] &gt; 0, therefore a[0] *= -1\ta = [-4,-3,-2,-7,8,2,-3,-1]Observation: Notice index 4 and 5 have positive values, since those values were neverencountered, so the values at those indexes never became negative. Hence missing values are5 and 6.*/public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) { List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (int i: nums){\t\t\t\t// For each number in the array int idx = Math.abs(i)-1;\t// Look at the index that the number corresponds to if (nums[idx] &gt; 0)\t\t\t// If val is -ve, then it means we have encountered it. nums[idx] *= -1; \t\t// If not, make it -ve. } for (int i = 0; i &lt; nums.length; ++i) if (nums[i] &gt; 0)\t\t\t// Make another pass through the array, and the indices result.add(i+1);\t\t// where value was positive, index+1 was missing from return result;\t\t\t\t\t// the array}Assign Cookies/**We will employ a greedy algorithm where we first try to content children whose requirementsare small. We do this by sorting both the arrays, so we can match the child with leastrequirement with the smallest cookie available.*/public int findContentChildren(int[] g, int[] s) { Arrays.sort(g); Arrays.sort(s); int satisfied = 0, i = 0, j = 0; while (i &lt; g.length &amp;&amp; j &lt; s.length){\t// While children are left and we have cookies, if (s[j] &gt;= g[i]){\t\t// Check if the cookie at index j &gt;= child i's requirement satisfied++;\t\t// If so, increment the number of content child and we will i++;\t\t\t\t// process the next child. }\t\t\t\t\t\t// If cookie j &lt; child i's demand, check the next cookie by j++;\t\t\t\t\t// incrementing j. If cookie j &gt; child i's demand, we will }\t\t\t\t\t\t\t// still need to increment j, hence outside the conditional. return satisfied;\t\t\t// Return number of satisfied children}Poor PigsLink to the solution explanation. This problem is phrased poorly and I had to read the comments by other users to understand what it required from me. The link I marked here explains the logic pretty good. But the simple logic is this: The number of rounds $r = \\frac{Total Test Time}{Minutes To Die} +1$. Each pig has chances of dying in each round or staying alive till the end, so we plus 1. Now given the number of rounds $r$ and the number of samples $s$, how many volunteers $v$ will you need? $r^v = s$. Each round has some volunteers which in total at the end should be able to test out all the samples. Therefore, $v =\\log_rs$.public int poorPigs(int buckets, int minutesToDie, int minutesToTest) { int base = minutesToTest/minutesToDie+1;\t\t// How many rounds can you perform? return (int)Math.ceil(Math.log(buckets)/Math.log(base));}Find Pivot Indexpublic int pivotIndex(int[] nums) { int sum = 0, leftSum = 0;\t\t// We will test each index as a pivot by sliding it -&gt; for (int i: nums)\t\t\t\t// Precalculate the sum of the array sum += i; for (int i = 0; i &lt; nums.length; ++i){\t// Check if the sum of the leftSide of i is if (leftSum == sum - leftSum - nums[i])\t// equal to totalSum - leftSideSum - pivot return i;\t\t\t\t\t\t\t// which is i. If so, return i. leftSum += nums[i];\t\t\t\t\t\t// Otherwise add nums[i] to the leftSum and }\t\t\t\t\t\t\t\t\t\t\t// slide pivot to the -&gt;. return -1;\t\t\t\t\t\t\t\t// No pivot found. Return -1.}Squares of a Sorted Arraypublic int[] sortedSquares(int[] A) { int len = A.length;\t\t// Length of array A int pivot = 0;\t\t\t// Pivot is the index where values goes from -ve to +ve. while (pivot &lt; len &amp;&amp; A[pivot] &lt; 0) // While values are -ve. ++pivot;\t\t\t// increment pivot. We exit when we find a positive. int[] squares = new int[len];\t// Result array int index = 0;\t\t\t// Keeps track of where to where to put elements in result array if (pivot == 0)\t\t\t// pivot = 0 means pivot didn't shift, there are only +ve values for (int i: A)\t\t// So fill in the array with squares of numbers. squares[index++] = i*i; else{\t\t\t\t\t// Otherwise we have a negative somewhere. int left = pivot-1;\t// So we will compare values left and right of the pivot int right = pivot;\t// and whichever's smaller fills up the array first. while (left &gt; -1 &amp;&amp; right &lt; len){ int lsquare = A[left] * A[left]; int rsquare = A[right] * A[right]; if (lsquare &lt; rsquare){\t\t// left &lt; right, so add left square. decrement left squares[index++] = lsquare; --left; } else if (rsquare &lt; lsquare){\t// right &lt; left, add right square and increment. squares[index++] = rsquare; ++right; } else{ squares[index++] = lsquare;\t// both are equal. add both square and squares[index++] = rsquare;\t// decrement left, increment right. --left;\t\t\t\t\t\t// Continue doing this until we hit either end ++right;\t\t\t\t\t// of the array. }\t\t\t\t\t\t\t\t// In the end we need to check if elements on }\t\t\t\t\t\t\t\t\t// either side are left to be filled in. while (left &gt; -1)\t\t\t\t\t// Left side elements remain, so fill their squares[index++] = A[left] * A[left--]; // squares one by one till none left. while (right &lt; len)\t\t\t\t\t// Right side elements remain, so fill their squares[index++] = A[right] * A[right++];\t// squares in } return squares;}Repeated Substring PatternWe use the KMP Algorithm that allows us to match a string ‘s’ with another string ‘p’ to find the longest sequence of characters in ‘s’ that match ‘p’. We can use a Naive Pattern match where we start from the beginning of the string and start comparing the characters of ‘s’ with ‘p’. Initially, we keep the partition at index 0. If the character’s match, we move partition to the right by 1 till we get to the end of the string. If something doesn’t match, we don’t move the partition but look at the next character to match. In the end, wherever the partition is, that’s our longest length we could match with string ‘p’. The complexity of that is O(len(p)(len(s)-len(p)+1)).KMP fixes it by skipping characters that we know already match. In this problem, we aren’t matching with any other string but itself. So, we start from index 1 of the string and compare it from the beginning. If they match, we increase j by 1, note it down in lps array and then increase i by 1 to check the next character. j basically measures the longest chain of characters we were able to match. If we couldn’t match character at index i and if streak was greater than 0, then our new streak becomes whatever it was in the previous round of matching characters. If the streak is 0, then we simply note down at index i in our lps array 0, meaning longest length measured upto index i was 0.public boolean repeatedSubstringPattern(String s) { int maxLength = lps(s); return maxLength &gt; 0 &amp;&amp; s.length() % (s.length() - maxLength) == 0; }private int lps(String s){ int len = s.length(); int[] lps = new int[len]; int i = 1;\t\t// To match the string with itself. int j = 0; while (i &lt; len){ if (s.charAt(i) == s.charAt(j)){\t// if the chars match lps[i] = ++j;\t\t\t\t\t// we record that # of matches at index i was ++i;\t\t\t\t\t\t\t// 1+j and increment i to check next character } else{\t\t\t\t\t\t\t\t// character did not match if (j &gt; 0)\t\t\t\t\t\t// If our matching streak &gt; 0 j = lps[j-1];\t\t\t\t// our new streak becomes the previous round's streak else\t\t\t\t\t\t\t// Otherwise, streak is already 0. lps[i++] = 0;\t\t\t\t// So we record that # of matches made at i is 0 }\t\t\t\t\t\t\t\t\t// We increment i to check next index. } return lps[len-1];\t\t\t\t\t\t// Longest prefix length that was also a suffix}\t\t\t\t\t\t\t\t\t\t\t// is whatever was recorded at the end of array.Island PerimeterThe idea is simple. Count the number of cells with value 1 which denotes the land. Check towards the left and up to that cell and check if it shares any edge with another cell with value 1. If it does record that. In the end, the formula for perimeter is 4 * (the number of land cells) - 2 * (overlapping edges).Reasoning: Perimeter of a square is 4 times the length of it’s side. Here all squares are of length 1. So total perimeter is 4*(number of cells with value = 1). But we also need to account the edges that are common between two adjacent land cells. If one square shares an edge with another, we just lost one side from both the square, resulting in a loss of two sides. Therefore, we need to subtract twice the number of overlapping edges from the total perimeter to get the total perimeter.public int islandPerimeter(int[][] grid) { int land = 0; int overlap = 0; for (int row = 0; row &lt; grid.length; ++row) for (int col = 0; col &lt; grid[0].length; ++col){ if (grid[row][col] == 1){ ++land; if (row-1 &gt; -1 &amp;&amp; grid[row-1][col] == 1)\t// Check above the current cell. ++overlap;\t\t// If it's a land, we need to record one overlap. if (col-1 &gt; -1 &amp;&amp; grid[row][col-1] == 1)\t// Similarly, check to the left. ++overlap;\t\t// If it's a land, we need to increment overlap } } return 4*land - 2*overlap;\t\t// Check the reasoning above.}Number Complementpublic int findComplement(int num) { int pow2 = 1;\t\t\t\t// Easily keep track of power of 2. int comp = 0;\t\t\t\t// Complement number while (num != 0){\t\t\t// Since num gets divided by 2, it will be 0 in the end. int bit = num % 2 == 0 ? 1 : 0;\t// If bit is 0 then complement is 1 &amp; vice versa. comp += bit * pow2;\t\t// Multiply it by the appropriate power of 2 and add to comp pow2 *= 2;\t\t\t\t// Update power of 2 for next iteration. num /= 2;\t\t\t\t// Divide num by 2 to get the next bit. } return comp;\t\t\t\t// Comp is now the complement.}Binary WatchThe idea is as follows. We have 10 lights. First 4 represent hours. Namely 1, 2, 4 and 8, which are the first four powers of 2. The next 6 lights, represent minutes. Those are 1, 2, 4, 8, 16 and 32. These are powers of 2 from 0-5. So if we iterate from 1 to 9, powers of numbers 1-3 gives us hours and powers of numbers 4-9 minus 4 gives us minutes. So, if we have, let’s say 2 lights, we need to find every combination of 2 lights. So in our helper function, we iterate from 1-9 to check every hour and minute combination. We also need to keep a track of the lights that we used, so we don’t use the same light again. If hours are &gt; 11 or minutes are &gt; 59, we have an invalid time and we can abort. If the number of lights are 0, that means we found a valid time and we should add it to the result. Now, if the lights are not 0, then we need to check every possible combination from the last light used to 9. If i &lt; 4, then we are looking at an hourly combination, otherwise it’s a minute combination. So we recurse with updated lights used, decrease the numOfLights since we used one, update respective hours or minutes until we hit base case.List&lt;String&gt; result;public List&lt;String&gt; readBinaryWatch(int num) { result = new ArrayList&lt;&gt;(); helper(0, num, 0, 0); return result;}private void helper(int lightsUsed, int numOfLights, int hrs, int min){ if (hrs &gt; 11 || min &gt; 59)\t\t// Base case. Invalid time return; if (numOfLights == 0){\t\t\t// All lights used, so add time to the list. result.add(hrs + \":\" + (min &lt; 10 ? \"0\" + min : min)); return; } for (int i = lightsUsed; i &lt; 10; i++){\t// Otherwise start recursing from number of prev if (i &lt; 4)\t\t\t\t\t\t\t// light used. i &lt; 4 means hours helper(i+1, numOfLights-1, hrs + (int)Math.pow(2, i), min); else\t\t\t\t\t\t\t\t// i = [4,9] means minute. So recurse. helper(i+1, numOfLights-1, hrs, min + (int)Math.pow(2,i-4)); }}Minimum Moves to Equal Array ElementsThis was an interesting problem. But after working out a few examples by hand, you can notice that it is always a question of bringing the minimum element in par with everyone. So if you know the minimum of the array, we can check how many steps it will take to bring the minimum in par with other element by calculating the distance between them. For example, Let the array be [1,2,3] We can observe that the minimum here is 1. Let us list down all steps to make all elements equal. [2,2,4], Keeping the second element fixed. Notice that distance between the element where 1 was and where 3 was is till the same. [3,3,4], Keeping the last element fixed. [4,4,4], Keeping last element fixed. Here, we first tried to make 1 equal to it’s neighbor, which required us 1 step. Now, once it becomes equal to 1, the problem is how to make the last element in the original array, which is 3 equal to 1. It requires 2 steps, resulting in a total of of 3. The reason is that the moment you decide to increment the minimum element to match the next element, you fix the neighboring element and have to increment everything else. This will make the minimum and its neighbor the same, but it will also keep the distance between the minimum and all other elements the same because we just incremented everything. So, the total number of moves required is the distance between the elements of the array and the minimum.public int minMoves(int[] nums){ int min = nums[0]; for (int i: nums) if (i &lt; min) min = i; int moves = 0; for (int i: nums) moves += i-min; return moves;} Now the above solution required two passes of the array. Can we do even better? Notice that in the end, all we are doing is finding the min and subtracting min from all the elements in the array. That means we are subtracting min n times where n is the length of the array. Why n times? Because there are n elements in the array. Shouldn’t it be (n-1) times? No, because the distance of the min from min is 0. So we need to subtract min from itself too, so n times. We can achieve this by first calculating the total of the array while simultaneously keeping track of the minimum. Once done, all we need to do is subtract min n times from the sum, which is equivalent to subtracting min from each element. This results in a much overall better algorithm, requiring only 1 pass of the array.public int minMoves(int[] nums) { int sum = 0, min = nums[0]; for (int i: nums){ sum += i; if (i &lt; min) min = i; } return sum - min*nums.length;}License Key FormattingThe idea is simple. I maintain a temporary array s that contains only the characters in string S after converting them to uppercase. I maintain a variable length that counts how many characters I found in the string S. If length is 0, that means it contains only dashes (-). Then I record the offset. Offset basically measures how many characters of the String S will be grouped unevenly in the beginning part of the string. I can check that by using the modulus operator and finding out the remainder. That many characters (of length &lt; K) will be in the beginning part of the string. Next step is to calculate how many dashes I will need. It’s basically length / K. Then I create the char array that will hold the characters of the formatted key. It’s length will be number of characters + the dashes we will need. We need to take care of a special case here. If the offset is 0, meaning I was able to divide characters in equal group, I need to subtract 1. Eg, let’s say we had 8 characters and K was 4. dashes = 8 / 4 = 2. We can divide 8 characters equally into 2 groups using only 1 dash. But since dashes was 2, it is clearly off by 1. This is the case when offset is 0. kIndex tracks where character is to be inserted in the key array. used tracks how many characters of the array s, which indirectly holds the characters of String S, are used. First I copy down the characters of length offset. Because those are the ones of uneven length. kIndex and used variables are updated. Last thing to do is to use all the remaining characters in array s, but we take K characters at a time, because we know that the segments are going to be of equal length. We also need to insert ‘-‘ after each segment, but only if kIndex is not at the beginning or at the end of the key array, because inserting it at those points is invalid. Create a new string and return it.public String licenseKeyFormatting(String S, int K) { char[] s = new char[S.length()]; int length = 0; for (char c: S.toCharArray()) if (c != '-') s[length++] = Character.toUpperCase(c); if (length == 0) return \"\"; int offset = length % K; int dashes = length / K; char[] key = new char[length + dashes + (offset == 0 ? -1 : 0)]; int kIndex = 0; int used = 0; while (used &lt; offset) key[kIndex++] = s[used++]; while (used &lt; index){ if (kIndex &gt; 0 &amp;&amp; kIndex &lt; key.length) key[kIndex++] = '-'; for (int i = 0; i &lt; K; ++i) key[kIndex++] = s[used++]; } return new String(key);}Max Consecutive OnesSolution 1: I came up with this solution initially. 4 ms runtime and passes 99.97% submissions.public int findMaxConsecutiveOnes(int[] nums) { int start = 0;\t\t\t\t\t// Keep track of start of a streak, if any int max = 0;\t\t\t\t\t// max length of the streak while (start &lt; nums.length){\t// While we are not at the end of the array if (nums[start] == 1){\t\t// Check if we have a 1 at start, if so int streak = 0;\t\t\t// initialize streak and check how long can we continue while (start &lt; nums.length &amp;&amp; nums[start] == 1){\t// that streak. ++streak;\t\t\t// Increment streak and left for each consecutive 1 ++start;\t\t\t// make sure you don't forget that start &lt; nums.length }\t\t\t\t\t\t// before checking nums[start] to prevent out-of-bounds if (streak &gt; max)\t\t// Check if the current streak is better than the max = streak;\t\t// previous streak. } ++start;\t\t\t\t\t// Increment start in either case to check for new }\t\t\t\t\t\t\t\t// streaks. return max;}Solution 2: After analyzing the problem further, I noticed that 0 denotes the end of a streak. If we observe 1, we increment streak by 1. But if I see a 0, I reset my streak to 0. This solution too had a 4 ms runtime and passed 99.97% submissions.public int findMaxConsecutiveOnes(int[] nums) { int max = 0;\t\t\t\t// Global max streak int streak = 0;\t\t\t\t// Local max streak. for (int i: nums){\t\t\t// For each number in nums if (i == 1){\t\t\t// If we see a 1 ++streak;\t\t\t// increment our ongoing streak. if (streak &gt; max)\t// If the local streak &gt; global max max = streak;\t// update global max streak. } else\t\t\t\t\t// otherwise we just saw a 0. streak = 0;\t\t\t// So our streak resets to 0. } return max;\t\t\t\t\t// return the global max streak.}PermutationsThe idea is as follows. Given an array a = {1,2,3}, we want to generate all it’s possible combinations. What we are trying to do here is that we first take the element at index 0, and find permutations of the remaining thing. When we do that, we insert the element at index 0 in front of the list to get 1 permutation. Similarly, we then take the element at index 1, and permute the remaining contents of the array and insert the element at index 1 in the beginning of the array to get another permutation and so on. In this problem, we are asked to return a list of list, so we first copy the numbers of the array into an ArrayList. Let’s run this code for the above example. Given nums = {1,2,3}, our ArrayList will be the same, al = [1,2,3]. Our result list is empty, result = [] and index = 0. helper([1,2,3], 0) swap (0, 0) → al = [1,2,3] helper(1,2,3, 1) swap(1, 1) → al = [1,2,3] helper([1,2,3], 2) swap(2, 2) → [1,2,3] helper([1,2,3], 3) We update our result list now, because index == length. Therefore, result = [[1,2,3]]. Our recursive stack collapses and we move on to the next instruction, which is undo the step, al = [1,2,3]. swap(1, 2) → al = [1,3,2] helper([1,3,2], 3) Again, index == length, add it to the list. result = [[1,2,3], [1,3,2]]. Recursion stack collapses, we undo the swap, al = [1,2,3] swap(0, 1) → al = [2,1,3] helper([2,1,3], 1) swap(1,1) → al = [2,1,3] helper([2,1,3], 2) swap(2, 2) → al = [2,1,3] helper([2,1,3], 3) index == length, add the current order to the list. result = [[1,2,3], [1,3,2], [2,1,3]] swap(1, 2) → al = [2,3,1] helper([2,3,1], 3) index == length, add the order to the list. Result = [[1,2,3], [1,3,2], [2,1,3], [2,3,1]] swap(0, 2) → al = [3,2,1] helper([3,2,1], 2) swap(2,2) → al = [3,2,1] helper([3,2,1], 3) index == length, add the order to the list. Result = [[1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,2,1]] swap(1,2) → al = [3,1,2] helper([3,1,2], 3) index == length, add the order to the list. Result = [[1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,2,1], [3,1,2]] All branches have been explored now, since the iteration ends and we return the result list.int len;\t\t\t\t\t\t// To store the length of the input arrayList&lt;List&lt;Integer&gt;&gt; result;\t\t// Result listpublic List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { result = new ArrayList&lt;&gt;(); List&lt;Integer&gt; numList = new ArrayList&lt;&gt;();\t// Creating a copy of the nums array for (int i: nums)\t\t\t// because it's easier to create a list from a list. numList.add(i);\t\t\t// Add everything to the list. len = nums.length; helper(numList, 0);\t\t\t// Call the aux function. return result;}private void helper(List&lt;Integer&gt; order, int index){ if (index == len)\t\t\t// If we have checked all the numbers in the array, add a result.add(new ArrayList&lt;&gt;(order));\t// clone of the list to the array. for (int i = index; i &lt; len; ++i){\t// Otherwise from index to the end of the array, swap(order, i, index);\t// take one element, swap it with itself, then the next and helper(order, index+1);\t// so on. Recurse again, but on the next index we just swapped. swap(order, i, index);\t// Undo the swap so that it helps us in generating the next }\t\t\t\t\t\t\t// permutation.}private void swap(List&lt;Integer&gt; list, int i, int j){\t// Swap elements in a list. int temp = list.get(i); list.set(i, list.get(j)); list.set(j, temp);}Construct the RectangleThe idea is very simple. We just need to iterate from width = sqrt(area) to 1 and check if area is perfectly divisible by width. If at any point, width is divisible, then that must be our minimum difference length and width, because we are diverging from the center on both sides. Width decreases while length keeps increasing. Think of it like this, for area = 24, we have many factors of 24, namely 1, 2, 3,4, 6, 8, 12, 24. It’s sqrt when rounded down is 4. So we check for width = 4, is 24 perfectly divisible by 4? Yes, so divide it and whatever you get is going to be the minimal difference values. Suppose 4 and 6 weren’t the factors for 24. In that case we decrease width by 1, which is 3. Check again, is 24 divisible by 3. Yes? Then that must be our answer. We are diverging away from the center on both sides equally, width to the left towards 1 and length to the right towards area . Therefore the moment we find one value that divides area perfectly, that’s our required values.public int[] constructRectangle(int area) { int[] dimensions = {area, 1};\t\t// We know that if nothing works out, n*1 is always boolean done = false;\t\t\t\t// going to be the answer int width = (int)Math.sqrt(area);\t// We only need to check width from sqrt(area) while (!done){\t\t\t\t\t\t// While not done if (area % length == 0){\t\t// check if area is perfectly divisible by width dimensions[0] = width;\t\t// if so, we found our width and the length. dimensions[1] = area/width; done = true;\t\t\t\t// mark done as false } --width;\t\t\t\t\t\t// otherwise decrease the length } return dimensions;\t\t\t\t\t// return the dimensions found.Merge Intervalspublic List&lt;Interval&gt; merge(List&lt;Interval&gt; intervals) { if (intervals == null || intervals.size() &lt; 2) return intervals; Collections.sort(intervals, (a,b) -&gt; a.start-b.start);\t// Sort the list so we can \t\t\t\t\t\t\t\t\t\t\t\t\t// compare adjacent intervals. List&lt;Interval&gt; merged = new ArrayList&lt;&gt;(); merged.add(intervals.get(0));\t\t\t\t\t// Add the initial interval. for (Interval i: intervals){\t\t\t\t\t// For each interval Interval last = merged.get(merged.size()-1);// Get the last added time. if (i.start &gt; last.end)\t\t\t\t\t\t// If it's time is greater than the last merged.add(i);\t\t\t\t\t\t\t// interval's end, it doesn't overlap else{\t\t\t\t\t\t\t\t\t\t// otherwise it does. last.end = last.end &gt; i.end ? last.end : i.end;\t// So check which has greater end time, and make the last added interval's time equals that merged.set(merged.size()-1, last);\t\t// And set it as the last added interval } } return merged;\t\t\t\t\t\t\t\t\t// Return the merged list.}Merged sorted lists counterA keeps track of which element we are looking at in array ‘a’. Same with counterB counterK keeps track of where to insert the element in array ‘a’, since a has enough space. The problem states that it might have more than enough space, so we use only the spaces we need, which is the total of both their sizes. Since indexing in an array is 0-based, we subtract 1. We insert elements from the end, since the end part of ‘a’ is empty. We can insert from the front, but then we would need to shift elements to the right after each insertion from ‘b’. If array values are equal, add them to the end, and decrease both their counter to check new values in the next iteration If not equal, then check which one is greater, since the last part of the array should contain larger values. Whichever’s greater, put it in ‘a’ at index ‘counterA’ and decrement the respective counter. In the end, we might have some leftover elements either from ‘a’ or ‘b’ because we only process elements that are equal to the min(size(a), size(b)), until we run out of elements in one of the array. So, whichever array has elements pending, add it to the front of the array and return a.public int[] merge(int[] a, int sizeA, int[] b, int sizeB){ int counterA = sizeA-1, counterB = sizeB-1, counterK = sizeA+sizeB-1; while (counterA &gt; -1 &amp;&amp; counterB &gt; -1){ if (a[counterA] == b[counterB]){ a[counterK--] = a[counterA--]; a[counterK--] = b[counterB--]; } else a[counterK--] = a[counterA] &gt; b[counterB] ? a[counterA--] : b[counterB--]; } while (counterA &gt; -1) a[counterK--] = a[counterA--]; while (counterB &gt; -1) a[counterK--] = b[counterB--]; return a;}Next Greater Element Ipublic int[] nextGreaterElement(int[] nums1, int[] nums2) { HashMap&lt;Integer, Integer&gt; index = new HashMap&lt;&gt;();\t// We use the hashmap to keep a for (int i = 0; i &lt; nums2.length; ++i)\t\t\t\t// track of the index of each value index.put(nums2[i], i);\t\t\t\t\t\t\t// in nums 2. That way, when we want\t\t\t\t\t\t\t\t// to look for a value greater than a val in nums1, we know int[] result = new int[nums1.length];\t// which index to start iterating from. for (int i = 0; i &lt; nums1.length; ++i){\t// So for each val in nums1 int val = nums1[i]; for (int j = index.get(val); j &lt; nums2.length; ++j){\t// Iterate from that value's if (nums2[j] &gt; val){\t\t\t// index in nums2 to the end, and see if you can result[i] = nums2[j];\t\t// find any val &gt; nums1[i]. If you do, save it break;\t\t\t\t\t\t// in the result array and break the loop. } } if (result[i] == 0)\t\t// Now if we didn't find any value, then result[i] would be result[i] = -1;\t\t// 0, so we set that index to -1 in our result array. } return result;\t\t\t\t// simply return the result array.}String Without AAA or BBBpublic String strWithout3a3b(int A, int B) {\t\t\t\t char[] ch = new char[A+B];\t\t// We create an char array to store string chars int index = 0; char max = A &gt; B ? 'a' : 'b';\t// record the most frequent occurring element char min = max == 'a' ? 'b' : 'a';\t// and the least frequent occurring element while (A &gt; 0 || B &gt; 0){\t\t\t// While we haven't added all of the elements // We check that if our current index &gt; 1 and our previoud two characters in the array // are the same, then we must have written the max occurring char, so it's time to write // the minimum occurring element. We write it, and then decrement the specific A or B. if (index &gt; 1 &amp;&amp; max == ch[index-1] &amp;&amp; max == ch[index-2]){ ch[index++] = min; if (min == 'a')\t\t// If the minimum freq element is 'a', decrement A A--; else B--;\t\t\t// otherwise decrement B } else if (B &gt; A){\t\t// Otherwise, if B occurs more than A, then set char to B ch[index++] = 'b';\t// decrement B and increment index B--; } else{\t\t\t\t\t// A occurs more, so add A to the char array. ch[index++] = 'a';\t// Increment index, decrement A count A--; } } return new String(ch);\t\t// Create a string from the char array and return it.}Keyboard Row// Maps each character to the row in the keyboard in which it occurs.private int[] map = {2,3,3,2,1,2,2,2,1,2,2,2,3,3,1,1,1,1,2,1,1,3,1,3,1,3};public String[] findWords(String[] words) { String[] w = new String[words.length];\t// Store filtered words int index = 0;\t\t\t\t\t\t\t// Where to insert the filtered words for (String s: words)\t\t\t\t\t// for each word in words if (checkWord(s.toLowerCase()))\t\t// convert it to lowercase and check if all char w[index++] = s;\t\t\t\t\t// occurs in the same row, if it does, add it return Arrays.copyOfRange(w, 0, index);\t// Simply return a copy of the array from 0}\t\t\t\t\t\t\t\t\t\t\t// indexprivate boolean checkWord(String word){\t\t// Check if all chars in the word belong in the int row = map[word.charAt(0)-'a'];\t\t// same row. Check first chars row for (char c: word.toCharArray()){\t\t// For all the chars in the word if (map[c-'a'] != row)\t\t\t\t// if that char belongs to a different row, return false;\t\t\t\t\t// return false } return true;\t\t\t\t\t\t\t// All chars in same row, return true.}Find Mode in Binary Search Treeprivate TreeNode parent;\t\t// Keep track of parent at each nodeprivate int maxMode;\t\t\t// maxMode we foundprivate int currentMode;\t\t// mode recorded at each nodeprivate Set&lt;Integer&gt; modes;\t\t// keep distinct modes foundpublic int[] findMode(TreeNode root){ if (root == null)\t\t\t// node is null, so return empty array return new int[0]; maxMode = 1;\t\t\t\t// we have just seen the root, so maxMode so far is 1. currentMode = 1;\t\t\t// so is the current mode modes = new HashSet&lt;&gt;(); modes.add(root.val);\t\t// add the root to our modes set traverse(root);\t\t\t\t// start traversing it's left and right branches int[] result = new int[modes.size()];\t// We have found all the modes int idx = 0;\t\t\t\t// keep track of where to insert elements in result array for (int i: modes)\t\t\t// add all the distinct modes one by one result[idx++] = i; return result;\t\t\t\t// and return it.}private void traverse(TreeNode node){ if (node == null)\t\t\t// if node is null, stop return;\t\t\t\t\t// otherwise traverse the left branch traverse(node.left);\t\t// Once we hit the null, we start backtracking to the leaf updateMode(node);\t\t\t// then we call updateMode with the node parent = node;\t\t\t\t// once it's done, we update parent as the current node, so traverse(node.right);\t\t// when we backtrack, we can easily check that node and it's}\t\t\t\t\t\t\t\t// next node's value for similarity. Then traverse right.private void updateMode(TreeNode node){ if (parent != null &amp;&amp; parent.val == node.val){\t// If parent node isn't null and the ++currentMode;\t\t\t// node's value is the same as parent, we update currentMode if (currentMode &gt;= maxMode){\t// If the currentMode is greater or equal to maxMode if (currentMode &gt; maxMode)\t// just check if it's greater. If it is, remove all modes.clear();\t\t\t// previously recorded modes modes.add(node.val);\t\t// Add the current node to the set and update the maxMode = currentMode;\t\t// maxMode } } else{\t\t\t\t\t\t// otherwise, value's aren't the same. so our currentMode currentMode = 1;\t\t// becomes 1. If maxMode is also 1, then all we have been if (maxMode == 1)\t\t// seeing are distinct values, so add that node's value to modes.add(node.val);// to the mode's set. }}Base 7Solution 1 without StringBuilder (Beats 100%, 7ms) public String convertToBase7(int num) { if (num == 0) return \"0\"; int len = (int)(Math.log(Math.abs(num))/Math.log(7))+1;\t// Calculate # of bits int idx;\t\t// where to start inserting from char[] digits; if (num &lt; 0) {\t// If num is negative num = -num;\t// Make it positive digits = new char[len+1];\t// We need one more space for -ve sign in the front digits[0] = '-';\t\t\t// Put the -ve sign idx = len;\t\t\t\t\t// and index is now len } else{ digits = new char[len];\t\t// otherwise we only need \"len\" spaces idx = len-1;\t\t\t\t// index is len-1 } while (num != 0) {\t\t\t\t// While num != 0, calculate remainder and add it. digits[idx--] = (char)(num % 7 + '0');\t// Divide number by 7 num /= 7; } return new String(digits);\t\t// Just create a string and return it. }Solution 2 with StringBuilderpublic String convertToBase7(int num) { StringBuilder sb = new StringBuilder(); boolean isNegative = num &lt; 0;\t// Just so we can know if we need to add the \"-\" sign if (num &lt; 0)\t\t\t\t\t// Take the absolute value of num num = -num; while (num &gt; 6) {\t\t\t\t// Keep adding the remainder, and dividing num by 7. sb.append(num % 7); num /= 7; } sb.append(num);\t\t\t\t\t// Add whatever is left at the end. if (isNegative)\t\t\t\t\t// If num was negative, add the minus sign. sb.append('-'); return sb.reverse().toString();\t// Reverse the builder and return the toString()}Relative RanksThe idea employed here is simple. We need to store the relative ranks in sorted order. We can sort the array for that, but that is O(n log n). We can do better than that by finding the relative rank in linear time. First we find the maximum score in the array and create another array of length = maxScore + 1. We add 1 so that when we see the maxScore in the nums, we can assign it to maxScore index. Once we have done that, now we iterate over the nums array. Variable i keeps track of what rank to assign. We check a value in the array and at that index in our reverse sorted array, we put i+1, which basically marks it’s rank based on it’s position in the rankings. Some of then indexes would be default, that is a score of 0. We then check each value in the descend array and if it’s not 0, we assign it a rank, but not if the ranks are 1, 2 or 3. In that case, we assign it a special value of Gold, SIlver or Bronze.public String[] findRelativeRanks(int[] nums) { int maxScore = nums[0]; for (int n: nums) if (n &gt; maxScore) maxScore = n; int[] descend = new int[maxScore+1]; for (int i = 0; i &lt; nums.length; ++i) descend[nums[i]] = i+1; String[] result = new String[nums.length]; int rank = 1; for (int i = descend.length-1; i &gt; -1; --i){ int idx = descend[i]; if (descend[i] != 0){ if (rank == 1) result[idx-1] = \"Gold Medal\"; else if (rank == 2) result[idx-1] = \"Silver Medal\"; else if (rank == 3) result[idx-1] = \"Bronze Medal\"; else result[idx-1] = rank + \"\"; ++rank; } } return result;}Perfect Numberpublic boolean checkPerfectNumber(int num) { if (num == 1)\t\t// 1 is a special case, where it's only factor is itself. return false; int total = 1;\t\t// We know our total will atleast be 1, 1 is everyone's factor for (int i = 2; i &lt;= Math.sqrt(num); ++i)\t// Only loop through num's sqrt if (num % i == 0){\t\t\t\t// If i divides num perfectly int otherFactor = num/i;\t// Calculate the other factor total += i + (otherFactor == i ? 0 : otherFactor);\t// If i and other factor are }\t\t\t\t\t\t\t\t// different, add them both, otherwise just i. return total == num;\t\t\t\t// Check in the end if your total is the same as num}Detect Capitalpublic boolean detectCapitalUse(String word) { int len = word.length(); if (len &lt; 2)\t\t\t// Empty or size 1 words are ok. return true; char[] chars = word.toCharArray();\t// Get the char array boolean isUpper = false;\t// by default we let isUpper to false if (chars[0] &gt;= 'A' &amp;&amp; chars[0] &lt;= 'Z')\t\t// Check if first two letters are uppercase isUpper = chars[1] &gt;= 'A' &amp;&amp; chars[1] &lt;= 'Z'; // If first was upper and second wasnt for (int i = 1; i &lt; len; ++i){\t// isUpper = false, otherwise true. boolean isAlsoUpper = chars[i] &gt;= 'A' &amp;&amp; chars[i] &lt;= 'Z'; // We check onwards 1 char if (isUpper &amp;&amp; !isAlsoUpper)\t// If that char is lower and previous part was return false;\t\t\t\t// not lower, invalid use. if (!isUpper &amp;&amp; isAlsoUpper)\t// Or if previous part was lower and current letter return false;\t\t\t\t// is upper, we return false. } return true;\t\t\t\t// Everything proceeded smoothly. So return true.}Longest Uncommon Subsequence IThis is those kind of problems that shouldn’t be up there. The problem is stated rather poorly and the solution is even stupider. All you are checking for is if the two string’s aren’t the same, then whichever one has a larger length is essentially the longest uncommon subsequence because the other string cannot form the full string. I know, it’s stupid. public int findLUSlength(String a, String b) { if (a.equals(b)) return -1; return a.length() &gt; b.length() ? a.length() : b.length(); }Course Schedule IIThis is a graph problem where we require to sort the vertices topologically. There are two choices we have for sorting topologically - Depth First Search approach based on finshing times or the Kahn’s Algorithm. I have used Kahn’s algorithm in this solution. Runtime is 2ms [beats 100%] and uses 45.3 MB space [beats than 90.16%]. The idea for Kahn’s is simple - Enqueue all the nodes which has 0 incoming edges because those are the ones that can be started first. Then while the queue isn’t empty, remove one node at a time, process it’s outgoing nodes and decrease their indegrees by one. The reasoning behind that is let’s say Node 2 has two prerequisites, Node 0 and Node 1. Node 0 and Node 1 have 0 indegrees. So our first two nodes would be Node 1 and Node 0 and if they are finished, then their outgoing Nodes can be started, that is Node 2. Now when you decrease any node’s indegree and they become zero, add them to the queue because they can now be started. Keep doing this until the queue is empty.In my approach, I’m avoiding any unnecessary data structure and using only the most basic ones like array’s. So instead of using the queue, what I do is fill the array order which also stores the topological order. idx keeps track of the last index available to fill in the array. start mimics the poll behaviour of a queue. while (start != idx) makes sure that while we still have nodes to process, remove the one that can be started and decrease all the indegrees of outgoing edges.public int[] findOrder(int numCourses, int[][] prerequisites) { int[] indegrees = new int[numCourses];\t\t\t\t// We maintain each node's indegree List&lt;Integer&gt;[] graph = new ArrayList[numCourses];\t// Each node's outgoing edges for (int[] edge: prerequisites) {\t\t\t\t\t// Process each edge indegrees[edge[0]]++;\t\t\t\t\t\t\t// Update indegrees if (graph[edge[1]] == null)\t\t\t\t\t\t// Also store the edge in graph graph[edge[1]] = new ArrayList&lt;Integer&gt;(); graph[edge[1]].add(edge[0]); } int[] order = new int[numCourses];\t\t // We don't technically need a queue. int idx = 0; for (int i = 0; i &lt; numCourses; ++i) // Find all nodes who indegree is 0 if (indegrees[i] == 0) // and put them in the order array order[idx++] = i; int start = 0; // start tracks node to be polled. while (start != idx) { // while we can poll the queue int u = order[start++]; // poll the node u if (graph[u] != null) // If node u has outgoing edges for (int out: graph[u]) // Then for each of those nodes if (--indegrees[out] == 0) // decrease their indegrees and check if it's 0 order[idx++] = out; // if it's 0, add it to our queue (order) } if (idx != numCourses)\t\t\t\t\t\t// Cycle check. If our idx != numCourses then return new int[] {};\t\t\t\t\t// not all nodes could be processed. So we have return order;\t\t\t\t\t\t\t\t// a cycle. Otherwise return our order array.}Letter Combinations of a Phone NumberRuntime: 0 ms, faster than 100.00% of Java online submissions for Letter Combinations of a Phone Number.Memory Usage: 35.9 MB, less than 98.63% of Java online submissions for Letter Combinations of a Phone Number.How do we count numbers? 16, 17, 18, 19 and then what? 20 right? We see that the last number is 19, we can’t go past 9 so we set it to 0 and then increment the precedding digit to get 20. The idea is the same for this problem too. We keep a levels array to keep track of which character do we take from which number’s allowed alphabet letters. For example, let’s say the input string is 23. Our levels array would [0, 0] in the beginning. This says pick characters at index 0 and 0 from alphabet characters corresponding to 2 and 3 which gives us ad. Then, we increase the last most counter in our levels array by 1 giving us [0, 1]. This allows us to get ae in the next iteration and levels array would be [0, 2]. We get af and levels array becomes [0, 3]. Now this is where it becomes interesting. We are only allowed three letters for the digit corresponding to 3 and since we already used all of them , we now need to shift to the next character for digit 2, which is b. Level array looks like [1, 0]. This will allow us to get [b,e]. So you get the rough idea now. Only thing now is we watch out when to stop. We stop when we have utilized all available characters from the 0th index’s number’s allowed alphabet letters. In this case, we stop when levels array look like [3, 0].class Solution {\tprivate char[][] map = { {'a', 'b', 'c'}, // 2 {'d', 'e', 'f'}, // 3 {'g', 'h', 'i'}, // 4 {'j', 'k', 'l'}, // 5 {'m', 'n', 'o'}, // 6 {'p', 'q', 'r', 's'}, // 7 {'t', 'u', 'v'}, // 8 {'w', 'x', 'y', 'z'} // 9 }; private List&lt;String&gt; result = new ArrayList&lt;&gt;(); // Maintain the list of combinations private int[] numbers; // numbers parsed from input private int[] levels; // utility array to keep track of next character in string private int n; // number of input digits. private List&lt;String&gt; solution(String digits) { if (digits == null || digits.length() == 0) // stop if null or empty string return result; n = digits.length(); numbers = new int[n]; levels = new int[n]; for (int i = 0; i &lt; digits.length(); ++i) { // parse all the digits from the string as int if ((numbers[i] = digits.charAt(i) - '0') &lt; 2) // stop if any of them is 0 or 1 return result; } helper(); // start recursion return result; } private void helper() { if (levels[0] == map[numbers[0]-2].length) // if we are done iterating over all possible combinations, return; // stop recursion. char[] s = new char[n]; // stores all the characters of the string for (int i = 0; i &lt; n; ++i) // loop through levels array. The value at each index s[i] = map[numbers[i]-2][levels[i]]; // tells us which character to keep from which map index levels[n-1]++; // Increase the entry at the end of the levels array for (int i = levels.length-1; i &gt; 0; --i) { // Now loop through the levels array from the end if (levels[i] == map[numbers[i]-2].length) { // If the value = total number of characters allowed for that number levels[i] = 0; // then we set it to 0 and increment the previous level entry levels[i - 1]++; } } result.add(new String(s)); // Add the string and induce next recursive call. helper(); }}Sudoku SolverRuntime: 4 ms, faster than 90.01% of Java online submissions for Sudoku Solver.Memory Usage: 35.1 MB, less than 71.93% of Java online submissions for Sudoku Solver.private char[][] board;public void solveSudoku(char[][] board) { this.board = board; solve(0, 0);}private boolean solve(int row, int col) { if (col == 9) { // If col is 9, make it 0 and shift to the next row col = 0; row += 1; if (row == 9) // If row is also 9 now, then it means we have successfully filled all cells return true; // So return true and end backtracking. } for (int i = 1; i &lt; 10; ++i) { // Otherwise, we start picking values from 1-9 if (board[row][col] == '.') { // And try to plug it into empty cells if (isValid(row, col, i)) { // If that value is valid in that cell board[row][col] = (char)(i+'0'); // fill it if (solve(row, col+1)) // and move on to fill the next cell via recursive call return true; // If the recursion ended by returning true, then return true to signal success else // Otherwise, we were not able to put an value in that cell board[row][col] = '.'; // so change it back to 0 and the backtracking would try the next higher value in that cell. } } else return solve(row, col+1); // That cell wasn't empty, so move on to the next empty cell. } return false; // No solution found.}private boolean isValid(int row, int col, int val) { // row check for (int c = 0; c &lt; 9; ++c) if (board[row][c] - '0' == val) return false; // column check for (int r = 0; r &lt; 9; ++r) if (board[r][col] - '0' == val) return false; // box check int top = row / 3 * 3; int left = col / 3 * 3; for (int i = 0; i &lt; 3; ++i) { for (int j = 0; j &lt; 3; ++j) { if (board[top+i][left+j] - '0' == val) return false; } } return true;}Bulls and CowsRuntime: 1 ms, faster than 100.00% of Java online submissions for Bulls and Cows.Memory Usage: 36.3 MB, less than 100.00% of Java online submissions for Bulls and Cows.The idea is simple, first record the frequency of the digits of the secret number. Then we first find number of bulls by checking for exact indices match. After that we start to record the number of cows. The way we do is by again iterating over the guess string; only if there was a character mismatch and we still have the character available from freq table, we have a cow. Update it and decrement the frequency of the number we just used up.public String getHint(String secret, String guess) { int bulls = 0; int cows = 0; int[] freq = new int[10];\t\t\t\t\t\t\t// Freq of available digits from secret for (int i = 0; i &lt; guess.length(); ++i) { char s = secret.charAt(i); freq[s - '0']++;\t\t\t\t\t\t\t\t// Record the freq of the digit if (s == guess.charAt(i)) {\t\t\t\t\t\t// If it's a match, we have a bulls. bulls++; freq[s - '0']--;\t\t\t\t\t\t\t// We just used the character, so decrement it. } } for (int i = 0; i &lt; guess.length(); ++i) { int s = secret.charAt(i) - '0';\t\t\t\t\t// Convert the chars into int int g = guess.charAt(i) - '0'; if (s != g &amp;&amp; freq[g] &gt; 0) {\t\t\t\t\t// Only if they are a mismtach and we have a number g available in freq table cows++;\t\t\t\t\t\t\t\t\t\t// then it's a cow. freq[g]--;\t\t\t\t\t\t\t\t\t// We used up the number, so decrement it's freq. } } return new StringBuilder().append(bulls).append(\"A\").append(cows).append(\"B\").toString();}N-Queens IRuntime: 3 ms, faster than 73.76% of Java online submissions for N-Queens.Memory Usage: 37.6 MB, less than 100.00% of Java online submissions for N-Queens.The idea is same as sudoku, but insteading of scanning rows, we scan columns. Start with row 0, column 0 and see if we can place a queen there, if yes place it and try the next cell of row 0 by recursing. We can’t put the queen in the same row again, so we keep changing rows with column 1 until we find somewhere to place it. Keep doing this until you were successfully able to place all the queens as checked by the condition col == n. If so, add that solution to our list of accepted solutions.public class NQueens { private int[][] board; private int n; private List&lt;List&lt;String&gt;&gt; result; public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { this.n = n; board = new int[n][n]; result = new ArrayList&lt;&gt;(); solve(0); return result; } private boolean solve(int col) { if (col == n) addToList(); for (int row = 0; row &lt; n; ++row) { if (canPlaceQueen(row, col)) { board[row][col] = 1; if (solve(col+1)) { return true; } else board[row][col] = 0; } } return false; } private void addToList() { List&lt;String&gt; list = new LinkedList&lt;&gt;(); StringBuilder sb; for (int[] r: board) { sb = new StringBuilder(); for (int i: r) sb.append(i == 1 ? 'Q' : '.'); list.add(sb.toString()); } result.add(list); } private boolean canPlaceQueen(int row, int col) { // Check all rows for the same column for (int i = 0; i &lt; col; ++i) { if (board[row][i] == 1) return false; } // Check upper left diagonal of the cell for (int i = row, j = col; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) { if (board[i][j] == 1) return false; } // Check lower left diagonal of the cell. for (int i = row, j = col; i &lt; n &amp;&amp; j &gt;= 0; i++, j--) { if (board[i][j] == 1) return false; } return true; }}K-diff pairs in an ArrayPretty intuitive solution. Build a frequency HashMap for all the numbers in the array. In a special case where diff is 0, just count occurences in our freq map whose values are 2 or more. In other case, just loop through all the keys and make sure it’s supplement exists to count the number of K-diff pairs.public int findPairs(int[] nums, int k) { if (k &lt; 0) return 0; int pairs = 0; HashMap&lt;Integer, Integer&gt; freq = new HashMap&lt;&gt;(); for (int i: nums) { freq.put(i, freq.getOrDefault(i, 0)+1); } if (k == 0) { for (int i: freq.values()) if (i &gt; 1) pairs++; return pairs; } for (int i: freq.keySet()) { if (freq.containsKey(i+k)) pairs++; } return pairs;}Is SubsequenceRuntime: 0 ms, faster than 100.00% of Java online submissions for Is Subsequence.Memory Usage: 49.6 MB, less than 100.00% of Java online submissions for Is Subsequence.public boolean isSubsequence(String s, String t) { int idx = -1;\t\t\t\t\t\t\t\t// Set it to 0 to start check for 0th index for (char c: s.toCharArray()) {\t\t\t\t// For all the characters in String s idx = t.indexOf(c, idx+1);\t\t\t\t// Find it's index in String t from index one more than the last index matched if (idx &lt; 0)\t\t\t\t\t\t\t// idx &lt; 0 means not found return false; } return true;}Minimum Absolute Difference in BSTThe idea is to use the Inorder traversal of a BST. We repeatively iterate over the left branch to find the minimum diff and then do the same for the right branch, but this time we already know that the parent of the right branch has to be its minimum, so first set it and then traverse the right branch to find the minimum difference.int res = Integer.MAX_VALUE;\t\t\t\t\t\t\t\t// Hold the minimum difference.int prev = Integer.MAX_VALUE;\t\t\t\t\t\t\t\t// Holds the minimum value observed for the right branchpublic int getMinimumDifference(TreeNode root) { traverse(root);\t\t\t\t\t\t\t\t\t\t\t// Start iterating from the root. return res;}private void traverse(TreeNode node) { if (node == null)\t\t\t\t\t\t\t\t\t\t// Null node, so stop recursion return; traverse(node.left);\t\t\t\t\t\t\t\t\t// Keep traversing till the end of the tree res = Math.min(Math.abs(node.val-prev), res);\t\t\t// Check if we have a minimum, if so set it. prev = node.val;\t\t\t\t\t\t\t\t\t\t// The smallest value for the right branch is it's parent traverse(node.right);\t\t\t\t\t\t\t\t\t// Set it first and then traverse.}BST Tree to Greater TreeThe idea is simple. In a BST, we know everything on the right side of a node is greater than it and it’s left side. So when we are at any node, it’s value would be its value + sum of everything on its right side. So, we first compute the node’s value and then notice that the value for the node on the left is nothing but its value + parents value. So the node’s value is computed, do the same thing for the left side, but this time, the starting sum would be the parent’s value.public TreeNode convertBST(TreeNode root) { traverse(root, 0); return root;}private int traverse(TreeNode node, int sum) { if (node == null) return sum; node.val += traverse(node.right, sum); return traverse(node.left, node.val);}Student Attendance Record Ipublic boolean checkRecord(String s) { int A = 0;\t\t\t\t\t\t\t\t\t\t\t\t// Count number of A's seen int L = 0;\t\t\t\t\t\t\t\t\t\t\t\t// Count number of consecutive L's seen for (char c: s.toCharArray()) {\t\t// Loop through each character if (c == 'A') {\t\t\t\t\t\t\t\t// If c is A, increment A A++; if (A &gt; 1)\t\t\t\t\t\t\t\t// If A is more than 1, return false return false L = 0;\t\t\t\t\t\t\t\t\t\t// Always set L count to 0 } else if (c == 'L') {\t\t\t\t\t// If c is L, L++;\t\t\t\t\t\t\t\t\t\t\t// We might have consecutive L's, so start counting if (L &gt; 2) {\t\t\t\t\t\t\t// If we have more than 2 consecutive L's return false;\t\t\t\t\t// return false } } else\t\t\t\t\t\t\t\t\t\t\t\t\t// Lastly, we might have a P, that will reset our L = 0;\t\t\t\t\t\t\t\t\t\t// consecutive L streak. } return true;\t\t\t\t\t\t\t\t\t\t\t// Everything passed, so return true. }Reverse Words in String IIIRuntime: 2 ms, faster than 99.34% of Java online submissions for Reverse Words in a String III.Memory Usage: 37.9 MB, less than 100.00% of Java online submissions for Reverse Words in a String III.public String reverseWords(String s) { char[] arr = s.toCharArray(); int len = arr.length; int start = 0; int end; while (start &lt; len) {\t\t\t\t\t\t\t\t\t\t\t// Check the whole string end = start;\t\t\t\t\t\t\t\t\t\t\t\t\t// find the index of the first whitespace while(end &lt; len &amp;&amp; arr[end] != ' ')\t\t// denoting end of the word end++; reverseWord(arr, start, end-1);\t\t\t\t// reverse that specific word start = end+1;\t\t\t\t\t\t\t\t\t\t\t\t// update start to the new word beginning } return new String(arr);\t\t\t\t\t\t\t\t\t\t// create a new string out of the array }\t/*\tReverses a word in-place by iterating n/2 times where n = len of the word.\tTraverse upto the middle point of the word while swapping each word from start+offset to end-\t offset.\t**/ private void reverseWord(char[] arr, int start, int stop) { for (int i = 0; i &lt;= (stop-start)/2; ++i) { char temp = arr[start+i]; arr[start+i] = arr[stop-i]; arr[stop-i] = temp; } }Quad Tree Intersectionpublic Node intersect(Node qt1, Node qt2) { if (qt1.isLeaf)\t\t\t\t\t\t\t\t\t\t// If only a leaf, then return the one with true val return qt1.val ? qt1 : qt2; if (qt2.isLeaf) return qt2.val ? qt2 : qt1; Node n = new Node();\t\t\t\t\t\t\t// Prepare for recursion n.val = true;\t\t\t\t\t\t\t\t\t\t\t// By default, each level node is not a leaf with n.isLeaf = false;\t\t\t\t\t\t\t\t\t// value = true \t\t// Keep traversing all the way to a terminal node and then store it. n.topLeft = intersect(qt1.topLeft, qt2.topLeft); n.topRight = intersect(qt1.topRight, qt2.topRight); n.bottomLeft = intersect(qt1.bottomLeft, qt2.bottomLeft); n.bottomRight = intersect(qt1.bottomRight, qt2.bottomRight); \t\t// Check now if you're at the base case. If n's children are leaves and all their values are same, then make n a leaf and it's value the same as it's child. if (n.topLeft.isLeaf &amp;&amp; n.topRight.isLeaf &amp;&amp; n.bottomLeft.isLeaf &amp;&amp; n.bottomRight.isLeaf &amp;&amp; (n.topLeft.val == n.topRight.val &amp;&amp; n.topRight.val == n.bottomLeft.val &amp;&amp; n.bottomLeft.val == n.bottomRight.val)) { n.isLeaf = true; n.val = n.topLeft.val; } return n; }Long Pressed NameRuntime: 0 ms, faster than 100.00% of Java online submissions for Long Pressed Name.Memory Usage: 34.2 MB, less than 100.00% of Java online submissions for Long Pressed Name.public boolean isLongPressedName(String name, String typed) { char[] n = name.toCharArray();\t\t\t\t\t\t// Arrays are much nicer to work with char[] t = typed.toCharArray();\t\t\t\t\t\t// Record start and stop points for both int startN = 0, endN = n.length, startT = 0, endT = t.length; while (startT &lt; endT) {\t\t\t\t\t\t\t\t\t\t// While we haven't looked at the whole string int temp = startN+1;\t\t\t\t\t\t\t\t\t// Let's first count same consecutive letters int countN = 1;\t\t\t\t\t\t\t\t\t\t\t\t// in String name while (temp &lt; endN &amp;&amp; n[startN] == n[temp]) { temp++; countN++; } int countT = 0;\t\t\t\t\t\t\t\t\t\t\t\t// Do the same for typed string while (startT &lt; endT &amp;&amp; n[startN] == t[startT]) { startT++; countT++; }\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// If consecutive letters in typed string are if (countT &lt; countN)\t\t\t\t\t\t\t\t\t// less than the ones in original name return false;\t\t\t\t\t\t\t\t\t\t\t// return false startN = temp;\t\t\t\t\t\t\t\t\t\t\t\t// Otherwise, prepare for next character } return startN == endN;\t\t\t\t\t\t\t\t\t\t// Lastly, check if we were able to match }\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// all character of the name stringBinary Tree Zigzag Level Order TraversalThe idea here is simple. We perform a BFS as usual using a Queue but I maintain a variable called dir to check which side do I add from. dir=1 means add from Right-&gt;Left and dir=-1 means add from usual Left-&gt;Right. I am also using LinkedList because of easy addition of elements in both direction. When I need to add from Right-&gt;Left, I use the addFirst(E e) method of LinkedList to add to the head, otherwise normal add to the tail. One important thing to take care of at each iteration is to know how many nodes to dequeue, hence the usage of the variable children. This allows me to keep track of how many children were added to the queue at each stage so I dequeue exactly that many children in the next stage. Apart from that, everything is straightforward.public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; list = new LinkedList&lt;&gt;(); if (root == null) return list; Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(root);\t\t\t\t\t\t\t\t\t\t// Children = 1 because only root is added. int dir = 1, children = 1;\t\t\t// Added the root, so next time dir = 1 (Right-&gt;Left) while(!q.isEmpty()) { int pushed = 0; LinkedList&lt;Integer&gt; l = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; children; ++i) {\t\t// Poll only those nodes that were queued in TreeNode u = q.poll();\t\t\t\t\t\t\t// the previous stage. if (dir == 1) l.add(u.val); else l.addFirst(u.val);\t\t\t\t\t\t\t// Left-&gt;Right add if (u.left != null) {\t\t\t\t\t\t\t\t// Add children, notice I am counting here q.add(u.left);\t\t\t\t\t\t\t\t\t// how many children I am pushing/queuing ++pushed;\t\t\t\t\t\t\t\t\t\t\t\t// to the queue } if (u.right != null) {\t\t\t\t\t\t\t// Same thing for right child. q.add(u.right); ++pushed; } } list.add(l);\t\t\t\t\t\t\t\t\t\t\t\t\t\t// Add this list to main list children = pushed;\t\t\t\t\t\t\t\t\t\t\t// update # of children pushed dir = dir == 1 ? -1: 1;\t\t\t\t\t\t\t\t\t// update dir for next iteration } return list; }Array Partition IRuntime: 3 ms, faster than 99.90% of Java online submissions for Array Partition I.Memory Usage: 40.1 MB, less than 100.00% of Java online submissions for Array Partition I.I originally came up with the sorting solution where you sort the array and look at two numbers at a time and keep the smaller number out of them and add to the sum. It was way slower, so I checked the fastest submission and this one is pretty smart. The idea is really good. We know there are going to be 20,001 numbers, so reserve an array for it. Now let’s say we had duplicates in our array, ex [1,2,1,4,1,1], if we were to sort it, we would get [1,1,1,1,2,4]. Notice that those four 1’s don’t really matter because each of them pairs up with the other to give you a one 1. That is why we mark those particular indices as true and false. Notice that in our variable sum we would have counted them individually, making sum = 4 when in fact it should be 2 since we only take one of them from two pairs. If we have even occurrence of any number, they would be false, meaning we don’t need to account them in the diff calculation. Now coming to diff how do we compute it? First we have the seen array to know which elements we need to look at. If that particular index is true, then we check if it’s the first element of the pair which we maintain via the boolean value firstElemOfPair. If its true, then first becomes that value. Otherwise, we know that we’re looking at the second element so we update the diff which is basically that value subtract first. Notice that if we look at a pair in our example as (2,4), we would pick 2 and the diff would be 2. This needs to be subtracted from our sum, hence the reason to maintain both of them. At the end, we finally subtract sum and diff and divide the result by 2 because we were doubling our diff’s too.public int arrayPairSum(int[] nums) { boolean[] seen = new boolean[20001]; int sum = 0; for (int n: nums) { seen[n + 10000] = !seen[n+10000]; sum += n; } int diff = 0; int first = 0; boolean firstElemOfPair = true; for (int i = 0; i &lt; seen.length; ++i) { if (seen[i]) { if (firstElemOfPair) first = i; else diff += i-first; firstElemOfPair = !firstElemOfPair; } } return (sum-diff)/2; }Reshape the MatrixRuntime: 1 ms, faster than 100.00% of Java online submissions for Reshape the Matrix.Memory Usage: 38.4 MB, less than 100.00% of Java online submissions for Reshape the Matrix.public int[][] matrixReshape(int[][] nums, int r, int c) { int numsR = nums.length;\t\t\t\t // Get rows and col of nums int numsC = nums[0].length; if (numsR * numsC != r*c || (numsR == r &amp;&amp; numsC == c))\t// If can't reshape or problems return nums;\t\t\t\t\t\t\t\t\t // asks to reshape in the same dimensions, return the same array int[][] mat = new int[r][c];\t\t\t // New matrix to be returned int row = 0, col = 0, nR = 0, nC = 0; \t // To keep track of which element to consume and where to place it in the new matrix while (row != r) { mat[row][col++] = nums[nR][nC++];\t // Increment only the column value for both if (col == c) {\t\t\t\t\t\t\t\t // Check if we are at boundary, if so, increment row col = 0;\t\t\t\t\t\t\t\t\t // and set col to 0 for both cases. ++row; } if (nC == numsC) { nC = 0; ++nR; } } return mat; }Swap Nodes in PairsRuntime: 0 ms, faster than 100.00% of Java online submissions for Swap Nodes in Pairs.Memory Usage: 34.5 MB, less than 100.00% of Java online submissions for Swap Nodes in Pairs.The idea is simple. We add a dummy node in front for simplicity as it allows us to generalize the concept of getting two nodes at a time. We maintain a current pointer that points to the node in the actual LinkedList. Then, we get it’s next and it’s next.next and store it into n1 and n2. Now notice that before making n2’s next = n1, we need to store n2’s next into n1’s next. After we do that, we need to make sure that current’s next is n2 which is now working with the actual LinkedList. Then, we need to make sure that current.next.next is n1 which we just fixed and update current which is basically n1.public ListNode swapPairs(ListNode head) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode curr = dummy; while (curr.next != null &amp;&amp; curr.next.next != null) { ListNode n1 = curr.next; ListNode n2 = n1.next; n1.next = n2.next; curr.next = n2; curr.next.next = n1; curr = curr.next.next; } return dummy.next;}Generate ParenthesesIterative Approach 1: This one is very slow.Runtime: 4 ms, faster than 8.87% of Java online submissions for Generate Parentheses.Memory Usage: 36.1 MB, less than 100.00% of Java online submissions for Generate Parentheses.The idea is simple. We basically do a BFS and keep track of the parentheses combination we have obtained so far. Poll the queue and check if it’s length is 2*n (for a given n, we would have # of open brackets = # of closed brackets), add it to the list and check next combination. If not, then check if we can add an open bracket, add it and update number of open bracket count and add this combination to the queue. Then try to see if we can add a closed bracket, if you can add it, then update closed bracket count add that combination to the queue. Keep doing this until the queue becomes empty. This is the first approach I came up with which is naive as you can see since it’s doing an exhaustive search for all valid combination.private class Node { private String data; private int open; private int close; Node(String s, int o, int c) { data = s; open = o; close = c; }}public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; list = new LinkedList&lt;&gt;(); Queue&lt;Node&gt; q = new LinkedList&lt;&gt;(); q.add(new Node(\"(\", 1, 0)); while (!q.isEmpty()) { Node u = q.poll(); if (u.data.length() == 2*n) list.add(u.data); else { Node n1 = new Node(u.data, u.open, u.close); Node n2 = new Node(u.data, u.open, u.close); if (n1.open &lt; n) { n1.data = u.data + '('; ++n1.open; q.add(n1); } if (n2.close &lt; u.open) { n2.data = u.data + ')'; ++n2.close; q.add(n2); } } } return list;}Recursive Solution 2: This one is much more faster. I generalized the above idea into the fact that I am adding only valid combinations and any invalid combinations are automatically discarded. The logic is as follows: We know for a given n, the string length should be 2*n. So that forms our base case for recursion, if the length of String s is 2n, we want to add it to the list. Otherwise, we check if the number of open brackets we have so far is less than n. If so, we can add an open bracket. Then check if number of close bracket is less than open, if so that sequence would be valid and add a close bracket and recurse.Runtime: 1 ms, faster than 95.16% of Java online submissions for Generate Parentheses.Memory Usage: 36.1 MB, less than 100.00% of Java online submissions for Generate Parentheses.public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); helper(list, \"(\", 1, 0, n); return list;}private void helper(List&lt;String&gt; list, String s, int open, int close, int n) { if (s.length() == 2*n) list.add(s); else { if (open &lt; n) helper(list, s+'(', open+1, close, n); if (close &lt; open) helper(list, s+')', open, close+1, n); }}###Distribute CandiesPretty simple solution. We want to give maximize the number of unique candies to give to the sister. So we maintain a hashset to collect all the unique candies first. Both of them get half the candies, so let s = number of candies they get. Now, if the size of the set is greater than or equal to s, then the sister only gets s candies out of it. Otherwise, the maximum amount of unique candies she can get is equal to the set size.public int distributeCandies(int[] candies) { Set&lt;Integer&gt; set = new HashSet&lt;&gt;(candies.length); for (int i: candies) set.add(i); int share = candies.length/2; return set.size() &gt;= share ? share: set.size();}Maximum subproduct subarrayCredits for this simplistic solution to LeetCode user mzchen. The approach is very clever. Notice that if this problem was about finding maximum sum subarray, then a negative number would break the contiguous array. Here, what it does is that it makes our maximum product minimum when we see a negative number and vice versa. We keep track of maximum and minimum we have so far and check if we have a negative number. If so swap our max and min. Then, find the local maximum and minimum between current number and multiplying that number with our current max or min. After that, update our global max value and keep doing this for all values in the array.public int maxProduct(int[] nums) { int max = nums[0]; for (int i = 1, imax = max, imin = max; i &lt; nums.length; ++i) { if (nums[i] &lt; 0) { int temp = imax; imax = imin; imin = temp; } imax = Math.max(nums[i], imax * nums[i]); imin = Math.min(nums[i], imin * nums[i]); max = Math.max(max, imax); } return max;}Binary Tree Right Side ViewRuntime: 1 ms, faster than 95.45% of Java online submissions for Binary Tree Right Side View.Memory Usage: 36.3 MB, less than 100.00% of Java online submissions for Binary Tree Right Side View.This is an interesting problem cause initially, I thought we would always have a complete binary tree and I made my initial solution oriented towards it. But then I saw that it doesn’t say that anywhere and it could be any kind of binary tree. So it got me thinking towards a more generalized approach. Notice that to get a right side view of the binary tree, we only need the last value at any given level and put it into the list. So we maintain a queue and also the number of elements we enqueue at each stage. Initially, we put the root node in our queue and our enqueue count is 1. We dequeue exactly that many elements and again enqueue each of those dequeued node’s children. Notice that I am using the variable newEnqueued to keep track of newly enqueued elements. Lastly, we need to check if we dequeued the last element. If so, that must be a part of the solution since it has to be the rightmost element at that level, so I add it to the list. Update enqueued to the new value and repeat until our queue isn’t empty.public List&lt;Integer&gt; rightSideView(TreeNode root) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if (root == null) return list; Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(root); int enqueued = 1; while (!q.isEmpty()) { int newEnqueued = 0; for (int i = 0; i &lt; enqueued; ++i) { TreeNode u = q.poll(); if (u.left != null) { q.add(u.left); ++newEnqueued; } if (u.right != null) { q.add(u.right); ++newEnqueued; } if (i == enqueued-1) list.add(u.val); } enqueued = newEnqueued; } return list;}Find Minimum in Rotated Sorted ArrayRuntime: 0 ms, faster than 100.00% of Java online submissions for Find Minimum in Rotated Sorted Array.Memory Usage: 38.6 MB, less than 77.27% of Java online submissions for Find Minimum in Rotated Sorted Array.public int findMin(int[] nums) { if (nums.length == 1)\t\t\t\t\t\t\t\t\t// Base case. return nums[0]; int left = 0; int right = nums.length-1; int mid; while (nums[left] &gt; nums[right]) {\t\t// While we are in the ascending order half, mid = (left + right)/2;\t\t\t\t\t\t// Find the middle element if (nums[mid] &gt;= nums[left])\t\t\t// If mid element &gt;= left element, then our min left = mid + 1;\t\t\t\t\t\t\t\t// must be in the right half. else right = mid;\t\t\t\t\t\t\t\t\t// otherwise min in the left half. } return nums[left];\t\t\t\t\t\t\t\t\t\t// left points to minimum element.}Binary Search Tree IteratorRuntime: 15 ms, faster than 99.74% of Java online submissions for Binary Search Tree Iterator.Memory Usage: 49.9 MB, less than 93.83% of Java online submissions for Binary Search Tree Iterator.Logic is same as your In-Order traversal of any Binary Tree, but store the node values you visit in any data structure. Here I am using an ArrayList for storing each of the visited node’s value. Maintain idx value to keep track of which value to return. hasNext() method returns true as long as idx &lt; list.size().class BSTIterator { private List&lt;Integer&gt; list; private int idx = 0; public BSTIterator(TreeNode root) { list = new ArrayList&lt;&gt;(); traverse(root); } private void traverse(TreeNode node) { if (node == null) return; traverse(node.left); list.add(node.val); traverse(node.right); } /** @return the next smallest number */ public int next() { return list.get(idx++); } /** @return whether we have a next smallest number */ public boolean hasNext() { return idx != list.size(); }}Find Peak ElementThis question was asked to me for my internship at Yahoo! The idea is simple, we want any one of the peak. So to achieve O(log n) time, we have to mimic binary search algorithm. We look at the middle element and check it’s neighbor, if it’s greater than the middle element, then we know we will have atleast one peak on the right side. Why? Think what could happen. We know that the element next to middle is greater than it, so there are two possibilities on the right side, either elements keep increasing to the right of the middle’s next element or we might go up till a particular index and then go down. So in any case, we will have a peak on the right side. On the other case, if the element on the right side is smaller than the middle, then we know that the left half including the middle will have the peak cause middle is already greater than middle’s right, so we might have middle as the peak itself.public int findPeakElement(int[] nums) { if (nums.length == 1) return 0; int low = nums[0], high = nums.length - 1, mid; while (low &lt; high) { mid = (low + high)/2; if (nums[mid] &lt; nums[mid+1]) low = mid+1; else high = mid; } return low;}Next PermutationRuntime: 0 ms, faster than 100.00% of Java online submissions for Next Permutation.Memory Usage: 40.3 MB, less than 47.00% of Java online submissions for Next Permutation.This one was quite interesting in the sense it seems difficult but is very simple once you try out a few example. If we want to find the next lexicographical greater number, then we need to find a particular index from the right side of the array such that the number after it is greater than itself, because by swapping them would give us a next larger number. So what I first do is find the index of the number such that num[idx] &gt; num[idx-1]. We know at this point that all the numbers after that index are reverse sorted, so we need to fix it and sort them in increasing order because lexicographical order demands all the numbers in increasing manner. Example, say nums = [2,3,1,4,2,1,0]. You can see that that the next number should be [2,3,2,0,1,1,4]. Notice that I replaced the number at index 2 with the first number which is greater than it if the array after index 2 was sorted. This gaurantees us a larger lexicographical number. So the first while loop finds us that index number and then I reverse the array after it. Once you reverse it, we should expect the nums array to look like [2,3,1,0,1,2,4]. Note that now we need to find the number larger than the number at index 2, which is 1 in this case. The first number greater than 1 is 2, so the second while loop finds it and then we simply swap them to give us the next larger lexicographically greater number =&gt; [2,3,2,0,1,1,4].public void nextPermutation(int[] nums) { if (nums.length &lt; 2) return; int idx = nums.length-1; while (idx &gt; 0 &amp;&amp; nums[idx] &lt;= nums[idx-1]) --idx; reverse(nums, idx); if (idx == 0) return; int val = nums[idx-1]; int i = idx; while (i &lt; nums.length &amp;&amp; nums[i] &lt;= val) ++i; swap(nums, i, idx-1);}private void swap(int[] arr, int idx1, int idx2) { int temp = arr[idx1]; arr[idx1] = arr[idx2]; arr[idx2] = temp;}private void reverse(int[] arr, int start) { int end = arr.length-1; while (start &lt; end) swap(arr, start++, end--);}Search in Rotated Sorted ArrayThe idea is same as binary search except you need to keep track of which half to stay in. We compute the middle index and the value at that index. If the middle value is the target, then return that index. Otherwise, find the correct half. If the number on the left side is &lt; middle value then we know that between the left and middle index, values are increasing. We only need to now check if target is &lt; middle value, if so we need to adjust our right pointer otherwise adjust the left pointer. If left value is not &lt; middle value then we are at a shift where the array is pivoted. We again need to confirm now which half to take. There would be some index i such that nums[left] &gt; nums[i] &lt; nums[mid] and value are increasing upto i and shifts from index i onwards. In this case, we again need to adjust our index pointers and we repeat this loop until left &lt;= rightpublic int search(int[] nums, int target) { int left = 0, right = nums.length-1; while (left &lt;= right) { int mid = (left + right)/2; int midVal = nums[mid]; if (target == midVal) return mid; else if (nums[left] &lt;= midVal) { if (target &lt; midVal &amp;&amp; target &gt;= nums[left]) right = mid - 1; else left = mid + 1; } else { if (target &gt; midVal &amp;&amp; target &lt;= nums[right]) left = mid+1; else right = mid - 1; } } return -1;}Transpose MatrixPretty straightforward. Create matrix B of opposite dimensions to those of A. We maintain br and bc which tracks row and columns of B. We iterate over each element of A and put it in B[br][bc] and then ideally we would increment bc for an exact copy, but since we want transpose, we increment br and then reset it to 0 if we fill all the values in a row and increment column count, giving us the tranpose of the matrix.public int[][] transpose(int[][] A) { int[][] B = new int[A[0].length][A.length]; int br = 0, bc = 0; for (int i = 0; i &lt; A.length; ++i) { for (int j = 0; j &lt; A[0].length; ++j) { B[br][bc] = A[i][j]; if (++br == B.length) { br = 0; ++bc; } } } return B;}Merge K Sorted ListsThis was an onsite interview question at ThousandEyes. The idea is simple. Basically, we have multiple sorted lists so we have access to one value at a time, that is head of the lists initially and the consecutive nodes. So we need to fetch the minimum element out of all of them in constant time. The easiest way for us to do this is to use a PriorityQueue and define the logic of comparision of two ListNodes. Then, we add all the nodes inside the PQ and build our resulting List. Fetch the minimum valued ListNode and add it to our list. Then we also need to update that particular list’s head, so we add that list’s next in the PQ so the next time it is fetched, we fetch the correct node of the list. Repeat this until the list is empty and return dummy’s next node.public ListNode mergeKLists(ListNode[] lists) { if (lists.length == 0) return null; PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;(lists.length, (n1, n2) -&gt; n1.val - n2.val); for (ListNode ln: lists) if (ln != null) pq.add(ln); if (pq.isEmpty()) return null; ListNode node = new ListNode(-1); ListNode ret = node; while (!pq.isEmpty()) { node.next = pq.poll(); node = node.next; if (node.next != null) pq.add(node.next); } return ret.next;}" }, { "title": "Curated List of Project Based Tutorials", "url": "/posts/curated-list-of-project-based-tutorials/", "categories": "Computer Science, Projects", "tags": "projects", "date": "2022-10-26 00:00:00 +0530", "snippet": "Project Based Learning A list of programming tutorials in which aspiring software developers learn how to build an application from scratch. These tutorials are divided into different primary prog...", "content": "Project Based Learning A list of programming tutorials in which aspiring software developers learn how to build an application from scratch. These tutorials are divided into different primary programming languages. Tutorials may involve multiple technologies and languages.Table of Contents: C# C/C++ Clojure Dart Elixir Erlang F# Go Haskell HTML/CSS Java JavaScript Kotlin Lua OCaml PHP Python R Ruby Rust Scala Swift Additional resourcesC/C++: Build an Interpreter (Chapter 14 on is written in C) Memory Allocators 101 - Write a simple memory allocator Write a Shell in C Write a FUSE Filesystem Build Your Own Text Editor Build Your Own Lisp How to Program an NES Game in C Write an OS from scratch How to create an OS from scratch Building a CHIP-8 Emulator Beginning Game Programming with C++ and SDL Implementing a Key-Value Store Tiny 3D graphics projects Tiny Renderer or how OpenGL works: software rendering in 500 lines of code Understandable RayTracing in 256 lines of bare C++ KABOOM! in 180 lines of bare C++ 486 lines of C++: old-school FPS in a weekend Writing a minimal x86-64 JIT compiler in C++ Part 1 Part 2 Build a Live Code-reloader Library for C++ Write a hash table in C Let’s Build a Simple Database Let’s Write a Kernel Write a Bootloader in C Linux Container in 500 Lines of Code Write Your Own Virtual Machine Learning KVM - Implement Your Own Linux Kernel Write a C compiler Part 1: Integers, Lexing and Code Generation Part 2: Unary Operators Part 3: Binary Operators Part 4: Even More Binary Operators Part 5: Local Variables Part 6: Conditionals Part 7: Compound Statements Part 8: Loops Part 9: Functions Part 10: Global Variables Implementing a Language with LLVM Meta Crush Saga: a C++17 compile-time game High-Performance Matrix Multiplication Space Invaders from Scratch Part 1 Part 2 Part 3 Part 4 Part 5 Tetris Tutorial in C++ Platform Independent Writing a Linux Debugger Part 1: Setup Part 2: Breakpoints Part 3: Registers and memory Part 4: Elves and dwarves Part 5: Source and signals Part 6: Source-level stepping Part 7: Source-level breakpoints Part 8: Stack unwinding Part 9: Handling variables Part 10: Advanced topics Let’s write a compiler Part 1: Introduction, selecting a language, and doing some planning Part 2: A lexer Part 3: A parser Part 4: Testing Part 5: A code generator Part 6: Input and output Part 7: Arrays Part 8: Strings, forward references, and conclusion Network programming Let’s Code a TCP/IP Stack Part 1: Ethernet &amp; ARP Part 2: IPv4 &amp; ICMPv4 Part 3: TCP Basics &amp; Handshake Part 4: TCP Data Flow &amp; Socket API Part 5: TCP Retransmission Programming concurrent servers Part 1 - Introduction Part 2 - Threads Part 3 - Event-driven Part 4 - libuv Part 5 - Redis case study Part 6 - Callbacks, Promises and async/await MQTT Broker from scratch Part 1 - The protocol Part 2 - Networking Part 3 - Server Part 4 - Data structures Part 5 - Topic abstraction Part 6 - Handlers Bonus - Multithreading OpenGL: Creating 2D Breakout game clone in C++ with OpenGL Breakout Setting up Rendering Sprites Levels Collisions Ball Collision detection Collision resolution Particles Postprocessing Powerups Audio Render text Final thoughts Handmade Hero How to Make Minecraft in C++/OpenGL (video)C#: Learn C# By Building a Simple RPG Game Create a Rogue-like game in C# Create a Blank App with C# and Xamarin (work in progress) Build iOS Photo Library App with Xamarin and Visual Studio Building the CoreWiki This is a Wiki-style content management system that has been completely written in C# with ASP.NET Core and Razor Pages. You can find the source code here.Clojure: Build a Twitter Bot with Clojure Building a Spell-Checker Building a JIRA integration with Clojure &amp; Atlassian Connect Prototyping with Clojure Tetris in ClojureScriptDart:Flutter: Amazon Clone with Admin Panel Food Delivery App Google Docs Clone Instagram Clone Multiplayer TicTacToe Game TikTok Clone Ticket Booking App Travel App Twitch Clone WhatsApp Clone Wordle Clone Zoom CloneElixir Building a Simple Chat App With Elixir and Phoenix How to write a super fast link shortener with Elixir, Phoenix, and MnesiaErlang ChatBus : build your first multi-user chat room app with Erlang/OTP Making a Chat App with Erlang, Rebar, Cowboy and BulletF#: Write your own Excel in 100 lines of F#Java: Build an Interpreter (Chapter 4-13 is written in Java) Build a Simple HTTP Server with Java Build an Android Flashlight App (video) Build a Spring Boot App with User AuthenticationJavaScript: Build 30 things in 30 days with 30 tutorials Build an App in Pure JS Build a Jupyter Notebook Extension Build a TicTacToe Game with JavaScript Build a Simple Weather App With Vanilla JavaScript Build a Todo List App in JavaScriptHTML and CSS: Build A Loading Screen Build an HTML Calculator with JS Build Snake using only JavaScript, HTML &amp; CSSMobile Application: Build a React Native Todo Application Build a React Native Application with Redux ThunkWeb Applications:React: Create Serverless React.js Apps Create a Trello Clone Create a Character Voting App with React, Node, MongoDB and SocketIO React Tutorial: Cloning Yelp Build a Full Stack Movie Voting App with Test-First Development using Mocha, React, Redux and Immutable Build a Twitter Stream with React and Node Build A Simple Medium Clone using React.js and Node.js Integrate MailChimp in JS Build A Chrome Extension with React + Parcel Build A ToDo App With React Native Make a Chat Application Create a News App with React Native Learn Webpack For React Testing React App With Puppeteer and Jest Build Your Own React Boilerplate Code The Game Of Life With React A Basic React+Redux Introductory Tutorial Build an Appointment Scheduler Build A Chat App with Sentiment Analysis Build A Full Stack Web Application Setup Create Todoist clone with React and Firebase Build A Random Quote Machine Part 1 Part 2 Part 3 Part 4 Part 5 Part 6 Part 7 React Phone E-Commerce Project(video)Angular: Build an Instagram Clone with Angular 1.x Build an offline-capable Hacker News client with Angular 2+ Part 1 Part 2 Build a Google+ clone with Django and AngularJS (Angular 1.x) Build A Beautiful Real World App with Angular 8 : Part I Part II Build Responsive layout with BootStrap 4 and Angular 6 ToDo App with Angular 5 Introduction to Angular Part 1 Node: Build a real-time Markdown Editor with NodeJS Test-Driven Development with Node, Postgres and Knex Write a Twitter Bot in Node.js Part 1 Part 2 Build A Simple Search Bot in 30 minutes Build A Job Scraping Web App Building a GitHub App How to build your own Uber-for-X App using JavaScript, Node.JS, MongoDB and Web Sockets Part 1 Part 2 Vue Vue 2 + Firebase: How to build a Vue app with Firebase authentication system in 15 minutes Vue.js Application Tutorial – Creating a Simple Budgeting App with Vue Build a Blog with Vue, GraphQL and Apollo Build a full stack web application using MEVN (MongoDB, Express, Vue, Node) stack Part 1 Part 2 Vue.js To-Do List Tutorial (video) Vue 2 + Pub/Sub: Build a peer to peer multi-user platform for gamesOthers (Hapi, Express…): Build a Progressive Web Application (PWA) Part 1 Part 2 Part 3 Build A Native Desktop App with JS Build a Powerful API with NodeJs,GraphQL and Hapi Part I D3.js Learn D3 using examples Learn To Make A Line ChartGame Development: Make 2D Breakout Game using Phaser Make Flappy Bird in HTML5 and JavaScript with Phaser Part 1 Part 2 Desktop Application: Build A Desktop Chat App with React and ElectronMiscellaneous: How to Build a Web Framework in Less Than 20 Lines of Code Build Yourself a Redux How to write your own Virtual DOM Build A Realtime Serverless GraphQL API with WebSockets on AWSKotlin: Keddit - Learn Kotlin While Developing an Android ApplicationLua:LÖVE: BYTEPATH: Creation of a Complete Game with Lua and LÖVE Part 0: Introduction Part 1: Game Loop Part 2: Libraries Part 3: Rooms and Areas Part 4: Exercises Part 5: Game Basics Part 6: Player Basics Part 7: Player Stats and Attacks Part 8: Enemies Part 9: Director and Gameplay Loop Part 10: Coding Practices Part 11: Passives Part 12: More Passives Part 13: Skill Tree Part 14: Console Part 15: Final Python:Web Scraping: Mining Twitter Data with Python Scrape a Website with Scrapy and MongoDB How To Scrape With Python and Selenium WebDriver Which Movie Should I Watch using BeautifulSoupWeb Applications: Build a Microblog with Flask Create a Blog Web App In Django Choose Your Own Adventure Presentations Build a Todo List with Flask and RethinkDB Build a Todo List with Django and Test-Driven Development Build a RESTful Microservice in Python Microservices with Docker, Flask, and React Build A Simple Web App With Flask Create A Django API in under 20 minutes Build a Community-driven delivery application with Django, Postgres and JavaScript Part 1 Part 2 Realtime Chat application with Vue, django-notifs, RabbitMQ and uWSGI Part 1 Part 2 Part 3 Part 4 Part 5 Part 6 Bots: Build a Reddit Bot How to Make a Reddit Bot - YouTube (video) Build a Facebook Messenger Bot Making a Reddit + Facebook Messenger Bot How To Create a Telegram Bot Using Python Part 1 Part 2 Create a Twitter Bot In PythonData Science: Learn Python For Data Science by Doing Several Projects (video): Part 1: Introduction Part 2: Twitter Sentiment Analysis Part 3: Recommendation Systems Part 4: Predicting Stock Prices Part 5: Deep Dream in TensorFlow Part 6: Genetic Algorithms Machine Learning: Write Linear Regression From Scratch in Python (video) Step-By-Step Machine Learning In Python Predict Quality Of Wine Solving A Fruits Classification Problem Learn Unsupervised Learning with Python Build Your Own Neural Net from Scratch in Python Linear Regression in Python without sklearn Multivariate Linear Regression without sklearn Music Recommender using KNN Find Similar Quora Questions- Using BOW, TFIDF and Xgboost Using Word2Vec and Xgboost Detecting Fake News with Python and Machine LearningOpenCV: Build A Document Scanner Build A Face Detector using OpenCV and Deep Learning Build fastest custom object Detection system yusing YOLOv3(video playlist) Build a Face Recognition System using OpenCV, Python and Deep Learning Detect The Salient Features in an Image Build A Barcode Scanner Learn Face Clustering with Python Object Tracking with Camshift Semantic Segmentation with OpenCV and Deep Learning Text Detection in Images and Videos People Counter using OpenCV Tracking Multiple Objects with OpenCV Neural Style Transfer with OpenCV OpenCV OCR and Text Recognition Text Skew Correction Tutorial Facial Landmark Detection Tutorial Object Detection using Mask-R-CNN Automatic Target Detection Tutorial EigenFaces using OpenCV Faster(5-point) Facial Landmark Detection Tutorial Hand Keypoint Detection Dlib Correlation Object Tracking - Single Object Tracker Mutiple Object Tracker Image Stitching with OpenCV and Python Instance Segmentation with OpenCV Face mask detectorDeep Learning: Using Convolutional Neural Nets to Detect Facial Keypoints Generate an Average Face using Python and OpenCV Break A Captcha System using CNNs Use pre-trained Inception model to provide image predictions Create your first CNN Build A Facial Recognition Pipeline Build An Image Caption Generator Make your Own Face Recognition System Train a Language Detection AI in 20 minutes Object Detection With Neural Networks Learn Twitter Sentiment Analysis - Part I - Data Cleaning Part II - EDA, Data Visualisation Part III - Zipf’s Law, Data Visualisation Part IV - Feature Extraction(count vectoriser) Part V - Feature Extraction(Tfidf vectoriser) Part VI - Doc2Vec Part VII - Phrase Modeling + Doc2Vec Part VIII - Dimensionality Reduction Part IX - Neural Nets with Tfdif vectors Part X - Neural Nets with word2vec/doc2vec Part XI - CNN with Word2Vec Use Transfer Learning for custom image classification Learn to Code a simple Neural Network in 11 lines of Python Build a Neural Network using Gradient Descent Approach Train a Keras Model To Generate Colors Get Started with Keras on a Custom Dataset Use EigenFaces and FisherFaces on Faces94 dataset Kaggle MNIST Digit Recognizer Tutorial Fashion MNIST tutorial with tf.keras CNN using Keras to automatically classify root health Keras vs Tensorflow Deep Learning and Medical Image Analysis for Malaria Detection Transfer Learning for Image Classification using Keras Code a Smile Classifier using CNNS in Python Natural Language Processing using scikit-learn Code a Taylor Swift Lyrics Generator Mask detection using PyTorch LightningMiscellaneous: Build a Simple Interpreter Build a Simple Blockchain in Python Write a NoSQL Database in Python Building a Gas Pump Scanner with OpenCV/Python/iOS Build a Distributed Streaming System with Python and Kafka Writing a basic x86-64 JIT compiler from scratch in stock Python Making a low level (Linux) debugger Part 1 Part 2: C Implementing a Search Engine Part 1 Part 2 Part 3 Build the Game of Life Create terminal ASCII art Write a Tic-Tac-Toe AI Create photomosaic art Build the game “Snake” in the terminal Write yourself a Git A Python implementation of a Python bytecode runner Create a Voice assistant using PythonGo: Create a Real Time Chat App with Golang, Angular 2, and WebSocket Building Go Web Applications and Microservices Using Gin How to Use Godog for Behavior-driven Development in Go Building Blockchain in Go Part 1: Basic Prototype Part 2: Proof of Work Part 3: Persistence and CLI Part 4: Transactions 1 Part 5: Address Part 6: Transactions 2 Part 7: Network Building a container from scratch in Go - Liz Rice (Microscaling Systems)(video) Build Web Application with GoLang Building a Chat Application in Go with ReactJS Part 1: Initial Setup Part 2: Simple Communication Part 3: Designing our Frontend Part 4: Handling Multiple Clients Part 5: Improving the Frontend Part 6: Dockerizing your Backend Go WebAssembly Tutorial - Building a Calculator Tutorial REST Servers in Go Part 1 - standard library Part 2 - using a router package Part 3 - using a web framework Part 4 - using OpenAPI and Swagger Part 5 - middleware Part 6 - authentication Part 7 - GraphQL Let’s build a URL shortener in Go - with Gin &amp; Redis Part 1 - Project setup Part 2 - Storage Layer Part 3 - Short Link Generator Part 4 - Forwarding Building a TCP Chat in Go(video) Building a BitTorrent client from the ground up in Go REST API masterclass with Go, PostgreSQL and Docker(video playlist)in progressPHP: How To Build A Blog With Laravel (video) Make Your Own Blog (in Pure PHP) Build A Real Estate Website Example with SilverStripe Building Realtime Chat App with Laravel 5.4 and VueJS (video) Build A Social Network: Laravel 5 - Youtube (video) Build a full-featured multi-tenant app with Laravel Part 0: Introduction Part 1: Setup Part 2: Roles and Permissinos Part 3: Invitation Part 4: Authentication Part 5: Testing Part 6: User Profile Part 7: Deployment Build a Laravel CRUD Application From ScratchOCaml: Implement a Language with LLVM in OCamlRuby: Build a Network Stack with Ruby Build your own Redis Part 0: Introduction Part 1: Barebones TCP Server Part 2: PING &lt;-&gt; PONG Part 3: Concurrent Clients Part 4: ECHO Rebuilding Git in RubyRuby on Rails: The Ruby on Rails Tutorial Build Instagram From Scratch with Ruby on Rails Build a Social Network using Rails How To Build a Ruby on Rails ApplicationHaskell: Write You a Haskell - Build a modern functional compiler Write Yourself a Scheme in 48 hours Write You A Scheme, Version 2 Roll Your Own IRC Bot Making Movie Monad Making a Website with Haskell (outdated)R: Build Web Apps with Shiny Build A Cryptocurrency Bot Learn Associate Rule Mining in RRust: A Simple Web App in Rust Part 1 Part 2a Part 2b Write an OS in pure Rust Build a browser engine in Rust Write a Microservice in Rust Learning Rust with Too Many Linked Lists Rust in Detail: Writing Scalable Chat Service from Scratch Part 1: Implementing WebSocket. Introduction. Part 2: Sending and Receiving Messages Writing a Rust Roguelike for the Desktop and the Web Single Page Applications using Rust Writing NES Emulator in Rust Create a simulation of evolution using neural network and genetic algorithm, and compile the application to WebAssembly Part 1 Part 2 Part 3 Part 4 Scala: Simple actor-based blockchain No Magic: Regular ExpressionsSwift: Hacking with Swift - Learn Swift by doing 39 projects Retro first-person shooter from scratchAdditional Resources React Redux Links Udemy.com Full Stack Python Node School ScotchIO Exercism Egghead.io Michael Herman’s Blog Thinkster.io Enlight Hack Club Workshops CodeCrafters" }, { "title": "System Design Course", "url": "/posts/system-design-course/", "categories": "System Design, Full Course", "tags": "system-design, distributed-systems", "date": "2022-10-25 00:00:00 +0530", "snippet": " Learn how to design systems at scale and prepare for system design interviews.Download PDF Table of contents- **Getting Started** - [What is system design?](#what-is-system-design)- **Chapter I...", "content": " Learn how to design systems at scale and prepare for system design interviews.Download PDF Table of contents- **Getting Started** - [What is system design?](#what-is-system-design)- **Chapter I** - [IP](#ip) - [OSI Model](#osi-model) - [TCP and UDP](#tcp-and-udp) - [Domain Name System (DNS)](#domain-name-system-dns) - [Load Balancing](#load-balancing) - [Clustering](#clustering) - [Caching](#caching) - [Content Delivery Network (CDN)](#content-delivery-network-cdn) - [Proxy](#proxy) - [Availability](#availability) - [Scalability](#scalability) - [Storage](#storage)- **Chapter II** - [Databases and DBMS](#databases-and-dbms) - [SQL databases](#sql-databases) - [NoSQL databases](#nosql-databases) - [SQL vs NoSQL databases](#sql-vs-nosql-databases) - [Database Replication](#database-replication) - [Indexes](#indexes) - [Normalization and Denormalization](#normalization-and-denormalization) - [ACID and BASE consistency models](#acid-and-base-consistency-models) - [CAP theorem](#cap-theorem) - [PACELC Theorem](#pacelc-theorem) - [Transactions](#transactions) - [Distributed Transactions](#distributed-transactions) - [Sharding](#sharding) - [Consistent Hashing](#consistent-hashing) - [Database Federation](#database-federation)- **Chapter III** - [N-tier architecture](#n-tier-architecture) - [Message Brokers](#message-brokers) - [Message Queues](#message-queues) - [Publish-Subscribe](#publish-subscribe) - [Enterprise Service Bus (ESB)](#enterprise-service-bus-esb) - [Monoliths and Microservices](#monoliths-and-microservices) - [Event-Driven Architecture (EDA)](#event-driven-architecture-eda) - [Event Sourcing](#event-sourcing) - [Command and Query Responsibility Segregation (CQRS)](#command-and-query-responsibility-segregation-cqrs) - [API Gateway](#api-gateway) - [REST, GraphQL, gRPC](#rest-graphql-grpc) - [Long polling, WebSockets, Server-Sent Events (SSE)](#long-polling-websockets-server-sent-events-sse)- **Chapter IV** - [Geohashing and Quadtrees](#geohashing-and-quadtrees) - [Circuit breaker](#circuit-breaker) - [Rate Limiting](#rate-limiting) - [Service Discovery](#service-discovery) - [SLA, SLO, SLI](#sla-slo-sli) - [Disaster recovery](#disaster-recovery) - [Virtual Machines (VMs) and Containers](#virtual-machines-vms-and-containers) - [OAuth 2.0 and OpenID Connect (OIDC)](#oauth-20-and-openid-connect-oidc) - [Single Sign-On (SSO)](#single-sign-on-sso) - [SSL, TLS, mTLS](#ssl-tls-mtls)- **Chapter V** - [System Design Interviews](#system-design-interviews) - [URL Shortener](#url-shortener) - [Whatsapp](#whatsapp) - [Twitter](#twitter) - [Netflix](#netflix) - [Uber](#uber)- **Appendix** - [Next Steps](#next-steps) - [References](#references)What is system design?Before we start this course, let’s talk about what even is system design.System design is the process of defining the architecture, interfaces, and datafor a system that satisfies specific requirements. System design meets the needsof your business or organization through coherent and efficient systems. It requiresa systematic approach to building and engineering systems. A good system design requiresus to think about everything, from infrastructure all the way down to the data and how it’s stored.Why is System Design so important?System design helps us define a solution that meets the business requirements. It isone of the earliest decisions we can make when building a system. Often it is essentialto think from a high level as these decisions are very difficult to correct later. Italso makes it easier to reason about and manage architectural changes as the system evolves.IPAn IP address is a unique address that identifies a device on the internet or a local network. IP stands for “Internet Protocol”, which is the set of rules governing the format of data sent via the internet or local network.In essence, IP addresses are the identifier that allows information to be sent between devices on a network. They contain location information and make devices accessible for communication. The internet needs a way to differentiate between different computers, routers, and websites. IP addresses provide a way of doing so and form an essential part of how the internet works.VersionsNow, let’s learn about the different versions of IP addresses:IPv4The original Internet Protocol is IPv4 which uses a 32-bit numeric dot-decimal notation that only allows for around 4 billion IP addresses. Initially, it was more than enough but as internet adoption grew we needed something better.Example: 102.22.192.181IPv6IPv6 is a new protocol that was introduced in 1998. Deployment commenced in the mid-2000s and since the internet users have grown exponentially, it is still ongoing.This new protocol uses 128-bit alphanumeric hexadecimal notation. This means that IPv6 can provide about ~340e+36 IP addresses. That’s more than enough to meet the growing demand for years to come.Example: 2001:0db8:85a3:0000:0000:8a2e:0370:7334TypesLet’s discuss types of IP addresses:PublicA public IP address is an address where one primary address is associated with your whole network. In this type of IP address, each of the connected devices has the same IP address.Example: IP address provided to your router by the ISP.PrivateA private IP address is a unique IP number assigned to every device that connects to your internet network, which includes devices like computers, tablets, and smartphones, which are used in your household.Example: IP addresses generated by your home router for your devices.StaticA static IP address does not change and is one that was manually created, as opposed to having been assigned. These addresses are usually more expensive but are more reliable.Example: They are usually used for important things like reliable geo-location services, remote access, server hosting, etc.DynamicA dynamic IP address changes from time to time and is not always the same. It has been assigned by a Dynamic Host Configuration Protocol (DHCP) server. Dynamic IP addresses are the most common type of internet protocol addresses. They are cheaper to deploy and allow us to reuse IP addresses within a network as needed.Example: They are more commonly used for consumer equipment and personal use.OSI ModelThe OSI Model is a logical and conceptual model that defines network communication used by systems open to interconnection and communication with other systems. The Open System Interconnection (OSI Model) also defines a logical network and effectively describes computer packet transfer by using various layers of protocols.The OSI Model can be seen as a universal language for computer networking. It’s based on the concept of splitting up a communication system into seven abstract layers, each one stacked upon the last.Why does the OSI model matter?The Open System Interconnection (OSI) model has defined the common terminology used in networking discussions and documentation. This allows us to take a very complex communications process apart and evaluate its components.While this model is not directly implemented in the TCP/IP networks that are most common today, it can still help us do so much more, such as: Make troubleshooting easier and help identify threats across the entire stack. Encourage hardware manufacturers to create networking products that can communicate with each other over the network. Essential for developing a security-first mindset. Separate a complex function into simpler components.LayersThe seven abstraction layers of the OSI model can be defined as follows, from top to bottom:ApplicationThis is the only layer that directly interacts with data from the user. Software applications like web browsers and email clients rely on the application layer to initiate communication. But it should be made clear that client software applications are not part of the application layer, rather the application layer is responsible for the protocols and data manipulation that the software relies on to present meaningful data to the user. Application layer protocols include HTTP as well as SMTP.PresentationThe presentation layer is also called the Translation layer. The data from the application layer is extracted here and manipulated as per the required format to transmit over the network. The functions of the presentation layer are translation, encryption/decryption, and compression.SessionThis is the layer responsible for opening and closing communication between the two devices. The time between when the communication is opened and closed is known as the session. The session layer ensures that the session stays open long enough to transfer all the data being exchanged, and then promptly closes the session in order to avoid wasting resources. The session layer also synchronizes data transfer with checkpoints.TransportThe transport layer (also known as layer 4) is responsible for end-to-end communication between the two devices. This includes taking data from the session layer and breaking it up into chunks called segments before sending it to the Network layer (layer 3). It is also responsible for reassembling the segments on the receiving device into data the session layer can consume.NetworkThe network layer is responsible for facilitating data transfer between two different networks. The network layer breaks up segments from the transport layer into smaller units, called packets, on the sender’s device, and reassembles these packets on the receiving device. The network layer also finds the best physical path for the data to reach its destination this is known as routing. If the two devices communicating are on the same network, then the network layer is unnecessary.Data LinkThe data link layer is very similar to the network layer, except the data link layer facilitates data transfer between two devices on the same network. The data link layer takes packets from the network layer and breaks them into smaller pieces called frames.PhysicalThis layer includes the physical equipment involved in the data transfer, such as the cables and switches. This is also the layer where the data gets converted into a bit stream, which is a string of 1s and 0s. The physical layer of both devices must also agree on a signal convention so that the 1s can be distinguished from the 0s on both devices.TCP and UDPTCPTransmission Control Protocol (TCP) is connection-oriented, meaning once a connection has been established, data can be transmitted in both directions. TCP has built-in systems to check for errors and to guarantee data will be delivered in the order it was sent, making it the perfect protocol for transferring information like still images, data files, and web pages.But while TCP is instinctively reliable, its feedback mechanisms also result in a larger overhead, translating to greater use of the available bandwidth on the network.UDPUser Datagram Protocol (UDP) is a simpler, connectionless internet protocol in which error-checking and recovery services are not required. With UDP, there is no overhead for opening a connection, maintaining a connection, or terminating a connection. Data is continuously sent to the recipient, whether or not they receive it.It is largely preferred for real-time communications like broadcast or multicast network transmission. We should use UDP over TCP when we need the lowest latency and late data is worse than the loss of data.TCP vs UDPTCP is a connection-oriented protocol, whereas UDP is a connectionless protocol. A key difference between TCP and UDP is speed, as TCP is comparatively slower than UDP. Overall, UDP is a much faster, simpler, and more efficient protocol, however, retransmission of lost data packets is only possible with TCP.TCP provides ordered delivery of data from user to server (and vice versa), whereas UDP is not dedicated to end-to-end communications, nor does it check the readiness of the receiver. Feature TCP UDP Connection Requires an established connection Connectionless protocol Guaranteed delivery Can guarantee delivery of data Cannot guarantee delivery of data Re-transmission Re-transmission of lost packets is possible No re-transmission of lost packets Speed Slower than UDP Faster than TCP Broadcasting Does not support broadcasting Supports broadcasting Use cases HTTPS, HTTP, SMTP, POP, FTP, etc Video streaming, DNS, VoIP, etc Domain Name System (DNS)Earlier we learned about IP addresses that enable every machine to connect with other machines. But as we know humans are more comfortable with names than numbers. It’s easier to remember a name like google.com than something like 122.250.192.232.This brings us to Domain Name System (DNS) which is a hierarchical and decentralized naming system used for translating human-readable domain names to IP addresses.How DNS worksVideo: https://youtu.be/vhfRArT11jcDNS lookup involves the following eight steps: A client types example.com into a web browser, the query travels to the internet and is received by a DNS resolver. The resolver then recursively queries a DNS root nameserver. The root server responds to the resolver with the address of a Top Level Domain (TLD). The resolver then makes a request to the .com TLD. The TLD server then responds with the IP address of the domain’s nameserver, example.com. Lastly, the recursive resolver sends a query to the domain’s nameserver. The IP address for example.com is then returned to the resolver from the nameserver. The DNS resolver then responds to the web browser with the IP address of the domain requested initially.Once the IP address has been resolved, the client should be able to request content from the resolved IP address. For example, the resolved IP may return a webpage to be rendered in the browserServer typesNow, let’s look at the four key groups of servers that make up the DNS infrastructure.DNS ResolverA DNS resolver (also known as a DNS recursive resolver) is the first stop in a DNS query. The recursive resolver acts as a middleman between a client and a DNS nameserver. After receiving a DNS query from a web client, a recursive resolver will either respond with cached data, or send a request to a root nameserver, followed by another request to a TLD nameserver, and then one last request to an authoritative nameserver. After receiving a response from the authoritative nameserver containing the requested IP address, the recursive resolver then sends a response to the client.DNS root serverA root server accepts a recursive resolver’s query which includes a domain name, and the root nameserver responds by directing the recursive resolver to a TLD nameserver, based on the extension of that domain (.com, .net, .org, etc.). The root nameservers are overseen by a nonprofit called the Internet Corporation for Assigned Names and Numbers (ICANN).There are 13 DNS root nameservers known to every recursive resolver. Note that while there are 13 root nameservers, that doesn’t mean that there are only 13 machines in the root nameserver system. There are 13 types of root nameservers, but there are multiple copies of each one all over the world, which use Anycast routing to provide speedy responses.TLD nameserverA TLD nameserver maintains information for all the domain names that share a common domain extension, such as .com, .net, or whatever comes after the last dot in a URL.Management of TLD nameservers is handled by the Internet Assigned Numbers Authority (IANA), which is a branch of ICANN. The IANA breaks up the TLD servers into two main groups: Generic top-level domains: These are domains like .com, .org, .net, .edu, and .gov. Country code top-level domains: These include any domains that are specific to a country or state. Examples include .uk, .us, .ru, and .jp.Authoritative DNS serverThe authoritative nameserver is usually the resolver’s last step in the journey for an IP address. The authoritative nameserver contains information specific to the domain name it serves (e.g. google.com) and it can provide a recursive resolver with the IP address of that server found in the DNS A record, or if the domain has a CNAME record (alias) it will provide the recursive resolver with an alias domain, at which point the recursive resolver will have to perform a whole new DNS lookup to procure a record from an authoritative nameserver (often an A record containing an IP address). If it cannot find the domain, returns the NXDOMAIN message.Query TypesVideo: https://youtu.be/BZISxpdl4lQThere are three types of queries in a DNS system:RecursiveIn a recursive query, a DNS client requires that a DNS server (typically a DNS recursive resolver) will respond to the client with either the requested resource record or an error message if the resolver can’t find the record.IterativeIn an iterative query, a DNS client provides a hostname, and the DNS Resolver returns the best answer it can. If the DNS resolver has the relevant DNS records in its cache, it returns them. If not, it refers the DNS client to the Root Server or another Authoritative Name Server that is nearest to the required DNS zone. The DNS client must then repeat the query directly against the DNS server it was referred.Non-recursiveA non-recursive query is a query in which the DNS Resolver already knows the answer. It either immediately returns a DNS record because it already stores it in a local cache, or queries a DNS Name Server which is authoritative for the record, meaning it definitely holds the correct IP for that hostname. In both cases, there is no need for additional rounds of queries (like in recursive or iterative queries). Rather, a response is immediately returned to the client.Records TypesDNS records (aka zone files) are instructions that live in authoritative DNS servers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain.These records consist of a series of text files written in what is known as DNS syntax. DNS syntax is just a string of characters used as commands that tell the DNS server what to do. All DNS records also have a “TTL”, which stands for time-to-live, and indicates how often a DNS server will refresh that record.There are more record types but for now, let’s look at some of the most commonly used ones: A (Address record): This is the record that holds the IP address of a domain. AAAA (IP Version 6 Address record): The record that contains the IPv6 address for a domain (as opposed to A records, which stores the IPv4 address). CNAME (Canonical Name record): Forwards one domain or subdomain to another domain, does NOT provide an IP address. MX (Mail exchanger record): Directs mail to an email server. TXT (Text Record): This record lets an admin store text notes in the record. These records are often used for email security. NS (Name Server records): Stores the name server for a DNS entry. SOA (Start of Authority): Stores admin information about a domain. SRV (Service Location record): Specifies a port for specific services. PTR (Reverse-lookup Pointer records): Provides a domain name in reverse lookups. CERT (Certificate record): Stores public key certificates.SubdomainsA subdomain is an additional part of our main domain name. It is commonly used to logically separate a website into sections. We can create multiple subdomains or child domains on the main domain.For example, blog.example.com where blog is the subdomain, example is the primary domain and .com is the top-level domain (TLD). Similar examples can be support.example.com or careers.example.com.DNS ZonesA DNS zone is a distinct part of the domain namespace which is delegated to a legal entity like a person, organization, or company, who is responsible for maintaining the DNS zone. A DNS zone is also an administrative function, allowing for granular control of DNS components, such as authoritative name servers.DNS CachingA DNS cache (sometimes called a DNS resolver cache) is a temporary database, maintained by a computer’s operating system, that contains records of all the recent visits and attempted visits to websites and other internet domains. In other words, a DNS cache is just a memory of recent DNS lookups that our computer can quickly refer to when it’s trying to figure out how to load a website.The Domain Name System implements a time-to-live (TTL) on every DNS record. TTL specifies the number of seconds the record can be cached by a DNS client or server. When the record is stored in a cache, whatever TTL value came with it gets stored as well. The server continues to update the TTL of the record stored in the cache, counting down every second. When it hits zero, the record is deleted or purged from the cache. At that point, if a query for that record is received, the DNS server has to start the resolution process.Reverse DNSA reverse DNS lookup is a DNS query for the domain name associated with a given IP address. This accomplishes the opposite of the more commonly used forward DNS lookup, in which the DNS system is queried to return an IP address. The process of reverse resolving an IP address uses PTR records. If the server does not have a PTR record, it cannot resolve a reverse lookup.Reverse lookups are commonly used by email servers. Email servers check and see if an email message came from a valid server before bringing it onto their network. Many email servers will reject messages from any server that does not support reverse lookups or from a server that is highly unlikely to be legitimate.Note: Reverse DNS lookups are not universally adopted as they are not critical to the normal function of the internet.ExamplesThese are some widely used managed DNS solutions: Route53 Cloudflare DNS Google Cloud DNS Azure DNS NS1Load BalancingLoad balancing lets us distribute incoming network traffic across multiple resources ensuring high availability and reliability by sending requests only to resources that are online. This provides the flexibility to add or subtract resources as demand dictates.For additional scalability and redundancy, we can try to load balance at each layer of our system:But why?Modern high-traffic websites must serve hundreds of thousands, if not millions, of concurrent requests from users or clients. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers.A load balancer can sit in front of the servers and route client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization. This ensures that no single server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts sending requests to it.Workload distributionThis is the core functionality provided by a load balancer and has several common variations: Host-based: Distributes requests based on the requested hostname. Path-based: Using the entire URL to distribute requests as opposed to just the hostname. Content-based: Inspects the message content of a request. This allows distribution based on content such as the value of a parameter.LayersGenerally speaking, load balancers operate at one of the two levels:Network layerThis is the load balancer that works at the network’s transport layer, also known as layer 4. This performs routing based on networking information such as IP addresses and is not able to perform content-based routing. These are often dedicated hardware devices that can operate at high speed.Application layerThis is the load balancer that operates at the application layer, also known as layer 7. Load balancers can read requests in their entirety and perform content-based routing. This allows the management of load based on a full understanding of traffic.TypesLet’s look at different types of load balancers:SoftwareSoftware load balancers usually are easier to deploy than hardware versions. They also tend to be more cost-effective and flexible, and they are used in conjunction with software development environments. The software approach gives us the flexibility of configuring the load balancer to our environment’s specific needs. The boost in flexibility may come at the cost of having to do more work to set up the load balancer. Compared to hardware versions, which offer more of a closed-box approach, software balancers give us more freedom to make changes and upgrades.Software load balancers are widely used and are available either as installable solutions that require configuration and management or as a managed cloud service.HardwareAs the name implies, a hardware load balancer relies on physical, on-premises hardware to distribute application and network traffic. These devices can handle a large volume of traffic but often carry a hefty price tag and are fairly limited in terms of flexibility.Hardware load balancers include proprietary firmware that requires maintenance and updates as new versions and security patches are released.DNSDNS load balancing is the practice of configuring a domain in the Domain Name System (DNS) such that client requests to the domain are distributed across a group of server machines.Unfortunately, DNS load balancing has inherent problems limiting its reliability and efficiency. Most significantly, DNS does not check for server and network outages, or errors. It always returns the same set of IP addresses for a domain even if servers are down or inaccessible.Routing AlgorithmsNow, let’s discuss commonly used routing algorithms: Round-robin: Requests are distributed to application servers in rotation. Weighted Round-robin: Builds on the simple Round-robin technique to account for differing server characteristics such as compute and traffic handling capacity using weights that can be assigned via DNS records by the administrator. Least Connections: A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections. Least Response Time: Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections. Least Bandwidth: This method measures traffic in megabits per second (Mbps), sending client requests to the server with the least Mbps of traffic. Hashing: Distributes requests based on a key we define, such as the client IP address or the request URL.AdvantagesLoad balancing also plays a key role in preventing downtime, other advantages of load balancing include the following: Scalability Redundancy Flexibility EfficiencyRedundant load balancersAs you must’ve already guessed, the load balancer itself can be a single point of failure. To overcome this, a second or N number of load balancers can be used in a cluster mode.And, if there’s a failure detection and the active load balancer fails, another passive load balancer can take over which will make our system more fault-tolerant.FeaturesHere are some commonly desired features of load balancers: Autoscaling: Starting up and shutting down resources in response to demand conditions. Sticky sessions: The ability to assign the same user or device to the same resource in order to maintain the session state on the resource. Healthchecks: The ability to determine if a resource is down or performing poorly in order to remove the resource from the load balancing pool. Persistence connections: Allowing a server to open a persistent connection with a client such as a WebSocket. Encryption: Handling encrypted connections such as TLS and SSL. Certificates: Presenting certificates to a client and authentication of client certificates. Compression: Compression of responses. Caching: An application-layer load balancer may offer the ability to cache responses. Logging: Logging of request and response metadata can serve as an important audit trail or source for analytics data. Request tracing: Assigning each request a unique id for the purposes of logging, monitoring, and troubleshooting. Redirects: The ability to redirect an incoming request based on factors such as the requested path. Fixed response: Returning a static response for a request such as an error message.ExamplesFollowing are some of the load balancing solutions commonly used in the industry: Amazon Elastic Load Balancing Azure Load Balancing GCP Load Balancing DigitalOcean Load Balancer Nginx HAProxyClusteringAt a high level, a computer cluster is a group of two or more computers, or nodes, that run in parallel to achieve a common goal. This allows workloads consisting of a high number of individual, parallelizable tasks to be distributed among the nodes in the cluster. As a result, these tasks can leverage the combined memory and processing power of each computer to increase overall performance.To build a computer cluster, the individual nodes should be connected to a network to enable internode communication. The software can then be used to join the nodes together and form a cluster. It may have a shared storage device and/or local storage on each node.Typically, at least one node is designated as the leader node and acts as the entry point to the cluster. The leader node may be responsible for delegating incoming work to the other nodes and, if necessary, aggregating the results and returning a response to the user.Ideally, a cluster functions as if it were a single system. A user accessing the cluster should not need to know whether the system is a cluster or an individual machine. Furthermore, a cluster should be designed to minimize latency and prevent bottlenecks in node-to-node communication.TypesComputer clusters can generally be categorized into three types: Highly available or fail-over Load balancing High-performance computingConfigurationsThe two most commonly used high availability (HA) clustering configurations are active-active and active-passive.Active-ActiveAn active-active cluster is typically made up of at least two nodes, both actively running the same kind of service simultaneously. The main purpose of an active-active cluster is to achieve load balancing. A load balancer distributes workloads across all nodes to prevent any single node from getting overloaded. Because there are more nodes available to serve, there will also be an improvement in throughput and response times.Active-PassiveLike the active-active cluster configuration, an active-passive cluster also consists of at least two nodes. However, as the name active-passive implies, not all nodes are going to be active. For example, in the case of two nodes, if the first node is already active, then the second node must be passive or on standby.AdvantagesFour key advantages of cluster computing are as follows: High availability Scalability Performance Cost-effectiveLoad balancing vs ClusteringLoad balancing shares some common traits with clustering, but they are different processes. Clustering provides redundancy and boosts capacity and availability. Servers in a cluster are aware of each other and work together toward a common purpose. But with load balancing, servers are not aware of each other. Instead, they react to the requests they receive from the load balancer.We can employ load balancing in conjunction with clustering but it also is applicable in cases involving independent servers that share a common purpose such as to run a website, business application, web service, or some other IT resource.ChallengesThe most obvious challenge clustering presents is the increased complexity of installation and maintenance. An operating system, the application, and its dependencies must each be installed and updated on every node.This becomes even more complicated if the nodes in the cluster are not homogeneous. Resource utilization for each node must also be closely monitored, and logs should be aggregated to ensure that the software is behaving correctly.Additionally, storage becomes more difficult to manage, a shared storage device must prevent nodes from overwriting one another and distributed data stores have to be kept in sync.ExamplesClustering is commonly used in the industry, and often many technologies offer some sort of clustering mode. For example: Containers (eg. Kubernetes, Amazon ECS) Databases (eg. Cassandra, MongoDB) Cache (eg. Redis)Caching“There are only two hard things in Computer Science: cache invalidation and naming things.” - Phil KarltonA cache’s primary purpose is to increase data retrieval performance by reducing the need to access the underlying slower storage layer. Trading off capacity for speed, a cache typically stores a subset of data transiently, in contrast to databases whose data is usually complete and durable.Caches take advantage of the locality of reference principle “recently requested data is likely to be requested again”.Caching and MemorySimilar to a computer’s memory, a cache is a compact, fast-performing memory that stores data in a hierarchy of levels, starting at level one, and progressing from there sequentially. They are labeled as L1, L2, L3, and so on. A cache also gets written if requested, such as when there has been an update and new content needs to be saved to the cache, replacing the older content that was saved.No matter whether the cache is read or written, it’s done one block at a time. Each block also has a tag that includes the location where the data was stored in the cache. When data is requested from the cache, a search occurs through the tags to find the specific content that’s needed in level one (L1) of the memory. If the correct data isn’t found, more searches are conducted in L2.If the data isn’t found there, searches are continued in L3, then L4, and so on until it has been found, then, it’s read and loaded. If the data isn’t found in the cache at all, then it’s written into it for quick retrieval the next time.Cache hit and Cache missCache hitA cache hit describes the situation where content is successfully served from the cache. The tags are searched in the memory rapidly, and when the data is found and read, it’s considered a cache hit.Cold, Warm, and Hot CachesA cache hit can also be described as cold, warm, or hot. In each of these, the speed at which the data is read is described.A hot cache is an instance where data was read from the memory at the fastest possible rate. This happens when the data is retrieved from L1.A cold cache is the slowest possible rate for data to be read, though, it’s still successful so it’s still considered a cache hit. The data is just found lower in the memory hierarchy such as in L3, or lower.A warm cache is used to describe data that’s found in L2 or L3. It’s not as fast as a hot cache, but it’s still faster than a cold cache. Generally, calling a cache warm is used to express that it’s slower and closer to a cold cache than a hot one.Cache missA cache miss refers to the instance when the memory is searched and the data isn’t found. When this happens, the content is transferred and written into the cache.Cache InvalidationCache invalidation is a process where the computer system declares the cache entries as invalid and removes or replaces them. If the data is modified, it should be invalidated in the cache, if not, this can cause inconsistent application behavior. There are three kinds of caching systems:Write-through cacheData is written into the cache and the corresponding database simultaneously.Pro: Fast retrieval, complete data consistency between cache and storage.Con: Higher latency for write operations.Write-around cacheWhere write directly goes to the database or permanent storage, bypassing the cache.Pro: This may reduce latency.Con: It increases cache misses because the cache system has to read the information from the database in case of a cache miss. As a result, this can lead to higher read latency in the case of applications that write and re-read the information quickly. Read happen from slower back-end storage and experiences higher latency.Write-back cacheWhere the write is only done to the caching layer and the write is confirmed as soon as the write to the cache completes. The cache then asynchronously syncs this write to the database.Pro: This would lead to reduced latency and high throughput for write-intensive applications.Con: There is a risk of data loss in case the caching layer crashes. We can improve this by having more than one replica acknowledging the write in the cache.Eviction policiesFollowing are some of the most common cache eviction policies: First In First Out (FIFO): The cache evicts the first block accessed first without any regard to how often or how many times it was accessed before. Last In First Out (LIFO): The cache evicts the block accessed most recently first without any regard to how often or how many times it was accessed before. Least Recently Used (LRU): Discards the least recently used items first. Most Recently Used (MRU): Discards, in contrast to LRU, the most recently used items first. Least Frequently Used (LFU): Counts how often an item is needed. Those that are used least often are discarded first. Random Replacement (RR): Randomly selects a candidate item and discards it to make space when necessary.Distributed CacheA distributed cache is a system that pools together the random-access memory (RAM) of multiple networked computers into a single in-memory data store used as a data cache to provide fast access to data. While most caches are traditionally in one physical server or hardware component, a distributed cache can grow beyond the memory limits of a single computer by linking together multiple computers.Global CacheAs the name suggests, we will have a single shared cache that all the application nodes will use. When the requested data is not found in the global cache, it’s the responsibility of the cache to find out the missing piece of data from the underlying data store.Use casesCaching can have many real-world use cases such as: Database Caching Content Delivery Network (CDN) Domain Name System (DNS) Caching API CachingWhen not to use caching?Let’s also look at some scenarios where we should not use cache: Caching isn’t helpful when it takes just as long to access the cache as it does to access the primary data store. Caching doesn’t work as well when requests have low repetition (higher randomness), because caching performance comes from repeated memory access patterns. Caching isn’t helpful when the data changes frequently, as the cached version gets out of sync, and the primary data store must be accessed every time.It’s important to note that a cache should not be used as permanent data storage. They are almost always implemented in volatile memory because it is faster, and thus should be considered transient.AdvantagesBelow are some advantages of caching: Improves performance Reduce latency Reduce load on the database Reduce network cost Increase Read ThroughputExamplesHere are some commonly used technologies for caching: Redis Memcached Amazon Elasticache AerospikeContent Delivery Network (CDN)A content delivery network (CDN) is a geographically distributed group of servers that work together to provide fast delivery of internet content. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN.Why use a CDN?Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs and improving security. Serving content from CDNs can significantly improve performance as users receive content from data centers close to them and our servers do not have to serve requests that the CDN fulfills.How does a CDN work?In a CDN, the origin server contains the original versions of the content while the edge servers are numerous and distributed across various locations around the world.To minimize the distance between the visitors and the website’s server, a CDN stores a cached version of its content in multiple geographical locations known as edge locations. Each edge location contains a number of caching servers responsible for content delivery to visitors within its proximity.Once the static assets are cached on all the CDN servers for a particular location, all subsequent website visitor requests for static assets will be delivered from these edge servers instead of the origin, thus reducing origin load and improving scalability.For example, when someone in the UK requests our website which might be hosted in the USA, they will be served from the closest edge location such as the London edge location. This is much quicker than having the visitor make a complete request to the origin server which will increase the latency.TypesCDNs are generally divided into two types:Push CDNsPush CDNs receive new content whenever changes occur on the server. We take full responsibility for providing content, uploading directly to the CDN, and rewriting URLs to point to the CDN. We can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.Sites with a small amount of traffic or sites with content that isn’t often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.Pull CDNsIn a Pull CDN situation, the cache is updated based on request. When the client sends a request that requires static assets to be fetched from the CDN if the CDN doesn’t have it, then it will fetch the newly updated assets from the origin server and populate its cache with this new asset, and then send this new cached asset to the user.Contrary to the Push CDN, this requires less maintenance because cache updates on CDN nodes are performed based on requests from the client to the origin server. Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.DisadvantagesAs we all know good things come with extra costs, so let’s discuss some disadvantages of CDNs: Extra charges: It can be expensive to use a CDN, especially for high-traffic services. Restrictions: Some organizations and countries have blocked the domains or IP addresses of popular CDNs. Location: If most of our audience is located in a country where the CDN has no servers, the data on our website may have to travel further than without using any CDN.ExamplesHere are some widely used CDNs: Amazon CloudFront Google Cloud CDN Cloudflare CDN FastlyProxyA proxy server is an intermediary piece of hardware/software sitting between the client and the backend server. It receives requests from clients and relays them to the origin servers. Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compression).TypesThere are two types of proxies:Forward ProxyA forward proxy, often called a proxy, proxy server, or web proxy is a server that sits in front of a group of client machines. When those computers make requests to sites and services on the internet, the proxy server intercepts those requests and then communicates with web servers on behalf of those clients, like a middleman.AdvantagesHere are some advantages of a forward proxy: Block access to certain content Allows access to geo-restricted content Provides anonymity Avoid other browsing restrictionsAlthough proxies provide the benefits of anonymity, they can still track our personal information. Setup and maintenance of a proxy server can be costly and requires configurations.Reverse ProxyA reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients. When clients send requests to the origin server of a website, those requests are intercepted by the reverse proxy server.The difference between a forward and reverse proxy is subtle but important. A simplified way to sum it up would be to say that a forward proxy sits in front of a client and ensures that no origin server ever communicates directly with that specific client. On the other hand, a reverse proxy sits in front of an origin server and ensures that no client ever communicates directly with that origin server.Introducing reverse proxy results in increased complexity. A single reverse proxy is a single point of failure, configuring multiple reverse proxies (i.e. a failover) further increases complexity.AdvantagesHere are some advantages of using a reverse proxy: Improved security Caching SSL encryption Load balancing Scalability and flexibilityLoad balancer vs Reverse ProxyWait, isn’t reverse proxy similar to a load balancer? Well, no as a load balancer is useful when we have multiple servers. Often, load balancers route traffic to a set of servers serving the same function, while, reverse proxies can be useful even with just one web server or application server. A reverse proxy can also act as a load balancer but not the other way around.ExamplesBelow are some commonly used proxy technologies: Nginx HAProxy Traefik EnvoyAvailabilityAvailability is the time a system remains operational to perform its required function in a specific period. It is a simple measure of the percentage of time that a system, service, or machine remains operational under normal conditions.The Nine’s of availabilityAvailability is often quantified by uptime (or downtime) as a percentage of time the service is available. It is generally measured in the number of 9s.\\[Availability = \\frac{Uptime}{(Uptime + Downtime)}\\]If availability is 99.00% available, it is said to have “2 nines” of availability, and if it is 99.9%, it is called “3 nines”, and so on. Availability (Percent) Downtime (Year) Downtime (Month) Downtime (Week) 90% (one nine) 36.53 days 72 hours 16.8 hours 99% (two nines) 3.65 days 7.20 hours 1.68 hours 99.9% (three nines) 8.77 hours 43.8 minutes 10.1 minutes 99.99% (four nines) 52.6 minutes 4.32 minutes 1.01 minutes 99.999% (five nines) 5.25 minutes 25.9 seconds 6.05 seconds 99.9999% (six nines) 31.56 seconds 2.59 seconds 604.8 milliseconds 99.99999% (seven nines) 3.15 seconds 263 milliseconds 60.5 milliseconds 99.999999% (eight nines) 315.6 milliseconds 26.3 milliseconds 6 milliseconds 99.9999999% (nine nines) 31.6 milliseconds 2.6 milliseconds 0.6 milliseconds Availability in Sequence vs ParallelIf a service consists of multiple components prone to failure, the service’s overall availability depends on whether the components are in sequence or in parallel.SequenceOverall availability decreases when two components are in sequence.\\[Availability \\space (Total) = Availability \\space (Foo) * Availability \\space (Bar)\\]For example, if both Foo and Bar each had 99.9% availability, their total availability in sequence would be 99.8%.ParallelOverall availability increases when two components are in parallel.\\[Availability \\space (Total) = 1 - (1 - Availability \\space (Foo)) * (1 - Availability \\space (Bar))\\]For example, if both Foo and Bar each had 99.9% availability, their total availability in parallel would be 99.9999%.Availability vs ReliabilityIf a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve high availability even with an unreliable system.High availability vs Fault ToleranceBoth high availability and fault tolerance apply to methods for providing high uptime levels. However, they accomplish the objective differently.A fault-tolerant system has no service interruption but a significantly higher cost, while a highly available system has minimal service interruption. Fault-tolerance requires full hardware redundancy as if the main system fails, with no loss in uptime, another system should take over.ScalabilityScalability is the measure of how well a system responds to changes by adding or removing resources to meet demands.Let’s discuss different types of scaling:Vertical scalingVertical scaling (also known as scaling up) expands a system’s scalability by adding more power to an existing machine. In other words, vertical scaling refers to improving an application’s capability via increasing hardware capacity.Advantages Simple to implement Easier to manage Data consistentDisadvantages Risk of high downtime Harder to upgrade Can be a single point of failureHorizontal scalingHorizontal scaling (also known as scaling out) expands a system’s scale by adding more machines. It improves the performance of the server by adding more instances to the existing pool of servers, allowing the load to be distributed more evenly.Advantages Increased redundancy Better fault tolerance Flexible and efficient Easier to upgradeDisadvantages Increased complexity Data inconsistency Increased load on downstream servicesStorageStorage is a mechanism that enables a system to retain data, either temporarily or permanently. This topic is mostly skipped over in the context of system design, however, it is important to have a basic understanding of some common types of storage techniques that can help us fine-tune our storage components. Let’s discuss some important storage concepts:RAIDRAID (Redundant Array of Independent Disks) is a way of storing the same data on multiple hard disks or solid-state drives (SSDs) to protect data in the case of a drive failure.There are different RAID levels, however, and not all have the goal of providing redundancy. Let’s discuss some commonly used RAID levels: RAID 0: Also known as striping, data is split evenly across all the drives in the array. RAID 1: Also known as mirroring, at least two drives contains the exact copy of a set of data. If a drive fails, others will still work. RAID 5: Striping with parity. Requires the use of at least 3 drives, striping the data across multiple drives like RAID 0, but also has a parity distributed across the drives. RAID 6: Striping with double parity. RAID 6 is like RAID 5, but the parity data are written to two drives. RAID 10: Combines striping plus mirroring from RAID 0 and RAID 1. It provides security by mirroring all data on secondary drives while using striping across each set of drives to speed up data transfers.ComparisonLet’s compare all the features of different RAID levels: Features RAID 0 RAID 1 RAID 5 RAID 6 RAID 10 Description Striping Mirroring Striping with Parity Striping with double parity Striping and Mirroring Minimum Disks 2 2 3 4 4 Read Performance High High High High High Write Performance High Medium High High Medium Cost Low High Low Low High Fault Tolerance None Single-drive failure Single-drive failure Two-drive failure Up to one disk failure in each sub-array Capacity Utilization 100% 50% 67%-94% 50%-80% 50% VolumesVolume is a fixed amount of storage on a disk or tape. The term volume is often used as a synonym for the storage itself, but it is possible for a single disk to contain more than one volume or a volume to span more than one disk.File storageFile storage is a solution to store data as files and present it to its final users as a hierarchical directories structure. The main advantage is to provide a user-friendly solution to store and retrieve files. To locate a file in file storage, the complete path of the file is required. It is economical and easily structured and is usually found on hard drives, which means that they appear exactly the same for the user and on the hard drive.Example: Amazon EFS, Azure files, Google Cloud Filestore, etc.Block storageBlock storage divides data into blocks (chunks) and stores them as separate pieces. Each block of data is given a unique identifier, which allows a storage system to place the smaller pieces of data wherever it is most convenient.Block storage also decouples data from user environments, allowing that data to be spread across multiple environments. This creates multiple paths to the data and allows the user to retrieve it quickly. When a user or application requests data from a block storage system, the underlying storage system reassembles the data blocks and presents the data to the user or applicationExample: Amazon EBS.Object StorageObject storage, which is also known as object-based storage, breaks data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems.Example: Amazon S3, Azure Blob Storage, Google Cloud Storage, etc.NASA NAS (Network Attached Storage) is a storage device connected to a network that allows storage and retrieval of data from a central location for authorized network users. NAS devices are flexible, meaning that as we need additional storage, we can add to what we have. It’s faster, less expensive, and provides all the benefits of a public cloud on-site, giving us complete control.HDFSThe Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. It has many similarities with existing distributed file systems.HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks, all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance.Databases and DBMSWhat is a Database?A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a Database Management System (DBMS). Together, the data and the DBMS, along with the applications that are associated with them, are referred to as a database system, often shortened to just database.What is DBMS?A database typically requires a comprehensive database software program known as a Database Management System (DBMS). A DBMS serves as an interface between the database and its end-users or programs, allowing users to retrieve, update, and manage how the information is organized and optimized. A DBMS also facilitates oversight and control of databases, enabling a variety of administrative operations such as performance monitoring, tuning, and backup and recovery.ComponentsHere are some common components found across different databases:SchemaThe role of a schema is to define the shape of a data structure, and specify what kinds of data can go where. Schemas can be strictly enforced across the entire database, loosely enforced on part of the database, or they might not exist at all.TableEach table contains various columns just like in a spreadsheet. A table can have as meager as two columns and upwards of a hundred or more columns, depending upon the kind of information being put in the table.ColumnA column contains a set of data values of a particular type, one value for each row of the database. A column may contain text values, numbers, enums, timestamps, etc.RowData in a table is recorded in rows. There can be thousands or millions of rows in a table having any particular information.TypesBelow are different types of databases: SQL NoSQL Document Key-value Graph Timeseries Wide column Multi-model SQL and NoSQL databases are broad topics and will be discussed separately in SQL databases and NoSQL databases. Learn how they compare to each other in SQL vs NoSQL databases.ChallengesSome common challenges faced while running databases at scale: Absorbing significant increases in data volume: The explosion of data coming in from sensors, connected machines, and dozens of other sources. Ensuring data security: Data breaches are happening everywhere these days, it’s more important than ever to ensure that data is secure but also easily accessible to users. Keeping up with demand: Companies need real-time access to their data to support timely decision-making and to take advantage of new opportunities. Managing and maintaining the database and infrastructure: As databases become more complex and data volumes grow, companies are faced with the expense of hiring additional talent to manage their databases. Removing limits on scalability: A business needs to grow if it’s going to survive, and its data management must grow along with it. But it’s very difficult to predict how much capacity the company will need, particularly with on-premises databases. Ensuring data residency, data sovereignty, or latency requirements: Some organizations have use cases that are better suited to run on-premises. In those cases, engineered systems that are pre-configured and pre-optimized for running the database are ideal.SQL databasesA SQL (or relational) database is a collection of data items with pre-defined relationships between them. These items are organized as a set of tables with columns and rows. Tables are used to hold information about the objects to be represented in the database. Each column in a table holds a certain kind of data and a field stores the actual value of an attribute. The rows in the table represent a collection of related values of one object or entity.Each row in a table could be marked with a unique identifier called a primary key, and rows among multiple tables can be made related using foreign keys. This data can be accessed in many different ways without re-organizing the database tables themselves. SQL databases usually follow the ACID consistency model.Materialized viewsA materialized view is a pre-computed data set derived from a query specification and stored for later use. Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view. This performance difference can be significant when a query is run frequently or is sufficiently complex.It also enables data subsetting and improves the performance of complex queries that run on large data sets which reduces network loads. There are other uses of materialized views, but they are mostly used for performance and replication.N+1 query problemThe N+1 query problem happens when the data access layer executes N additional SQL statements to fetch the same data that could have been retrieved when executing the primary SQL query. The larger the value of N, the more queries will be executed, the larger the performance impact.This is commonly seen in GraphQL and ORM (Object-Relational Mapping) tools and can be addressed by optimizing the SQL query or using a dataloader that batches consecutive requests and makes a single data request under the hood.AdvantagesLet’s look at some advantages of using relational databases: Simple and accurate Accessibility Data consistency FlexibilityDisadvantagesBelow are the disadvantages of relational databases: Expensive to maintain Difficult schema evolution Performance hits (join, denormalization, etc.) Difficult to scale due to poor horizontal scalabilityExamplesHere are some commonly used relational databases: PostgreSQL MySQL MariaDB Amazon AuroraNoSQL databasesNoSQL is a broad category that includes any database that doesn’t use SQL as its primary data access language. These types of databases are also sometimes referred to as non-relational databases. Unlike in relational databases, data in a NoSQL database doesn’t have to conform to a pre-defined schema. NoSQL databases follow BASE consistency model.Below are different types of NoSQL databases:DocumentA document database (also known as a document-oriented database or a document store) is a database that stores information in documents. They are general-purpose databases that serve a variety of use cases for both transactional and analytical applications.Advantages Intuitive and flexible Easy horizontal scaling SchemalessDisadvantages Schemaless Non-relationalExamples MongoDB Amazon DocumentDB CouchDBKey-valueOne of the simplest types of NoSQL databases, key-value databases save data as a group of key-value pairs made up of two data items each. They’re also sometimes referred to as a key-value store.Advantages Simple and performant Highly scalable for high volumes of traffic Session management Optimized lookupsDisadvantages Basic CRUD Values can’t be filtered Lacks indexing and scanning capabilities Not optimized for complex queriesExamples Redis Memcached Amazon DynamoDB AerospikeGraphA graph database is a NoSQL database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data instead of tables or documents.The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation.Advantages Query speed Agile and flexible Explicit data representationDisadvantages Complex No standardized query languageUse cases Fraud detection Recommendation engines Social networks Network mappingExamples Neo4j ArangoDB Amazon Neptune JanusGraphTime seriesA time-series database is a database optimized for time-stamped, or time series, data.Advantages Fast insertion and retrieval Efficient data storageUse cases IoT data Metrics analysis Application monitoring Understand financial trendsExamples InfluxDB Apache DruidWide columnWide column databases, also known as wide column stores, are schema-agnostic. Data is stored in column families, rather than in rows and columns.Advantages Highly scalable, can handle petabytes of data Ideal for real-time big data applicationsDisadvantages Expensive Increased write timeUse cases Business analytics Attribute-based data storageExamples BigTable Apache Cassandra ScyllaDBMulti-modelMulti-model databases combine different database models (i.e. relational, graph, key-value, document, etc.) into a single, integrated backend. This means they can accommodate various data types, indexes, queries, and store data in more than one model.Advantages Flexibility Suitable for complex projects Data consistentDisadvantages Complex Less matureExamples ArangoDB Azure Cosmos DB CouchbaseSQL vs NoSQL databasesIn the world of databases, there are two main types of solutions, SQL (relational) and NoSQL (non-relational) databases. Both of them differ in the way they were built, the kind of information they store, and how they store it. Relational databases are structured and have predefined schemas while non-relational databases are unstructured, distributed, and have a dynamic schema.High-level differencesHere are some high-level differences between SQL and NoSQL:StorageSQL stores data in tables, where each row represents an entity and each column represents a data point about that entity.NoSQL databases have different data storage models such as key-value, graph, document, etc.SchemaIn SQL, each record conforms to a fixed schema, meaning the columns must be decided and chosen before data entry and each row must have data for each column. The schema can be altered later, but it involves modifying the database using migrations.Whereas in NoSQL, schemas are dynamic. Fields can be added on the fly, and each record (or equivalent) doesn’t have to contain data for each field.QueryingSQL databases use SQL (structured query language) for defining and manipulating the data, which is very powerful.In a NoSQL database, queries are focused on a collection of documents. Different databases have different syntax for querying.ScalabilityIn most common situations, SQL databases are vertically scalable, which can get very expensive. It is possible to scale a relational database across multiple servers, but this is a challenging and time-consuming process.On the other hand, NoSQL databases are horizontally scalable, meaning we can add more servers easily to our NoSQL database infrastructure to handle large traffic. Any cheap commodity hardware or cloud instances can host NoSQL databases, thus making it a lot more cost-effective than vertical scaling. A lot of NoSQL technologies also distribute data across servers automatically.ReliabilityThe vast majority of relational databases are ACID compliant. So, when it comes to data reliability and a safe guarantee of performing transactions, SQL databases are still the better bet.Most of the NoSQL solutions sacrifice ACID compliance for performance and scalability.ReasonsAs always we should always pick the technology that fits the requirements better. So, let’s look at some reasons for picking SQL or NoSQL based database:For SQL Structured data with strict schema Relational data Need for complex joins Transactions Lookups by index are very fastFor NoSQL Dynamic or flexible schema Non-relational data No need for complex joins Very data-intensive workload Very high throughput for IOPSDatabase ReplicationReplication is a process that involves sharing information to ensure consistency between redundant resources such as multiple databases, to improve reliability, fault-tolerance, or accessibility.Master-Slave ReplicationThe master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.Advantages Backups of the entire database of relatively no impact on the master. Applications can read from the slave(s) without impacting the master. Slaves can be taken offline and synced back to the master without any downtime.Disadvantages Replication adds more hardware and additional complexity. Downtime and possibly loss of data when a master fails. All writes also have to be made to the master in a master-slave architecture. The more read slaves, the more we have to replicate, which will increase replication lag.Master-Master ReplicationBoth masters serve reads/writes and coordinate with each other. If either master goes down, the system can continue to operate with both reads and writes.Advantages Applications can read from both masters. Distributes write load across both master nodes. Simple, automatic, and quick failover.Disadvantages Not as simple as master-slave to configure and deploy. Either loosely consistent or have increased write latency due to synchronization. Conflict resolution comes into play as more write nodes are added and as latency increases.Synchronous vs Asynchronous replicationThe primary difference between synchronous and asynchronous replication is how the data is written to the replica. In synchronous replication, data is written to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized.In contrast, asynchronous replication copies the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis and it is more cost-effective.IndexesIndexes are well known when it comes to databases, they are used to improve the speed of data retrieval operations on the data store. An index makes the trade-offs of increased storage overhead, and slower writes (since we not only have to write the data but also have to update the index) for the benefit of faster reads. Indexes are used to quickly locate data without having to examine every row in a database table. Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access to ordered records.An index is a data structure that can be perceived as a table of contents that points us to the location where actual data lives. So when we create an index on a column of a table, we store that column and a pointer to the whole row in the index. Indexes are also used to create different views of the same data. For large data sets, this is an excellent way to specify different filters or sorting schemes without resorting to creating multiple additional copies of the data.One quality that database indexes can have is that they can be dense or sparse. Each of these index qualities comes with its own trade-offs. Let’s look at how each index type would work:Dense IndexIn a dense index, an index record is created for every row of the table. Records can be located directly as each record of the index holds the search key value and the pointer to the actual record.Dense indexes require more maintenance than sparse indexes at write-time. Since every row must have an entry, the database must maintain the index on inserts, updates, and deletes. Having an entry for every row also means that dense indexes will require more memory. The benefit of a dense index is that values can be quickly found with just a binary search. Dense indexes also do not impose any ordering requirements on the data.Sparse IndexIn a sparse index, records are created only for some of the records.Sparse indexes require less maintenance than dense indexes at write-time since they only contain a subset of the values. This lighter maintenance burden means that inserts, updates, and deletes will be faster. Having fewer entries also means that the index will use less memory. Finding data is slower since a scan across the page typically follows the binary search. Sparse indexes are also optional when working with ordered data.Normalization and DenormalizationTermsBefore we go any further, let’s look at some commonly used terms in normalization and denormalization.KeysPrimary key: Column or group of columns that can be used to uniquely identify every row of the table.Composite key: A primary key made up of multiple columns.Super key: Set of all keys that can uniquely identify all the rows present in a table.Candidate key: Attributes that identify rows uniquely in a table.Foreign key: It is a reference to a primary key of another table.Alternate key: Keys that are not primary keys are known as alternate keys.Surrogate key: A system-generated value that uniquely identifies each entry in a table when no other column was able to hold properties of a primary key.DependenciesPartial dependency: Occurs when the primary key determines some other attributes.Functional dependency: It is a relationship that exists between two attributes, typically between the primary key and non-key attribute within a table.Transitive functional dependency: Occurs when some non-key attribute determines some other attribute.AnomaliesDatabase anomaly happens when there is a flaw in the database due to incorrect planning or storing everything in a flat database. This is generally addressed by the process of normalization.There are three types of database anomalies:Insertion anomaly: Occurs when we are not able to insert certain attributes in the database without the presence of other attributes.Update anomaly: Occurs in case of data redundancy and partial update. In other words, a correct update of the database needs other actions such as addition, deletion, or both.Deletion anomaly: Occurs where deletion of some data requires deletion of other data.ExampleLet’s consider the following table which is not normalized: ID Name Role Team 1 Peter Software Engineer A 2 Brian DevOps Engineer B 3 Hailey Product Manager C 4 Hailey Product Manager C 5 Steve Frontend Engineer D Let’s imagine, we hired a new person “John” but they might not be assigned a team immediately. This will cause an insertion anomaly as the team attribute is not yet present.Next, let’s say Hailey from Team C got promoted, to reflect that change in the database, we will need to update 2 rows to maintain consistency which can cause an update anomaly.Finally, we would like to remove Team B but to do that we will also need to remove additional information such as name and role, this is an example of a deletion anomaly.NormalizationNormalization is the process of organizing data in a database. This includes creating tables and establishing relationships between those tables according to rules designed both to protect the data and to make the database more flexible by eliminating redundancy and inconsistent dependency.Why do we need normalization?The goal of normalization is to eliminate redundant data and ensure data is consistent. A fully normalized database allows its structure to be extended to accommodate new types of data without changing the existing structure too much. As a result, applications interacting with the database are minimally affected.Normal formsNormal forms are a series of guidelines to ensure that the database is normalized. Let’s discuss some essential normal forms:1NFFor a table to be in the first normal form (1NF), it should follow the following rules: Repeating groups are not permitted. Identify each set of related data with a primary key. Set of related data should have a separate table. Mixing data types in the same column is not permitted.2NFFor a table to be in the second normal form (2NF), it should follow the following rules: Satisfies the first normal form (1NF). Should not have any partial dependency.3NFFor a table to be in the third normal form (3NF), it should follow the following rules: Satisfies the second normal form (2NF). Transitive functional dependencies are not permitted.BCNFBoyce-Codd normal form (or BCNF) is a slightly stronger version of the third normal form (3NF) used to address certain types of anomalies not dealt with by 3NF as originally defined. Sometimes it is also known as the 3.5 normal form (3.5NF).For a table to be in the Boyce-Codd normal form (BCNF), it should follow the following rules: Satisfied the third normal form (3NF). For every functional dependency X → Y, X should be the super key.There are more normal forms such as 4NF, 5NF, and 6NF but we won’t discuss them here. Check out this amazing video that goes into detail.In a relational database, a relation is often described as “normalized” if it meets the third normal form. Most 3NF relations are free of insertion, update, and deletion anomalies.As with many formal rules and specifications, real-world scenarios do not always allow for perfect compliance. If you decide to violate one of the first three rules of normalization, make sure that your application anticipates any problems that could occur, such as redundant data and inconsistent dependencies.AdvantagesHere are some advantages of normalization: Reduces data redundancy. Better data design. Increases data consistency. Enforces referential integrity.DisadvantagesLet’s look at some disadvantages of normalization: Data design is complex. Slower performance. Maintenance overhead. Require more joins.DenormalizationDenormalization is a database optimization technique in which we add redundant data to one or more tables. This can help us avoid costly joins in a relational database. It attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins.Once data becomes distributed with techniques such as federation and sharding, managing joins across the network further increases complexity. Denormalization might circumvent the need for such complex joins.Note: Denormalization does not mean reversing normalization.AdvantagesLet’s look at some advantages of denormalization: Retrieving data is faster. Writing queries is easier. Reduction in number of tables. Convenient to manage.DisadvantagesBelow are some disadvantages of denormalization: Expensive inserts and updates. Increases complexity of database design. Increases data redundancy. More chances of data inconsistency.ACID and BASE consistency modelsLet’s discuss the ACID and BASE consistency models.ACIDThe term ACID stands for Atomicity, Consistency, Isolation, and Durability. ACID properties are used for maintaining data integrity during transaction processing.In order to maintain consistency before and after a transaction relational databases follow ACID properties. Let us understand these terms:AtomicAll operations in a transaction succeed or every operation is rolled back.ConsistentOn the completion of a transaction, the database is structurally sound.IsolatedTransactions do not contend with one another. Contentious access to data is moderated by the database so that transactions appear to run sequentially.DurableOnce the transaction has been completed and the writes and updates have been written to the disk, it will remain in the system even if a system failure occurs.BASEWith the increasing amount of data and high availability requirements, the approach to database design has also changed dramatically. To increase the ability to scale and at the same time be highly available, we move the logic from the database to separate servers. In this way, the database becomes more independent and focused on the actual process of storing data.In the NoSQL database world, ACID transactions are less common as some databases have loosened the requirements for immediate consistency, data freshness, and accuracy in order to gain other benefits, like scale and resilience.BASE properties are much looser than ACID guarantees, but there isn’t a direct one-for-one mapping between the two consistency models. Let us understand these terms:Basic AvailabilityThe database appears to work most of the time.Soft-stateStores don’t have to be write-consistent, nor do different replicas have to be mutually consistent all the time.Eventual consistencyThe data might not be consistent immediately but eventually, it becomes consistent. Reads in the system are still possible even though they may not give the correct response due to inconsistency.ACID vs BASE Trade-offsThere’s no right answer to whether our application needs an ACID or a BASE consistency model. Both the models have been designed to satisfy different requirements. While choosing a database we need to keep the properties of both the models and the requirements of our application in mind.Given BASE’s loose consistency, developers need to be more knowledgeable and rigorous about consistent data if they choose a BASE store for their application. It’s essential to be familiar with the BASE behavior of the chosen database and work within those constraints.On the other hand, planning around BASE limitations can sometimes be a major disadvantage when compared to the simplicity of ACID transactions. A fully ACID database is the perfect fit for use cases where data reliability and consistency are essential.CAP TheoremVideo: https://youtu.be/8UryASGBiR4CAP theorem states that a distributed system can deliver only two of the three desired characteristics Consistency, Availability, and Partition tolerance (CAP). ConsistencyIn a consistent system, all nodes see the same data simultaneously. If we perform a read operation on a consistent system, it should return the value of the most recent write operation. The read should cause all nodes to return the same data. All users see the same data at the same time, regardless of the node they connect to. When data is written to a single node, it is then replicated across the other nodes in the system. For this to happen, whenever data is written to one node, it must be instantly forwarded or replicated across all the nodes in the system before the write is deemed “successful”.Financial data is a good example. When a user logs in to their banking institution, they do not want to see an error that no data is returned, or that the value is higher or lower than it actually is. Banking apps should return the exact value of a user’s account information. In this case, banks would rely on consistent databases.Examples of a consistent database include: Bank account balances Text messagesDatabase options for consistency: MongoDB Redis HBaseAvailabilityWhen availability is present in a distributed system, it means that the system remains operational all of the time. Every request will get a response regardless of the individual state of the nodes. This means that the system will operate even if there are multiple nodes down. Unlike a consistent system, there’s no guarantee that the response will be the most recent write operation.Example of a highly available database: On YouTube and social media like Facebook and Instagram, we can ignore consistency in views or likes count but the availability of videos and posts is essential. In e-commerce businesses. Online stores want to make their store and the functions of the shopping cart available 24/7 so shoppers can make purchases exactly when they need.Database options for availability: Cassandra DynamoDB Cosmos DBPartition toleranceWhen a distributed system encounters a partition, it means that there’s a break in communication between nodes. If a system is partition-tolerant, the system does not fail, regardless of whether messages are dropped or delayed between nodes within the system. To have partition tolerance, the system must replicate records across combinations of nodes and networks.CAP theorem NoSQL databasesNoSQL databases can be classified based on whether they support high availability or high consistency.NoSQL databases are great for distributed networks. They allow for horizontal scaling, and they can quickly scale across multiple nodes. When deciding which NoSQL database to use, it’s important to keep the CAP theorem in mind. NoSQL databases can be classified based on the two CAP features they support. Consistency-Availability TradeoffWe live in a physical world and can’t guarantee the stability of a network, so distributed databases must choose Partition Tolerance (P). This implies a tradeoff between Consistency (C) and Availability (A).CA databaseRelational databases, such as PostgreSQL, allow for consistency and availability if the systems are vertically scale on a single machine, we can avoid fault tolerance.A CA database delivers consistency and availability across all nodes. It can’t do this if there is a partition between any two nodes in the system, and therefore can’t deliver fault tolerance.Example: PostgreSQL, MariaDB.CP databaseCP databases enable consistency and partition tolerance, but not availability. When a partition occurs, the system has to turn off inconsistent nodes until the partition can be fixed. That’s why they are not 100% available. MongoDB is an example of a CP database. It’s a NoSQL database management system (DBMS) that uses documents for data storage. It’s considered schema-less, which means that it doesn’t require a defined database schema. It’s commonly used in big data and applications running in different locations. The CP system is structured so that there’s only one primary node that receives all of the write requests in a given replica set. Secondary nodes replicate the data in the primary nodes, so if the primary node fails, a secondary node can stand-in.Example: MongoDB, Apache HBase.AP databaseAP databases enable availability and partition tolerance, but not consistency. In the event of a partition, all nodes are available, but they’re not all updated. For example, if a user tries to access data from a bad node, they won’t receive the most up-to-date version of the data. When the partition is eventually resolved, most AP databases will sync the nodes to ensure consistency across them. Apache Cassandra is an example of an AP database. It’s a NoSQL database with no primary node, meaning that all of the nodes remain available. Cassandra allows for eventual consistency because users can resync their data right after a partition is resolved.Example: Apache Cassandra, CouchDB.CAP theorem and microservicesMicroservices are defined as loosely coupled services that can be independently developed, deployed, and maintained. They include their own stack, database, and database model, and communicate with each other through a network. Microservices have become especially popular in hybrid cloud and multi-cloud environments, and they are also widely used in on-premises data centers. If you want to create a microservices application, you can use the CAP theorem to help you determine a database that will best fit your needs.PACELC TheoremThe PACELC theorem is an extension of the CAP theorem. The CAP theorem states that in the case of network partitioning (P) in a distributed system, one has to choose between Availability (A) and Consistency (C).PACELC extends the CAP theorem by introducing latency (L) as an additional attribute of a distributed system. The theorem states that else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).The PACELC theorem was first described by Daniel J. Abadi.PACELC theorem was developed to address a key limitation of the CAP theorem as it makes no provision for performance or latency.For example, according to the CAP theorem, a database can be considered Available if a query returns a response after 30 days. Obviously, such latency would be unacceptable for any real-world application.TransactionsA transaction is a series of database operations that are considered to be a “single unit of work”. The operations in a transaction either all succeed, or they all fail. In this way, the notion of a transaction supports data integrity when part of a system fails. Not all databases choose to support ACID transactions, usually because they are prioritizing other optimizations that are hard or theoretically impossible to implement together.Usually, relational databases support ACID transactions, and non-relational databases don’t (there are exceptions).StatesA transaction in a database can be in one of the following states:ActiveIn this state, the transaction is being executed. This is the initial state of every transaction.Partially CommittedWhen a transaction executes its final operation, it is said to be in a partially committed state.CommittedIf a transaction executes all its operations successfully, it is said to be committed. All its effects are now permanently established on the database system.FailedThe transaction is said to be in a failed state if any of the checks made by the database recovery system fails. A failed transaction can no longer proceed further.AbortedIf any of the checks fail and the transaction has reached a failed state, then the recovery manager rolls back all its write operations on the database to bring the database back to its original state where it was prior to the execution of the transaction. Transactions in this state are aborted.The database recovery module can select one of the two operations after a transaction aborts: Restart the transaction Kill the transactionTerminatedIf there isn’t any roll-back or the transaction comes from the committed state, then the system is consistent and ready for a new transaction and the old transaction is terminated.Distributed TransactionsA distributed transaction is a set of operations on data that is performed across two or more databases. It is typically coordinated across separate nodes connected by a network, but may also span multiple databases on a single server.Why do we need distributed transactions?Unlike an ACID transaction on a single database, a distributed transaction involves altering data on multiple databases. Consequently, distributed transaction processing is more complicated, because the database must coordinate the committing or rollback of the changes in a transaction as a self-contained unit.In other words, all the nodes must commit, or all must abort and the entire transaction rolls back. This is why we need distributed transactions.Now, let’s look at some popular solutions for distributed transactions:Two-Phase commitThe two-phase commit (2PC) protocol is a distributed algorithm that coordinates all the processes that participate in a distributed transaction on whether to commit or abort (roll back) the transaction.This protocol achieves its goal even in many cases of temporary system failure and is thus widely used. However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome.This protocol requires a coordinator node, which basically coordinates and oversees the transaction across different nodes. The coordinator tries to establish the consensus among a set of processes in two phases, hence the name.PhasesTwo-phase commit consists of the following phases:Prepare phaseThe prepare phase involves the coordinator node collecting consensus from each of the participant nodes. The transaction will be aborted unless each of the nodes responds that they’re prepared.Commit phaseIf all participants respond to the coordinator that they are prepared, then the coordinator asks all the nodes to commit the transaction. If a failure occurs, the transaction will be rolled back.ProblemsFollowing problems may arise in the two-phase commit protocol: What if one of the nodes crashes? What if the coordinator itself crashes? It is a blocking protocol.Three-phase commitThree-phase commit (3PC) is an extension of the two-phase commit where the commit phase is split into two phases. This helps with the blocking problem that occurs in the two-phase commit protocol.PhasesThree-phase commit consists of the following phases:Prepare phaseThis phase is the same as the two-phase commit.Pre-commit phaseCoordinator issues the pre-commit message and all the participating nodes must acknowledge it. If a participant fails to receive this message in time, then the transaction is aborted.Commit phaseThis step is also similar to the two-phase commit protocol.Why is the Pre-commit phase helpful?The pre-commit phase accomplishes the following: If the participant nodes are found in this phase, that means that every participant has completed the first phase. The completion of prepare phase is guaranteed. Every phase can now time out and avoid indefinite waits.SagasA saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.CoordinationThere are two common implementation approaches: Choreography: Each local transaction publishes domain events that trigger local transactions in other services. Orchestration: An orchestrator tells the participants what local transactions to execute.Problems The Saga pattern is particularly hard to debug. There’s a risk of cyclic dependency between saga participants. Lack of participant data isolation imposes durability challenges. Testing is difficult because all services must be running to simulate a transaction.ShardingBefore we discuss sharding, let’s talk about data partitioning:Data PartitioningData partitioning is a technique to break up a database into many smaller parts. It is the process of splitting up a database or a table across multiple machines to improve the manageability, performance, and availability of a database.MethodsThere are many different ways one could use to decide how to break up an application database into multiple smaller DBs. Below are three of the most popular methods used by various large-scale applications:Horizontal Partitioning (or Sharding)In this strategy, we split the table data horizontally based on the range of values defined by the partition key. It is also referred to as database sharding.Vertical PartitioningIn vertical partitioning, we partition the data vertically based on columns. We divide tables into relatively smaller tables with few elements, and each part is present in a separate partition.In this tutorial, we will specifically focus on sharding.What is sharding?Sharding is a database architecture pattern related to horizontal partitioning, which is the practice of separating one table’s rows into multiple different tables, known as partitions or shards. Each partition has the same schema and columns, but also a subset of the shared data. Likewise, the data held in each is unique and independent of the data held in other partitions.The justification for data sharding is that, after a certain point, it is cheaper and more feasible to scale horizontally by adding more machines than to scale it vertically by adding powerful servers. Sharding can be implemented at both application or the database level.Partitioning criteriaThere are a large number of criteria available for data partitioning. Some most commonly used criteria are:Hash-BasedThis strategy divides the rows into different partitions based on a hashing algorithm rather than grouping database rows based on continuous indexes.The disadvantage of this method is that dynamically adding/removing database servers becomes expensive.List-BasedIn list-based partitioning, each partition is defined and selected based on the list of values on a column rather than a set of contiguous ranges of values.Range BasedRange partitioning maps data to various partitions based on ranges of values of the partitioning key. In other words, we partition the table in such a way that each partition contains rows within a given range defined by the partition key.Ranges should be contiguous but not overlapping, where each range specifies a non-inclusive lower and upper bound for a partition. Any partitioning key values equal to or higher than the upper bound of the range are added to the next partition.CompositeAs the name suggests, composite partitioning partitions the data based on two or more partitioning techniques. Here we first partition the data using one technique, and then each partition is further subdivided into sub-partitions using the same or some other method.AdvantagesBut why do we need sharding? Here are some advantages: Availability: Provides logical independence to the partitioned database, ensuring the high availability of our application. Here individual partitions can be managed independently. Scalability: Proves to increase scalability by distributing the data across multiple partitions. Security: Helps improve the system’s security by storing sensitive and non-sensitive data in different partitions. This could provide better manageability and security to sensitive data. Query Performance: Improves the performance of the system. Instead of querying the whole database, now the system has to query only a smaller partition. Data Manageability: Divides tables and indexes into smaller and more manageable units.Disadvantages Complexity: Sharding increases the complexity of the system in general. Joins across shards: Once a database is partitioned and spread across multiple machines it is often not feasible to perform joins that span multiple database shards. Such joins will not be performance efficient since data has to be retrieved from multiple servers. Rebalancing: If the data distribution is not uniform or there is a lot of load on a single shard, in such cases we have to rebalance our shards so that the requests are as equally distributed among the shards as possible.When to use sharding?Here are some reasons where sharding might be the right choice: Leveraging existing hardware instead of high-end machines. Maintain data in distinct geographic regions. Quickly scale by adding more shards. Better performance as each machine is under less load. When more concurrent connections are required.Consistent HashingLet’s first understand the problem we’re trying to solve.Why do we need this?In traditional hashing-based distribution methods, we use a hash function to hash our partition keys (i.e. request ID or IP). Then if we use the modulo against the total number of nodes (server or databases). This will give us the node where we want to route our request.\\[\\begin{align*}&amp; Hash(key_1) \\to H_1 \\bmod N = Node_0 \\\\&amp; Hash(key_2) \\to H_2 \\bmod N = Node_1 \\\\&amp; Hash(key_3) \\to H_3 \\bmod N = Node_2 \\\\&amp; ... \\\\&amp; Hash(key_n) \\to H_n \\bmod N = Node_{n-1}\\end{align*}\\]Where,key: Request ID or IP.H: Hash function result.N: Total number of nodes.Node: The node where the request will be routed.The problem with this is if we add or remove a node, it will cause N to change, meaning our mapping strategy will break as the same requests will now map to a different server. As a consequence, the majority of requests will need to be redistributed which is very inefficient.We want to uniformly distribute requests among different nodes such that we should be able to add or remove nodes with minimal effort. Hence, we need a distribution scheme that does not depend directly on the number of nodes (or servers), so that, when adding or removing nodes, the number of keys that need to be relocated is minimized.Consistent hashing solves this horizontal scalability problem by ensuring that every time we scale up or down, we do not have to re-arrange all the keys or touch all the servers.Now that we understand the problem, let’s discuss consistent hashing in detail.How does it workConsistent Hashing is a distributed hashing scheme that operates independently of the number of nodes in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.Using consistent hashing, only K/N data would require re-distributing.\\[R = K/N\\]Where,R: Data that would require re-distribution.K: Number of partition keys.N: Number of nodes.The output of the hash function is a range let’s say 0...m-1 which we can represent on our hash ring. We hash the requests and distribute them on the ring depending on what the output was. Similarly, we also hash the node and distribute them on the same ring as well.\\[\\begin{align*}&amp; Hash(key_1) = P_1 \\\\&amp; Hash(key_2) = P_2 \\\\&amp; Hash(key_3) = P_3 \\\\&amp; ... \\\\&amp; Hash(key_n) = P_{m-1}\\end{align*}\\]Where,key: Request/Node ID or IP.P: Position on the hash ring.m: Total range of the hash ring.Now, when the request comes in we can simply route it to the closest node in a clockwise (can be counterclockwise as well) manner. This means that if a new node is added or removed, we can use the nearest node and only a fraction of the requests need to be re-routed.In theory, consistent hashing should distribute the load evenly however it doesn’t happen in practice. Usually, the load distribution is uneven and one server may end up handling the majority of the request becoming a hotspot, essentially a bottleneck for the system. We can fix this by adding extra nodes but that can be expensive.Let’s see how we can address these issues.Virtual NodesIn order to ensure a more evenly distributed load, we can introduce the idea of a virtual node, sometimes also referred to as a VNode.Instead of assigning a single position to a node, the hash range is divided into multiple smaller ranges, and each physical node is assigned several of these smaller ranges. Each of these subranges is considered a VNode. Hence, virtual nodes are basically existing physical nodes mapped multiple times across the hash ring to minimize changes to a node’s assigned range.For this, we can use k number of hash functions.\\[\\begin{align*}&amp; Hash_1(key_1) = P_1 \\\\&amp; Hash_2(key_2) = P_2 \\\\&amp; Hash_3(key_3) = P_3 \\\\&amp; . . . \\\\&amp; Hash_k(key_n) = P_{m-1}\\end{align*}\\]Where,key: Request/Node ID or IP.k: Number of hash functions.P: Position on the hash ring.m: Total range of the hash ring.As VNodes help spread the load more evenly across the physical nodes on the cluster by diving the hash ranges into smaller subranges, this speeds up the re-balancing process after adding or removing nodes. This also helps us reduce the probability of hotspots.Data replicationTo ensure high availability and durability, consistent hashing replicates each data item on multiple N nodes in the system where the value N is equivalent to the replication factor.The replication factor is the number of nodes that will receive the copy of the same data. In eventually consistent systems, this is done asynchronously.AdvantagesLet’s look at some advantages of consistent hashing: Makes rapid scaling up and down more predictable. Facilitates partitioning and replication across nodes. Enables scalability and availability. Reduces hotspots.DisadvantagesBelow are some disadvantages of consistent hashing: Increases complexity. Cascading failures. Load distribution can still be uneven. Key management can be expensive when nodes transiently fail.ExamplesLet’s look at some examples where consistent hashing is used: Data partitioning in Apache Cassandra. Load distribution across multiple storage hosts in Amazon DynamoDB.Database FederationFederation (or functional partitioning) splits up databases by function. The federation architecture makes several distinct physical databases appear as one logical database to end-users.All of the components in a federation are tied together by one or more federal schemas that express the commonality of data throughout the federation. These federated schemas are used to specify the information that can be shared by the federation components and to provide a common basis for communication among them.Federation also provides a cohesive, unified view of data derived from multiple sources. The data sources for federated systems can include databases and various other forms of structured and unstructured data.CharacteristicsLet’s look at some key characteristics of a federated database: Transparency: Federated database masks user differences and implementations of underlying data sources. Therefore, the users do not need to be aware of where the data is stored. Heterogeneity: Data sources can differ in many ways. A federated database system can handle different hardware, network protocols, data models, etc. Extensibility: New sources may be needed to meet the changing needs of the business. A good federated database system needs to make it easy to add new sources. Autonomy: A Federated database does not change existing data sources, interfaces should remain the same. Data integration: A federated database can integrate data from different protocols, database management systems, etc.AdvantagesHere are some advantages of federated databases: Flexible data sharing. Autonomy among the database components. Access heterogeneous data in a unified way. No tight coupling of applications with legacy databases.DisadvantagesBelow are some disadvantages of federated databases: Adds more hardware and additional complexity. Joining data from two databases is complex. Dependence on autonomous data sources. Query performance and scalability.N-tier architectureN-tier architecture divides an application into logical layers and physical tiers. Layers are a way to separate responsibilities and manage dependencies. Each layer has a specific responsibility. A higher layer can use services in a lower layer, but not the other way around.Tiers are physically separated, running on separate machines. A tier can call to another tier directly, or use asynchronous messaging. Although each layer might be hosted in its own tier, that’s not required. Several layers might be hosted on the same tier. Physically separating the tiers improves scalability and resiliency and adds latency from the additional network communication.An N-tier architecture can be of two types: In a closed layer architecture, a layer can only call the next layer immediately down. In an open layer architecture, a layer can call any of the layers below it.A closed-layer architecture limits the dependencies between layers. However, it might create unnecessary network traffic, if one layer simply passes requests along to the next layer.Types of N-Tier architecturesLet’s look at some examples of N-Tier architecture:3-Tier architecture3-Tier is widely used and consists of the following different layers: Presentation layer: Handles user interactions with the application. Business Logic layer: Accepts the data from the application layer, validates it as per business logic and passes it to the data layer. Data Access layer: Receives the data from the business layer and performs the necessary operation on the database.2-Tier architectureIn this architecture, the presentation layer runs on the client and communicates with a data store. There is no business logic layer or immediate layer between client and server.Single Tier or 1-Tier architectureIt is the simplest one as it is equivalent to running the application on a personal computer. All of the required components for an application to run are on a single application or server.AdvantagesHere are some advantages of using N-tier architecture: Can improve availability. Better security as layers can behave like a firewall. Separate tiers allow us to scale them as needed. Improve maintenance as different people can manage different tiers.DisadvantagesBelow are some disadvantages of N-tier architecture: Increased complexity of the system as a whole. Increased network latency as the number of tiers increases. Expensive as every tier will have its own hardware cost. Difficult to manage network security.Message BrokersA message broker is a software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to “talk” with one another directly, even if they were written in different languages or implemented on different platforms.Message brokers can validate, store, route, and deliver messages to the appropriate destinations. They serve as intermediaries between other applications, allowing senders to issue messages without knowing where the receivers are, whether or not they are active, or how many of them there are. This facilitates the decoupling of processes and services within systems.ModelsMessage brokers offer two basic message distribution patterns or messaging styles: Point-to-Point messaging: This is the distribution pattern utilized in message queues with a one-to-one relationship between the message’s sender and receiver. Publish-subscribe messaging: In this message distribution pattern, often referred to as “pub/sub”, the producer of each message publishes it to a topic, and multiple message consumers subscribe to topics from which they want to receive messages.We will discuss these messaging patterns in detail in the later tutorials.Message brokers vs Event streamingMessage brokers can support two or more messaging patterns, including message queues and pub/sub, while event streaming platforms only offer pub/sub-style distribution patterns. Designed for use with high volumes of messages, event streaming platforms are readily scalable. They’re capable of ordering streams of records into categories called topics and storing them for a predetermined amount of time. Unlike message brokers, however, event streaming platforms cannot guarantee message delivery or track which consumers have received the messages.Event streaming platforms offer more scalability than message brokers but fewer features that ensure fault tolerance like message resending, as well as more limited message routing and queueing capabilities.Message brokers vs Enterprise Service Bus (ESB)Enterprise Service Bus (ESB) infrastructure is complex and can be challenging to integrate and expensive to maintain. It’s difficult to troubleshoot them when problems occur in production environments, they’re not easy to scale, and updating is tedious.Whereas message brokers are a “lightweight” alternative to ESBs that provide similar functionality, a mechanism for inter-service communication, at a lower cost. They’re well-suited for use in the microservices architectures that have become more prevalent as ESBs have fallen out of favor.ExamplesHere are some commonly used message brokers: NATS Apache Kafka RabbitMQ ActiveMQMessage QueuesA message queue is a form of service-to-service communication that facilitates asynchronous communication. It asynchronously receives messages from producers and sends them to consumers.Queues are used to effectively manage requests in large-scale distributed systems. In small systems with minimal processing loads and small databases, writes can be predictably fast. However, in more complex and large systems writes can take an almost non-deterministic amount of time.WorkingMessages are stored in the queue until they are processed and deleted. Each message is processed only once by a single consumer. Here’s how it works: A producer publishes a job to the queue, then notifies the user of the job status. A consumer picks up the job from the queue, processes it, then signals that the job is complete.AdvantagesLet’s discuss some advantages of using a message queue: Scalability: Message queues make it possible to scale precisely where we need to. When workloads peak, multiple instances of our application can all add requests to the queue without the risk of collision Decoupling: Message queues remove dependencies between components and significantly simplify the implementation of decoupled applications. Performance: Message queues enable asynchronous communication, which means that the endpoints that are producing and consuming messages interact with the queue, not each other. Producers can add requests to the queue without waiting for them to be processed. Reliability: Queues make our data persistent, and reduce the errors that happen when different parts of our system go offline.FeaturesNow, let’s discuss some desired features of message queues:Push or Pull DeliveryMost message queues provide both push and pull options for retrieving messages. Pull means continuously querying the queue for new messages. Push means that a consumer is notified when a message is available. We can also use long-polling to allow pulls to wait a specified amount of time for new messages to arrive.FIFO (First-In-First-Out) QueuesIn these queues, the oldest (or first) entry, sometimes called the “head” of the queue, is processed first.Schedule or Delay DeliveryMany message queues support setting a specific delivery time for a message. If we need to have a common delay for all messages, we can set up a delay queue.At-Least-Once DeliveryMessage queues may store multiple copies of messages for redundancy and high availability, and resend messages in the event of communication failures or errors to ensure they are delivered at least once.Exactly-Once DeliveryWhen duplicates can’t be tolerated, FIFO (first-in-first-out) message queues will make sure that each message is delivered exactly once (and only once) by filtering out duplicates automatically.Dead-letter QueuesA dead-letter queue is a queue to which other queues can send messages that can’t be processed successfully. This makes it easy to set them aside for further inspection without blocking the queue processing or spending CPU cycles on a message that might never be consumed successfully.OrderingMost message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they’re sent and that a message is delivered at least once.Poison-pill MessagesPoison pills are special messages that can be received, but not processed. They are a mechanism used in order to signal a consumer to end its work so it is no longer waiting for new inputs, and are similar to closing a socket in a client/server model.SecurityMessage queues will authenticate applications that try to access the queue, this allows us to encrypt messages over the network as well as in the queue itself.Task QueuesTasks queues receive tasks and their related data, run them, then deliver their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.BackpressureIf queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. Backpressure can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with exponential backoff strategy.ExamplesFollowing are some widely used message queues: Amazon SQS RabbitMQ ActiveMQ ZeroMQPublish-SubscribeSimilar to a message queue, publish-subscribe is also a form of service-to-service communication that facilitates asynchronous communication. In a pub/sub model, any message published to a topic is pushed immediately to all the subscribers of the topic.The subscribers to the message topic often perform different functions, and can each do something different with the message in parallel. The publisher doesn’t need to know who is using the information that it is broadcasting, and the subscribers don’t need to know where the message comes from. This style of messaging is a bit different than message queues, where the component that sends the message often knows the destination it is sending to.WorkingUnlike message queues, which batch messages until they are retrieved, message topics transfer messages with little or no queuing and push them out immediately to all subscribers. Here’s how it works: A message topic provides a lightweight mechanism to broadcast asynchronous event notifications and endpoints that allow software components to connect to the topic in order to send and receive those messages. To broadcast a message, a component called a publisher simply pushes a message to the topic. All components that subscribe to the topic (known as subscribers) will receive every message that was broadcasted.AdvantagesLet’s discuss some advantages of using publish-subscribe: Eliminate Polling: Message topics allow instantaneous, push-based delivery, eliminating the need for message consumers to periodically check or “poll” for new information and updates. This promotes faster response time and reduces the delivery latency which can be particularly problematic in systems where delays cannot be tolerated. Dynamic Targeting: Pub/Sub makes the discovery of services easier, more natural, and less error-prone. Instead of maintaining a roster of peers where an application can send messages, a publisher will simply post messages to a topic. Then, any interested party will subscribe its endpoint to the topic, and start receiving these messages. Subscribers can change, upgrade, multiply or disappear and the system dynamically adjusts. Decoupled and Independent Scaling: Publishers and subscribers are decoupled and work independently from each other, which allows us to develop and scale them independently. Simplify Communication: The Publish-Subscribe model reduces complexity by removing all the point-to-point connections with a single connection to a message topic, which will manage subscriptions and decide what messages should be delivered to which endpoints.FeaturesNow, let’s discuss some desired features of publish-subscribe:Push DeliveryPub/Sub messaging instantly pushes asynchronous event notifications when messages are published to the message topic. Subscribers are notified when a message is available.Multiple Delivery ProtocolsIn the Publish-Subscribe model, topics can typically connect to multiple types of endpoints, such as message queues, serverless functions, HTTP servers, etc.FanoutThis scenario happens when a message is sent to a topic and then replicated and pushed to multiple endpoints. Fanout provides asynchronous event notifications which in turn allows for parallel processing.FilteringThis feature empowers the subscriber to create a message filtering policy so that it will only get the notifications it is interested in, as opposed to receiving every single message posted to the topic.DurabilityPub/Sub messaging services often provide very high durability, and at least once delivery, by storing copies of the same message on multiple servers.SecurityMessage topics authenticate applications that try to publish content, this allows us to use encrypted endpoints and encrypt messages in transit over the network.ExamplesHere are some technologies commonly used for publish-subscribe: Amazon SNS Google Pub/SubEnterprise Service Bus (ESB)An Enterprise Service Bus (ESB) is an architectural pattern whereby a centralized software component performs integrations between applications. It performs transformations of data models, handles connectivity, performs message routing, converts communication protocols, and potentially manages the composition of multiple requests. The ESB can make these integrations and transformations available as a service interface for reuse by new applications.AdvantagesIn theory, a centralized ESB offers the potential to standardize and dramatically simplify communication, messaging, and integration between services across the enterprise. Here are some advantages of using an ESB: Improved developer productivity: Enables developers to incorporate new technologies into one part of an application without touching the rest of the application. Simpler, more cost-effective scalability: Components can be scaled independently of others. Greater resilience: Failure of one component does not impact the others, and each microservice can adhere to its own availability requirements without risking the availability of other components in the system.DisadvantagesWhile ESBs were deployed successfully in many organizations, in many other organizations the ESB came to be seen as a bottleneck. Here are some disadvantages of using an ESB: Making changes or enhancements to one integration could destabilize others who use that same integration. A single point of failure can bring down all communications. Updates to the ESB often impact existing integrations, so there is significant testing required to perform any update. ESB is centrally managed which makes cross-team collaboration challenging. High configuration and maintenance complexity.ExamplesBelow are some widely used Enterprise Service Bus (ESB) technologies: Azure Service Bus IBM App Connect Apache Camel Fuse ESBMonoliths and MicroservicesMonolithsA monolith is a self-contained and independent application. It is built as a single unit and is responsible for not just a particular task, but can perform every step needed to satisfy a business need.AdvantagesFollowing are some advantages of monoliths: Simple to develop or debug. Fast and reliable communication. Easy monitoring and testing. Supports ACID transactions.DisadvantagesSome common disadvantages of monoliths are: Maintenance becomes hard as the codebase grows. Tightly coupled application, hard to extend. Requires commitment to a particular technology stack. On each update, the entire application is redeployed. Reduced reliability as a single bug can bring down the entire system. Difficult to scale or adopt technologies new technologies.Modular monolithsA Modular Monolith is an approach where we build and deploy a single application (that’s the Monolith part), but we build it in a way that breaks up the code into independent modules for each of the features needed in our application.This approach reduces the dependencies of a module in such as way that we can enhance or change a module without affecting other modules. When done right, this can be really beneficial in the long term as it reduces the complexity that comes with maintaining a monolith as the system grows.MicroservicesA microservices architecture consists of a collection of small, autonomous services where each service is self-contained and should implement a single business capability within a bounded context. A bounded context is a natural division of business logic that provides an explicit boundary within which a domain model exists.Each service has a separate codebase, which can be managed by a small development team. Services can be deployed independently and a team can update an existing service without rebuilding and redeploying the entire application.Services are responsible for persisting their own data or external state (database per service). This differs from the traditional model, where a separate data layer handles data persistence.CharacteristicsThe microservices architecture style has the following characteristics: Loosely coupled: Services should be loosely coupled so that they can be independently deployed and scaled. This will lead to the decentralization of development teams and thus, enabling them to develop and deploy faster with minimal constraints and operational dependencies. Small but focused: It’s about scope and responsibilities and not size, a service should be focused on a specific problem. Basically, “It does one thing and does it well”. Ideally, they can be independent of the underlying architecture. Built for businesses: The microservices architecture is usually organized around business capabilities and priorities. Resilience &amp; Fault tolerance: Services should be designed in such a way that they still function in case of failure or errors. In environments with independently deployable services, failure tolerance is of the highest importance. Highly maintainable: Service should be easy to maintainable and test because services that cannot be maintained will be re-written.AdvantagesHere are some advantages of microservices architecture: Loosely coupled services. Services can be deployed independently. Highly agile for multiple development teams. Improves fault tolerance and data isolation. Better scalability as each service can be scaled independently. Eliminates any long-term commitment to a particular technology stack.DisadvantagesMicroservices architecture brings its own set of challenges: Complexity of a distributed system. Testing is more difficult. Expensive to maintain (individual servers, databases, etc.). Inter-service communication has its own challenges. Data integrity and consistency. Network congestion and latency.Best practicesLet’s discuss some microservices best practices: Model services around the business domain. Services should have loose coupling and high functional cohesion. Isolate failures and use resiliency strategies to prevent failures within a service from cascading. Services should only communicate through well-designed APIs. Avoid leaking implementation details. Data storage should be private to the service that owns the data Avoid coupling between services. Causes of coupling include shared database schemas and rigid communication protocols. Decentralize everything. Individual teams are responsible for designing and building services. Avoid sharing code or data schemas. Fail fast by using a circuit breaker to achieve fault tolerance. Ensure that the API changes are backward compatible.PitfallsBelow are some common pitfalls of microservices architecture: Service boundaries are not based on the business domain. Underestimating how hard is to build a distributed system. Shared database or common dependencies between services. Lack of Business Alignment. Lack of clear ownership. Lack of idempotency. Trying to do everything ACID instead of BASE. Lack of design for fault tolerance may result in cascading failures.Beware of the distributed monolithDistributed Monolith is a system that resembles the microservices architecture but is tightly coupled within itself like a monolithic application. Adopting microservices architecture comes with a lot of advantages. But while making one, there are good chances that we might end up with a distributed monolith.Our microservices are just a distributed monolith if any of these apply to it: Requires low latency communication. Services don’t scale easily. Dependency between services. Sharing the same resources such as databases. Tightly coupled systems.One of the primary reasons to build an application using microservices architecture is to have scalability. Therefore, microservices should have loosely coupled services which enable every service to be independent. The distributed monolith architecture takes this away and causes most components to depend on one another, increasing design complexity.Microservices vs Service-oriented architecture (SOA)You might have seen Service-oriented architecture (SOA) mentioned around the internet, sometimes even interchangeably with microservices, but they are different from each other and the main distinction between the two approaches comes down to scope.Service-oriented architecture (SOA) defines a way to make software components reusable via service interfaces. These interfaces utilize common communication standards and focus on maximizing application service reusability whereas microservices are built as a collection of various smallest independent service units focused on team autonomy and decoupling.Why you don’t need microservicesSo, you might be wondering, monoliths seem like a bad idea to begin with, why would anyone use that?Well, it depends. While each approach has its own advantages and disadvantages, it is advised to start with a monolith when building a new system. It is important to understand, that microservices are not a silver bullet instead they solve an organizational problem. Microservices architecture is about your organizational priorities and team as much as it’s about technology.Before making the decision to move to microservices architecture, you need to ask yourself questions like: “Is the team too large to work effectively on a shared codebase?” “Are teams blocked on other teams?” “Does microservices deliver clear business value for us?” “Is my business mature enough to use microservices?” “Is our current architecture limiting us with communication overhead?”If your application does not require to be broken down into microservices, you don’t need this. There is no absolute necessity that all applications should be broken down into microservices.We frequently draw inspiration from companies such as Netflix and their use of microservices, but we overlook the fact that we are not Netflix. They went through a lot of iterations and models before they had a market-ready solution, and this architecture became acceptable for them when they identified and solved the problem they were trying to tackle.That’s why it’s essential to understand in-depth if your business actually needs microservices. What I’m trying to say is microservices are solutions to complex concerns and if your business doesn’t have complex issues, you don’t need them.Event-Driven Architecture (EDA)Event-Driven Architecture (EDA) is about using events as a way to communicate within a system. Generally, leveraging a message broker to publish and consume events asynchronously. The publisher is unaware of who is consuming an event and the consumers are unaware of each other. Event-Driven Architecture is simply a way of achieving loose coupling between services within a system.What is an event?An event is a data point that represents state changes in a system. It doesn’t specify what should happen and how the change should modify the system, it only notifies the system of a particular state change. When a user makes an action, they trigger an event.ComponentsEvent-driven architectures have three key components: Event producers: Publishes an event to the router. Event routers: Filters and pushes the events to consumers. Event consumers: Uses events to reflect changes in the system.Note: Dots in the diagram represents different events in the system.PatternsThere are several ways to implement the event-driven architecture, and which method we use depends on the use case but here are some common examples: Sagas Publish-Subscribe Event Sourcing Command and Query Responsibility Segregation (CQRS)Note: Each of these methods is discussed separately.AdvantagesLet’s discuss some advantages: Decoupled producers and consumers. Highly scalable and distributed. Easy to add new consumers. Improves agility.ChallengesHere are some challenges of event-drive architecture: Guaranteed delivery. Error handling is difficult. Event-driven systems are complex in general. Exactly once, in-order processing of events.Use casesBelow are some common use cases where event-driven architectures are beneficial: Metadata and metrics. Server and security logs. Integrating heterogeneous systems. Fanout and parallel processing.ExamplesHere are some widely used technologies for implementing event-driven architectures: NATS Apache Kafka Amazon EventBridge Amazon SNS Google PubSubEvent SourcingInstead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects.This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.Event sourcing vs Event-Driven Architecture (EDA)Event sourcing is seemingly constantly being confused with Event-driven Architecture (EDA). Event-driven architecture is about using events to communicate between service boundaries. Generally, leveraging a message broker to publish and consume events asynchronously within other boundaries.Whereas, event sourcing is about using events as a state, which is a different approach to storing data. Rather than storing the current state, we’re instead going to be storing events. Also, event sourcing is one of the several patterns to implement an event-driven architecture.AdvantagesLet’s discuss some advantages of using event sourcing: Excellent for real-time data reporting. Great for fail-safety, data can be reconstituted from the event store. Extremely flexible, any type of message can be stored. Preferred way of achieving audit logs functionality for high compliance systems.DisadvantagesFollowing are the disadvantages of event sourcing: Requires an extremely efficient network infrastructure. Requires a reliable way to control message formats, such as a schema registry. Different events will contain different payloads.Command and Query Responsibility Segregation (CQRS)Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system’s actions into commands and queries. It was first described by Greg Young.In CQRS, a command is an instruction, a directive to perform a specific task. It is an intention to change something and doesn’t return a value, only an indication of success or failure. And, a query is a request for information that doesn’t change the system’s state or cause any side effects.The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.CQRS with Event SourcingThe CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.AdvantagesLet’s discuss some advantages of CQRS: Allows independent scaling of read and write workloads. Easier scaling, optimizations, and architectural changes. Closer to business logic with loose coupling. The application can avoid complex joins when querying. Clear boundaries between the system behavior.DisadvantagesBelow are some disadvantages of CQRS: More complex application design. Message failures or duplicate messages can occur. Dealing with eventual consistency is a challenge. Increased system maintenance efforts.Use casesHere are some scenarios where CQRS will be helpful: The performance of data reads must be fine-tuned separately from the performance of data writes. The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly. Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn’t affect the availability of the others. Better security to ensure that only the right domain entities are performing writes on the data.API GatewayThe API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.Why do we need an API Gateway?The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management.FeaturesBelow are some desired features of an API Gateway: Authentication and Authorization Service discovery Reverse Proxy Caching Security Retry and Circuit breaking Load balancing Logging, Tracing API composition Rate limiting and throttling Versioning Routing IP whitelisting or blacklistingAdvantagesLet’s look at some advantages of using an API Gateway: Encapsulates the internal structure of an API. Provides a centralized view of the API. Simplifies the client code. Monitoring, analytics, tracing, and other such features.DisadvantagesHere are some possible disadvantages of an API Gateway: Possible single point of failure. Might impact performance. Can become a bottleneck if not scaled properly. Configuration can be challenging.Backend For Frontend (BFF) patternIn the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by Sam Newman.Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.GraphQL performs really well as a backend for frontend (BFF).When to use this pattern?We should consider using a Backend For Frontend (BFF) pattern when: A shared or general purpose backend service must be maintained with significant development overhead. We want to optimize the backend for the requirements of a specific client. Customizations are made to a general-purpose backend to accommodate multiple interfaces.ExamplesFollowing are some widely used gateways technologies: Amazon API Gateway Apigee API Gateway Azure API Gateway Kong API GatewayREST, GraphQL, gRPCA good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC.What’s an API?Before we even get into API technologies, let’s first understand what is an API.An API is a set of definitions and protocols for building and integrating application software. It’s sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.RESTA REST API (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by Roy Fielding in the year 2000.In REST API, the fundamental unit is a resource.ConceptsLet’s discuss some concepts of a RESTful API.ConstraintsIn order for an API to be considered RESTful, it has to conform to these architectural constraints: Uniform Interface: There should be a uniform way of interacting with a given server. Client-Server: A client-server architecture managed through HTTP. Stateless: No client context shall be stored on the server between requests. Cacheable: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side. Layered system: An application architecture needs to be composed of multiple layers. Code on demand: Return executable code to support a part of your application. (optional)HTTP VerbsHTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs. Each of them implements a different semantic, but some common features are shared by a group of them.Below are some commonly used HTTP verbs: GET: Request a representation of the specified resource. HEAD: Response is identical to a GET request, but without the response body. POST: Submits an entity to the specified resource, often causing a change in state or side effects on the server. PUT: Replaces all current representations of the target resource with the request payload. DELETE: Deletes the specified resource. PATCH: Applies partial modifications to a resource.HTTP response codesHTTP response status codes indicate whether a specific HTTP request has been successfully completed.There are five classes defined by the standard: 1xx - Informational responses. 2xx - Successful responses. 3xx - Redirection responses. 4xx - Client error responses. 5xx - Server error responses.For example, HTTP 200 means that the request was successful.AdvantagesLet’s discuss some advantages of REST API: Simple and easy to understand. Flexible and portable. Good caching support. Client and server are decoupled.DisadvantagesLet’s discuss some disadvantages of REST API: Over-fetching of data. Sometimes multiple round trips to the server are required.Use casesREST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios.ExampleHere’s an example usage of a REST API that operates on a users resource. URI HTTP verb Description /users GET Get all users /users/{id} GET Get a user by id /users POST Add a new user /users/{id} PATCH Update a user by id /users/{id} DELETE Delete a user by id There is so much more to learn when it comes to REST APIs, I will highly recommend looking into Hypermedia as the Engine of Application State (HATEOAS).GraphQLGraphQL is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by Facebook and later open-sourced in 2015.GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.In GraphQL, the fundamental unit is a query.ConceptsLet’s briefly discuss some key concepts in GraphQL:SchemaA GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.QueriesA query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a mutation which provides a way to modify server-side data.ResolversResolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.AdvantagesLet’s discuss some advantages of GraphQL: Eliminates over-fetching of data. Strongly defined schema. Code generation support. Payload optimization.DisadvantagesLet’s discuss some disadvantages of GraphQL: Shifts complexity to server-side. Caching becomes hard. Versioning is ambiguous. N+1 problem.Use casesGraphQL proves to be essential in the following scenarios: Reducing app bandwidth usage as we can query multiple resources in a single query. Rapid prototyping for complex systems. When we are working with a graph-like data model.ExampleHere’s a GraphQL schema that defines a User type and a Query type.type Query { getUser: User}type User { id: ID name: String city: String state: String}Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.{ getUser { id name city }}This will give the following response to the client.{ \"getUser\": { \"id\": 123, \"name\": \"Karan\", \"city\": \"San Francisco\" }}Learn more about GraphQL at graphql.org.gRPCgRPC is a modern open-source high-performance Remote Procedure Call (RPC) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more.ConceptsLet’s discuss some key concepts of gRPC.Protocol buffersProtocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It’s like JSON, except it’s smaller and faster, and it generates native language bindings.Service definitionLike many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the Interface Definition Language (IDL) for describing both the service interface and the structure of the payload messages.AdvantagesLet’s discuss some advantages of gRPC: Lightweight and efficient. High performance. Built-in code generation support. Bi-directional streaming.DisadvantagesLet’s discuss some disadvantages of gRPC: Relatively new compared to REST and GraphQL. Limited browser support. Steeper learning curve. Not human readable.Use casesBelow are some good use cases for gRPC: Real-time communication via bi-directional streaming. Efficient inter-service communication in microservices. Low latency and high throughput communication. Polyglot environments.ExampleHere’s a basic example of a gRPC service defined in a *.proto file. Using this definition, we can easily code generate the HelloService service in the programming language of our choice.service HelloService { rpc SayHello (HelloRequest) returns (HelloResponse);}message HelloRequest { string greeting = 1;}message HelloResponse { string reply = 1;}REST vs GraphQL vs gRPCNow that we know how these API designing techniques work, let’s compare them based on the following parameters: Will it cause tight coupling? How chatty (distinct API calls to get needed information) are the APIs? What’s the performance like? How complex is it to integrate? How well does the caching work? Built-in tooling and code generation? What’s API discoverability like? How easy is it to version APIs? Type Coupling Chattiness Performance Complexity Caching Codegen Discoverability Versioning REST Low High Good Medium Great Bad Good Easy GraphQL Medium Low Good High Custom Good Good Custom gRPC High Medium Great Low Custom Great Bad Hard Which API technology is better?Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API.Long polling, WebSockets, Server-Sent Events (SSE)Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let’s discuss some approaches to overcome this problem.Long pollingHTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.WorkingLet’s understand how long polling works: The client makes an initial request and waits for a response. The server receives the request and delays sending anything until an update is available. Once an update is available, the response is sent to the client. The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.AdvantagesHere are some advantages of long polling: Easy to implement, good for small-scale projects. Nearly universally supported.DisadvantagesA major downside of long polling is that it is usually not scalable. Below are some of the other reasons: Creates a new connection each time, which can be intensive on the server. Reliable message ordering can be an issue for multiple requests. Increased latency as the server needs to wait for a new request.WebSocketsWebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.WorkingLet’s understand how WebSockets work: The client initiates a WebSocket handshake process by sending a request. The request also contains an HTTP Upgrade header that allows the request to switch to the WebSocket protocol (ws://). The server sends a response to the client, acknowledging the WebSocket handshake request. A WebSocket connection will be opened once the client receives a successful handshake response. Now the client and server can start sending data in both directions allowing real-time communication. The connection is closed once the server or the client decides to close the connection.AdvantagesBelow are some advantages of WebSockets: Full-duplex asynchronous messaging. Better origin-based security model. Lightweight for both client and server.DisadvantagesLet’s discuss some disadvantages of WebSockets: Terminated connections aren’t automatically recovered. Older browsers don’t support WebSockets (becoming less relevant).Server-Sent Events (SSE)Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.WorkingLet’s understand how server-sent events work: The client makes a request to the server. The connection between client and server is established and it remains open. The server sends responses or events to the client when new data is available.Advantages Simple to implement and use for both client and server. Supported by most browsers. No trouble with firewalls.Disadvantages Unidirectional nature can be limiting. Limitation for the maximum number of open connections. Does not support binary data.Geohashing and QuadtreesGeohashingGeohashing is a geocoding method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by Gustavo Niemeyer in 2008.For example, San Francisco with coordinates 37.7564, -122.4016 can be represented in geohash as 9q8yy9mf.How does Geohashing work?Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes 9q8yy9mf and 9q8yy9vx are spatially closer as they share the prefix 9q8yy9.Geohashing can also be used to provide a degree of anonymity as we don’t need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.The cell sizes of the geohashes of different lengths are as follows: Geohash length Cell width Cell height 1 5000 km 5000 km 2 1250 km 1250 km 3 156 km 156 km 4 39.1 km 19.5 km 5 4.89 km 4.89 km 6 1.22 km 0.61 km 7 153 m 153 m 8 38.2 m 19.1 m 9 4.77 m 4.77 m 10 1.19 m 0.596 m 11 149 mm 149 mm 12 37.2 mm 18.6 mm Use casesHere are some common use cases for Geohashing: It is a simple way to represent and store a location in a database. It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes. We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.ExamplesGeohashing is widely used and it is supported by popular databases. MySQL Redis Amazon DynamoDB Google Cloud FirestoreQuadtreesA quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of Octrees which are used to partition three-dimensional space.Types of QuadtreesQuadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees: Point quadtrees Point-region (PR) quadtrees Polygonal map (PM) quadtrees Compressed quadtrees Edge quadtreesWhy do we need Quadtrees?Aren’t latitude and longitude enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using euclidean distance, for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the Hilbert curve, we can easily improve range query performance.Use casesBelow are some common uses of quadtrees: Image representation, processing, and compression. Spacial indexing and range queries. Location-based services like Google Maps, Uber, etc. Mesh generation and computer graphics. Sparse data storage.Circuit breakerThe circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we’ll also want some kind of monitor alert if the circuit breaker trips.Why do we need circuit breaking?It’s common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What’s worse if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems.StatesLet’s discuss circuit breaker states:ClosedWhen everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state.OpenIn this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified.Half-openIn this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state.Rate LimitingRate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.Why do we need Rate Limiting?Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following: Avoid resource starvation as a result of Denial of Service (DoS) attacks. Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills. Rate limiting can be used as defense or mitigation against some common attacks. For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.AlgorithmsThere are various algorithms for API rate limiting, each with its advantages and disadvantages. Let’s briefly discuss some of these algorithms:Leaky BucketLeaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked).Token BucketHere we use a concept of a bucket. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period.Fixed WindowThe system uses a window size of n seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold.Sliding LogSliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.Sliding WindowSliding Window is a hybrid approach that combines the fixed window algorithm’s low processing cost and the sliding log’s improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window’s request rate based on the current timestamp to smooth out bursts of traffic.Rate Limiting in Distributed SystemsRate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:InconsistenciesWhen using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like Redis but this will increase latency and cause race conditions.Race ConditionsThis issue happens when we use a naive “get-then-set” approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model’s problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a “set-then-get” approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.Service DiscoveryService discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.Why do we need Service Discovery?In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.ImplementationsThere are two main service discovery patterns:Client-side discoveryIn this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.Server-side discoveryIn this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.Service RegistryA service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.Service RegistrationWe also need a way to obtain service information, often known as service registration. Let’s look at two possible service registration approaches:Self-RegistrationWhen using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive.Third-party RegistrationThe registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.Service meshService-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. Istio and envoy are some of the most commonly used service mesh technologies.ExamplesHere are some commonly used service discovery infrastructure tools: etcd Consul Apache Thrift Apache ZookeeperSLA, SLO, SLILet’s briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.Why are they important?SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.SLAAn SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.SLAs are often written by a company’s business or legal team.SLOAn SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.SLIAn SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI’s value must always meet or exceed the value determined by the SLO.Disaster recoveryDisaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.Disaster Recovery is often not actively discussed during system design interviews but it’s important to have some basic understanding of this topic. You can learn more about disaster recovery from AWS Well-Architected Framework.Why is disaster recovery important?Disaster recovery can have the following benefits: Minimize interruption and downtime Limit damages Fast restoration Better customer retentionTermsLet’s discuss some important terms relevantly for disaster recovery:RTORecovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.RPORecovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.StrategiesA variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.Back-upThis is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.Cold SiteIn this type of disaster recovery, an organization sets up basic infrastructure in a second site.Hot siteA hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.Virtual Machines (VMs) and ContainersBefore we discuss virtualization vs containerization, let’s learn what are virtual machines (VMs) and Containers.Virtual Machines (VM)A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine’s resources from the hardware and provisions them appropriately so they can be used by the VM.VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.What is a Hypervisor?A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.Why use a Virtual Machine?Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won’t interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.ContainersA container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.Why do we need containers?Let’s discuss some advantages of using containers:Separation of responsibilityContainerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.Workload portabilityContainers can run virtually anywhere, greatly easing development and deployment.Application isolationContainers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.Agile developmentContainers allow developers to move much more quickly by avoiding concerns about dependencies and environments.Efficient operationsContainers are lightweight and allow us to use just the computing resources we need.Virtualization vs ContainerizationIn traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.OAuth 2.0 and OpenID Connect (OIDC)OAuth 2.0OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user’s credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user’s data.ConceptsThe OAuth 2.0 protocol defines the following entities: Resource Owner: The user or system that owns the protected resources and can grant access to them. Client: The client is the system that requires access to the protected resources. Authorization Server: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner. Resource Server: A server that protects the user’s resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources. Scopes: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server. Access Token: A piece of data that represents the authorization to access resources on behalf of the end-user.How does OAuth 2.0 work?Let’s learn how OAuth 2.0 works: The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code. The Authorization Server authenticates the client and verifies that the requested scopes are permitted. The resource owner interacts with the authorization server to grant access. The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned. With the Access Token, the client can request access to the resource from the Resource Server.DisadvantagesHere are the most common disadvantages of OAuth 2.0: Lacks built-in security features. No standard implementation. No common set of scopes.OpenID ConnectOAuth 2.0 is designed only for authorization, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.When an Authorization Server supports OIDC, it is sometimes called an identity provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.ConceptsThe OpenID Connect (OIDC) protocol defines the following entities: Relying Party: The current application. OpenID Provider: This is essentially an intermediate service that provides a one-time code to the Relying Party. Token Endpoint: A web server that accepts the One-Time Code (OTC) and provides an access code that’s valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT). UserInfo Endpoint: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-userBoth OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.Single Sign-On (SSO)Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.ComponentsLet’s discuss some key components of Single Sign-On (SSO).Identity Provider (IdP)User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user’s identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.Service ProviderA service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.Identity BrokerAn identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.SAMLSecurity Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.How does SSO work?Now, let’s discuss how Single Sign-On works: The user requests a resource from their desired application. The application redirects the user to the Identity Provider (IdP) for authentication. The user signs in with their credentials (usually, username and password). Identity Provider (IdP) sends a Single Sign-On response back to the client application. The application grants access to the user.SAML vs OAuth 2.0 and OpenID Connect (OIDC)There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience.AdvantagesFollowing are the benefits of using Single Sign-On: Ease of use as users only need to remember one set of credentials. Ease of access without having to go through a lengthy authorization process. Enforced security and compliance to protect sensitive data. Simplifying the management with reduced IT support cost and admin time.DisadvantagesHere are some disadvantages of Single Sign-On: Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised. The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.ExamplesThese are some commonly used Identity Providers (IdP): Okta Google Auth0 OneLoginSSL, TLS, mTLSLet’s briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a “big picture” system design perspective, this topic is not very important but still good to know about.SSLSSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).Why is it called an SSL certificate if it is deprecated?Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.Why was SSL so important?Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.TLSTransport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.There are three main components to what the TLS protocol accomplishes: Encryption: hides the data being transferred from third parties. Authentication: ensures that the parties exchanging information are who they claim to be. Integrity: verifies that the data has not been forged or tampered with.mTLSMutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.Why use mTLS?mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization’s network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.Nowadays, mTLS is commonly used by microservices or distributed systems in a zero trust security model to verify each other.System Design InterviewsSystem design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they’re not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.Expectations are quite different at different engineering levels as well. Because someone with a lot of practical experience will approach it quite differently from someone who’s new in the industry. As a result, it’s hard to come up with a single strategy that will help us stay organized during the interview.Let’s look at some common strategies for the system design interviews:Requirements clarificationsSystem design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:Functional requirementsThese are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.For example: “What are the features that we need to design for this system?” “What are the edge cases we need to consider, if any, in our design?”Non-functional requirementsThese are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.For example: “Each request should be processed with the minimum latency” “System should be highly available”Extended requirementsThese are basically “nice to have” requirements that might be out of the scope of the system.For example: “Our system should record metrics and analytics” “Service health and performance monitoring?”Estimation and ConstraintsEstimate the scale of the system we’re going to design. It is important to ask questions such as: “What is the desired scale that this system will need to handle?” “What is the read/write ratio of our system?” “How many requests per second?” “How much storage will be needed?”These questions will help us scale our design later.Data model designOnce we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them. “What are the different entities in the system?” “What are the relationships between these entities?” “How many tables do we need?” “Is NoSQL a better choice here?”API designNext, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don’t have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.For example:createUser(name: string, email: string): UserIt is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.High-level component designNow we have established our data model and API design, it’s time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system. “Is it best to design a monolithic or a microservices architecture?” “What type of database should we use?”Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client’s perspective.Detailed designNow it’s time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional. “How should we partition our data?” “What about load distribution?” “Should we use cache?” “How will we handle a sudden spike in traffic?”Also, try not to be too opinionated about certain technologies, statements like “I believe that NoSQL databases are just better, SQL databases are not scalable” reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.Identify and resolve bottlenecksFinally, it’s time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask: “Do we have enough database replicas?” “Is there any single point of failure?” “Is database sharding required?” “How can we make our system more robust?” “How to improve the availability of our cache?”Make sure to read the engineering blog of the company you’re interviewing with. This will help you get a sense of what technology stack they’re using and which problems are important to them.URL ShortenerLet’s design a URL shortener, similar to services like Bitly, TinyURL.What is a URL Shortener?A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.For example, the following long URL can be changed to a shorter URL.Long URL: https://karanpratapsingh.com/courses/system-design/url-shortenerShort URL: https://bit.ly/3I71d3oWhy do we need a URL shortener?URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.RequirementsOur URL shortening system should meet the following requirements:Functional requirements Given a URL, our service should generate a shorter and unique alias for it. Users should be redirected to the original URL when they visit the short link. Links should expire after a default timespan.Non-functional requirements High availability with minimal latency. The system should be scalable and efficient.Extended requirements Prevent abuse of services. Record analytics and metrics for redirections.Estimation and ConstraintsLet’s start with the estimation and constraints.Note: Make sure to check any scale or traffic related assumptions with your interviewer.TrafficThis will be a read-heavy system, so let’s assume a 100:1 read/write ratio with 100 million links generated per month.Reads/Writes Per monthFor reads per month:\\[100 \\times 100 \\space million = 10 \\space billion/month\\]Similarly for writes:\\[1 \\times 100 \\space million = 100 \\space million/month\\]What would be Requests Per Second (RPS) for our system?100 million requests per month translate into 40 requests per second.\\[\\frac{100 \\space million}{(30 \\space days \\times 24 \\space hrs \\times 3600 \\space seconds)} = \\sim 40 \\space URLs/second\\]And with a 100:1 read/write ratio, the number of redirections will be:\\[100 \\times 40 \\space URLs/second = 4000 \\space requests/second\\]BandwidthSince we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for then write requests would be:\\[40 \\times 500 \\space bytes = 20 \\space KB/second\\]Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:\\[4000 \\space URLs/second \\times 500 \\space bytes = \\sim 2 \\space MB/second\\]StorageFor storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:\\[100 \\space million \\times 10\\space years \\times 12 \\space months = 12 \\space billion\\]Like earlier, if we assume each stored recorded will be approximately 500 bytes. We will need around 6TB of storage:\\[12 \\space billion \\times 500 \\space bytes = 6 \\space TB\\]CacheFor caching, we will follow the classic Pareto principle also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.Since we get around 4K read or redirection requests each second. This translates into 350M requests per day.\\[4000 \\space URLs/second \\times 24 \\space hours \\times 3600 \\space seconds = \\sim 350 \\space million \\space requests/day\\]Hence, we will need around 35GB of memory per day.\\[20 \\space percent \\times 350 \\space million \\times 500 \\space bytes = 35 \\space GB/day\\]High-level estimateHere is our high-level estimate: Type Estimate Writes (New URLs) 40/s Reads (Redirection) 4K/s Bandwidth (Incoming) 20 KB/s Bandwidth (Outgoing) 2 MB/s Storage (10 years) 6 TB Memory (Caching) ~35 GB/day Data model designNext, we will focus on the data model design. Here is our database schema:Initially, we can get started with just two tables:usersStores user’s details such as name, email, createdAt, etc.urlsContains the new short URL’s properties such as expiration, hash, originalURL, and userID of the user who created the short URL. We can also use the hash column as an index to improve the query performance.What kind of database should we use?Since the data is not strongly relational, NoSQL databases such as Amazon DynamoDB, Apache Cassandra, or MongoDB will be a better choice here, if we do decide to use an SQL database then we can use something like Azure SQL Database or Amazon RDS.For more details, refer to SQL vs NoSQL.API designLet us do a basic API design for our services:Create URLThis API should create a new short URL in our system given an original URL.createURL(apiKey: string, originalURL: string, expiration?: Date): stringParametersAPI Key (string): API key provided by the user.Original Url (string): Original URL to be shortened.Expiration (Date): Expiration date of the new URL (optional).ReturnsShort URL (string): New shortened URL.Get URLThis API should retrieve the original URL from a given short URL.getURL(apiKey: string, shortURL: string): stringParametersAPI Key (string): API key provided by the user.Short Url (string): Short URL mapped to the original URL.ReturnsOriginal URL (string): Original URL to be retrieved.Delete URLThis API should delete a given shortURL from our system.deleteURL(apiKey: string, shortURL: string): booleanParametersAPI Key (string): API key provided by the user.Short Url (string): Short URL to be deleted.ReturnsResult (boolean): Represents whether the operation was successful or not.Why do we need an API key?As you must’ve noticed, we’re using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.High-level designNow let us do a high-level design of our system.URL EncodingOur system’s primary goal is to shorten a given URL, let’s look at different approaches:Base62 ApproachIn this approach, we can encode the original URL using Base62 which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.\\[Number \\space of \\space URLs = 62^N\\]Where,N: Number of characters in the generated URL.So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.\\[\\begin{gather*}62^5 = \\sim 916 \\space million \\space URLs \\\\62^6 = \\sim 56.8 \\space billion \\space URLs \\\\62^7 = \\sim 3.5 \\space trillion \\space URLs\\end{gather*}\\]This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.MD5 ApproachThe MD5 message-digest algorithm is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.\\[MD5(original\\_url) \\rightarrow base62encode \\rightarrow hash\\]However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It’s better to look for more scalable approaches.Counter ApproachIn this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.\\[Counter(0-3.5 \\space trillion) \\rightarrow base62encode \\rightarrow hash\\]The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it’s essentially a distributed system.To solve this issue we can use a distributed system manager such as Zookeeper which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.\\[\\begin{align*}&amp; Range \\space 1: \\space 1 \\rightarrow 1,000,000 \\\\&amp; Range \\space 2: \\space 1,000,001 \\rightarrow 2,000,000 \\\\&amp; Range \\space 3: \\space 2,000,001 \\rightarrow 3,000,000 \\\\&amp; ...\\end{align*}\\]Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.Key Generation Service (KGS)As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.How to handle concurrent access?Once the key is used, we can mark it in the database to make sure we don’t reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.KGS database estimationsAs per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.\\[6 \\space characters \\times 56.8 \\space billion = \\sim 390 \\space GB\\]While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.CachingNow, let’s talk about caching. As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use Redis or Memcached servers alongside our API server.For more details, refer to caching.DesignNow that we have identified some core components, let’s do the first draft of our system design.Here’s how it works:Creating a new URL When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS). Key Generation Service provides a unique key to the API server and marks the key as used. API server writes the new URL entry to the database and cache. Our service returns an HTTP 201 (Created) response to the user.Accessing a URL When a client navigates to a certain short URL, the request is sent to the API servers. The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL. If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.Detailed designIt’s time to discuss the finer details of our design.Data PartitioningTo scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning List-Based Partitioning Range Based Partitioning Composite PartitioningThe above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.For more details, refer to Sharding and Consistent Hashing.Database cleanupThis is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:Active cleanupIn active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a cron job.Passive cleanupFor passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.CacheNow let us talk about caching.Which cache eviction policy to use?As we discussed before, we can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.How to handle cache miss?Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.Metrics and AnalyticsRecording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor’s country, platform, the number of views, etc alongside the URL entry in our database.SecurityFor security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.We can also use an API Gateway as they can support capabilities like authorization, rate limiting, and load balancing out of the box.Identify and resolve bottlenecksLet us identify and resolve bottlenecks such as single points of failure in our design: “What if the API service or Key Generation Service crashes?” “How will we distribute our traffic between our components?” “How can we reduce the load on our database?” “What if the key database used by KGS fails?” “How to improve the availability of our cache?”To make our system more resilient we can do the following: Running multiple instances of our Servers and Key Generation Service. Introducing load balancers between clients, servers, databases, and cache servers. Using multiple read replicas for our database as it’s a read-heavy system. Standby replica for our key database in case it fails. Multiple instances and replicas for our distributed cache.WhatsAppLet’s design a WhatsApp like instant messaging service, similar to services like WhatsApp, Facebook Messenger, and WeChat.What is WhatsApp?WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.RequirementsOur system should meet the following requirements:Functional requirements Should support one-on-one chat. Group chats (max 100 people). Should support file sharing (image, video, etc.).Non-functional requirements High availability with minimal latency. The system should be scalable and efficient.Extended requirements Sent, Delivered, and Read receipts of the messages. Show the last seen time of users. Push notifications.Estimation and ConstraintsLet’s start with the estimation and constraints.Note: Make sure to check any scale or traffic-related assumptions with your interviewer.TrafficLet us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 4 different people every day. This gives us 2 billion messages per day.\\[50 \\space million \\times 20 \\space messages = 2 \\space billion/day\\]Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 200 million files we would need to store.\\[5 \\space percent \\times 2 \\space billion = 200 \\space million/day\\]What would be Requests Per Second (RPS) for our system?2 billion requests per day translate into 24K requests per second.\\[\\frac{2 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 24K \\space requests/second\\]StorageIf we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.\\[2 \\space billion \\times 100 \\space bytes = \\sim 200 \\space GB/day\\]As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 50 KB on average, we will require 10 TB of storage every day.\\[100 \\space million \\times 100 \\space KB = 10 \\space TB/day\\]And for 10 years, we will require about 38 PB of storage.\\[(10 \\space TB + 0.2 \\space TB) \\times 10 \\space years \\times 365 \\space days = \\sim 38 \\space PB\\]BandwidthAs our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.\\[\\frac{10.2 \\space TB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 120 \\space MB/second\\]High-level estimateHere is our high-level estimate: Type Estimate Daily active users (DAU) 50 million Requests per second (RPS) 24K/s Storage (per day) ~10.2 TB Storage (10 years) ~38 PB Bandwidth ~120 MB/s Data model designThis is the general data model which reflects our requirements.We have the following tables:usersThis table will contain a user’s information such as name, phoneNumber, and other details.messagesAs the name suggests, this table will store messages with properties such as type (text, image, video, etc.), content, and timestamps for message delivery. The message will also have a corresponding chatID or groupID.chatsThis table basically represents a private chat between two users and can contain multiple messages.users_chatsThis table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.groupsThis table represents a group between multiple users.users_groupsThis table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.What kind of database should we use?While our data model seems quite relational, we don’t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.API designLet us do a basic API design for our services:Get all chats or groupsThis API will get all chats or groups for a given userID.getAll(userID: UUID): Chat[] | Group[]ParametersUser ID (UUID): ID of the current user.ReturnsResult (Chat[] | Group[]): All the chats and groups the user is a part of.Get messagesGet all messages for a user given the channelID (chat or group id).getMessages(userID: UUID, channelID: UUID): Message[]ParametersUser ID (UUID): ID of the current user.Channel ID (UUID): ID of the channel (chat or group) from which messages need to be retrieved.ReturnsMessages (Message[]): All the messages in a given chat or group.Send messageSend a message from a user to a channel (chat or group).sendMessage(userID: UUID, channelID: UUID, message: Message): booleanParametersUser ID (UUID): ID of the current user.Channel ID (UUID): ID of the channel (chat or group) user wants to send a message to.Message (Message): The message (text, image, video, etc.) that the user wants to send.ReturnsResult (boolean): Represents whether the operation was successful or not.Join or leave a groupSend a message from a user to a channel (chat or group).joinGroup(userID: UUID, channelID: UUID): booleanleaveGroup(userID: UUID, channelID: UUID): booleanParametersUser ID (UUID): ID of the current user.Channel ID (UUID): ID of the channel (chat or group) the user wants to join or leave.ReturnsResult (boolean): Represents whether the operation was successful or not.High-level designNow let us do a high-level design of our system.ArchitectureWe will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let’s try to divide our system into some core services.User ServiceThis is an HTTP-based service that handles user-related concerns such as authentication and user information.Chat ServiceThe chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.Notification ServiceThis service will simply send push notifications to the users. It will be discussed in detail separately.Presence ServiceThe presence service will keep track of the last seen status of all users. It will be discussed in detail separately.Media serviceThis service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.What about inter-service communication and service discovery?Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.Real-time messagingHow do we efficiently send and receive messages? We have two different options:Pull modelThe client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like Long polling.Push modelThe client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use WebSockets or Server-Sent Events (SSE) for this.The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with WebSockets is a better choice because then we can push data to the client once it’s available without any delay given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike Server-Sent Events (SSE) which are only unidirectional.Note: Learn more about Long polling, WebSockets, Server-Sent Events (SSE).Last seenTo implement the last seen functionality, we can use a heartbeat mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows: Key Value User A 2022-07-01T14:32:50 User B 2022-07-05T05:10:35 User C 2022-07-10T04:33:25 This will give us the last time the user was active. This functionality will be handled by the presence service combined with Redis or Memcached as our cache.Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as “user hasn’t performed any action in the last 30 seconds”, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.NotificationsOnce a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user’s active connection and last seen into consideration.If the recipient is not active, the chat service will add an event to a message queue with additional metadata such as the client’s device platform which will be used to route the notification to the correct platform later on.The notification service will then consume the event from the message queue and forward the request to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) based on the client’s device platform (Android, iOS, web, etc). We can also add support for email and SMS.Why are we using a message queue?Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they’re sent and that a message is delivered at least once which is an important part of our service functionality.While this seems like a classic publish-subscribe use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like Amazon SQS or RabbitMQ to support this functionality.Read receiptsHandling read receipts can be tricky, for this use case we can wait for some sort of Acknowledgment (ACK) from the client to determine if the message was delivered and update the corresponding deliveredAt field. Similarly, we will mark message the message seen once the user opens the chat and update the corresponding seenAt timestamp field.DesignNow that we have identified some core components, let’s do the first draft of our system design.Detailed designIt’s time to discuss our design decisions in detail.Data PartitioningTo scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning List-Based Partitioning Range Based Partitioning Composite PartitioningThe above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.For more details, refer to Sharding and Consistent Hashing.CachingIn a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won’t have to retrieve old messages unless requested.Which cache eviction policy to use?We can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.How to handle cache miss?Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.For more details, refer to Caching.Media access and storageAs we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.But where can we store files at scale? Well, object storage is what we’re looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as HDFS or GlusterFS.Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user.We can use object stores like Amazon S3, Azure Blob Storage, or Google Cloud Storage for this use case.Content Delivery Network (CDN)Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case.API gatewaySince we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an API Gateway that supports multiple protocols without any issues.API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.We can use services like Amazon API Gateway or Azure API Gateway for this use case.Identify and resolve bottlenecksLet us identify and resolve bottlenecks such as single points of failure in our design: “What if one of our services crashes?” “How will we distribute our traffic between our components?” “How can we reduce the load on our database?” “How to improve the availability of our cache?” “Wouldn’t API Gateway be a single point of failure?” “How can we make our notification system more robust?” “How can we reduce media storage costs”? “Does chat service has too much responsibility?”To make our system more resilient we can do the following: Running multiple instances of each of our services. Introducing load balancers between clients, servers, databases, and cache servers. Using multiple read replicas for our databases. Multiple instances and replicas for our distributed cache. We can have a standby replica of our API Gateway. Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust. We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost. We can create a group service separate from the chat service to further decouple our services.TwitterLet’s design a Twitter like social media service, similar to services like Facebook, Instagram, etc.What is Twitter?Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.RequirementsOur system should meet the following requirements:Functional requirements Should be able to post new tweets (can be text, image, video, etc.). Should be able to follow other users. Should have a newsfeed feature consisting of tweets from the people the user is following. Should be able to search tweets.Non-Functional requirements High availability with minimal latency. The system should be scalable and efficient.Extended requirements Metrics and analytics. Retweet functionality. Favorite tweets.Estimation and ConstraintsLet’s start with the estimation and constraints.Note: Make sure to check any scale or traffic-related assumptions with your interviewer.TrafficThis will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.\\[200 \\space million \\times 5 \\space messages = 1 \\space billion/day\\]Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.\\[10 \\space percent \\times 1 \\space billion = 100 \\space million/day\\]What would be Requests Per Second (RPS) for our system?1 billion requests per day translate into 12K requests per second.\\[\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second\\]StorageIf we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.\\[1 \\space billion \\times 100 \\space bytes = \\sim 100 \\space GB/day\\]We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.\\[100 \\space million \\times 100 \\space KB = 5 \\space TB/day\\]And for 10 years, we will require about 19 PB of storage.\\[(5 \\space TB + 0.1 \\space TB) \\times 365 \\space days \\times 10 \\space years = \\sim 19 \\space PB\\]BandwidthAs our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.\\[\\frac{5.1 \\space TB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 60 \\space MB/second\\]High-level estimateHere is our high-level estimate: Type Estimate Daily active users (DAU) 100 million Requests per second (RPS) 12K/s Storage (per day) ~5.1 TB Storage (10 years) ~19 PB Bandwidth ~60 MB/s Data model designThis is the general data model which reflects our requirements.We have the following tables:usersThis table will contain a user’s information such as name, email, dob, and other details.tweetsAs the name suggests, this table will store tweets and their properties such as type (text, image, video, etc.), content, etc. We will also store the corresponding userID.favoritesThis table maps tweets with users for the favorite tweets functionality in our application.followersThis table maps the followers and followees as users can follow each other (N:M relationship).feedsThis table stores feed properties with the corresponding userID.feeds_tweetsThis table maps tweets and feed (N:M relationship).What kind of database should we use?While our data model seems quite relational, we don’t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.API designLet us do a basic API design for our services:Post a tweetThis API will allow the user to post a tweet on the platform.postTweet(userID: UUID, content: string, mediaURL?: string): booleanParametersUser ID (UUID): ID of the user.Content (string): Contents of the tweet.Media URL (string): URL of the attached media (optional).ReturnsResult (boolean): Represents whether the operation was successful or not.Follow or unfollow a userThis API will allow the user to follow or unfollow another user.follow(followerID: UUID, followeeID: UUID): booleanunfollow(followerID: UUID, followeeID: UUID): booleanParametersFollower ID (UUID): ID of the current user.Followee ID (UUID): ID of the user we want to follow or unfollow.Media URL (string): URL of the attached media (optional).ReturnsResult (boolean): Represents whether the operation was successful or not.Get newsfeedThis API will return all the tweets to be shown within a given newsfeed.getNewsfeed(userID: UUID): Tweet[]ParametersUser ID (UUID): ID of the user.ReturnsTweets (Tweet[]): All the tweets to be shown within a given newsfeed.High-level designNow let us do a high-level design of our system.ArchitectureWe will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let’s try to divide our system into some core services.User ServiceThis service handles user-related concerns such as authentication and user information.Newsfeed ServiceThis service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.Tweet ServiceThe tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.Search ServiceThe service is responsible for handling search-related functionality. It will be discussed in detail separately.Media serviceThis service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.Notification ServiceThis service will simply send push notifications to the users.Analytics ServiceThis service will be used for metrics and analytics use cases.What about inter-service communication and service discovery?Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.NewsfeedWhen it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let’s divide our problem into two parts:GenerationLet’s assume we want to generate the feed for user A, we will perform the following steps: Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows. Fetch the relevant tweets for each of the retrieved IDs. Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc. Return the ranked tweets data to the client in a paginated manner.Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.PublishingPublishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches: Pull Model (or Fan-out on load)When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.The downside of this approach is that the users will not be able to view recent feeds unless they “pull” the data from the server, which will increase the number of read operations on the server. Push Model (or Fan-out on write)In this model, once a user creates a tweet, it is “pushed” to all the follower’s feeds immediately. This prevents the system from having to go through a user’s entire followers list to check for updates.However, the downside of this approach is that it would increase the number of write operations on the database. Hybrid ModelA third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.The hybrid model allows only users with a lesser number of followers to use the push model and for users with a higher number of followers celebrities, the pull model will be used.Ranking AlgorithmAs we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.For example, Facebook used to utilize an EdgeRank algorithm, here, the rank of each feed item is described by:\\[Rank = Affinity \\times Weight \\times Decay\\]Where,Affinity: is the “closeness” of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.Weight: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.Decay: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.RetweetsRetweets are one of our extended requirements. To implement this feature we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the type enum and content property of the new tweet to link it with the original tweet.For example, the type enum property can be of type tweet, similar to text, video, etc and content can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet. id userID type content createdAt ad34-291a-45f6-b36c 7a2c-62c4-4dc8-b1bb text Hey, this is my first tweet… 1658905644054 f064-49ad-9aa2-84a6 6aa2-2bc9-4331-879f tweet ad34-291a-45f6-b36c 1658906165427 This is a very basic implementation, to improve this we can create a separate table itself to store retweets.SearchSometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. Elasticsearch can help us with this use case.Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of Apache Lucene.How do we identify trending topics?Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last N seconds and update them every M seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.NotificationsPush notifications are an integral part of any social media platform. We can use a message queue or a message broker such as Apache Kafka with the notification service to dispatch requests to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) which will handle the delivery of the push notifications to user devices.For more details, refer to the WhatsApp system design where we discuss push notifications.Detailed designIt’s time to discuss our design decisions in detail.Data PartitioningTo scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning List-Based Partitioning Range Based Partitioning Composite PartitioningThe above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.For more details, refer to Sharding and Consistent Hashing.Mutual friendsFor mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as Neo4j and ArangoDB.This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.Metrics and AnalyticsRecording analytics and metrics is one of our extended requirements. As we will be using Apache Kafka to publish all sorts of events, we can process these events and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing.CachingIn a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won’t have to retrieve old messages unless requested.Which cache eviction policy to use?We can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.How to handle cache miss?Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.For more details, refer to Caching.Media access and storageAs we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.But where can we store files at scale? Well, object storage is what we’re looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as HDFS or GlusterFS.Content Delivery Network (CDN)Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case.Identify and resolve bottlenecksLet us identify and resolve bottlenecks such as single points of failure in our design: “What if one of our services crashes?” “How will we distribute our traffic between our components?” “How can we reduce the load on our database?” “How to improve the availability of our cache?” “How can we make our notification system more robust?” “How can we reduce media storage costs”?To make our system more resilient we can do the following: Running multiple instances of each of our services. Introducing load balancers between clients, servers, databases, and cache servers. Using multiple read replicas for our databases. Multiple instances and replicas for our distributed cache. Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust. We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.NetflixLet’s design a Netflix like video streaming service, similar to services like Amazon Prime Video, Disney Plus, Hulu, Youtube, Vimeo, etc.What is Netflix?Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.RequirementsOur system should meet the following requirements:Functional requirements Users should be able to stream and share videos. The content team (or users in YouTube’s case) should be able to upload new videos (movies, tv shows episodes, and other content). Users should be able to search for videos using titles or tags. Users should be able to comment on a video similar to YouTube.Non-Functional requirements High availability with minimal latency. High reliability, no uploads should be lost. The system should be scalable and efficient.Extended requirements Certain content should be geo-blocked. Resume video playback from the point user left off. Record metrics and analytics of videos.Estimation and ConstraintsLet’s start with the estimation and constraints.Note: Make sure to check any scale or traffic-related assumptions with your interviewer.TrafficThis will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.\\[200 \\space million \\times 5 \\space videos = 1 \\space billion/day\\]Assuming, a 200:1 read/write ratio, about 50 million videos will be uploaded every day.\\[\\frac{1}{200} \\times 1 \\space billion = 50 \\space million/day\\]What would be Requests Per Second (RPS) for our system?1 billion requests per day translate into 12K requests per second.\\[\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second\\]StorageIf we assume each video is 100 MB on average, we will require about 5 PB of storage every day.\\[50 \\space million \\times 100 \\space MB = 5 \\space PB/day\\]And for 10 years, we will require an astounding 18,250 PB of storage.\\[5 \\space PB \\times 365 \\space days \\times 10 \\space years = \\sim 18,250 \\space PB\\]BandwidthAs our system is handling 5 PB of ingress every day, we will require a minimum bandwidth of around 58 GB per second.\\[\\frac{5 \\space PB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 58 \\space GB/second\\]High-level estimateHere is our high-level estimate: Type Estimate Daily active users (DAU) 200 million Requests per second (RPS) 12K/s Storage (per day) ~5 PB Storage (10 years) ~18,250 PB Bandwidth ~58 GB/s Data model designThis is the general data model which reflects our requirements.We have the following tables:usersThis table will contain a user’s information such as name, email, dob, and other details.videosAs the name suggests, this table will store videos and their properties such as title, streamURL, tags, etc. We will also store the corresponding userID.tagsThis table will simply store tags associated with a video.viewsThis table helps us to store all the views received on a video.commentsThis table stores all the comments received on a video (like YouTube).What kind of database should we use?While our data model seems quite relational, we don’t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.API designLet us do a basic API design for our services:Upload a videoGiven a byte stream, this API enables video to be uploaded to our service.uploadVideo(title: string, description: string, data: Stream&lt;byte&gt;, tags?: string[]): booleanParametersTitle (string): Title of the new video.Description (string): Description of the new video.Data (Byte[]): Byte stream of the video data.Tags (string[]): Tags for the video (optional).ReturnsResult (boolean): Represents whether the operation was successful or not.Streaming a videoThis API allows our users to stream a video with the preferred codec and resolution.streamVideo(videoID: UUID, codec: Enum&lt;string&gt;, resolution: Tuple&lt;int&gt;, offset?: int): VideoStreamParametersVideo ID (UUID): ID of the video that needs to be streamed.Codec (Enum&lt;string&gt;): Required codec of the requested video, such as h.265, h.264, VP9, etc.Resolution (Tuple&lt;int&gt;): Resolution of the requested video.Offset (int): Offset of the video stream in seconds to stream data from any point in the video (optional).ReturnsStream (VideoStream): Data stream of the requested video.Search for a videoThis API will enable our users to search for a video based on its title or tags.searchVideo(query: string, nextPage?: string): Video[]ParametersQuery (string): Search query from the user.Next Page (string): Token for the next page, this can be used for pagination (optional).ReturnsVideos (Video[]): All the videos available for a particular search query.Add a commentThis API will allow our users to post a comment on a video (like YouTube).comment(videoID: UUID, comment: string): booleanParametersVideoID (UUID): ID of the video user wants to comment on.Comment (string): The text content of the comment.ReturnsResult (boolean): Represents whether the operation was successful or not.High-level designNow let us do a high-level design of our system.ArchitectureWe will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let’s try to divide our system into some core services.User ServiceThis service handles user-related concerns such as authentication and user information.Stream ServiceThe tweet service will handle video streaming-related functionality.Search ServiceThe service is responsible for handling search-related functionality. It will be discussed in detail separately.Media serviceThis service will handle the video uploads and processing. It will be discussed in detail separately.Analytics ServiceThis service will be used for metrics and analytics use cases.What about inter-service communication and service discovery?Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.Video processingThere are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.Here’s how we can process videos once they’re uploaded by the content team (or users in YouTube’s case) and are queued for processing in our message queue.Let’s discuss how this works: File ChunkerThis is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes, this slight variation becomes a huge factor for a better user experience as whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved. Content FilterThis step checks if the video adheres to the content policy of the platform, this can be pre-approved in the case of Netflix as per the content rating of the media or can be strictly enforced like YouTube.This entire step is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a dead-letter queue (DLQ) and someone from the moderation team can do further inspection. TranscoderTranscoding is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different codecs to perform bitrate adjustment, image downsampling, or re-encoding the media.This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as FFmpeg or cloud-based solutions like AWS Elemental MediaConvert can be used to implement this step of the pipeline. Quality ConversionThis is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.This allows us to fetch the desired quality of the video as per the user’s request, and once the media file finishes processing, it will be uploaded to a distributed file storage such as HDFS, GlusterFS, or an object storage such as Amazon S3 for later retrieval during streaming.Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline.Why are we using a message queue?Processing videos as a long-running task makes much more sense, and a message queue also decouples our video processing pipeline from the uploads functionality. We can use something like Amazon SQS or RabbitMQ to support this.Video streamingVideo streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don’t re-fetch the same content, we can use a Content Delivery Network (CDN).Netflix takes this a step further with its Open Connect program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.What is the difference between Netflix’s Open Connect and a traditional Content Delivery Network (CDN)?Netflix Open Connect is our purpose-built Content Delivery Network (CDN) responsible for serving Netflix’s video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.Additionally, we can use Adaptive bitrate streaming protocols such as HTTP Live Streaming (HLS) which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the offset property we stored in the views table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.SearchingSometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. Elasticsearch can help us with this use case.Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of Apache Lucene.How do we identify trending content?Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last N seconds and update them every M seconds using some sort of batch job mechanism.SharingSharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.For more details, refer to the URL Shortener system design.Detailed designIt’s time to discuss our design decisions in detail.Data PartitioningTo scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning List-Based Partitioning Range Based Partitioning Composite PartitioningThe above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.For more details, refer to Sharding and Consistent Hashing.Geo-blockingPlatforms like Netflix and YouTube use Geo-blocking to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.We can determine the user’s location either using their IP or region settings in their profile then use services like Amazon CloudFront which supports a geographic restrictions feature or a geolocation routing policy with Amazon Route53 to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.RecommendationsNetflix uses a machine learning model which uses the user’s viewing history to predict what the user might like to watch next, an algorithm like Collaborative Filtering can be used.However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as: User profile information like age, gender, and location. Browsing and scrolling behavior of the user. Time and date a user watched a title. The device which was used to stream the content. The number of searches and what terms were searched.For more detail, refer to Netflix recommendation research.Metrics and AnalyticsRecording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.CachingIn a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like Redis or Memcached but what kind of cache eviction policy would best fit our needs?Which cache eviction policy to use?Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.How to handle cache miss?Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.For more details, refer to Caching.Media streaming and storageAs most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.We will use distributed file storage such as HDFS, GlusterFS, or an object storage such as Amazon S3 for storage and streaming of the content.Content Delivery Network (CDN)Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case.Identify and resolve bottlenecksLet us identify and resolve bottlenecks such as single points of failure in our design: “What if one of our services crashes?” “How will we distribute our traffic between our components?” “How can we reduce the load on our database?” “How to improve the availability of our cache?”To make our system more resilient we can do the following: Running multiple instances of each of our services. Introducing load balancers between clients, servers, databases, and cache servers. Using multiple read replicas for our databases. Multiple instances and replicas for our distributed cache.UberLet’s design an Uber like ride-hailing service, similar to services like Lyft, OLA Cabs, etc.What is Uber?Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.RequirementsOur system should meet the following requirements:Functional requirementsWe will design our system for two types of users: Customers and Drivers.Customers Customers should be able to see all the cabs in the vicinity with an ETA and pricing information. Customers should be able to book a cab to a destination. Customers should be able to see the location of the driver.Drivers Drivers should be able to accept or deny the customer requested ride. Once a driver accepts the ride, they should see the pickup location of the customer. Drivers should be able to mark the trip as complete on reaching the destination.Non-Functional requirements High reliability. High availability with minimal latency. The system should be scalable and efficient.Extended requirements Customers can rate the trip after it’s completed. Payment processing. Metrics and analytics.Estimation and ConstraintsLet’s start with the estimation and constraints.Note: Make sure to check any scale or traffic-related assumptions with your interviewer.TrafficLet us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.\\[100 \\space million \\times 10 \\space actions = 1 \\space billion/day\\]What would be Requests Per Second (RPS) for our system?1 billion requests per day translate into 12K requests per second.\\[\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second\\]StorageIf we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.\\[1 \\space billion \\times 400 \\space bytes = \\sim 400 \\space GB/day\\]And for 10 years, we will require about 1.4 PB of storage.\\[400 \\space GB \\times 10 \\space years \\times 365 \\space days = \\sim 1.4 \\space PB\\]BandwidthAs our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.\\[\\frac{400 \\space GB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 5 \\space MB/second\\]High-level estimateHere is our high-level estimate: Type Estimate Daily active users (DAU) 100 million Requests per second (RPS) 12K/s Storage (per day) ~400 GB Storage (10 years) ~1.4 PB Bandwidth ~5 MB/s Data model designThis is the general data model which reflects our requirements.We have the following tables:customersThis table will contain a customer’s information such as name, email, and other details.driversThis table will contain a driver’s information such as name, email, dob and other details.tripsThis table represents the trip taken by the customer and stores data such as source, destination, and status of the trip.cabsThis table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.ratingsAs the name suggests, this table stores the rating and feedback for the trip.paymentsThe payments table contains the payment-related data with the corresponding tripID.What kind of database should we use?While our data model seems quite relational, we don’t necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.API designLet us do a basic API design for our services:Request a RideThrough this API, customers will be able to request a ride.requestRide(customerID: UUID, source: Tuple&lt;float&gt;, destination: Tuple&lt;float&gt;, cabType: Enum&lt;string&gt;, paymentMethod: Enum&lt;string&gt;): RideParametersCustomer ID (UUID): ID of the customer.Source (Tuple&lt;float&gt;): Tuple containing the latitude and longitude of the trip’s starting location.Destination (Tuple&lt;float&gt;): Tuple containing the latitude and longitude of the trip’s destination.ReturnsResult (boolean): Represents whether the operation was successful or not.Cancel the RideThis API will allow customers to cancel the ride.cancelRide(customerID: UUID, reason?: string): booleanParametersCustomer ID (UUID): ID of the customer.Reason (UUID): Reason for canceling the ride (optional).ReturnsResult (boolean): Represents whether the operation was successful or not.Accept or Deny the RideThis API will allow the driver to accept or deny the trip.acceptRide(driverID: UUID, rideID: UUID): booleandenyRide(driverID: UUID, rideID: UUID): booleanParametersDriver ID (UUID): ID of the driver.Ride ID (UUID): ID of the customer requested ride.ReturnsResult (boolean): Represents whether the operation was successful or not.Start or End the TripUsing this API, a driver will be able to start and end the trip.startTrip(driverID: UUID, tripID: UUID): booleanendTrip(driverID: UUID, tripID: UUID): booleanParametersDriver ID (UUID): ID of the driver.Trip ID (UUID): ID of the requested trip.ReturnsResult (boolean): Represents whether the operation was successful or not.Rate the TripThis API will enable customers to rate the trip.rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): booleanParametersCustomer ID (UUID): ID of the customer.Trip ID (UUID): ID of the completed trip.Rating (int): Rating of the trip.Feedback (string): Feedback about the trip by the customer (optional).ReturnsResult (boolean): Represents whether the operation was successful or not.High-level designNow let us do a high-level design of our system.ArchitectureWe will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let’s try to divide our system into some core services.Customer ServiceThis service handles customer-related concerns such as authentication and customer information.Driver ServiceThis service handles driver-related concerns such as authentication and driver information.Ride ServiceThis service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.Trip ServiceThis service handles trip-related functionality in our system.Payment ServiceThis service will be responsible for handling payments in our system.Notification ServiceThis service will simply send push notifications to the users. It will be discussed in detail separately.Analytics ServiceThis service will be used for metrics and analytics use cases.What about inter-service communication and service discovery?Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.How is the service expected to work?Here’s how our service is expected to work: Customer requests a ride by specifying the source, destination, cab type, payment method, etc. Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA). The request is then broadcasted to the nearby drivers for them to accept or deny. If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup. The customer is picked up and the driver can start the trip. Once the destination is reached, the driver will mark the ride as complete and collect payment. After the payment is complete, the customer can leave a rating and feedback for the trip if they like.Location TrackingHow do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:Pull modelThe client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like Long polling.Push modelThe client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use WebSockets or Server-Sent Events (SSE) for this.The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with WebSockets is a better choice because then we can push data to the client once it’s available without any delay given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike Server-Sent Events (SSE) which are only unidirectional.Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.Note: Learn more about Long polling, WebSockets, Server-Sent Events (SSE).Ride MatchingWe need a way to efficiently store and query nearby drivers. Let’s explore different solutions we can incorporate into our design.SQLWe already have access to the latitude and longitude of our customers, and with databases like PostgreSQL and MySQL we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+RHowever, this is not scalable, and performing this query on large datasets will be quite slow.GeohashingGeohashing is a geocoding method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by Gustavo Niemeyer in 2008.Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.For example, San Francisco with coordinates 37.7564, -122.4016 can be represented in geohash as 9q8yy9mf.Now, using the customer’s geohash we can determine the nearest available driver by simply comparing it with the driver’s geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.QuadtreesA Quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of Octrees which are used to partition three-dimensional space.Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.We can save further computation by only subdividing a node after a certain threshold.Quadtree seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as Redis to cache the latest updates. And with the application of mapping algorithms such as the Hilbert curve, we can perform efficient range queries to find nearby drivers for the customer.What about race conditions?Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a Mutex to avoid any race conditions. Furthermore, every action should be transactional in nature.For more details, refer to Transactions and Distributed Transactions.How to find the best drivers nearby?Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.Dealing with high demandIn cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.For more details, learn how surge pricing works with Uber.PaymentsHandling payments at scale is challenging, to simplify our system we can use a third-party payment processor like Stripe or PayPal. Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a webhook to capture all the payment-related data.NotificationsPush notifications will be an integral part of our platform. We can use a message queue or a message broker such as Apache Kafka with the notification service to dispatch requests to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) which will handle the delivery of the push notifications to user devices.For more details, refer to the WhatsApp system design where we discuss push notifications.Detailed designIt’s time to discuss our design decisions in detail.Data PartitioningTo scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can shard our database either based on existing partition schemes or regions. If we divide the locations into regions using let’s say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using Consistent hashing.For more details, refer to Sharding and Consistent Hashing.Metrics and AnalyticsRecording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.CachingIn a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like Redis or Memcached but what kind of cache eviction policy would best fit our needs?Which cache eviction policy to use?Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.How to handle cache miss?Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.For more details, refer to Caching.Identify and resolve bottlenecksLet us identify and resolve bottlenecks such as single points of failure in our design: “What if one of our services crashes?” “How will we distribute our traffic between our components?” “How can we reduce the load on our database?” “How to improve the availability of our cache?” “How can we make our notification system more robust?”To make our system more resilient we can do the following: Running multiple instances of each of our services. Introducing load balancers between clients, servers, databases, and cache servers. Using multiple read replicas for our databases. Multiple instances and replicas for our distributed cache. Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust.Next StepsCongratulations, you’ve finished the course!Now that you know the fundamentals of System Design, here are some additional resources: Distributed Systems (by Dr. Martin Kleppmann) System Design Interview: An Insider’s Guide Microservices (by Chris Richardson) Serverless computing KubernetesIt is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale: Microsoft Engineering Google Research Blog Netflix Tech Blog AWS Blog Facebook Engineering Uber Engineering Blog Airbnb Engineering GitHub Engineering Blog Intel Software Blog LinkedIn Engineering Paypal Developer Blog Twitter EngineeringLast but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.I hope this course was a great learning experience. I would love to hear feedback from you.Wishing you all the best for further learning!ReferencesHere are the resources that were referenced while creating this course. Cloudflare learning center IBM Blogs Fastly Blogs NS1 Blogs Grokking the System Design Interview System Design Primer AWS Blogs Martin Fowler PagerDuty resources VMWare Blogs Blog Disclaimer: This webpage is a modification of @karanpratapsingh’s system-design repository with CC BY-NC-ND 4.0 license." }, { "title": "Data Structures and Algorithms for Coding Interview", "url": "/posts/data-structures-and-algorithms-for-coding-interview/", "categories": "Computer Science, DSAlgo", "tags": "data-structures, algorithms", "date": "2022-10-25 00:00:00 +0530", "snippet": "Repository Link: https://github.com/SamirPaul1/DSAlgo In this repository, I have stored solutions to various problems and concepts of Data Structures and Algorithms in Python in a structured manne...", "content": "Repository Link: https://github.com/SamirPaul1/DSAlgo In this repository, I have stored solutions to various problems and concepts of Data Structures and Algorithms in Python in a structured manner. Topics Covered: Dynamic Programming Sorting Algorithms LinkedList Object-Oriented Programming Binary Trees Graph Algorithms Heap Matrix Trie Binary Search Backtracking Stack Queue Greedy String Bit Manipulation Array HashMap DFS BFS Two Pointers Math RecursionIn various folders of the above topics, you can find questions and concepts related to that topic. In the Dynamic Programming section, you can find all the questions covered and not covered in Aditya Verma’s dynamic programming playlist folder-wise with my handwritten notes.✍️ If you are preparing for an interview from Striver’s SDE Sheet then the 30-Days-SDE-Sheet-Practice will be helpful to you. Here I have stored solutions to questions of each day with short notes to each solution, as short notes about the approach are very helpful during revision.🎯 In the Questions-Sheet directory, you can find questions asked by top product-based companies. There is a collection of books and pdfs on various important computer science fundamentals in the BOOKS-and-PDFs directory.📚 View this repository in online VS Code: https://samirpaul.in/DSAlgo. I am continuously trying to improve this repository by adding new questions and concepts related to the respective topic. Please feel free to contribute to this repository.💻Things you can contribute to: Update the existing solution with a better one (better complexity). Add new questions and solutions in Python3 to the respective directory. Add new resources to BOOKS-and-PDFs &amp; Questions-Sheet. Solve issues raised by other people or yourself. Provide well-documented source code with detailed explanations.Stargazers over timeList of Important Questions:✨The following list of questions was recommended by Love Babbar on this video. I have documented all those questions here.✌️ Topic Important DSA Questions Link   Topic: Problem: Related Link   &lt;-&gt;       Array Reverse the array &lt;-&gt;   Array Find the maximum and minimum element in an array &lt;-&gt;   Array Find the “Kth” max and min element of an array &lt;-&gt;   Array Given an array which consists of only 0, 1 and 2. Sort the array without using any sorting algo &lt;-&gt;   Array Move all the negative elements to one side of the array &lt;-&gt;   Array Find the Union and Intersection of the two sorted arrays. &lt;-&gt;   Array Write a program to cyclically rotate an array by one. https://leetcode.com/problems/rotate-array/   Array find Largest sum contiguous Subarray [V. IMP] https://leetcode.com/problems/maximum-subarray/   Array Minimise the maximum difference between heights [V.IMP] https://leetcode.com/problems/smallest-range-ii/   Array Minimum no. of Jumps to reach end of an array https://leetcode.com/problems/jump-game   Array find duplicate in an array of N+1 Integers &lt;-&gt;   Array Merge 2 sorted arrays without using Extra space. &lt;-&gt;   Array Kadane’s Algorithm https://leetcode.com/problems/maximum-subarray/   Array Merge Intervals &lt;-&gt;   Array Next Permutation &lt;-&gt;   Array Count Inversion &lt;-&gt;   Array Best time to buy and Sell stock &lt;-&gt;   Array find all pairs on integer array whose sum is equal to given number &lt;-&gt;   Array find common elements In 3 sorted arrays &lt;-&gt;   Array Rearrange the array in alternating positive and negative items with O(1) extra space &lt;-&gt;   Array Find if there is any subarray with sum equal to 0 https://leetcode.com/problems/subarray-sum-equals-k/   Array Find factorial of a large number &lt;-&gt;   Array find maximum product subarray &lt;-&gt;   Array Find longest coinsecutive subsequence &lt;-&gt;   Array Given an array of size n and a number k, fin all elements that appear more than “ n/k “ times. &lt;-&gt;   Array Maximum profit by buying and selling a share atmost twice &lt;-&gt;   Array Find whether an array is a subset of another array &lt;-&gt;   Array Find the triplet that sum to a given value &lt;-&gt;   Array Trapping Rain water problem &lt;-&gt;   Array Chocolate Distribution problem &lt;-&gt;   Array Smallest Subarray with sum greater than a given value &lt;-&gt;   Array Three way partitioning of an array around a given value &lt;-&gt;   Array Minimum swaps required bring elements less equal K together &lt;-&gt;   Array Minimum no. of operations required to make an array palindrome &lt;-&gt;   Array Median of 2 sorted arrays of equal size &lt;-&gt;   Array Median of 2 sorted arrays of different size &lt;-&gt;   Array Subarray Sums Divisible by K     Array Continuous Subarray Sum     &lt;-&gt;       &lt;-&gt;       Matrix Spiral traversal on a Matrix &lt;-&gt;   Matrix Search an element in a matriix &lt;-&gt;   Matrix Find median in a row wise sorted matrix &lt;-&gt;   Matrix Find row with maximum no. of 1’s &lt;-&gt;   Matrix Print elements in sorted order using row-column wise sorted matrix &lt;-&gt;   Matrix Largest Rectangle in Histogram     Matrix Maximum size rectangle https://practice.geeksforgeeks.org/problems/max-rectangle/1   Matrix Find a specific pair in matrix &lt;-&gt;   Matrix Rotate matrix by 90 degrees &lt;-&gt;   Matrix Kth smallest element in a row-cpumn wise sorted matrix &lt;-&gt;   Matrix Common elements in all rows of a given matrix &lt;-&gt;   String Reverse a String &lt;-&gt;   String Check whether a String is Palindrome or not &lt;-&gt;   String Find Duplicate characters in a string &lt;-&gt;   String Why strings are immutable in Java? &lt;-&gt;   String Write a Code to check whether one string is a rotation of another &lt;-&gt;   String Write a Program to check whether a string is a valid shuffle of two strings or not &lt;-&gt;   String Count and Say problem &lt;-&gt;   String Write a program to find the longest Palindrome in a string.[ Longest palindromic Substring] &lt;-&gt;   String Find Longest Recurring Subsequence in String &lt;-&gt;   String Print all Subsequences of a string. &lt;-&gt;   String Print all the permutations of the given string &lt;-&gt;   String Split the Binary string into two substring with equal 0’s and 1’s &lt;-&gt;   String Word Wrap Problem [VERY IMP]. &lt;-&gt;   String EDIT Distance [Very Imp] &lt;-&gt;   String Find next greater number with same set of digits. [Very Very IMP] &lt;-&gt;   String Balanced Parenthesis problem.[Imp] &lt;-&gt;   String Word break Problem[ Very Imp] &lt;-&gt;   String Rabin Karp Algo &lt;-&gt;   String KMP Algo &lt;-&gt;   String Convert a Sentence into its equivalent mobile numeric keypad sequence. &lt;-&gt;   String Minimum number of bracket reversals needed to make an expression balanced. &lt;-&gt;   String Count All Palindromic Subsequence in a given String. &lt;-&gt;   String Count of number of given string in 2D character array &lt;-&gt;   String Search a Word in a 2D Grid of characters. &lt;-&gt;   String Boyer Moore Algorithm for Pattern Searching. &lt;-&gt;   String Converting Roman Numerals to Decimal &lt;-&gt;   String Longest Common Prefix &lt;-&gt;   String Number of flips to make binary string alternate &lt;-&gt;   String Find the first repeated word in string. &lt;-&gt;   String Minimum number of swaps for bracket balancing. &lt;-&gt;   String Find the longest common subsequence between two strings. &lt;-&gt;   String Program to generate all possible valid IP addresses from given string. &lt;-&gt;   String Write a program tofind the smallest window that contains all characters of string itself. &lt;-&gt;   String Rearrange characters in a string such that no two adjacent are same &lt;-&gt;   String Minimum characters to be added at front to make string palindrome &lt;-&gt;   String Given a sequence of words, print all anagrams together &lt;-&gt;   String Find the smallest window in a string containing all characters of another string &lt;-&gt;   String Recursively remove all adjacent duplicates &lt;-&gt;   String String matching where one string contains wildcard characters &lt;-&gt;   String Function to find Number of customers who could not get a computer &lt;-&gt;   String Transform One String to Another using Minimum Number of Given Operation &lt;-&gt;   String Check if two given strings are isomorphic to each other &lt;-&gt;   String Recursively print all sentences that can be formed from list of word lists &lt;-&gt;   Searching &amp; Sorting Find first and last positions of an element in a sorted array &lt;-&gt;   Searching &amp; Sorting Find a Fixed Point (Value equal to index) in a given array https://leetcode.com/problems/find-pivot-index/   Searching &amp; Sorting Search in a rotated sorted array https://leetcode.com/problems/search-in-rotated-sorted-array/   Searching &amp; Sorting square root of an integer &lt;-&gt;   Searching &amp; Sorting Maximum and minimum of an array using minimum number of comparisons &lt;-&gt;   Searching &amp; Sorting Optimum location of point to minimize total distance https://leetcode.com/problems/best-meeting-point/   Searching &amp; Sorting Find the repeating and the missing &lt;-&gt;   Searching &amp; Sorting find majority element &lt;-&gt;   Searching &amp; Sorting Searching in an array where adjacent differ by at most k &lt;-&gt;   Searching &amp; Sorting find a pair with a given difference &lt;-&gt;   Searching &amp; Sorting find four elements that sum to a given value &lt;-&gt;   Searching &amp; Sorting maximum sum such that no 2 elements are adjacent &lt;-&gt;   Searching &amp; Sorting Count triplet with sum smaller than a given value &lt;-&gt;   Searching &amp; Sorting merge 2 sorted arrays &lt;-&gt;   Searching &amp; Sorting print all subarrays with 0 sum &lt;-&gt;   Searching &amp; Sorting Product array Puzzle &lt;-&gt;   Searching &amp; Sorting Sort array according to count of set bits &lt;-&gt;   Searching &amp; Sorting minimum no. of swaps required to sort the array &lt;-&gt;   Searching &amp; Sorting Bishu and Soldiers &lt;-&gt;   Searching &amp; Sorting Rasta and Kheshtak &lt;-&gt;   Searching &amp; Sorting Kth smallest number again Using Min Heap   Searching &amp; Sorting Find pivot element in a sorted array &lt;-&gt;   Searching &amp; Sorting K-th Element of Two Sorted Arrays &lt;-&gt;   Searching &amp; Sorting Aggressive cows &lt;-&gt;   Searching &amp; Sorting Book Allocation Problem https://leetcode.com/problems/capacity-to-ship-packages-within-d-days/   Searching &amp; Sorting EKOSPOJ: &lt;-&gt;   Searching &amp; Sorting Job Scheduling Algo &lt;-&gt;   Searching &amp; Sorting Missing Number in AP &lt;-&gt;   Searching &amp; Sorting Smallest number with atleastn trailing zeroes infactorial &lt;-&gt;   Searching &amp; Sorting Painters Partition Problem: &lt;-&gt;   Searching &amp; Sorting ROTI-Prata SPOJ &lt;-&gt;   Searching &amp; Sorting DoubleHelix SPOJ &lt;-&gt;   Searching &amp; Sorting Subset Sums &lt;-&gt;   Searching &amp; Sorting Findthe inversion count &lt;-&gt;   Searching &amp; Sorting Implement Merge-sort in-place &lt;-&gt;   Searching &amp; Sorting Partitioning and Sorting Arrays with Many Repeated Entries &lt;-&gt;   LinkedList Write a Program to reverse the Linked List. (Both Iterative and recursive) &lt;-&gt;   LinkedList Reverse a Linked List in group of Given Size. [Very Imp] https://leetcode.com/problems/reverse-nodes-in-k-group/   LinkedList Write a program to Detect loop in a linked list. &lt;-&gt;   LinkedList Write a program to Delete loop in a linked list. &lt;-&gt;   LinkedList Find the starting point of the loop. &lt;-&gt;   LinkedList Remove Duplicates in a sorted Linked List.     LinkedList Remove Duplicates from Sorted List II     LinkedList Remove Duplicates in a Un-sorted Linked List.     LinkedList Write a Program to Move the last element to Front in a Linked List. &lt;-&gt;   LinkedList Add “1” to a number represented as a Linked List. &lt;-&gt;   LinkedList Add two numbers represented by linked lists. &lt;-&gt;   LinkedList Intersection of two Sorted Linked List. &lt;-&gt;   LinkedList Intersection Point of two Linked Lists. &lt;-&gt;   LinkedList Merge Sort For Linked lists.[Very Important] &lt;-&gt;   LinkedList Quicksort for Linked Lists.[Very Important] &lt;-&gt;   LinkedList Find the middle Element of a linked list. &lt;-&gt;   LinkedList Check if a linked list is a circular linked list. &lt;-&gt;   LinkedList Split a Circular linked list into two halves. &lt;-&gt;   LinkedList Write a Program to check whether the Singly Linked list is a palindrome or not. &lt;-&gt;   LinkedList Deletion from a Circular Linked List. &lt;-&gt;   LinkedList Reverse a Doubly Linked list. &lt;-&gt;   LinkedList Find pairs with a given sum in a DLL. &lt;-&gt;   LinkedList Count triplets in a sorted DLL whose sum is equal to given value “X”. &lt;-&gt;   LinkedList Sort a “k”sorted Doubly Linked list.[Very IMP] &lt;-&gt;   LinkedList Rotate DoublyLinked list by N nodes. &lt;-&gt;   LinkedList Rotate a Doubly Linked list in group of Given Size.[Very IMP] &lt;-&gt;   LinkedList Can we reverse a linked list in less than O(n) ? &lt;-&gt;   LinkedList Why Quicksort is preferred for. Arrays and Merge Sort for LinkedLists ? &lt;-&gt;   LinkedList Flatten a Linked List &lt;-&gt;   LinkedList Sort a LL of 0’s, 1’s and 2’s &lt;-&gt;   LinkedList Clone a linked list with next and random pointer &lt;-&gt;   LinkedList Merge K sorted Linked list &lt;-&gt;   LinkedList Multiply 2 no. represented by LL &lt;-&gt;   LinkedList Delete nodes which have a greater value on right side &lt;-&gt;   LinkedList Segregate even and odd nodes in a Linked List &lt;-&gt;   LinkedList Program for n’th node from the end of a Linked List &lt;-&gt;   LinkedList Find the first non-repeating character from a stream of characters &lt;-&gt;   Binary Trees level order traversal &lt;-&gt;   Binary Trees Reverse Level Order traversal &lt;-&gt;   Binary Trees Height of a tree &lt;-&gt;   Binary Trees Diameter of a tree &lt;-&gt;   Binary Trees Mirror of a tree &lt;-&gt;   Binary Trees Inorder Traversal of a tree both using recursion and Iteration &lt;-&gt;   Binary Trees Preorder Traversal of a tree both using recursion and Iteration &lt;-&gt;   Binary Trees Postorder Traversal of a tree both using recursion and Iteration &lt;-&gt;   Binary Trees Left View of a tree &lt;-&gt;   Binary Trees Right View of Tree https://leetcode.com/problems/binary-tree-right-side-view/   Binary Trees Top View of a tree https://leetcode.com/problems/vertical-order-traversal-of-a-binary-tree/   Binary Trees Bottom View of a tree &lt;-&gt;   Binary Trees Zig-Zag traversal of a binary tree https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/   Binary Trees Check if a tree is balanced or not &lt;-&gt;   Binary Trees Diagnol Traversal of a Binary tree https://www.youtube.com/watch?v=e9ZGxH1y_PE   Binary Trees Boundary traversal of a Binary tree https://www.youtube.com/watch?v=0ca1nvR0be4   Binary Trees Construct Binary Tree from String with Bracket Representation &lt;-&gt;   Binary Trees Convert Binary tree into Doubly Linked List &lt;-&gt;   Binary Trees Convert Binary tree into Sum tree &lt;-&gt;   Binary Trees Construct Binary tree from Inorder and preorder traversal &lt;-&gt;   Binary Trees Find minimum swaps required to convert a Binary tree into BST &lt;-&gt;   Binary Trees Check if Binary tree is Sum tree or not &lt;-&gt;   Binary Trees Check if all leaf nodes are at same level or not &lt;-&gt;   Binary Trees Check if a Binary Tree contains duplicate subtrees of size 2 or more [ IMP ] &lt;-&gt;   Binary Trees Check if 2 trees are mirror or not &lt;-&gt;   Binary Trees Sum of Nodes on the Longest path from root to leaf node &lt;-&gt;   Binary Trees Check if given graph is tree or not. [ IMP ] &lt;-&gt;   Binary Trees Find Largest subtree sum in a tree &lt;-&gt;   Binary Trees Maximum Sum of nodes in Binary tree such that no two are adjacent &lt;-&gt;   Binary Trees Print all “K” Sum paths in a Binary tree &lt;-&gt;   Binary Trees Find LCA in a Binary tree &lt;-&gt;   Binary Trees Find distance between 2 nodes in a Binary tree &lt;-&gt;   Binary Trees Kth Ancestor of node in a Binary tree &lt;-&gt;   Binary Trees Find all Duplicate subtrees in a Binary tree [ IMP ] &lt;-&gt;   Binary Trees Tree Isomorphism Problem &lt;-&gt;   Binary Trees Copy List with Random Pointer     Binary Search Trees Fina a value in a BST &lt;-&gt;   Binary Search Trees Deletion of a node in a BST &lt;-&gt;   Binary Search Trees Find min and max value in a BST &lt;-&gt;   Binary Search Trees Find inorder successor and inorder predecessor in a BST &lt;-&gt;   Binary Search Trees Check if a tree is a BST or not &lt;-&gt;   Binary Search Trees Populate Inorder successor of all nodes &lt;-&gt;   Binary Search Trees Find LCA of 2 nodes in a BST &lt;-&gt;   Binary Search Trees Construct BST from preorder traversal &lt;-&gt;   Binary Search Trees Convert Binary tree into BST &lt;-&gt;   Binary Search Trees Convert a normal BST into a Balanced BST &lt;-&gt;   Binary Search Trees Merge two BST [ V.V.V&gt;IMP ] &lt;-&gt;   Binary Search Trees Find Kth largest element in a BST &lt;-&gt;   Binary Search Trees Find Kth smallest element in a BST &lt;-&gt;   Binary Search Trees Count pairs from 2 BST whose sum is equal to given value “X” &lt;-&gt;   Binary Search Trees Find the median of BST in O(n) time and O(1) space &lt;-&gt;   Binary Search Trees Count BST ndoes that lie in a given range &lt;-&gt;   Binary Search Trees Replace every element with the least greater element on its right &lt;-&gt;   Binary Search Trees Given “n” appointments, find the conflicting appointments &lt;-&gt;   Binary Search Trees Check preorder is valid or not &lt;-&gt;   Binary Search Trees Check whether BST contains Dead end &lt;-&gt;   Binary Search Trees Largest BST in a Binary Tree [ V.V.V.V.V IMP ] &lt;-&gt;   Binary Search Trees Flatten BST to sorted list &lt;-&gt;   Binary Search Trees Check Completeness of a Binary Tree     Binary Search Trees Non-overlapping Intervals     Binary Search Trees Largest BST in Binary Tree https://leetcode.com/problems/maximum-sum-bst-in-binary-tree/   Greedy Activity Selection Problem &lt;-&gt;   Greedy Job SequencingProblem &lt;-&gt;   Greedy Huffman Coding &lt;-&gt;   Greedy Water Connection Problem &lt;-&gt;   Greedy Fractional Knapsack Problem &lt;-&gt;   Greedy Greedy Algorithm to find Minimum number of Coins &lt;-&gt;   Greedy Maximum trains for which stoppage can be provided &lt;-&gt;   Greedy Minimum Platforms Problem &lt;-&gt;   Greedy Buy Maximum Stocks if i stocks can be bought on i-th day &lt;-&gt;   Greedy Find the minimum and maximum amount to buy all N candies &lt;-&gt;   Greedy Minimize Cash Flow among a given set of friends who have borrowed money from each other Optimal Account Balancing   Greedy Minimum Cost to cut a board into squares &lt;-&gt;   Greedy Number of Islands &lt;-&gt;   Greedy Find maximum meetings in one room https://www.lintcode.com/problem/919   Greedy Maximum product subset of an array &lt;-&gt;   Greedy Maximize array sum after K negations &lt;-&gt;   Greedy Maximize the sum of arr[i]*i &lt;-&gt;   Greedy Maximum sum of absolute difference of an array &lt;-&gt;   Greedy Maximize sum of consecutive differences in a circular array &lt;-&gt;   Greedy Minimum sum of absolute difference of pairs of two arrays &lt;-&gt;   Greedy Program for Shortest Job First (or SJF) CPU Scheduling &lt;-&gt;   Greedy Program for Least Recently Used (LRU) Page Replacement algorithm &lt;-&gt;   Greedy Smallest subset with sum greater than all other elements &lt;-&gt;   Greedy Chocolate Distribution Problem &lt;-&gt;   Greedy DEFKIN -Defense of a Kingdom &lt;-&gt;   Greedy DIEHARD -DIE HARD &lt;-&gt;   Greedy GERGOVIA -Wine trading in Gergovia &lt;-&gt;   Greedy Picking Up Chicks &lt;-&gt;   Greedy CHOCOLA –Chocolate &lt;-&gt;   Greedy ARRANGE -Arranging Amplifiers &lt;-&gt;   Greedy K Centers Problem &lt;-&gt;   Greedy Minimum Cost of ropes &lt;-&gt;   Greedy Find smallest number with given number of digits and sum of digits &lt;-&gt;   Greedy Rearrange characters in a string such that no two adjacent are same &lt;-&gt;   Greedy Find maximum sum possible equal sum of three stacks &lt;-&gt;   Greedy Maximum Sub-String after at most K changes https://leetcode.com/problems/maximize-the-confusion-of-an-exam/   BackTracking Rat in a maze Problem &lt;-&gt;   BackTracking Printing all solutions in N-Queen Problem &lt;-&gt;   BackTracking Word Break Problem using Backtracking &lt;-&gt;   BackTracking Remove Invalid Parentheses &lt;-&gt;   BackTracking Sudoku Solver &lt;-&gt;   BackTracking m Coloring Problem &lt;-&gt;   BackTracking Print all palindromic partitions of a string &lt;-&gt;   BackTracking Subset Sum Problem &lt;-&gt;   BackTracking The Knight’s tour problem &lt;-&gt;   BackTracking Tug of War &lt;-&gt;   BackTracking Find shortest safe route in a path with landmines &lt;-&gt;   BackTracking Combinational Sum &lt;-&gt;   BackTracking Find Maximum number possible by doing at-most K swaps &lt;-&gt;   BackTracking Print all permutations of a string &lt;-&gt;   BackTracking Find if there is a path of more than k length from a source &lt;-&gt;   BackTracking Longest Possible Route in a Matrix with Hurdles &lt;-&gt;   BackTracking Print all possible paths from top left to bottom right of a mXn matrix &lt;-&gt;   BackTracking Partition of a set intoK subsets with equal sum &lt;-&gt;   BackTracking Find the K-th Permutation Sequence of first N natural numbers &lt;-&gt;   Stacks &amp; Queues Implement Stack from Scratch &lt;-&gt;   Stacks &amp; Queues Implement Queue from Scratch &lt;-&gt;   Stacks &amp; Queues Implement 2 stack in an array &lt;-&gt;   Stacks &amp; Queues find the middle element of a stack &lt;-&gt;   Stacks &amp; Queues Implement “N” stacks in an Array &lt;-&gt;   Stacks &amp; Queues Check the expression has valid or Balanced parenthesis or not. &lt;-&gt;   Stacks &amp; Queues Reverse a String using Stack &lt;-&gt;   Stacks &amp; Queues Design a Stack that supports getMin() in O(1) time and O(1) extra space. &lt;-&gt;   Stacks &amp; Queues Find the next Greater element &lt;-&gt;   Stacks &amp; Queues The celebrity Problem https://www.youtube.com/watch?v=CiiXBvrX-5A   Stacks &amp; Queues Arithmetic Expression evaluation https://leetcode.com/problems/evaluate-reverse-polish-notation/   Stacks &amp; Queues Evaluation of Postfix expression https://www.youtube.com/watch?v=422Q_yx2yA8   Stacks &amp; Queues Implement a method to insert an element at its bottom without using any other data structure. &lt;-&gt;   Stacks &amp; Queues Reverse a stack using recursion &lt;-&gt;   Stacks &amp; Queues Sort a Stack using recursion &lt;-&gt;   Stacks &amp; Queues Merge Overlapping Intervals &lt;-&gt;   Stacks &amp; Queues Largest rectangular Area in Histogram &lt;-&gt;   Stacks &amp; Queues Length of the Longest Valid Substring &lt;-&gt;   Stacks &amp; Queues Expression contains redundant bracket or not &lt;-&gt;   Stacks &amp; Queues Implement Stack using Queue &lt;-&gt;   Stacks &amp; Queues Implement Stack using Deque &lt;-&gt;   Stacks &amp; Queues Stack Permutations (Check if an array is stack permutation of other) &lt;-&gt;   Stacks &amp; Queues Implement Queue using Stack &lt;-&gt;   Stacks &amp; Queues Implement “n” queue in an array &lt;-&gt;   Stacks &amp; Queues Implement a Circular queue &lt;-&gt;   Stacks &amp; Queues LRU Cache Implementationa &lt;-&gt;   Stacks &amp; Queues Reverse a Queue using recursion &lt;-&gt;   Stacks &amp; Queues Reverse the first “K” elements of a queue &lt;-&gt;   Stacks &amp; Queues Interleave the first half of the queue with second half &lt;-&gt;   Stacks &amp; Queues Find the first circular tour that visits all Petrol Pumps &lt;-&gt;   Stacks &amp; Queues Minimum time required to rot all oranges &lt;-&gt;   Stacks &amp; Queues Distance of nearest cell having 1 in a binary matrix &lt;-&gt;   Stacks &amp; Queues First negative integer in every window of size “k” &lt;-&gt;   Stacks &amp; Queues Check if all levels of two trees are anagrams or not. &lt;-&gt;   Stacks &amp; Queues Sum of minimum and maximum elements of all subarrays of size “k”. &lt;-&gt;   Stacks &amp; Queues Minimum sum of squares of character counts in a given string after removing “k” characters. &lt;-&gt;   Stacks &amp; Queues Queue based approach or first non-repeating character in a stream. &lt;-&gt;   Stacks &amp; Queues Next Smaller Element &lt;-&gt;   Heap Implement a Maxheap/MinHeap using arrays and recursion. &lt;-&gt;   Heap Sort an Array using heap. (HeapSort) &lt;-&gt;   Heap Maximum of all subarrays of size k. &lt;-&gt;   Heap “k” largest element in an array &lt;-&gt;   Heap Kth smallest and largest element in an unsorted array &lt;-&gt;   Heap Merge “K” sorted arrays. [ IMP ] &lt;-&gt;   Heap Merge 2 Binary Max Heaps &lt;-&gt;   Heap Kth largest sum continuous subarrays &lt;-&gt;   Heap Leetcode- reorganize strings &lt;-&gt;   Heap Merge “K” Sorted Linked Lists [V.IMP] &lt;-&gt;   Heap Smallest range in “K” Lists &lt;-&gt;   Heap Median in a stream of Integers &lt;-&gt;   Heap Check if a Binary Tree is Heap &lt;-&gt;   Heap Connect “n” ropes with minimum cost &lt;-&gt;   Heap Convert BST to Min Heap &lt;-&gt;   Heap Convert min heap to max heap &lt;-&gt;   Heap Rearrange characters in a string such that no two adjacent are same. &lt;-&gt;   Heap Minimum sum of two numbers formed from digits of an array &lt;-&gt;   Graph Create a Graph, print it &lt;-&gt;   Graph Implement BFS algorithm &lt;-&gt;   Graph Implement DFS Algo &lt;-&gt;   Graph Detect Cycle in Directed Graph using BFS/DFS Algo &lt;-&gt;   Graph Detect Cycle in UnDirected Graph using BFS/DFS Algo &lt;-&gt;   Graph Search in a Maze &lt;-&gt;   Graph Minimum Step by Knight &lt;-&gt;   Graph flood fill algo &lt;-&gt;   Graph Clone a graph &lt;-&gt;   Graph Making wired Connections &lt;-&gt;   Graph word Ladder &lt;-&gt;   Graph Dijkstra algo &lt;-&gt;   Graph Implement Topological Sort &lt;-&gt;   Graph Minimum time taken by each job to be completed given by a Directed Acyclic Graph &lt;-&gt;   Graph Find whether it is possible to finish all tasks or not from given dependencies &lt;-&gt;   Graph Find the no. of Isalnds &lt;-&gt;   Graph Given a sorted Dictionary of an Alien Language, find order of characters &lt;-&gt;   Graph Implement Kruksal’sAlgorithm &lt;-&gt;   Graph Implement Prim’s Algorithm &lt;-&gt;   Graph Total no. of Spanning tree in a graph &lt;-&gt;   Graph Implement Bellman Ford Algorithm &lt;-&gt;   Graph Implement Floyd warshallAlgorithm &lt;-&gt;   Graph Travelling Salesman Problem &lt;-&gt;   Graph Graph ColouringProblem &lt;-&gt;   Graph Snake and Ladders Problem &lt;-&gt;   Graph Find bridge in a graph &lt;-&gt;   Graph Count Strongly connected Components(Kosaraju Algo) &lt;-&gt;   Graph Check whether a graph is Bipartite or Not &lt;-&gt;   Graph Detect Negative cycle in a graph &lt;-&gt;   Graph Longest path in a Directed Acyclic Graph &lt;-&gt;   Graph Journey to the Moon &lt;-&gt;   Graph Cheapest Flights Within K Stops &lt;-&gt;   Graph Oliver and the Game &lt;-&gt;   Graph Water Jug problem using BFS &lt;-&gt;   Graph Water Jug problem using BFS &lt;-&gt;   Graph Find if there is a path of more thank length from a source &lt;-&gt;   Graph M-ColouringProblem &lt;-&gt;   Graph Minimum edges to reverse o make path from source to destination &lt;-&gt;   Graph Paths to travel each nodes using each edge(Seven Bridges) &lt;-&gt;   Graph Vertex Cover Problem &lt;-&gt;   Graph Chinese Postman or Route Inspection &lt;-&gt;   Graph Number of Triangles in a Directed and Undirected Graph &lt;-&gt;   Graph Minimise the cashflow among a given set of friends who have borrowed money from each other &lt;-&gt;   Graph Two Clique Problem &lt;-&gt;   Trie Construct a trie from scratch &lt;-&gt;   Trie Find shortest unique prefix for every word in a given list &lt;-&gt;   Trie Word Break Problem (Trie solution) &lt;-&gt; Trie Given a sequence of words, print all anagrams together &lt;-&gt;   Trie Implement a Phone Directory &lt;-&gt;   Trie Print unique rows in a given boolean matrix &lt;-&gt;   Dynamic Programming Coin ChangeProblem &lt;-&gt;   Dynamic Programming Knapsack Problem &lt;-&gt;   Dynamic Programming Binomial CoefficientProblem &lt;-&gt;   Dynamic Programming Permutation CoefficientProblem &lt;-&gt;   Dynamic Programming Program for nth Catalan Number &lt;-&gt;   Dynamic Programming Matrix Chain Multiplication &lt;-&gt;   Dynamic Programming Edit Distance &lt;-&gt;   Dynamic Programming Subset Sum Problem &lt;-&gt;   Dynamic Programming Friends Pairing Problem &lt;-&gt;   Dynamic Programming Gold Mine Problem &lt;-&gt;   Dynamic Programming Assembly Line SchedulingProblem &lt;-&gt;   Dynamic Programming Painting the Fenceproblem &lt;-&gt;   Dynamic Programming Maximize The Cut Segments &lt;-&gt;   Dynamic Programming Longest Common Subsequence &lt;-&gt;   Dynamic Programming Longest Repeated Subsequence &lt;-&gt;   Dynamic Programming Longest Increasing Subsequence &lt;-&gt;   Dynamic Programming Space Optimized Solution of LCS &lt;-&gt;   Dynamic Programming LCS (Longest Common Subsequence) of three strings &lt;-&gt;   Dynamic Programming Maximum Sum Increasing Subsequence &lt;-&gt;   Dynamic Programming Count all subsequences having product less than K &lt;-&gt;   Dynamic Programming Longest subsequence such that difference between adjacent is one &lt;-&gt;   Dynamic Programming Maximum subsequence sum such that no three are consecutive &lt;-&gt;   Dynamic Programming Egg Dropping Problem &lt;-&gt;   Dynamic Programming Maximum Length Chain of Pairs &lt;-&gt;   Dynamic Programming Maximum size square sub-matrix with all 1s &lt;-&gt;   Dynamic Programming Maximum sum of pairs with specific difference &lt;-&gt;   Dynamic Programming Min Cost PathProblem &lt;-&gt;   Dynamic Programming Maximum difference of zeros and ones in binary string &lt;-&gt;   Dynamic Programming Minimum number of jumps to reach end &lt;-&gt;   Dynamic Programming Minimum cost to fill given weight in a bag &lt;-&gt;   Dynamic Programming Minimum removals from array to make max –min &lt;= K &lt;-&gt;   Dynamic Programming Longest Common Substring &lt;-&gt;   Dynamic Programming Count number of ways to reacha given score in a game &lt;-&gt;   Dynamic Programming Count Balanced Binary Trees of Height h &lt;-&gt;   Dynamic Programming LargestSum Contiguous Subarray [V&gt;V&gt;V&gt;V IMP ] &lt;-&gt;   Dynamic Programming Smallest sum contiguous subarray &lt;-&gt;   Dynamic Programming Unbounded Knapsack (Repetition of items allowed) &lt;-&gt;   Dynamic Programming Word Break Problem &lt;-&gt;   Dynamic Programming Largest Independent Set Problem &lt;-&gt;   Dynamic Programming Partition problem &lt;-&gt;   Dynamic Programming Longest Palindromic Subsequence &lt;-&gt;   Dynamic Programming Count All Palindromic Subsequence in a given String &lt;-&gt;   Dynamic Programming Longest Palindromic Substring &lt;-&gt;   Dynamic Programming Longest alternating subsequence &lt;-&gt;   Dynamic Programming Weighted Job Scheduling &lt;-&gt;   Dynamic Programming Coin game winner where every player has three choices &lt;-&gt;   Dynamic Programming Count Derangements (Permutation such that no element appears in its original position) [ IMPORTANT ] &lt;-&gt;   Dynamic Programming Maximum profit by buying and selling a share at most twice [ IMP ] &lt;-&gt;   Dynamic Programming Optimal Strategy for a Game &lt;-&gt;   Dynamic Programming Optimal Binary Search Tree &lt;-&gt;   Dynamic Programming Palindrome PartitioningProblem &lt;-&gt;   Dynamic Programming Word Wrap Problem &lt;-&gt;   Dynamic Programming Mobile Numeric Keypad Problem [ IMP ] &lt;-&gt;   Dynamic Programming Boolean Parenthesization Problem &lt;-&gt;   Dynamic Programming Largest rectangular sub-matrix whose sum is 0 &lt;-&gt;   Dynamic Programming Largest area rectangular sub-matrix with equal number of 1’s and 0’s [ IMP ] &lt;-&gt;   Dynamic Programming Maximum sum rectangle in a 2D matrix &lt;-&gt;   Dynamic Programming Maximum profit by buying and selling a share at most k times &lt;-&gt;   Dynamic Programming Find if a string is interleaved of two other strings &lt;-&gt;   Dynamic Programming Maximum Length of Pair Chain &lt;-&gt;   Dynamic Programming Partition Equal Subset Sum https://leetcode.com/submissions/detail/561942165/   Dynamic Programming Target Sum     Bit Manipulation Count set bits in an integer &lt;-&gt;   Bit Manipulation Find the two non-repeating elements in an array of repeating elements &lt;-&gt;   Bit Manipulation Count number of bits to be flipped to convert A to B &lt;-&gt;   Bit Manipulation Count total set bits in all numbers from 1 to n &lt;-&gt;   Bit Manipulation Program to find whether a no is power of two &lt;-&gt;   Bit Manipulation Find position of the only set bit &lt;-&gt;   Bit Manipulation Copy set bits in a range &lt;-&gt;   Bit Manipulation Divide two integers without using multiplication, division and mod operator &lt;-&gt;   Bit Manipulation Calculate square of a number without using *, / and pow() &lt;-&gt;   Bit Manipulation Power Set &lt;-&gt;   Moore voting algorithm Majority Element https://www.youtube.com/watch?v=n5QY3x_GNDg   Moore voting algorithm Majority Element II https://www.youtube.com/watch?v=yDbkQd9t2ig   30 Days Interview Preparation Plan🎯Originally the below sheet was prepared by Raj Vikramaditya A.K.A Striver. I have documented this sheet here in markdown. Day1: (Arrays) Sort an array of 0’s 1’s 2’s without using extra space or sorting algo Repeat and Missing Number Merge two sorted Arrays without extra space Kadane’s Algorithm Merge Overlapping Subintervals Find the duplicate in an array of N+1 integers. Day2: (Arrays) Set Matrix Zeros Pascal Triangle Next Permutation Inversion of Array (Using Merge Sort) Stock Buy and Sell Ro tate Matrix Day3: (Arrays/maths) Search in a 2D matrix Pow(X,n) Majority Element (&gt;N/2 times) Majority Element (&gt;N/3 times) Grid Unique Paths Reverse Pairs (Leetcode) Go through Puzzles from GFG** (Search on own) Day4: (Hashing) 2 Sum problem 4 Sum problem Longest Consecutive Sequence Largest Subarray with 0 sum Count number of subarrays with given XOR (this clearsa lot of problems) Longest substring without repeat Day5: (LinkedList) Reverse a LinkedList Find middle of LinkedList Merge two sorted Linked List Remove N-th node from back of LinkedList Delete a given Node when a node is given. (0(1) solution) Add two numbers as LinkedList Day6: Find intersection point of Y LinkedList Detect a cycle in Linked List Reverse a LinkedList in groups of size k Check if a LinkedList is palindrome or not. Find the starting point of the Loop of LinkedList Flattening of a LinkedList** Rotate a LinkedList Day7: (2-pointer) Clone a Linked List with random and next pointer 3 sum Trapping rainwater Remove Duplicate from Sorted array Max consecutive ones Day8: (Greedy) N meeting in one room Minimum number of platforms required for a railway Job sequencing Problem Fractional Knapsack Problem Greedy algorithm to find minimum number of coins Activity Selection (it i s same as N meeting in one room) Day9 (Recursion): Subset Sums Subset-II Combination sum- Combination sum Palindrome Partitioning K-th permutation Sequence Day10: (Recursion and Backtracking) Print all Permutations of a string/array N queens Problem SudokuSolver M coloring Problem Rat in a Maze 6.Word Break -&gt; print all waysDay11 : (Binary Search) N-th root of an integer (use binary search) (square root, cube root, ..) Matrix Median Find the element that appears once in sorted array, and rest element appears twice (Binary search) Search element in a sorted and rotated array/ find pivot where it is rotated** Median of 2 sorted arrays K-th element of two sorted arrays Allocate Minimum Number of Pages Aggressive Cows Day12: (Bits) (Optional, very rare topic in interviews, but if you have time left, someone mightask) Check if a number if a power of 2 or not in O(1) Count total set bits Divide Integers without / operator Power Set (this is very important) Find MSB in o(1) Find square of a number without using multiplication or division operators.Day13: (Stack and Queue) Implement Stack Using Arrays Implement Queue Using Arrays Implement Stack using Queue (using single queue) Implement Queue using Stack (0(1) amortised method) Check for balanced parentheses Next Greater Element Sort a Stack Day14: Next Smaller Element Similar to previous question next greater element, just do pop the greater elements out .. LRU cache (vvvv. imp) LFU Cache (Hard, can be ignored) 4.Largest rectangle in histogram (Do the one pass solution)Two passOne pass Sliding Window maximum video Implement Min Stack Rotten Orange (Using BFS) Stock Span Problem Find maximum of minimums of every window size10.The Celebrity ProblemDay15: (String) Reverse Words in a String Longest Palindrome in a string Roman Number to Integer and vice versa Implement ATOI/STRSTR Longest Common Prefix Rabin KarpDay16: (String) Prefix Function/Z-Function KMP algo / LPS(pi) array Minimum characters needed to be inserted in the beginning to make it palindromic. Check for Anagrams Count and Say Compare version numbersDay17: (Binary Tree) Inorder Traversal (with recursion and without recursion) Preorder Traversal (with recursion and without recursion) Postorder Traversal (with recursion and without recursion) LeftView Of Binary Tree Bottom View of Binary Tree Top View of Binary Tree**Day18: (Binary Tree) Level order Traversal / Level order traversal in spiral form Height of a Binary Tree Diameter of Binary Tree Check if Binary tree is height balanced or not LCA in Binary Tree Check if two trees are identical or not**Day 19: (Binary Tree) Maximum path sum Construct Binary Tree from inorder and preorder Construct Binary Tree from Inorder and Postorder Symmetric Binary Tree Flatten Binary Tree to LinkedList Check if Binary Tree is mirror of itself or notDay 20: (Binary Search Tree) Populate Next Right pointers of Tree Search given Key in BST Construct BST from given keys. Check is a BT is BST or not Find LCA of two nodes in BST Find the inorder predecessor/successor of a given Key in BST.**Day21: (BinarySearchTree) Floor and Ceil in a BST Find K-th smallest and K-th largest element in BST (2 different Questions) Find a pair with a given sum in BST BST iterator Size of the largest BST in a Binary Tree Serialize and deserialize Binary TreeDay22: (Mixed Questions) Binary Tree to Double Linked List Find median in a stream of running integers. K-th largest element in a stream. Distinct numbers in Window. K-th largest element in an unsorted array. Flood-fill AlgorithmDay23: (Graph) Theory Clone a graph (Not that easy as it looks) DFS BFS Detect A cycle in Undirected Graph/Directed Graph Topo Sort Number of islands (Do in Grid and Graph both) Bipartite CheckDay24: (Graph) Theory SCC(using KosaRaju’s algo) Djisktra’s Algorithm Bellman Ford Algo Floyd Warshall Algorithm MST using Prim’s Algo MST using Kruskal’s AlgoDay25: (Dynamic Programming) Max Product Subarray Longest Increasing Subsequence Longest Common Subsequence 0-1 Knapsack Edit Distance Maximum sum increasing subsequence Matrix Chain MultiplicationDay26: (DP) Maximum sum path in matrix, (count paths, and similar type do, also backtrack to find the maximum path) Coin change Subset Sum Rod Cutting Egg Dropping Word Break Palindrome Partitioning (MCM Variation) Maximum profit in Job schedulingFor core revision&lt;/&gt;Day27: Revise OS notes that you would have made during your sem If not made notes, spend 2 or 3 days and make notes from Knowledge Gate.Day28: Revise DBMS notes that you would have made during your semesters. If not made notes, spend 2 or 3 days and make notes from Knowledge Gate.Day29: Revise CN notes, that you would have made during your sem. If not made notes, spend 2 or 3 days and make notes from Knowledge Gate.Day30: Make a note of how will your represent your projects, and prepare all questions related to tech which you have used in your projects. Prepare a note which you can say for 3-10 minutes when he asks you that say something about the project.System Design – Concepts📚 https://github.com/SamirPaul1/system-design-primer https://www.freecodecamp.org/news/systems-design-for-interviews/ https://github.com/shashank88/system_design " }, { "title": "Computer Networks Notes", "url": "/posts/computer-networks-notes/", "categories": "Computer Science, Computer Networks", "tags": "computer-networks", "date": "2022-10-25 00:00:00 +0530", "snippet": "Chapter 1: Computer Networks and the Internet1.1 What is the Internet?1.1.1 A nuts-and-bolts descriptionThe Internet is a computer networks that interconnects hundreds of millions of computing devi...", "content": "Chapter 1: Computer Networks and the Internet1.1 What is the Internet?1.1.1 A nuts-and-bolts descriptionThe Internet is a computer networks that interconnects hundreds of millions of computing devices through the world. Today not only computers and workstation are being connected to the network, therefore the term computer network may sound a bit dated.All the devices connected to the Internet are called hosts or end systems. End systems are connected together by a network of communication links and packets switches.Different links can transmit data at different rates, with the transmission rate of a link measured in bits/second.When one end system has data to send to another end system, the sending end system segments the data and adds header bytes to each segment. The resulting packages of information, called packets, are then sent through the network to the destination and system where they a reassembled into the original data.A packet switch takes a packet arriving on one of its incoming communication links and forwards that packet on one of its outgoing communication links. The two most prominent types of packets switches are routers and link switches. The sequence of communication links and packet switches traversed by a packet from the sending end system to the receiving end system is known as route or path.End systems access the Internet through Internet Service Providers (ISPs), including residential ISPs (cable or phone company), corporate, university ISPs …Each ISP in itself is a network of packet switches and communication links.Lower tier (which interconnect end-systems) ISPs are interconnected through national and international upper tier ISP. An upper-tier ISP consists of high speed routers interconnected with high-speed fiber-optic links. Each ISP network is managed independently.End systems, packet switches and other pieces of the Internet run protocols that control the sending and receiving of information within the Internet.1.1.2 A Services DescriptionThe Internet can be described as an infrastructure that provides services to applications. These applications (Web, social networks, VoIP…) are said to be distributed since they involve multiple end systems that exchange data with each other.Internet applications run on end systems, not in the packet switches or routers, packet switches facilitate the exchange of data, but they are not concerned with the application that is the source or sink of data.End systems attached to the Internet provide and Application Programming Interface (API) that specifies how a program running on one end system asks the Internet infrastructure to deliver data to a specific destination program running on another end system.1.1.3 What Is a Protocol?All the activity in the Internet that involves two or more communicating remote entities is governed by a protocol.A protocol defines the format and the order of messages exchanged between two or more communicating entities, as weel as the actions taken on the trasmission and/or receipt of a message or other event1.2 The Network EdgeComputers and other devices connected to the Internet are often referred to as end systems as they sit at the edge of the Internet. They are also called hosts as they host, run, applications programs such as a Web Browser or an email client.Hosts are sometimes further divided into two categories: clients and servers. The former being desktop, mobile pcs, smartphones, the latter being powerful machines that store and distribute Web pages, streams…Nowadays most of the servers reside in large data centers1.2.1 Access NetworksThey are the networks that physically connect end systems to the first router on a path from the end system to any other distant end system.Examples: mobile network, national or global ISP, local or regional ISP, home networks enterprise networks.Home Access: DSL, Cable, FITH, Dial-Up and SatelliteToday, the two most prevalent types of broadband residential access are digital subscriber line (DSL) and cable.A residence typically obtains DSL access from the telephone company (telco) that provides its wired local phone access. The customer’s telco is therefore its ISP.DSL modem use the existing telephone lines to exchange data with DSLAMs (digital subscriber line access multiplexer) located in the telco local central office. The DSL modem takes digital data and translates it to high-frequency tones for transmission over telephone wires, these analog signals from many houses are translated back into digital format at the DSLAM. The use of different frequencies allows the phone line to carry a high-speed downstream channel, a medium-speed upstream channel and an ordinary two-way telephone channel.Hundreds or even thousands of households connect to a single DSLAM.DSL: 24 Mbps downstream and 2.5 Mbps upstream (MAX VALUES). Because of the difference between these two values, the access is said to be asymmetric.Cable Internet access makes use of the cable television company’s existing cable television infrastructure. Cable modems connect to CMTS (Cablem Modem Termination System) which does the same job the DSLAM does for phone lines. The access is typically asymmetric.CABLE: 42.8 Mbps downstream and 30.7 Mbps upstream (MAX VALUES).Cable Internet access is a shared broadcast medium: each packet travels downstream on every link to every home and viceversa. For this, if several users are simultaneously using the downstream channel, the actual rate will be significantly lower.Another up-and-coming technology that promises very high speeds is fiber to the home (FTTH). The concept is simple: provide an optical fiber path from the Central Office (CO)Access in the Enterprise and the Home: Ethernet and WiFiOn corporate and university campuses, and increasingly in home settings, a Local Area Network (LAN) is used to connect an end system to the edge router.Ethernet is by far the most prevalent access technology is corporate, university and home networks. Ethernet uses twisted-pair copper wire to connect to an Ethernet switch which is connected into the larger Internet.The Internet is increasingly accessed wirelessly: wireless users transmit/receive packets to/from an access point connected into the enterprise’s network which in turn is connected to the wired Internet.Wide-Area Wireless Access: 3G and LTESmartphones and Tablets employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station operated by the cellular network provider. Third generation (3G) wireless and fourth generation (4G) of wide-area network are being deployed. LTE (“Long-Term Evolution”) has its root in 3G and can potentially achieve rates in excess of 10 Mbps.1.2.2 Physical MediaThe book talks about it in detail but we haven’t talked about it in classA bit, when traveling from source to destination, passes through a series of transmitter-receiver pairs, for each pair, the bit is sent by propagating electromagnetic waves or optical pulses across a physical medium. This can take many shapes and forms and doesn’t have to be of the same type for each transmitter-receiver pair along the path.Physical media fall into two categories: guided media: the waves are guided along a solid medium (fiber-optic cable, twisted-pair copper wire, coaxial cable) unguided media: the waves propagate in the atmosphere and in outer space (wireless LAN, digital satellite channel)1.3 The Network Core1.3.1 Packet SwitchingIn a network application, end systems exchange messages with each other. To send a message from a source end system to a destination end system, the source breaks long messages into smaller chunks of data known as packets.Between source and destination, each packet travels through communication links and packet switches (for which there are two predominant types, routers and link-layer switches).Packets are transmitted over each communication link at a rate equal to the full transmission rate of the link. So, if a source end system or a packet switch is send a packet of L bits over a link with transmission rate R bits/sec, then the time to transmit the packet is L/R seconds.Store-and-forward TransmissionMost packet switches use store-and-forward transmission at the inputs to the links. Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. The link must buffer (“store”) the packet’s bits and only after the router has received all of the packet’s bits can it begin to transmit (“forward”) the packet onto the outbound link.Queuing Delays and Packet LossEach packet switch has multiple links attached to it. For each attached link, the packet switch has an output buffer (or output queue) which stores packets that the router is about to send into that link.If an arriving packet needs to be transmitted onto a link but finds the link busy with the transmission of another packet, the arriving packet must wait in the output buffer. Thus, packets suffer output buffer queuing delays which are variable and depend on the level of congestion in the network. Since the amount of buffer space is finite, an arriving packet may find the buffer completely full. In this case, packet loss will occur, either the arriving packet or one of the already queued packets will be dropped.Forwarding tables and routing protocolsIn the Internet, every end system has an address called an IP address. When a source end system wants to send a packet to a destination end system, the source includes the destination’s IP address in the packet’s header.Each router has a forwarding table that maps destination addresses (or portions of the destination addresses) to that router’s outbound links. When a packet arrives at the router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link.A number of special routing protocols are used to automatically set the forwarding tables.1.3.2 Circuit SwitchingIn circuit-switched networks, the resources needed along a path(buffers, link transmission rate) to provide for communication between the end systems are reserved for the duration of the communication sessions.When two hosts want to communicate, the network establishes a dedicated end-to-end connection between them.Multiplexing in Circuit-Switched NetworksA circuit in a link is implemented with either frequency-division multiplexing (FDM) or time-division multiplexing (TDM).With FDM, the frequency spectrum of a link is divided up among the connections established across the link. The width of the band is called the bandwidth.For a TDM link, time is divided into frames of fixed duration, and each frame is divided into a fixed number of time slots.Packet Switching Versus Circuit SwitchingPacket switching is more flexible, uses resources efficiently and is simpler to implement (even if it requires congestion control).Circuit switching offers performance guarantees but uses resources inefficiently1.3.3 A Network of NetworksTo create the Internet, ISPs must be interconnected, thus creating a network of networks.Much of the evolution of the structure of the Internet is driven by economics and national policy, rather than by performance consideration.Today’s Internet is complex, consisting of a dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs are diverse in their coverage, with some spanning multiple continents and oceans, and others limited to narrow geographic regions. The lower-tier ISPs connect to the higher-tier ISPs and the higher-tier ISPs interconnect with one another. Users and content providers are customers of lower-tier ISPs and lower-tier ISPs are customers of higher-tier ISPs. Recently, major content providers (Google) have also created their own networks and connect directly into lower-tier ISPs where possible.1.4 Delay, Loss and Throughput in Packet-Switched NetworksComputer networks necessarily constrain throughput (the amount of data per second that can be transferred) between end system, introduce delays between end systems and can actually lose packets.1.4.1 Overview of Delay in Packet-Switched networksAs a packet travels from one node (host or router) to the subsequent host along his path, it suffers from several types of delays at each node along the path.Types of DelayProcessing DelayThe processing delay consists of the time required to examine the packet’s header and determine where to direct the packet. It may also include other factors, such as the time needed to check for bit-level errors occurred during transmission.They typically are of the order of microseconds or less.After processing the packet is sent to the queue preceding the link to the next routerQueuing DelayAt the queue, the packet experiences a queuing delay as it waits to be transmitted onto the link. It depends on the number of earlier-arriving packets, therefore if the queue is empty, then the packet’s queuing delay will be 0.Typically of the order of microseconds or milliseconds.Transmission delaysIf the length of the packet is L bits, and the transmission rate of the link is R bits/sec, then the transmission delay is L/R.This is the amount of time required to push (transmit) all of the packet’s bits into the link.Typically on the order of microseconds to milliseconds.Propagation DelayThe time required to propagate a bit from the beginning of the link to the next router is the propagation delay. The bit propagates at the propagation speed of the link, which depends on the physical medium of the link.The propagation delay is the distance between two routers divided by the propagation speed of the link.Total nodal delayit is the summation of the previous delays1.4.2 Queuing Delay and Packet LossThe queuing delay depends can vary from packet to packet, therefore when characterizing queuing delay, one typically uses statistical measures, such as average queuing delay, variance of queuing delay, and the probability that the queuing delay exceeds some specified value.Packet LossA queue preceding a link has finite capacity. If a packet finds a full queue, then the router will drop it, the packet will be lost.The fraction of lost packets increases as the traffic intensity increases.1.4.3 End-to-End DelayLet’s now consider the total delay, from source to destination (not only the nodal delay). Let’s suppose there are N-1 routers between the source host and the destination host, then the nodal delays accumulate and give an end-to-end delay:d(end_end) = N * [d(proc) + d(queue) + d(trans) + d(prop)]1.4.4 Throughput in Computer NetworksAnother critical performance measure in computer networks is end-to-end throughput.The instantaneous throughput at any instant of time is the rate (in bits/sec) at which host B is receiving a file.If the file consists of F bits and the transfers takes T seconds to transfer the whole file, then the average throughput of the file is F/T bits/sec.For a simple two-link network, the throughput is the min of all the throughputs, that is the transmission rate of the bottleneck link.Therefore, the constraining factor for throughput in today’s Internet is typically the access network.1.5 Protocol Layers and Their Service Models1.5.1 Layered ArchitectureA layered architecture allows us to discuss a well-defined, specific part of a large and complex system. This simplification itself is of considerable value by providing modularity, making it much easier to change the implementation of the service provided by the layer: as long as the layer provides the same service to the layer above it, and uses the same services from the layer below it, the remainder of the system remains unchanged when a layer’s implementation is changed.Protocol LayeringTo provide structure to the design of network protocols, the network designers organize protocols in layers. Each protocol belongs to one of the layers. We are interested in the services that a layer offers to the layer above, service model of a layer.When taken together, the protocols of the various layers are called the protocol stack. The Internet protocol stack consists of five layers: Application Transport Network Link PhysicalApplication LayerWhere network applications and their applications-layer protocols reside.The Internet’s application layer includes many protocols: HTTP, SMTP, FTP, DNS.An application-layer protocol is distributed over multiple end systems, with the application in one end system using the protocol to exchange packets of information with the application in another end system. This packet of information at the application layer is called message.Transport LayerIt transports application-layer messages between application endpoints.In the Internet there are two transport protocols: TCP and UDP.TCP provides a connection-oriented service to its application: the service includes guaranteed delivery of application-layer messages to the destination and flow control unit. TCP also breaks long messages into shorter segments and provides a congestion-control mechanism, so that a source throttles its transmission rate when the network is congested.HTTP and SMTP use TCPUDP provides a connectionless service to its applications: it’s a no-frills service that provides no guarantees, no reliability, no flow control and no congestion control.A transport-layer packet is called segmentSkype uses UDP (speed required)Network LayerIt is responsible for moving network-layer packets known as datagrams from one host to another.The Internet’s network layer includes the IP Protocol. There is only one IP Protocol and all the Internet components that have a network layer must run it.The Internet’s network layer also contains routing protocols that determine the routes that datagrams take between sources and destinations.The Internet has many routing protocols.Often it is simply referred to as the IP protocols, forgetting that it includes routing too.Link LayerTo move a packet from one node to the next, the network layer relies on the services of the link layer.The services provided by the link layer depend on the specific link-layer protocol that is employed over the link.Examples are Ethernet, WiFi.We will refer to the link-layer packets as framesPhysical LayerThe job of the physical layer is to move the individual bits within the frame from one node to the next.The protocols are link dependent and further depend of the actual transmission medium of the link.1.5.2 EncapsulationRouters and link-layer switches are both packet switches but routers and link-layer switches do not implement all of the layers in the protocol stack: link-layer switches implement Physical and Link while router add the Network Layer too.From the Application Layer, the message passes to the transport layer, which appends additional information to it (the Header) that will be used by the receiver-side transport layer. The transport layer then adds its own header and passes the datagram to the link layer which adds it own link-layer header information.Thus, we see that at each layer, a packet has two types of fields: header fields and a payload field, the payload typically being the packet from the layer above.The process of encapsulation can be more complex: for example a large message may be divided into multiple transport-layer segments, which will be divided into multiple datagrams….1.6 Networks Under AttackMalwareAlong with all the good files we exchange on the Internet, come malicious software, collectively known as malware that can also enter and infect our devices.Once a device infected, the malware can do all kinds of evil things: deleting files, install spyware…A compromised host may also be enrolled in a network of thousands of similarly compromised devices, known as botnet which can be used for spam or distributed denial-of-service.Much of the malware is self-replicating: it seeks entry into other hosts from the infected machines. Malware can spread in the from of a virus or a worm. Viruses are malware that requires some form of user interaction to infect the user’s device. Worms are malware that can enter a device without any explicit user interaction.DoSDenial-of-Service attacks render a network, host, or other piece of infrastructure unusable by legittimate users. Most of them fall into one of the three categories: Vulnerability Attack: a few well-crafted messages are sent to a vulnerable application or operating system running on the targeted host. The service might stop or the host might crash. Bandwidth flooding: a deluge of packets is sent to the targeted host, so many packets that the target’s access link becomes clogged preventing legitimate packets from reaching the server Connection flooding: a large number of half-open or fully open TCP connections are established at the targeted host, which can become so bogged down that it stops accepting legitimate connections.In a distributed DoS (DDoS) attack the attacker controls multiple sources and has each source blast traffic at the target.SniffingA passive receiver can record a copy of every packet that passes through the network. It is then called a packet sniffer.Because packet sniffers are passive (they do not inject packets into the channel), they are difficult to detect. Some of the best defenses against packet sniffing involve cryptography.SpoofingThe ability to inject packets into the Internet with a false source address is known as IP Spoofing and is but one of many ways in which one user can masquerade as another user.To solve this problem we will need end-point authentication.The history of the Internet shaped is structureThe Internet was originally designed to be based on the model of a group of mutually trusting users attached to a transparent network, a model in which there is no need for security. Many aspects of the original Internet architecture deeply reflect this notion of mutual trust, such as the ability for one to send a packet to any other user is the default rather than a requested/granted capability.However today’s Internet certainly does not involve “mutually trusted users”: communication among mutually trusted users is the exception rather the rule.History of Computer Networking and the InternetChapter 2: Application LayerNetwork applications are the raison d’être of a computer network. They include text email, remote access to computers, file transfers, the WorldWideWeb (mid 90s), web searching, e-commerce, Twitter/Facebook, Amazon, Netflix, Youtube, WoW…2.1 Principles of Network ApplicationsAt the core of network application development is writing programs that run on different end systems and communicate with each over the network. The programs running on end systems might be different (server-client architecture) or identical (Peer-to-Peer architecture).Importantly we write programs that run on end systems/hosts, not on network-core devices (routers/link-layer switches).2.1.1 Network Application ArchitecturesFrom the application developer’s perspective, the network architecture is fixed and provides a specific set of services to applications.The application architecture, on the other hand, is chosen by him. In choosing the application architecture, a developer will likely draw one of the two predominant architectural paradigms used in modern network applications: Client-server architecture: there is an always on host, called the server which serves requests from many other hosts, called clients: [Web Browser and Web Server]. Clients do not communicate directly with each other. The server has a fixed, well-known address, called an IP address that clients use to connect to him. Often, a single server host is incapable of keeping up with all the requests from clients, for this reason, a data center, housing a large number of hosts, is often used to create a powerful virtual server (via proxyin). P2P architecture: there is minimal or no reliance on dedicated servers in data centers, the application exploits direct communication between pairs of intermittently connected bots, called peers. They are end systems owned and controlled by users. [Bittorrent, Skype]. P2P applications provide self-scalability (the network load is distributed) They are also cost-effective since they don’t require significant infrastructure and server bandwidth. P2P face challenges: ISP Friendly (asymmetric nature of residential ISPs) Security Incentives (convincing users to participate) Some applications have hybrid architectures, such as for many instant messaging applications: a server keeps track of the IP addresses of users, but user-to-user messages are sent directly between users.2.1.2 Processes CommunicatingIn the jargon of operating systems, it’s not programs but processes that communicate. A process can be thought of as a program that is running within an end system.Processes on two different end systems communicate with each other by exchanging messages across the computer network: a sending process creates and sends messages into the network, a receiving process receives these messages and possibly responds by sending messages back.Client and Server ProcessesA network application consists of pairs of processes that send messages to each other over a network. For each pair of communicating processes we label: the process that initiates the communication as the client [web browser] the process that waits to be contacted to begin the session as the server [web server]This labels stand even for P2P applications in the context of a communication session.The Interface Between the Process and the Computer NetworkA process sends messages into, and receives messages from, the network through a software interface called a socket.A socket is the interface between the application layer and the transport layer within a host, it is also referred to as the Application Programming Interface (API) between the application and the network.The application developer has control of everything on the application-layer of the socket but has little control of the transport-layer side of the socket. The only control that he has over the transport-layer is: The choice of the transport protocol Perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizesAddressing ProcessesIn order for a process running on one host to send packets to a process running on another host, the receiving process needs to have an address. To identify the receiving processes, two pieces of information need to be specified: The address of the host. In the Internet, the host is identified by its IP Address, a 32-bit (or 64) quantity that identifies the host uniquely. An identifier that specifies the receiving process in the destination host: the destination port number. Popular applications have been assigned specific port numbers (web server -&gt; 80)2.1.3 Transport Services Available to ApplicationsWhat are the services that a transport-layer protocol can offer to applications invoking it?Reliable Data TransferFor many applications, such as email, file transfer, web document transfers and financial applications, packet’s drops and data loss can have devastating consequences. If a protocol provides guarantees that the data sent is delivered completely and correctly, it is said to provide reliable data transfer. The sending process can just pass its data into the socket and know with complete confidence that the data will arrive without errors at the receiving process.ThroughputA transport-layer protocol could provide guaranteed available throughput at some specific rate. Applications that have throughput requirements are said to be bandwidth-sensitive applications.TimingA transport-layer protocol can also provide timing guarantees. Example: guarantees that every bit the sender pumps into the socket arrives at the receiver’s socket no more than 100 msec later, interesting for real-time applications such as telephony, virtual environments…SecurityA transport-layer protocol can provide an application with one or more security services. It could encrypt all data transmitted by sending process and in the receiving host decrypt it.2.1.4 Transport Services Provided by the InternetThe Internet makes two transport protocols available to applications: TCP and UDP.TCP ServicesTCP includes a connection-oriented service and a reliable data transfer service: Connection-oriented service: client and server exchange transport-layer control information before the application-level messages begin to flow. This so-called handshaking procedure alerts the client and server, allowing them to prepare for an onslaught of packets. Then a TCP connection is said to exist between the sockets of the two processes. When the application finishes sending messages, it must tear down the connectionSECURING TCPNether TCP nor UDP provide encryption. Therefore the Internet community has developed an enhancement for TCP called Secure Sockets Layer (SSL), which not only does everything that traditional TCP does but also provides critical process-to-process security services including encryption, data integrity and end-point authentication. It is not a third protocol, but an enhancement of TCP, the enhancement being implemented in the application layer in both the client and the server side of the application (highly optimized libraries exist). SSL has its own socket API, similar to the traditional one. Sending processes passes cleartext data to the SSL socket which encrypts it. Reliable data transfer service The communicating processes can rely on TCP to deliver all data sent without error and in the proper order.TCP also includes a congestion-control mechanism, a service for the general welfare of the Internet rather than for the direct benefit of the communicating processes. It throttles a sending process when the network is congested between sender and receiver.UDP ServicesUDP is a no-frills, lightweight transport protocol, providing minimal services. It is connectionless, there’s no handshaking. The data transfer is unreliable: there are no guarantees that the message sent will ever reach the receiving process. Furthermore messages may arrive out of order. UDP does not provide a congestion-control mechanism neither.Services Not Provided by Internet Transport ProtocolsThese two protocols do not provide timing or throughput guarantees, services not provided by today’s Internet transport protocols. We therefore design applications to cope, to the greatest extent possible, with this lack of guarantees.2.1.5 Application-Layer ProtocolsAn application-layer protocol defines how an application’s processes, running on different end systems, pass messages to each other. It defines: The type of the messages exchanged (request/response) The syntax of the various message types The semantics of the fields (meaning of the information in fields) The rules for determining whem and how a process sends messages and responds to messages2.2 The Web and HTTPIn the early 1990s, a major new application arrived on the scene: the World Wide Web (Berners-Lee 1994), the first application that caught the general public’s eye.The Web operates on demand: users receives what they want, when they want it.It is enormously easy for an individual to make information available over the web, hyperlinks and search engines help us navigate through the ocean of web sites…2.2.1 Overview of HTTPThe HyperText Transfer Protocol (HTTP), the Web’s application-layer protocol is a the heart of the Web. It is implemented in two programs: a client program and a server program.The two programs talk to each other by exchanging HTTP messages.A Web page (or document) consists of objects. An object is simply a file (HTML file, jpeg image…) that is addressable by a single URL.Most Web pages consist of a base HTML file and several referenced objects. The HTML file references the other objects in the page with the objects’ URLs.Each URL has two components: the hostname of the server that houses the object and the object’s path name.Web Browsers implement the client side of HTTP.HTTP uses TCP as its underlying transport protocol.The server sends requested files to clients without storing any state information about the client: it is a stateless protocol2.2.2 Non-Persistent and Persistent ConnectionsIn many Internet applications, the client and server communicate for an extended period of time, depending on the application and on how the application is being used, the series of requests may be back-to-back, periodically at regular intervals or intermittently. When this is happening over TCP, the developer must take an important decision: should each request/response pair be sent over a separate TCP connection or should all of the requests and their corresponding responses be sent over the same TCP connection?In the former approach, the application is said to use non-persistent connections and in the latter it is said to use persistent connectionsBy default HTTP uses non-persistent connections but can be configured to be use persistent connections.To estimate the amount of time that elapses when a client requests the base HTML file until the entire file is received by the client we define the round-trip time (RTT) which is the time it takes for a small packet to travel from client to server and then back to the client.HTTP with Non-Persistent ConnectionsFor the page and each object it contains, a TCP connection must be opened (handshake request, handshake answer), we therefore observe an addition RTT, and for each object we will have a request followed by the replyThis model can be expensive on the server side: a new connection needs to be established for each requested object, for each connection a TCP buffer must be allocated along some memory to store TCP variables.HTTP with Persistent ConnectionsThe server leaves the TCP connection open after sending a response, subsequent requests and responses between the same client and server will be sent over the same connection. In particular an entire web page (text + objects) ca be sent over a single persistent TCP connection, multiple web pages residing on the same server can be sent from the server to the same client over a single persistent TCP connection.These requests can be make back-to-back without waiting for replies to pending requests (pipelining).When the server receives back-to-back requests, it sends the objects back-to-back.If connection isn’t used for a pre-decided amount of time, it will be closed.2.2.3 HTTP Message FormatTwo types of HTTP messages:HTTP Request MessageGET /somedir/page.html HTTP/1.1Host: www.someschool.eduConnection: closeUser-agent: Mozilla/5.0Accept-language: fr Ordinary ASCII text First line: request line Other lines: header lines the first lines has 3 fields: method field, URL field, HTTP version field: method field possible values: GET, POST, HEAD, PUT, DELETE The majority of HTTP requests use the GET method, used to request an object.The entity body (empty with GET) is used by the POST method, for example for filling out forms. The user is still requesting a Web page but the specific contents of the page depend on what the user entered into the form fields. When POST is used, the entity body contains what the user entered into the form fields.Requests can also be made with GET including the inputted data in the requested URL.The HEAD method is similar to GET, when a server receives it, it responds with an HTTP message but it leaves out the requested object. It is often used for debugging.PUT is often used in conjunction with web publishing tools, to allow users to upload an object to a specific path on the web servers.Finally, DELETE allows a user or application to delete an object on a web server.HTTP Response MessageA typical HTTP response message:HTTP/1.1 200 OKConnection: closeDate: ...Server: ...Last-Modified: ...Content-Length: ...Content-Type: text/html(data data data data data ...) Status line: protocol version, status code, corresponding status message six header lines: \t- the connection will be closed after sending the message date and time when the response was created (when the server retrieves the object from the file system, insert object in the message, sends the response message) Type of the server / software Last modified: useful for object caching Content-Length: number of bytes in the object Content-Type entity body: contains the requested object itself (data)Some common status codes: 200 OK: request succeeded, information returned 301 Moved Permanently: the object has moved, the new location is specified in the header of the response 400 Bad Request: generic error code, request not understood 404 Not Found: The requested document doesn’t exist on the server 505 HTTP Version Not Supported: The requested HTTP protocol version is not supported by the server2.2.4 User-Server Interaction: CookiesAn HTTP server is stateless in order to simplify server design and improves performances. A website can identify users using cookies.Cookie technology has 4 components: Cookie header in HTTP response message Cookie header in HTTP request message Cookie file on the user’s end-system managed by the browser Back-end database at the WebsiteUser connects to website using cookies: Server creates a unique identification number and creates an entry in its back-end database indexed by the identification number -server responds to user’s browser including in the header: Set-cookie: identification number The browser will append to the cookie file the hostname of the server and the identification number header Each time the browser will request a page, it will consult the cookie file, extract the identification number for the site and put a cookie header line including the identification numberThe server can track the user’s activity: it knows exactly what pages, in which order and at what times that identification number has visited. This is also why cookies are controversial: a website can learn a lot about a user and sell this information to a third party.Therefore cookies can be used to create a user session layer on top of stateless HTTP.2.2.5 Web CachingA Web cache, also called proxy server is a network entity that satisfies HTTP requests on behalf of an origin Web server. It has its own disk storage and keeps copies of recently requested objects in this storage. The browser establishes a TCP connection to the web cache, sending an HTTP request for the object to the Web cache. The web cache checks to see if it has a copy of the object stored locally. If yes, it will return it within an HTTP response message to the browser. If not, the Web cache opens a TCP connection to the origin server, which responds with the requested object. The Web caches receives the object, stores a copy in its storage and sends a copy, within an HTTP response message, to the browser over the existing TCP connection.Therefore a cache is both a server and a client at the same time.Usually caches are purchased and installed by ISPs.They can substantially reduce the response time for a client request and substantially reduce traffic on an institution’s access link to the Internet.Through the use of Content Distribution Networks (CDNs) web caches are increasingly playing an important role in the Internet. A CDN installs many geographically distributed caches throughout the Internet, localizing much of the traffic.2.2.6 The Conditional GETCaches introduce a new problem: what if the copy of an object residing in the cache is stale?The conditional GET is used to verify that an object is up to date.An HTTP request message is a conditional get if the request message uses the GET method the request message includes an If-modified-since: header line.A conditional get message is sent from the cache to server which responds only if the object has been modified.2.5 DNS - The Internet’s Directory ServiceOne identifier for a host is its hostname [cnn.com, www.yahoo.com]. Hostnames are mnemonic and therefore used by humans. Hosts are also identified by IP addresses.2.5.1 Services provided by DNSRouters and use IP addresses. The Internet’s domain name system (DNS) translates hostnames to IP addresses. The DNS is: A distributed database implemented in a hierarchy of DNS Servers An application-layer protocol that allows hosts to query the distributed database.DNS servers are often UNIX machines running the Berkeley Internet Name Domaine (BIND) software.DNS runs over UDP and uses port 53It is often employed by other application-layer protocols (HTTP, FTP…) to translate user-supplied hostnames to IP addresses.How it works: The user machine runs the client side of the DNS application The browser extracts www. xxxxx . xxx from the URL and passes the hostname to the client side of the DNS application The DNS sends a query containing the hostname to a DNS server The DNS client eventually receives a reply including the IP address for the hostname The browser can initiate a TCP connection.DNS adds an additional delayDNS provides other services in addition to translating hostnames to IP addresses: host aliasing: a host with a complicated hostname can have more alias names. The original one is said to be a canonical hostname. mail server aliasing: to make email servers’ hostnames more mnemonic. This also allows for an e-mail server and an Web server to have the same hostname. load distribution: replicated servers can have the same hostname. In this case, a set of IP addresses is associated with one canonical hostname. When a client make a DNS query for a name mapped to a set of addresses, the server responds with the entire set, but rotates the ordering within each reply.2.5.2 Overview of How DNS WorksFrom the perspective of the invoking application in the user’s host, DNS is a black box providing a simple, straightforward translation service.Having one single global DNS server would be simple, but it’s not realistic because it would a single point of failure, it would have an impossible traffic volume, it would be geographically too distant from some querying clients, its maintenance would be impossible.A Distributed, Hierarchical DatabaseThe DNS uses a large number of servers, organized in a hierarchical fashion and distributed around the world.The three classes of DNS servers: Root DNS servers: In the Internet there are 13 root DNS servers, most hosted in North America, each of these is in reality a network of replicated servers, for both security and reliability purposes (total: 247) Top-level domain (TLD) servers: responsible for top-level domains such as com org net edu and govand all of the country top-level domains uk fr jp Authoritative DNS servers: every organization with publicly accessible hosts must provide publicly accessible DNS records that map the names of those hosts to IP addresses. An organization can choose to implement its own authoritative DNS server or to pay to have the records stored in an authoritative DNS of some service provider.Finally there are local DNS servers which is central to the DNS architecture. They are hosted by ISPs. When a hosts connects to one of these, the local DNS server provides the host with the IP addresses of one or more of its local DNS servers. Requests can ho up to the root DNS servers and back down.We can have both recursive and iterative queries.In recursive queries the user sends the request its nearest DNS which will ask to a higher-tier server, which will ask to lower order… the chain goes on until it reaches a DNS that can reply, the reply will follow the inverse path that the request had.In iterative queries the same machine sends requests and receives replies.Any DNS can be iterative or recursive or both.DNS CachingDNS extensively exploits DNS caching in order to improve the delay performance and to reduce the number of DNS messages ricocheting around the Internet.In a query chain, when a DNS receives a DNS reply it can cache the mapping in its local memory.2.5.3 DNS Records and MessagesThe DNS servers that implement the DNS distributed database store resource records (RRs) including RRs that provide hostname-to-IP address mappings.Each DNS reply messages carries one or more resource records.A resource record is a four-tuple that contains the fields: (Name, Value, Type, TTL)TTL is the time to live of the resource record (when a resource should be removed from a cache). The meaning of Name and Value depend on Type:| Type | Name | Value ||— | — | — || A \t| a hostname \t| IP address \t|| NS \t| a domain (foo.com) \t| hostname of an authoritative DNS server which knows how to obtain the IP addresses for hosts in the domain. Used to route queries further along in the query chain \t|| CNAME \t| a alias name \t| canonical hostname for the name in Name \t|| MX \t| alias hostname \t| canonical hostname of a mail server that has an alias hostname Name \t|DNS MessagesThe only types of DNS messages are DNS queries and reply messages. They have the same format: first 12 bytes in the header section: 16-bit number identifying the query, which will be copied into the reply query so that the client can match received replies with sent queries. 1 bit query/reply flag (0 query, 1 reply). 1 bit flag authoritative flag set in reply messages when DNS server is an authoritative for a queried name. 1 bit recursion flag if the client desires that the server performs recursion when it doesn’t have a record, 1 bit recursion-available field is set in the reply if the DNS server supports recursion question section: information about the query: name field containing the name being queried, type field answer section: resource records for the name originally queried: Type, Value, TTL. Multiple RRs can be returned if the server has multiple IP addresses authority section: records for other authoritative servers. additional section: other helpful records: canonical hostnames…Inserting Records into the DNS DatabaseWe created a new company. Next we register th domain name newcompany.com at a registrar. A registrar is a commercial entity that verifies the uniqueness of the domain name, enters it into the DNS database and collects a small fee for these services. When we register the address, we need the provide the registrar with the IP address of our primary and secondary authoritative DNS servers, that will make sure that a Type NS and a Type A records are entered into the TLD com servers for our two DNS servers.Focus on security: DNS vulnerabilities DDoS bandwidth-flooding attack MITM: the mitm answers queries with false replies tricking the user into connecting to another server. The DNS infrastructure can be used to launch a DDoS attack against a targeted hostTo date, there hasn’t been an attack that that has successfully impeded the DNS service, DNS has demonstrated itself to be surprisingly robust against attacks. However there have been successful reflector attacks, these can be addressed by appropriate configuration of DNS servers.2.6 Peer-to-Peer Applications2.6.1 File DistributionIn P2P file distribution, each peer can redistribute any portion of the file it has received to any peers, thereby assisting the server in the distribution process. As of 2012 the most popular P2P file distribution protocol is BitTorrent, developed by Bram Cohen.Scalability of P2P architecturesDenote the upload rate of the server’s access link by $u_s$, the upload rate of the ith peer’s access link by $u_i$ and the download rate of the ith access link by $d_i$, tthe size of the to be distributed in bits ()Comparison client-server and P2P.Client-ServerThe server must transmit one copy of the file to N peers, thus it transmits NF *bits. The time to distribute the file is at least NF/u_s.Denote $d_min = min{ d_i }$ the link with the slowest download rate cannot obtain all *F bits in less than $F/d_min$ secondsTherefore:\\(D_{cs} \\geq \\max \\left\\{ \\frac{NF}{u_s} , \\frac{F}{d_min} \\right\\}\\)P2PWhen a peer receives some file data, it can use its own upload capacity to redistribute the data to other peers. At the beginning of the distribution only the server has the file. It must send all the bits at least once. $D \\geq F/u_s$ The peer with the lowest download rate cannot obtain all F bits of the file in less than $F/d_min $ seconds. The total upload capacity of the system is equal to the summation of the upload rates of the server and of all the peers. The system must upload F bits to N peers, thus delivering a total of NF bits which can’t be done faster that $u_total$.We obtain:\\(D_{P2P} = \\max \\left\\{ \\frac{F}{u_s} , \\frac{F}{d_{min}} , \\frac{NF}{u_s + \\sum_{i=1}^N u_j} \\right\\}\\)BitTorrentIn BitTorrent the collection of all peers participating in the distribution of a particular file is called a torrent. Peers in a torrent download equal-size chunks of the file from one another with a typical chunk size of 256 KBytes.At the beginning a peer has no chunks, it accumulates more and more chunks over time. While it downloads chunks it also uploads chunks to other peers. Once a peer has acquired the entire file it may leave the torrent or remain in it and continue to upload chunks to other peers (becoming a seeder). Any peer can leave the torrent at any time and later rejoin it at anytime as well.Each torrent has an infrastructure node called a tracker: when a peer joins a torrent, it registers itself with the tracker and periodically informs it that it is still in the torrent. The tracker keeps track of the peers participating in the torrent. A torrent can have up to thousands of peers participating at any instant of time.User joins the torrent, the tracker randomly selects a subset of peers from the set of participating peers. User establishes concurrent TCP connections with all of these peers, called neighboring peers. The neighboring peers can change over time.The user will ask each of his neighboring peers for the list of chunks they have (one list per neighbor).The user starts downloading the chunks that have the fewest repeated copies among the neighbors (rares first technique). In this manner the rarest chunks get more quickly redistributed, roughly equalizing the numbers of copies of each chunk in the torrent.Every 10 seconds the user measures the rate at which she receives bits and determines the four peers that are sending to her at the highest rate. It then reciprocates by sending chunks to these same four peers. The four peers are called unchocked. Every 30 seconds it also choses one additional neighbor and sends it chunks. These peers are called optmistically unchocked.2.6.2 Distributed Hash Tables (DHTs)How to implement a simple database in a P2P network?In the P2P system each peer will only hold a small subset of the totality of the (key, value) pairs. Any peer can query the distributed database with a particular key, the database will locate the peers that have the corresponding pair and return the pair to querying peer. Any peer can also insert a new pair in the databse. Such a distributed database is referred to as a distributed hash table (DHT).In a P2P file sharing application a DHT can be used to store the chunks associated to the IP of the peer in possession of them.An approach:Let’s assign an identifier to each peer, where the identifier is an integer in the range [0, 2^n -1] for some fixed n. Such an identifier can be expressed by a n-bit representation. A hash function is used to transform non-integer values into integer values. We suppose that this function is available to all peers.How to assign keys to peers? We assign each (key,value) pair to the peer whose identifier is the closest to key, which is the identifier defined as the closest successor of the key.To avoid having each peer keeping track of all other peers (scalability issue) we useCircular DHTIf we organize peers into a circle, each peer only keeps track of its immediate successor and predecessor (modulo 2^n). This circular arrangement of peers is a special case of an overlay network: the peers form an abstract logical network which resides above the “underlay” computer network, the overlay links are not physical but virtual liaisons between pairs of peers. A single overlay link typically uses many physical links and physical routers in the underlying network.In the circle a peer asks “who is responsible for key k?” and it sends the message clockwise around the circle. Whenever a peer receives such message, it knows the identifier of its predecessor and predecessor, it can determine whether it is responsible (closest to) for the key in question. If not, it passes the message to its successor. When the message reaches the peer responsible for the key, it can send a message back to the querying peer indicating that it is responsible for that key.Using this system N/2* messages are sent on average (N = number of peers). In designing a DHT there is always a tradeoff between the number of neighbors for each peer and the number of DHT messages needed to resolve a single query. (1 message if each peer keeps track of all other peers; N/2 messages if each knows only 2 neighbors).To improve our circular DHT we could add shortcuts so that each peer not only keeps track of its immediate successor and predecessor but also of relatively small number of shortcut peers scattered around the circle.How many shortcut neighbors? Studies show that DHT can be designed so that the number of neighbors per peer as well as the number of messages per query is O(log *N*) (N the number of peers).Peer ChurnIn a P2P system, a peer can come or go without warning. To keep the DHT overlay in place in presence of a such peer churn we require each peer to keep track (know to IP address) of its predecessor and successor, and to periodically verify that its two successors are alive.If a peer abruptly leaves, its successor and predecessor need to update their information. The predecessor replaces its first successor with its second successor and ask it for the identifier and IP address of its immediate successor.What if a peer joins? If it only knows one peer, it will ask him what will be his predecessor and successor. The message will reach the predecessor which will send the new arrived its predecessor and successor information. The new arrived can join the DHT making its predecessor successor its own successor and by notifying its predecessor to change its successor information.2.7 Socket Programming: Creating Network ApplicationsOnly code explication —-&gt; skippingChapter 3: Transport Layer3.1 Introduction and Transport-Layer ServicesA transport-layer protocol provides for logical communication (as if the hosts running the processes were directly connected) between application processes running on different hosts. Application processes use the logical communication provided by the transport layer to send messages to each other, free from the worry of the details of the physical infrastructure used.Transport-layer protocols are implemented in the end systems but not in network routers.On the sending side, the transport layer converts the application messages into transport-layer packets, known as transport-layer segments. This is done by breaking them into smaller chunks and adding a transport-layer header to each chunk. The transport-layer then passes the segment to the network-layer packet at the sending end-system.On the receiving side, the network layer extracts the transport-layer segment from the datagram and passes the segment up to the transport-layer which then processes the received segment, making the data in the segment available to the received application.3.1.1 Relationship Between Transport and Network LayersA transport-layer protocol provides logical communication between processes running on different hosts. Whereas a network-layer protocol provides logical communication between hosts.3.1.2 Overview of the Transport Layer in the InternetA TCP/IP network (such as the Internet) makes two distinct transport-layer protocols available to the application layer: UDP [ User Datagram Protocol], which provides an unreliable, connectionless service to the invoking application TCP [Transmission Control Protocol] which provides a reliable, connection-oriented service to the invoking application.We need to spend a few words on the network-layer protocol: the Internet network-layer protocol is the IP (Internet Protocol). It provides a logical communication between hosts. The IP service model is a best-effort delivery service: it makes the best effort to deliver segments between hosts, but it doesnt provide guarantees: it doesn’t guarantee segment delivery it doesn’t guarantee orderly delivery of segments it doesn’t guarantee the integrity of the data in the segmentsThus IP is said to be an unreliable service.Every host has at least one network-layer address a so-called IP address.UDP and TCP extend IP’s delivery service between 2 end systems to a delivery service between two processes running on the end systems.Extend host-to-host delivery to process-to-process delivery is called transport-layer multiplexing and demultiplexing.UDP provides process-to-process delivery and error checking services. Therefore it is an unreliable service.TCP provides reliable data transfer using flow control, sequence numbers, acknowledgements and timers. TCP thus converts IP’s unreliable service between end systems into a reliable data transport service between processes.TCP also provides congestion control, a service not really provided to the invoking application as it is to the Internet as a whole: it prevents any TCP connection from swamping the links and routers between communication hosts with an excessive amount of traffic giving each connection traversing a congested link an equal share of the bandwidth.3.2 Multiplexing and DemultiplexingHere we’ll cover multiplexing &amp; demultiplexing in the context of the Internet but a multiplexing/demultiplexing service is needed for all computer networks. The job of delivering the data in a transport-layer segment to the correct socket is called demultiplexing. The job of gathering data chunks at the source host from different sockets, encapsulating each data chunk with header information (which will be used in demultiplexing) to create segments and passing the segments to the networks layer is called multiplexing.Therefore sockets need to have unique identifiers and each segment needs to have special fields that indicate the socket to which the segment is delivered. These fields are the source port number field and the destination port number field. Each port number is a 16-bit number ranging from 0 to 65535. Port numbers ranging from 0 to 1023 are called well-known port numbers and are restricted, reserved for us by well-known application protocols such as HTTP (80) and FTP (21). Designing an application, we should assign it a port number.Connectionless Multiplexing and DemultiplexingA UDP socket is fully identified by the two-tuple:(destination IP address , destination port number)therefore if two UDP segments have different source IP address and/or source port numbers but have the same destination IP address and destination port number, than the two segments will be directed to the same destination process via the same destination socket.The source port number serves as part of the return address.Connection-oriented Multiplexing and DemultiplexingA TCP socket is identified by the four-tuple:(source IP address, source port number, destination IP address, destination port number)When a TCP segment arrives from the network to a host, the host uses all four values to demultiplex the segment to the appropriate socket.Two arriving TCP segments with different source IP addresses or source port numbers will (with the exception of a TCP carrying the original connection establishment request) be directed to two different sockets.Routine: The TCP server application always has a welcoming socket that waits for connection establishment requests from TCP clients on port number X The TCP client creates a socket and sends a connection establishment request (a TCP segment including destination port, source port number and a special connection-establishment bit set in the TCP header) The server OS receives the incoming connection-request segment on port X, it locates the server process that is waiting to accept a connection on port number X, then creates a new socket which will be identified by (source port number in the segment (cleint), IP address of source host (client), the destination port number in the segment (its own), its own IP address) With the TCP connection in place, client and server can now send data to each otherThe server may support many simultaneous TCP connection sockets, with each socket attached to a process and each socket identified by its own four-tuple.When a TCP segment arrives at the host, all the fours fields are used to demultiplex the segment to the appropriate socket.Port ScanningCan be used both by attackers and system administrator to find vulnerabilities in the target or to know network applications are running in the network.The most used port scanner is nmap free and open source.For TCP it scans port looking for port accepting connections, for UDP looking for UDP ports that respond to transmitted UDP segments.It then returns a list of open, closed or unreachable ports.A host running nmap can attempt to scan any target anywhere in the InternetWeb Servers and TCPIn a web server, all segments have destination port 80 and both the initial connection-establishment segments and the segments carrying HTTP request messages will have destination port 80, the server will distinguish clients using the source IP addresses and port numbers.Moreover in today’s high-performing Web, servers often use only one process and create a new thread with a new connection soket for each new client connection.If using persistent HTTP, client and server will exchange messages via the same server socket. If using non-persistent HTTP, a new TCP connection is created and closed for every request/response and hence a new socket is created and closed for every request/response.3.3 Connectionless Transport: UDPUDP does multiplexing/demultiplexing, light error checking, nothing more. If the developer chooses UDP, the application is almost directly talking with IP.Note that with UDP there is no handshaking between sending and receiving transport-layer entities before sending a segment. For this reason UDP is said to be connectionless.DNS is an example of an application layer protocol that typically uses UDP: there is no handshaking and when a client doesn’t receive a reply either it tries sending the query to another name server or it informs the invoking application that it can’t get a reply. Why should a developer choose UDP? Finer application-level controll over what data is sent and when: as soon as the application passes data to UDP, UDP will package the data inside a segment and immediately pass it to the network layer. TCP’s congestion control can delay the sending of the segment and will try sending the packet until this is received. In real time applications the sending rate is important, so we can trade off some data loss for some sending rate. No connection establishement UDP justs send data without any formal preliminaries without introducing any delay, probably the reason why DNS runs over UDP. No connection state: because a UDP application doesn’t need to keep track of the users or to keep connections alive, it can typically support many more active clients than a TCP application Small packet header overhead TCP has 20 bytes of header overhead in every segment versus the 8 of UDPIt is possible for an application developer to have reliable data transfer when using UDP. This can be done if reliability is built into the application itself (eg adding acknowledgement and retransmission mechanisms) but it is a nontrivial task and may keep the developer busy for a long time.3.3.1 UDP Segment StructureThe UDP header has only four fields, each consisting of two bytes: source port number destination port number checksum (used for error detection.) length (which specifies the number of bytes in the UDP segment, header + data)This length field is needed since the size of the data field may differ from one UDP segment to the next.3.3.2 UDP ChecksumProvides for error detection, to determine whether the bits in the segment have been altered as it moves from source to destination.At the send side, UDP performs the 1s complement of the sum of all the 16-bit (max 64) words in the segment, with any overflow encountered during the sum being wrapped around. This result is put in the checksum field of the UDP segment header.UDP implements error detection according to the end-end principle: certain functionality (error detection in this case) must be implemented on an end-end basis: “functions placed at the lower levels may be redundant or of little value when compared to the cost of providing them at the higher level”.3.4 Principles of Reliable Data TransferIt is the responsibility of a realiable data transfer protocol to implement reliable data service: no transferred data bits are corrupted or lost and all are delivered in the order in which they were sent.We will consider the following actions: The sending side of the data transfer protocol will be invoked from above by a call to rdt_send() On the receiving side rdt_rcv() will be called when a packet arrives while deliver_data() will be called when the rdt protocol wants to deliver data to the upper layer.We use the term packet rather than segment because the concepts explained here applies to computer networks in general.We will only consider the case of unidirectional data transfer that is data transfer from the sending to the receiving side. The case of reliable bidirectional (full-duplex) data transfer is not more difficult but more tedious to explain. Nonetheless sending and receiving side will need to transmit packets in both directions.3.4.1 Building a Reliable Data Transfer ProtocolFinite-state machines (FSM) are boring! And unlikely to be asked at the exam, therefore I decided not to cover them here.3.4.2 Pipelined Reliable Data Transfer ProtocolsIn today’s high-speed networks stop-and-wait protocols are simply not tolerable: we cannot send one packet and wait for the ACK and then send the second one, it is inefficient as we can see computing the utilization of the channel:\\[U = \\frac{L/R}{RTT+ L/R}\\]The solution is simple: rather than operate in a stop-and-wait manner, the sender is allowed to send multiple packets without waiting for acknowledgements. Since the many in-transit send-to-receiver packets can be visualized as filling a pipeline, this technique is known as pipelining.Some consequences: The range of sequence numbers must be increased: each in-transit packet must have a unique sequence number Sender and receiver may have to buffer more than one packet.Two basic approaches toward pipelined error recovery can be identified: Go-Back-N and Selective Repeat3.4.3 Go-Back-N (GBN)The sender is allowed to send N packets (sender window size = N), the receiver has a window of size 1.If a segment from sender to receiver is lost, the receiver discards all the segments with sequence number greater than the sequence number of the dropped packet, answering with ACK with this sequence number. (no packet re-ordering)The sender will wait for ACK in order to move the window and send new packets. The wait is not infinite, after a certain time a timeout will occur and the sender will retransmit all the packets in the sending window.In a Go-Back-N protocol, acknowledgements are cumulative: if sender receives ACK3 he will know that all the packets from 0 to 3 have been received, even if hasn’t received ACK2.3.4.4 Selective RepeatWhen the window-size and bandwidth-delay product are both large, many packets can be in the pipeline and a single packet error can thus cause GBN to retransmit a large number of packets, many unnecessarily.Selective Repeat avoid unnecessary retransmissions by having the sender retransmit only those that packets it suspects were received in error at the receiver:individual acknowledgements (opposed to cumulative).sender window size = N and receiver window site = N.The sender has a timer for each packet in its window. When a timeout occurs, only the missing packet is resent.The receiver buffers out of order packets.3.5 Conncetion-Oriented Transport: TCP3.5.1 The TCP ConnectionTCP is said to be connection-oriented because before one application process can begin to send data to another, the two processes must first “handshake” with each other. During the connection establishment, both sides of the connection will initialize many TCP state variables.TCP connection is not an end-to-end TDM or FDM circuit nor is it a virtual circuit as the connection state resides entirely in the two end systems and not in the intermediate network elements.A TCP connection provides a full-duplex service: when a connection between process A and process B, application layer data can flow from A to B and, at the same time, from B to A.TCP is also point-to-point: a connection is always between a single sender and a single receiver, no multicast possible.Establishment of the connection: the client first sends a special TCP segment, the server responds with a second special TCP segment and the client answer again with a third special TCP segment. The first two cannot contain a payload while the third can. Three segments: three-way handshake.Both the sender and the receiver have buffers that are set up during the handshake.The maximum amount if data that can be grabbed and placed in a segment is limited by the maximum segment size (MSS).TCP therefore splits data into smaller chunks and pairs each chunk of client data with a TCP header thereby forming TCP segments which are passed down to the network layer. When TCP receives a segment at the other end, the segment’s data is placed in the TCP connection’s receive buffer. Each side of the connection has its own send buffer and its own receive buffer3.5.2 TCP Segment Structure 32 bit sequence number and acknowledgement number necessary for reliable data transmission 16 bit receive window used for flow control, indicates the number of bytes that a receiver is willing to accept 4 bit header length field. The TCP header can be of a variable length due to the TCP options field (usually empty therefore usual length is 20 bytes) options field used to negotiate MSS or as a window scaling factor for use in high speed networks. flag field: 6 bits: \t1. ACK used to indicate that the value carried in the acknowledgement field is valid, that is the segment contains an acknowledgement for a segment that has been successfully received. , 3. and 4. RST, SYN, FIN for connection setup and teardown PSH indicates that the receiver should pass the data to upper layer immediately URG indicates that there is data in the segment that the sending side upper layer has marked as urgent. Sequence Numbers and Acknowledgment NumbersTCP views data as an unstructured, but ordered, stream of bytes and TCP’s use of sequence numbers reflects this view: sequence numbers are over the stream of bytes and not over the series of transmitted segments.The sequence number for a segment is the byte-stream number of the first byte in the segment.EX 500,000 bytes, MSS = 1,000 bytes =&gt; 500 segments are created. First is numbered 0, second 1000, third 2000…..The acknowledgement number that Host A puts in its segment is the sequence number of the next byte Host A is expecting from Host B.TCP is said to provide cumulative acknowledgements: if sender receives ACK 536 he will know that all the bytes from 0 to 535 have been well received.What does a host do when it receives out-of-order segments? The receiver buffers the out-of-order bytes and waits for the missing bytes to fill in the gaps.Usually both sides of a TCP connection randomly choose an initial sequence number randomly both for security and for minimizing the possibility that a segment that is still present in the network from an earlier, already terminated connection between two hosts is mistaken for a valid segment in a later connection between these same two hosts.3.5.3 Round-Trip Time Estimation and TimeoutTCP uses a timeout/retransmit mechanism to recover from lost segments. The question rises: How long should the timeout intervals be?Clearly the timeout should be larger than the connection’s round-trip time? How much larger? How can the RTT be evaluated?Estimating the Round-Trip TimeThe sample RTT, SampleRTT, for a segment is the amount of time between when the segment is sent (passed to network layer) and when an acknowledgement for the segment is received.Most TCP implementations take one SampleRTT at a time: at any point in time, the SampleRTT is being estimated for only one of the transmitted but currently unacknowledged segments, leading to a new value of SampleRTT for approximatively every RTT.TCP never computes a SampleRTT for a segment that has been retransmitted, only for segments transmitted once.In order to estimate a typical RTT, TCP keeps an average called EstimatedRTT of the SampleRTT values. Upon obtaining a new SampleRTT TCP updates this estimation according to the formula:EstimatedRTT = (1 - a) * EstimatedRTT + a * SampleRTTwhere usually a = 1/8 = 0.125We note that this weighted average puts more weight on recent samples than on old samples. In statistics such an average is called an exponential weighted moving average (EWMA).It is also useful to having an estimate of the variability of the RTT. We can measure how much SampleRTT typically deviates from EstimatedRTT:DevRTT = (1 - b) * DevRTT + b* | SampleRTT - EstimatedRTT |We note that this is an EWMA of the difference of estimated and last measured RTT. The recommended value for b is b = 0.25Setting and Managing the Retransmission Timeout IntervalTimeoutInterval = EstimatedRTT + 4 * DevRTTAn initial TimeoutInterval value of 1 second is recommended.Also when a timeout occurs, the value of TimeoutInterval is doubled in order to avoid a premature timeout occurring for a subsequent segment that will soon be acknowledged. As soon as a segment is received and EstimatedRTT is updated, the TimeoutInterval is again computed using the formula above.3.5.4 Reliable Data TransferTCP creates a reliable data transfer service on top of IP’s unreliable best-effort service. It ensures that the data stream that a process reads out of its TCP receive buffer is uncorrupted, without gaps, without duplication and in sequence.We supposed until now that an individual timer was associated with each transmitted segment. However timer management can require considerable overhead. Thus the recommended TCP timer management procedures (defined by RFC standards) use only a single retransmission timer (it is helpful to think of the timer as being associated with the oldest unacknowledged segment). Upon receiving data from the application layer, TCP encapsulates it in a segment and passes to the segment to IP. If the timer is not running for some other segment, TCP starts it when the segment is passed to IP, the timer expiration interval being TimeoutInterval If the timeout occurs, TCP responds by retransmitting the segment that caused the timeout and by restarting the timer An valid acknowledgement segment is received: TCP compares the ACK y value with its sendBase (the sequence number of the oldest unacknowledged byte). If y &gt; sendBase then ACK is acknowledging one or more previously unacknowledged segments (cumulative acknowledgement). The sendBase variable is updated and the timer is restarted if there are not-yet-acknowledged segments.Doubling the Timeout IntervalEach time TCP retransmits, it sets the next timeout interval to twice the prevous value. However when the timer is restarted after receiving data from the application layer or after receiving an ACK, the TimeoutInterval is recomputed as described previouslyFast RetransmitThe problem with timeout-triggered retransmission is that the timeout period can be relatively long.The sender can however often detect packet loss before the timeout event occurs by noting duplicate ACKs. A duplicate ACK is an ACK that reacknowledges a segment for which the sender has already received an earlier acknowledgement.When the TCP sender receives three duplicate ACK for the same data it takes this as an indication that the segment following the segment that has been ACKed three times has been lost. In the case that three duplicate ACKs are received, the TCP sender performs a fast restransmit: it retransmits the missing segment before that segment’s timer expires.Go-Back-N or Selective Repeat?Acknowledgments are cumulative (GBN) but many TCP implementations will buffer correctly received but out-of-order segments.Also consider fast retransmit where only the missing packet is resent (SR) instead of all the window (GBN).We can see that TCP’s error recovery mechanism is categorized as a hybdrid of GB and SR protocols.3.5.5 Flow ControlThe host on each side of a TCP connection set aside a receive buffer for the connection. When TCP receives bytes that are correct and in sequence, it places the data in the receive buffer. The associated application process will read data from this buffer, but necessarily at the instant the data arrives (busy, not interested…). Thus the the sender can easily overflow the connection’s receive bufffer by sending too much data too quickly. To avoid this event, TCP provides a flow-control service.Flow control is a speed-matching service: matching the rate at which the sender is sending against the rate at which the receiving application is reading.Flow control and congestion control are not the same!: the former preventing overflow at the receiver side and being actuated only by the two end points, the latter preventing congestion of the network.TCP provides flow control by having the sender maintain a variable called the receive window, used to give the sender an idea of how much free buffer space is available at the receiver.Host A sends a large file to Host B over TCP.B side B allocates a receive buffer to its connection, its size being RcvBuffer B also keeps the variables: LastByteRead (number of last byte in the data stream read by the application process) and LastByteRcvd (the number of the last byte arrived from the network and placed in the receive buffer)We have: LastByteRcvd - LastByteRead &lt;= RcvBuffer (we don’t want overflow!)Receive window aka the amount of spare room in the buffer rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]rwnd is dynamicA sideA keeps track of two variables:1. `LastByteSent`2. `LastByteAcked`Through the connection’s life A must make sure that LastByteSent - LastByteSent &lt;= rwndIf B’s buffer becomes full, he sends rwnd = 0. If B has nothing to send to A, when the application process empties B’s buffer, TCP does not send a new segment with the new value of rwnd to A (TCP sends to A only if it needs to send data or if it needs to send an ACK).Therefore A is never informed that B’s buffer has some free space and he is blocked and can trasmit no more data.To solve this problem, TCP requires A to continue to send segments with one data byte when B’s receive window is 0, these segments will be acknowledged by B. Eventually the buffer will begin to empty and the acknowledgements will contain à non-zero rwnd value.We remember that UDP has no flow control service3.5.6 TCP Connection ManagementHow is the connection established? Three-way handshake The client-side TCP sends a special TCP segment to server-side TCP. This segment doesn’t contain any application-layer data but the flag bit SYN is set to 1. The segment is referred to as a SYN segment. The client also randomly chooses an initial sequence number (client_isn) and puts this number in the sequence number field of the initial TCP SYN segment. (randomizing client_isn is interesting to avoid security attacks). The TCP SYN segment arrives at the server-side, it is extracted from the datagram. The server allocates the TCP buffers and variables to the connection and sends a connection-granted segment to the client. This segment also contains no application-layer data. The SYN flag is set to 1, the ACK field in the header is set to client_isn+1. The server chooses its own initial sequence number server_isn and puts this value in the sequence number field of the TCP segment header. This segment is referred to as SYNACK segment. Upon receiving the SYNACK segment, the client also allocates buffers and variables to the connection. The client then sends the server yet another segment which acknowledges the SYNACK (server_isn+1 is set the acknowledgement field of the TCP segment header)After this setup, all the segments will have the SYN bit set to 0 in their headers.Tearing down a TCP connectionThe client decides to end the connection: The client sends a special TCP segment to the server, this special segment having the FIN bit flag set to 1 in the header. The server receives the segment and sends an acknowledgement to the client. The server then sends its own shutdown segment which also has the FIN bit set to 1 The client acknowledges the server’s shutdown segment. The “resources” (buffers and variables) in the hosts are deallocated.What if the two ends are not ready for communication?A host receives a TCP segment whose port number or source IP address do not match with any of the ongoing sockets in the host -&gt; the host sends a special reset segment to the source (RST flag bit set to 1) and drops the packet (UDP does responds with a special ICMP datagram)3.6 Principles of Congestion Control3.6.1 The Causes and the Costs of CongestionScenario 1: Two Senders, A Router with Infinite BuffersA -&gt; D, B -&gt; C, A and B connect to the Internet through the same router, B and C connect to the Internet through the same router(pas envie)3.7 TCP Congestion ControlTCP limits the rate at which it sends traffic into its connection as a function of perceived network congestion.The TCP congestion-control mechanism operating at the sender keeps track of an additional variable: the congestion window, noted cwnd which imposes a constraint on the rate at which a TCP sender can send traffic into the network. Specifically: LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}.Limiting the amount of unacknowledged data at the sender we can limit the sender’s send rate.At the beginning of each RTT the sender sends cwnd bytes of data and at the end of the RTT he acknowledges. Thus the sender’s send rate is roughly cwnd/RTT bytes/sec. Adjusting the value of cwnd the sender can adjust the rate at which it sends data into the connection.Let now consider a loss event (timeout OR three duplicate ACKs). When there is excessive congestion some router buffers along the path overflows, causing a loss event at the sender which is taken by the sender to be an indication of congestion on the sender-to-receiver path.If there is no congestion then all the acknowledgements will be received at the sender, which will take these arrivals as an indication that segments have been received and that he can increase the congestion window size and hence its transmission rate. If acknowledgements arrive at a slow rate then the congestion window will be increased at a relatively slow rate and, viceversa, it will be increased more quickly if ACKs arrive at a high rate.Because TCP uses acknowledgements to trigger (or clock) its increase in congestion window size, TCP is said to be self-clocking. TCP uses the principles: A lost segment implies congestion therefore the sender rate should be decreased. An acknowledged segment means the network’s working, therefore the sender’s rate can be increased (if ACK of unacknowledged segment) Bandwidth probing: the transmission rates increases with ACKs and decreases with loss events: TCP is continuously checking (probing) the congestion state of the networkTCP Congestion-Control AlgorithmThree components :1 - Slow StartWhen a TCP connection begins, cwnd is usually initialized to a small value of 1 MSS and only one segment is sent. Each acknowledged packet will cause the cwnd to be increased by 1 MSS and the sender will send now two segments (because the window is increased by one for each ack).Therefore the number of segments doubles at each RTT, therefore the sending rate also doubles every RTT. Thus TCP send rate starts slow but grows exponentially during the slow start phase.When does the growth end? Timeout: cwnd is set to 1 MSS and the slow start is started anew. Also the variable slow start threshold is initialized: ssthresh = cwnd / 2 - (half of value of cwnd when congestion is detected) When cwnd &gt;= ssthresh slow starts is stopped -&gt; congestion avoidance state Three duplicate ACKs: fast retransmit and fast recovery state2 - Congestion AvoidanceTCP suppose congestion is present, how to adapt?Instead of doubling cwnd every RTT, cwnd is increased by just a single MSS every RTT.When should this linear increase stop? Timeout: cwnd is set to 1 MSS, and ssthresh = cwnd (when loss happened) / 2 Three duplicate ACKs: cwnd = (cwnd / 2) + 3 MSS and ssthresh = cwnd (when 3 ACKs received) / 2 -&gt; fast recovery state3 - Fast Recoverycwnd is increased by 1 MSS for every duplicate ACK received for the missing state that caused TCP to enter this state. When the ACK arrives for the missing segment, TCP goes into Congestion Avoidance after reducing cwnd.If a timeout occurs cwnd is set to 1 MSS and ssthresh is set to half the value of cwnd when the loss event occurred.Fast recovery is recommended but not required in TCP, in fact only the newer version of TCP, TCP Reno incorporated fast recovery.Macroscopic Description of TCP ThroughputWhat is the average throughput (average rate) of a long-lived TCP connection?Ignoring the slow start phase (usually very short as the rate grows exponentially). When the window size is w the transmission rate is roughly w/RTT. w is increased by 1 MSS each RTT until a loss event.Denote by W the value of w when a loss event occurs. Then we haveaverage throughput of a connection = (0.75 * W)/RTTTCP Over High-Bandwidth PathsToday’s high speed links allow to have huge windows. What happens if one of the segments in the window gets lost? What fraction of the transmitted segments could be lost that would allow the TCP congestion control to achieve the desired rate?average throughput of a connection = (1.22 * MSS)/(RTT * sqrt(L))Where L is the loss rateChapter 4: The Network LayerIn the chapter, there is an important distinction between the routing and forwarding functions of the network layer. Forwarding involves the transfer of a packet from an incoming link to an outgoing link within a single router while routing involves all of a network’s routers whose collective interactions via routing protocols determine the paths that packets take on their trips from source to destination.4.1 IntroductionThe primary role of routers is to forward datagrams from input links to output links. Routers do not run nor the application-layer or the transport-layer, they go only up until the network layer.4.1.1 Forwarding and RoutingThe role of the network layer is deceptively simple: to move packets from a sending hosts to a receiving host. To do so it performs two important functions: Forwarding: When a packet arrives to a router’s input link, the router must move the packet to the appropriate output link. It is an action local to the router Routing: The network layer must determine the route or path taken by packets as they flow from a sender to a receiver. The algorithms that calculate these paths are referred to as routing algorithsm. It is a network-wide actionEvery router has a forwarding table. When a router receives a packet, it extracts a value from a specific field in the header and searches for that value in in the forwarding table.The procedure used to set up and update the table depends on the protocol used. However a router receives and sends routing protocol messages to configure its forwarding table.We also need to mark the distinction between routers and packet switches. Packet-switches: performs forwarding according to the value in a field in the header of the packet. Some packet switches called link-layer switches base their forwarding decisions on values in the fields of the link-layer frame (link-layer devices) Routers: base forwarding decisions on the value in the network-layer field. (network-layer devices) but also must implement link layer (no 3 without 2)Connection Setupin some computer networks there is a third really important networks-layer function: connection setup: a path-wide process that sets up connection state in routers.4.1.2 Network Service ModelsThe network service model defines the characteristics of end-to-end transport of packets between sending and receiving end systems. Some possible service for a network layer: Sending side: Guaranteed delivery Guaranteed delivery with bounded delay Flow and receiving side: In-order packet delivery Guaranteed minimal bandwidth Guaranteed maximum jitter (amount of time between transmission of two successive packets at the sender side is equal to the amount of time between their receipt at the destination, or that this spacing changes by no more than some specified value) Security services: encryption for confidentiality, data integrity and source authentication The Internet’s network layer doesn’t provide any of these: it provides a best-effort service there are no timing or bandwidth guarantees, no loss or order guarantees and congestion control indications.4.2 Virtual Circuit and Datagrams NetworksAs in transport layer, the network layer can use connection or connection-less protocols. There however some differences with the transport layer: In the network layer these services are host-to-host services (not the case for the TL, just look at TCP) The network layer provides either a host-to-host connectionless service or a host-to-host connection service but no both. Connection service -&gt; Virtual-Circuit (VC) networks, Connectionless service -&gt; datagram networks4.2.1 Virtual-Circuit NetworksThe Internet is a datagram network but many alternative network architectures (ATM) are virtual-circuit networks. The connections in VC are called *virtual circuits (VCs)3.A VC consists of A source-to-destination path VC numbers, one for each link along the path Entries in the forwarding table in each router along the pathA packet belonging to a virtual circuit will carry a VC number in its header. Because a VC may have different VC numbers on each link, each router must replace the VC number of traversing packets with a new VC number, which is obtained from the forwarding table. How is this determined?Whenever a VC is established across a router, an entry is added to the forwarding table, and one (corresponding to the terminating VC) is removed whenever a VC ends.The routers must maintain connection state information for the ongoing connections (using the tablea). There are 3 phases in a VC: VC Setup: sending side contacts networks layer specifying the IP address of the destination. The network sets up the VC. The path is determined as well as the VC number for each link along the path. The forwarding tables are updated and resources reserved. Data transfer: the packets flow VC teardown: The call termination propagates along the path, the forwarding tables are updatedDuring network-layer setup all the routers along the path between source and destination are involved in VC setup, and each router is fully aware of all VCs passing through it (not in TCP: setup and connection only between source and destination).The messages used by end ssystems to initiate or terminate a VC are called signaling messages and the protocols used to exchange them are called signaling protocols.4.2.2 Datagram NetworksEach time an end system wants to send a packet, it sampts the packet with the address of the destination end system and pops the packet into the network. The routers along the path will use this address to forward it.The router has a forward table that maps destination addresses to link interfaces. When a packet arrives, it reads the destination address, uses the table to determine what link to use, and forwards the packet to that output link interface.If we consider IPv4, addresses are 32 bits long. To avoid having tables with 2^32 entries, routers use prefixes. When there are multiple mathces to one address, the router uses the longest prefix matching rule.Although routers in datagram networks maintain no connection state information, they nevertheless maintain forwarding state information in their forwarding tables.4.2.3 Origins of VC and Datagram NetworksVC has its roots in the telephony world, which uses circuits switching too.The datagram model instead comes from the need to simplify as much as possible the network to bring computers together.4.3 What’s Inside a Router? Input ports: performs the physical layer functions of incoming link at the router. It is also here that the forwarding table is consulted to determine the output port to which the arriving packet will be forwarded via the switching fabric. Control packets (protocol info) are forwarded to the routing processor. Switching fabric: connects input prots to output ports. Output ports: stores packets received from the switching fabric and performs the necessary link layer and physical layer functions. Routing processor: executes the routing protocols (algorithms), maintains routing tables and attached link state information and computes the forwarding table for the router.Input ports, switching fabric and output ports implement the forwarding function and are almost always implemented in hardware (routing forwarding plane hardware) while the routing processor implements the routing function and is usually implemented in software running on traditional CPU (router control plane)4.3.1 Input ProcessingThe packet arrives and the link and phyisical layer unpacking functions are performed. The forwarding table is computed and updated by the routing processor with a shadow copy typically stored at each input port so that forwarding decision can be made locallly without invoking the centralized routing processor on a per packet basis and thus avoiding a centralized processing bottleneck. The table is transferred to ports through separated bus. The lookup is then just a search (implemented in hardware and using high performance algorithms), speed also depends on the memory technology (DRAM, SRAM…). Lookup is important but input processing also consists of physical and link layer processing chekcing the packet’s version number, checksum, time to live…. updating counters for network management.Input ports than moves the packet to the switching fabric (eventually queuing them if this is busy)4.3.2 SwitchingCan be performed in different ways:Switching via memorySwitching under the control of the CPU and input and output ports functioned as traditional I/O devices in a traditional operating system. The packet arrives, is copied into the processor memory, the processor determines the output port and copies the packet to the output port’s buffer.No parallel forwarding (only 1 memory read/write bus)Switching via a busAn input port transfers a packet directly to the output port over a shared bus without intervention by the routing processor. The input port pre-pends an internal header to the packet. All the output ports receive the packet but only the one that matches the label in the internal header will keep the packet. The output port will remove this internal header. The switching speed is limited to the bus speed as one packet at a time can cross the bus (multiple arriving packets will have to wait). Sufficient only for small area and enterprise networksSwitching via an interconnected networkTo overcome the bandwidth limitation of a single shared bus a more sophisticated interconnection network can be used.A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports to N output ports. Each vertical bus intersects each horizontal bus at a crosspoint which can be opened or closed at any time by the switch fabric controller. If a packet has to go from input X to output Y, only the crosspoint between the horizontal bus from X and the vertical bus to Y will be closed.Thus packets directed to different output ports can be forwarded simultaneously, but not multiple packets directed to the same output port.4.3.3 Output Processingtakes packets stored in the output’s port’s memory and transmits them over the output link, thus selecting de dequeuing packets for transmission and performing the necessary link and physical layer transmission functions.4.3.4 Where Does Queuing Occur?Queues may form at both the input ports and the output ports. The location and the extent of queuing will depend on traffic load, speed of the switching fabric, and line speed. As the queues grow large, the router’s memory can eventually be exhausted and packet loss will occur. IS THIS USEFUL ? NOT COVERED BY TEACHER4.4 The Internet Protocol (IP): Forwarding and Addressing in the InternetWe know move to study of the network layer in the Internet. There are two versions of the IP (Internet Protocol) in use today: IPv4 and IPv6.There 3 main components in the Internet: the IP Protocol (addressing, datagram format and packet handling conventions), the routing protocol (path selection), the Internet Control Message Protocol (ICMP) (error reporting and network information).4.4.1 Datagram FormatA network layer packet is referred to as a datagram.Some fields: Version number: 4 bits specifying the IP protocol version of the datagram (IPv4 or IPv6 ) Header length: the length of the packet is variable therefore this field tells where the header ends and the data begins. Usually datagrams contain no option so that the typical IP datagram has 20-byte header Type of service (TOS): allows different types of datagrams to be distinguished from each other. (eg real time vs non real time) Datagram length: 16 bits specifying the total length, that is header + data measured in bytes. 16 bits -&gt; max header length = 65535 bytes, but usually datagrams are rarely larger than 1500 bytes. Identifier, flags, fragmentation offset: used for IP fragmentation. (NB: IPv6 doesn’t allow fragmentation at routers) Time-to-live (TTL): used to avoid that datagrams circulate forever. It is decreased by one each time the datagram is processed by a router. When TTL = 0, the datagram is dropped Protocol: only used when datagram reaches its final destination, it specifies what transport protocol to which the data of the datagram should be passed. EX: 6 -&gt; TCP, 17 -&gt; UDP Header checksum: helps the router to detect bit errors in a received IP datagram. Computation: each two bytes in the header are considered as numbers, summed up using the 1s complement arithmetic. The 1s complement of this sum is then put in the checksum field. A router computes the checksum for each datagram. If the computed one doesn’t equal the one in the field then the router has detected an error. Usually the datagram is discarded. As it is recomputed at each router, it may change. Source and destination IP addresses Options: rarely used, dropped by IPv6 Data (payload): usually contains the transport layer segment but can also contain ICMP messagesIP Datagram FragmentationThe maximum amount of data that a link layer can carry is called the Maximum Transmission Unit (MTU). As each datagram is encapsulated in a link layer frame, the MTU imposes a hard limit on the length of the datagram. Each of the links along the route can use different link-layer protocols and therefore can have different MTU.We therefore have to break the IP datagram into smaller datagrams, each of which will go in different link layer frames. Each of these smaller datagrams is referred to as a fragment.A fragment must be reassembled before it can be passed to the transport layer. To reduce the workload on routers, the designers of IPv4 decided that reassembling should only be done at the destination end system.In IPv4, to comply with fragmentation, the header contains the fields: Identifiers: identifies the unfragmented datagram (same for all fragments) flags: in particular there is one flag set to 0 if the fragment is the last or to 1 if there are more to come fragmentation offset: an integer x, the data in the fragment should be inserted beginning at byte x * 8If one fragment contains error or is lost, all the others are dropped and TCP will have the sender retransmit all the data.Fragmentation complicates the network and end systems and can be used in lethal DoS attacks such as the Jolt2 attack4.4.2 IPv4 AddressingThe boundary between the host and the physical link is called an interface. A router has multiple links connected to it, therefore multiple interfaces and therefore a router has multiple IP addresses and an IP address is technically associated with an interface rather than with a host or router.IPv4 addresses are 32 bits long (4 bytes) -&gt; max 2^32 possible addresses. They are typically writen in dotted decimal notation where each byte of the address is written in deciaml from and separated by a period from the others.EX 193.32.216.9 === 11000001 00100000 11011000 00001001Each interface on every host (except host behind NATs) must have a unique IP address. How are these computed?A portion is determined by the subnet to which the host is connected.A subnet is the portion of the network interconnected end systems and one one router. (also called IP network or network). IP assigns an address to a subnet x.x.x.x/y where /y notation, sometimes known as a subnet mask indicates that the leftmost y bits of the 32 bit quantity define the subnet address. If y is 24, then any host attached to the a.a.a.0/24 subnet would be required to have an address of the form a.a.a.xxx.FIGURE 4.17 WTFThe Internet’s address assignment strategy is known as Classless Interdomain Routing (CIDR). It generalizes the notion of subnet addressing. Consider a.b.c.d/x : the x most significant bits constitute the network portion of the IP address and are often referred to as the prefix (or network prefix). EX an organization is assigned a block of contiguous addresses, that is, a range of addresses with a common prefix.When someone outside the organization want to send a datagram to someone inside, he will only need this x bits. The remaining 32-x bits can be thought of as distinguishing among the devices within the organization. These bits may have an additional subnetting structure.There is yet another type of IP address, the IP broadcast address 255.255.255.255. When a datagram is sent to this address, the datagram is delivered to all hosts on the same subnet.Obtaining a Block of AddressesA network administrator contacts an ISP which would provide a partition of the addresses that had already been allocated to him.EX ISP has 200.23.16.0/20, it splits in 8 equal sized blocks: 200.23.16.0/23, 200.23.18.0/23, 200.23.20.0/23, …, 200.23.30.0/23Who assigns set of addresses to ISPs? The Internet Corporation for Assigned Names and Numbers (ICANN) which allocates IP addresses, manages DNS root servers, assigns domain names and solves domain name disputes.Obtaining a Host Address: The Dynamic Host Configuration ProtocolOnce an organization has obtained a block of addresses, it can assign individual IP addresses to the hosts and router interfaces which are part of it. This can be done either manually (by the network administrator) or automatically by the Dynamic Host Configuration Protocol (DHCP).It can be configured so that a host receives the same IP each time it connects to the network or a temporary IP addresses that will change upon each connection. DHCP also transmits to hosts additional information (subnet mask, address of first-hop = default gateway, address of local DNS server).As it automates the connection of a host into the network, DHCP is often referred to as a plug-and-play protocol. It is also popular in wireless LANs where hosts join and leave frequently and in *residential ISP access networks.DHCP is a client-server protocol, the client being a newly arriving host needing network configuration information and the server being a router or a DHCP relay agent that know the address of a DHCP server for that network.For a new client there is a 4 step process i nthe DHCP protcol: DHCP server discovery c (client) looks for a server sending DHCP discover message a UDP packet directed to port 67. This segment is encapsulated in datagram sent to 255.255.255.255 (broadcast address) from address 0.0.0.0 DHCP server offer(s) s (server) replies with a DHCP offer message broadcast to all nodes on the subnet using (sent to 255.255.255.0). c may receiver many of these (more servers) containing the transaction ID, proposed IP address and an address lease time (amout of time for which the address will be valid) DHCP request: c chooses one offer and responds to s with a DHCP request message echoing back the configuration parameters DHCP ACK s responds with DHCP ACK message confirmingDHCP also provides a mechanism for renewing the lease on an address.Network Address Translation (NAT)Every IP-capable device needs an IP address. The number of connected devices grows fast, how to deal with IPv4 address space exhaustion?Network Address Translation (NAT)The NAT-enabled router defines a realm (or private network) (a network whose addresses only have meaning to devices within that network) and it can use the whole 32 bit address space for devices connected to it, it will also have a public address used to communicate with the exterior. The picture is explicative.From the outside the router looks like a single device with a single IP address. It hides the details of the internal network from the outside world. Internal addresses can be assigned using DHCP.Problems with NAT: Port number should be used for addressingi processes not hosts Routers shouldn’t have access to the transport layer (ports) NAT violates end-to-end argument (any host should be able to contact any other host) NAT interferes with P2P applications (peers hidden by NAT), therefore the need of connection reversal for NAT traversalUPnPNAT traversal is increasingly provided by Universal Plug and Play. It requires both the host and the NAT to be compatible. Host requests a NAT mapping_(private IP address, private port number) -&gt; (public IP address, public port number)If the NAT accepts and creates the mapping, then outsiders can create connections to (public IP address, public port number).4.4.3 Internet Control Message ProtocolICMP is used to communicate network-layer information between hosts and routers, usually for error reporting (ex Destination network unreachable).ICMP is considered part of IP but architecturally lies just above IP as ICMP messages are carried inside IP datagrams as payloads.ICMP have a type and a code field and carry the header and the first 8 bytes of the datagram that caused the message to be generated in the first place.Ping and traceroute are implemented using ICMP messagesInspecting datagrams: firewalls and intrusion detection systemsFirewalls inspect the datagram and segment header fields denying suspicious datagrams entry into the internal network. Firewalls can block ICMP packages or packets based on port numbers, addresses.Additional protection can be provided by IDS, placed at the boundary of the network, performs deep packet inspection examining not only headers but also payloads (including application layer data). IDS have databases of packet signatures that are know to be dangerous. As packets flow through the IDS, it tries to match them to signatures in its database, if a match is found, an alert is created. IPS (intrusion prevention system) in addition to detecting, also blocks packets raising alerts.4.4.4 IPv6Developed because of IPv4 address space exhaustionDatagram format the size of the source and destination addresses is increased from 32 to 128 bits: every grain of sand on the planet can be addressable.Unicast and multicast addresses are joind by the anycast address which allow a datagram to be delivered to any one of a group of hosts. A number of IPv4 fields have been dropped or made optional resulting in a 40-byte fixed-length header which allows faster datagram processing. Flow label not clear definition. 20-bit Version: 4-bit for IPv6 or 4. If ipv6 -&gt; 0110 Traffic class: 8 bit similar to TOS Payload length: 16 bit unsigned integer indicating number of bytes following the 40-byte datagram header Next header: transport layer protocol Hop limit: decremented by one by each router forwarding the datagram, when 0, the datagram is discardedFragmentation and reassembly cannot be done by intermediate routers, only by source and destination. If a router cannot trasmit a datagram because too big, it drops it and sends back an ICMP error message “Packet too big”. This reduces a lot the workload on the network.As the transport layer and the link layer already perform check-summing, this functionality has been removed from the network layer for faster datagram processing.An option field is no longer part of the header, instead it is one of the possible next headers pointed to from the header.A new version of ICMP has been defined for IPv6 which includes messages adapted to IPv6 (“packet too big”) and replaces IGMP (Internet Group Management Protocol), used to manage a host’s joining and leaving of multicast groups.Transitioning from IPv4 to IPv6IPv6 is back compatible with IPv4 but not viceversa.It’s not humanable possible to decide a date on which all machines would change their protocol.The most straightfoward way is a dual stack approach where IPv6 nodes also have a complete IPv4 implementation. To determine whether anotehr node is IPv6 or IPv4-only DNS can be used, just checking whether the node has a IPv6 address or an IPv4 one. However this will bring about the loss of data in specific IPv6 header fields.Another approach would be tunneling : when two IPv6 nodes are connected by intervening IPv4 routers, we call the IPv4 nodes tunnel, the entire IPv6 datagram is put in the payload field of a IPv4 datagram which will be propagated by the tunnel unaware of the details and received by the destination IPv6 node which is able to extract the IPv6 datagram and to route it.This migration shows the difficulty in changing network-layer protocols.4.5 Routing AlgorithmsA host is attached directly to one router, the default router for the host (also called first hop router). Whenever a host sends a packet, the packet is transferred to its default router, which we’ll call source router, we’ll call the default router for the destination host as the destination router. Routing a packet from source to destination boils down to routing the packet from source router to destination router.The purpose of a routing algorithm is simple: given a set of routers connected by links, it finds a “good” path from source to destination router. A good path is the least expensive one.Graphs (see Algorithms course) are used to formulate routing problems, the node representing routers and the edges the links connecting them. Each edge also has a value representing its cost. For any nodes x and y in the G(raph) we denote c(x,y) the cost of the edge between them. If (x,y) doesn’t belong to G, we set c(x,y) = infinity. We only consider undirected graphs.We just have to find the least costly paths between sources and destinations.We can classify routing algorithms in two groups: Global routing algorithms: compute the least-cost path between a source and a destination using complete, global knowledge about the network. They are often referred to as link-state (LS) algorithms since the algorithm must be aware of the cost of each link in the network Decentralized routing algorthms: compute the least-cost path in an iterative, distributed manner: no node has complete information about the cost of all network links. Instead, each node begins with only the knowledge of the costs of its own directly attached links.We could also make another classification separating static routing algorithms (routes change very slowly, eg after human intervention) and dynamic routing algorithms( routing change as the load or topology change). Finally another distinction could be made between load-sensitive or load-insensitive algorithms according to whether link costs vary reflecting the level of congestion.4.5.1 The Link-State (LS) Routing AlgorithmAll link costs are known. In practice this is accomplished by having each node broadcast link-state packets to all other nodes in the network, each packet containing the identities and costs of its attached links resulting in all nodes having an identical and complete view of the network (each node could run the algorithm).A link-state algorithm can be Dijkstra’s algorithm or Prim’s algorithm.Code and example page 3944.5.2 The Distance-Vector (DV) Routing AlgorithmThe distance-vector algorithm is iterative, asynchronous and distributed. Distributed because each node receives some information from one or more of its directly attached neighbors, performs a calculation and then distributes the results back to its neighbors. iterative: the process continues on until no more information is exchanged between neighbors (self terminating) asynchronous: the nodes are not required to operate in lockstep with each otherThe least cost between x and y d(x,y) can be determined using the Bellman-Ford equation :d(x,y) = min_v {c(x,y) + d(v,y)}… to be continued4.5.3 Hierarchical RoutingIn practice it is not possible to have a network of interconnected routers running the same routing algorithm because of two reasons: Scale if the number of routers is large, running LS or DV algorithms for the whole network becomes prohibitive for memory, processing, storing and timing costs. Administrative autonomoy an organization should be able to organize its network as it wishes, while still being able to connect its network to the outside world.Therefore routers are organized into autonomous systems (ASs), each of which being under the same administrative control. Routers in the same AS run the same routing algorithm and have information about each other. The routing algorithm running within an AS is called an intra-autonomous system routing protocol. In an AS, one or more routers will have the task of being responsible for forwarding packets outside the AS, these routers are called gateway routers.To obtain reachability information from neighboring ASs and propagating the reachability information to all routers interal to its AS, gateway routers use inter-AS routing protocols. Two communicating ASs must run the same inter-AS routing protocol.When a router needs to forward a packet outside its AS and there are multiple gateway routers, the router has to make a choice. One often employed practice is to use hot-potato routing: the AS gets rid of the packet as quickly as possible (as inexpensively as possible), the router sends the packet to the gateway router that has the smallest router-to-gateway cost among all gateways with a path to the destination.An AS can decide what (internal) destinations to advertise to neighboring ASs: this a policy decision.4.6 Routing in the Internet4.6.1 Intra-AS Routing in the Internet: RIPIntra-AS routing protocols are also known as interior gateway protocols. Historically two of these have been used extensively in the Internet: Routing Information Protocol (RIP) and Open Shortest Path First (OSPF).RIP was started for the Xerox Network Systems (XNS) architecture and was was widely deployed after being included in BSD. It is a distance-vector protocol working very similarly to what studied before. RIP uses hop count as a cost metric (each link has cost 1). Costs are from source router a destination subnet (not router-to-router as previously seen).hop = number of subnets traversed along the shortest path from source to destination subnet, including the destination subnet.Routing updates [messages] are exchanged between neighbors approximately every 30 seconds using a RIP response message, which contains a list of up to 25 destination subnets within the AS as well as the sender’s distance to each of those subnets. Response messages are also known as RIP advertisements.Each router maintains a RIP table known as a routing table which includes both the router’s distance vector and the router’s forwarding table. There are three columns in it: the destination subnet, the identity of next router along shortest path to reach destination and the number of hops to get to the destination along the shortest path.If a router doesn’t hear from its neighbor for at least once every 180 seconds, that neighbor is considered to be no longer reachable (died or link down).Routers can also request information about its neighbor’s cost to a given destination using RIP’s request messages, which are transmitted over UDP using port 520.RIP is implemented in software but has access to the routing tables through the UNIX kernel.4.6.2 Intra-AS Routing in the Internet: OSPFOSPF and the related IS-IS are typically deployed in upper-tier ISPs whereas RIP is deployed in lower-tier ISPs and enterprise networks. Open indicates that the routing protocol speficication is publicly available.It was conceived as the successor to RIP. It is however a link state protocol that uses flooding of link-state information and a Dijkstra least-cost path algorithm: routers construct a complete topological map (graph) of the AS, then run Dijkstra’s algorithm to determine a shortest-path tree to all subnets with itself as the root node. Link costs are individually configured by the networks administrator who might choose to set all the link costs to 1, thus achieving minimum hop routuing or might choose to set the link weights to be inversely proportional to link capacity in order to discourage traffic from using low-bandwidth links.A router broadcasts routing information to all other routers in the AS, not just the neighbors. The broadcast happens whenever there is a change in a link’s state or every 30 minutes if the link’s state doesn’t change. OSPF advertisements are contained in OSPF messages that are carried by IP with an upper-lyerprotocol of 89 for OSPF, therefore OSPF must implement reliable message transfer and link-state broadcast; OSP also checks that links are operational using HELLO messages to attached neighbors. OSPF offers some services: security: OSPF messages can be authenticated (not active by default). multiple same-cost paths: two paths having same cost can be used at the same time. integrated support for unicast and multicast routing support for hierarchy within a single routing domain: ability to structure an autonomous system hierarchically. A OSPF AS can be configured hierarchically into areas, each running its own OSPF algorithm, with each router broadcasting its link state to all other routers in that area. Area border routers are responsible for routing packets outside the area and one area is configured to be the backbone area, which routes traffic between other areas in the AS, it contains area border routers but also normal routers.4.6.3 Inter-AS Routing: BGPThe Border Gateway Protocol (BGP) is the de facto standard inter-AS routing protocol in today’s Internet. It provides each AS means to: obtain reachability information from neighboring ASs propagate reachability information to all internal routers determine good routes to subnets using reachability information and AS policy. it allows each subnet to advertise its existence to the rest of the InternetBasicsIt is a very complex algorithm. Routers exchange information over semipermanent TCP connections using port 179. There is typically one such BGP TCP connection for each link directly connecting two routers in two different ASs but there are also semipermanent TCP connections between routers in the same AS. For each connection, the two routers at the end of it are called BGP peers and the connection is called a BGP session. A session spanning two ASs is an external BGP (eBGP) session and BGP sessions between routers within an AS is called an internal BGP (iBGP) session. Destinations are not hosts, but CIDRized prefixes, each representing a subnet or collection of subnets.Path Attributes and BGP RoutesIn BGP an AS is identified by its globally unique AS number (ASN) which is assigned by ICANN regional registries. When a router advertises a prefix across a BGP session, it includes with the prefix a number of BGP attributes, a prefix with its attributes is called a route. Two other important attributes are: AS-PATH: contains the ASs through which the advertisement for the prefix has passed. When a prefix is passed into an AS, the AS adds its ASN to the AS-PATH. This attribute is used to detect and prevent looping advertisements (if router sees that its AS is already in AS-PATH, it rejects the ad) and to choose among multiple paths to the same prefix. -NEXT-HOP: the router interface that begins the AS-PATH.BGP also includes attributes allowing routers to assign preferences metrics to the routes and indicating how to prefix was inserted into BGP at the origins.When a router receives a route advertisement, it uses its import policy to decide whether to accept or filter the route and whether to set certain attributes such as the router preference metrics.BGP Route SelectionThe input of the selection is the set of all routes that have been learned and accepted by the router. If two or more routes exist for the same prefix, elimination rules are applied until only one remains.Chapter 8: Security in Computer Networks8.1 What is Network Security?Desirable properties of secure communication: Confindentiality: only sender and receiver should be able to understand the contents of the transmitted message -&gt; encryption Message integrity: make sure the content of the communication is not altered -&gt; checksum End-point authentication: sender and receiver should be able to confirm the identity of the other party involved in the communication. Operation security: ability to counter attacks to internal networks -&gt; firewalls, IPS, IDSPossible attacks: eavesdropping: sniffing and recording messages flowing in a channel modification, inserion, deletion of messages or message contentThese two allow to mount many other types of attacks8.2 Principle of CryptographySee Information Science, BA2ADDITION:Block CiphersToday there are two broad classes of symmetric encryption techniques: stream ciphers and block ciphers(used for PGP, SSL, IPssec)In a block cipher, the message to be encrypted is processed into blocks of k bis and each block is encrypted independently. To encode a bloc, the cipher uses a on-to-one mapping to map the k-bit block of cleartext to a k-bit block of ciphertext. To avoid bruteforce attacks, cipher blocks usually employ large blocks (k=64) but longer blocks implies longer tables to store the mappings.Block ciphers typically use functions that simulate randomly permuted tables. EX64 bit input split into 8 8-bit chunks, each of which is processed by a 8-bit to 8-bit table, each chunk having its table. The encrypted chunks are reassembled into a 64 bits message which is fed again to the input. After n such cycles, the function provides a 64-bit block of ciphertext. The key for this block would be the eight permutation tables, assuming that the scramble function is publicly known. Popular block ciphers: DES (Data Encryption Standard), 3DES, AES (Advanced Encryption Standard). These use functions instead of predetermined tables. Each of them uses a string of bits for a key (64-bit blocks with 56-bit key in DES, 128-bits blocks and 128/192/256 bits-long keys)Cipher-Block ChainingWe need to avoid long messages avoiding that two or more identical ciphertexts (produced for identical cleartexts by a symmetric encryption).(I DON’T FINISH THIS PART, IT GOES TOO DEEP INTO ENCRYPTION TECHNIQUES WHICH IS NOT WHAT WE ARE INTERESTED IN)8.3 Message Integrity and Digital SignaturesWe want to provide message integrity (aka message authentication). Message integrity is verified when: The message received indeed originated from the sender The message was not tampered with on its way to the receiver8.3.1 Cryptographic Hash FunctionsA hash function takes an input m and computes a fixed length size string H(m) known as a hash. A cryptographic hash function is required to have an additional property:it is computationally infeasible to find any two different messages x and y such that H(x) = H(y)Some used cryptographic hashing functions are md5, SHA…8.3.2 Message Authentication CodeTo perform message integrity we also need a shared secret s, called the authentication key. The procedure is then: Alice creates message m, concatenates m+s and computes the hash H(m+s) to create the message authentication code (MAC) Alice appends the MAC to the message m creating (m+H(m+s)) Bob receives the message and knowing the hash function and the secret, computes the hash. He creates H(m+s) and compares it with what he received.MAC is nice because it doesn’t require any encryption algorithmThe most popular standard of mac today is HMAC which can be used with either MD5 or SHA-1. The problem then is: how to distribute the secret? Physically?8.3.3 Digital SignaturesA digital signature is a cryptographic technique to indicate the owner or creator of a document or to signify one’s agreement with a document’s content.Just as with handwritten signatures, digital signatures should be created in a way that they are verifiable (prove that the the author of a signature is indeed the author) and nonforgeable** (prove that only that individual could have signed the document).We can use the public and private keys we already created for asymmetric confidentiality.To sign a message m Bob can encrypt the message with the private key (only the matching public key will be able to decrypt).However encryption and decryption and computationally expensive therefore: Bob computes the hash of the message Bob uses his private key to encrypt the hash Bob contants the encrypted hash and the message Alice can decrypt, find the hash, compute a hash herself check for identityWe saw that both digital signatures and MACs involve using a hash function but digital signatures, requiring encryption, need heavier operations and also need a Public Key infrastructure (PKI) with certification authorities.Public Key CertificationAn important application of digital signatures is public key certification, that is, certifying that a public key belongs to a specific entity. It is used in IPsec and SSL.A Certification Authority binds a public key to a particular entity. It has the follow roles: A CA verifies that an entity (person, router, …) is who it says it is. The method depends on the authority The CA creates a cerificate that binds the public key of the entity to the identity. The certificate contains the public key and globally unique identifying information about the owner of the public key. The certificate is digitally signed by the CA8.4 End-Point AuthenticationEnd-point authentication is the process of one entity proving its identity to another entity over a computer network.Authentication must be done solely on the basis of messages and data exchanged as part of an authentication protocol. Typically this would run before the two communicating parties run some other protocol.We can analyze authentication developing a simple algorithm step by step:Version 1.0Alice simply sends a message to Bob saying “I’m Alice”Version 2.0Alice and Bob always communicate using the same addresses. Bob can simply check that the message has the source IP of Alice. However is fairly easy to spoof an IP address: crafting a special datagram is feasible using a custom kernel e.g Linux.Version 3.0Alice and Bob could share a secret password, a secrete between the authenticator and the person being authenticated.Alice: I’m Alice, Password.However password can be eavesdropped, sniffed (read and stored).Version 3.1We could encrypt the password using a shared symmetric cryptographic key.However this protocol is subject to playback attacks an eavesdropper could sniff the encrypted secret and, without having to decrypt, could send it to impersonate Alice.Version 4.0To avoid playback attacks we could use the same principle behind TCP’s three way handshake. A nonce is a number that a protocol will use only once in a lifetime.The procedure is then: Alice sends: I am Alice bob chooses a nonce and sends it to Alice Alice encrypts it using Alice and Bob’s symmetric secret key and sends the encrypted nonce. Bob decrypts the received nonce and checks for equality with the one he generated.8.5 Securing e-mailSecurity functionalities are provided by many layers of the network stack. Why? There is a need for security at higher layers as well as blanket coverage at lower layers and it easier to provide security at higher layers.8.5.1 Secure E-MailWhat features do we want? Confindentiality, Sender authentication, Receiver authentication. Confidentiality: to overcome the problem of sharing a symmetric secret, Alice and Bob use asymmetric cryptography. Bob makes his public key publicly available (key server or web page) and Alice encrypts her message with Bob’s public key. Bob can decrypt using his private key. However asymmetric crypto is quite inefficient. A session key can be used: Alice selects a random symmetric key. She uses it to encrypt the message. She the encrypts this key using Bob’s public key and concatenates the symmetricly encrypted message and the asymmetricly encrypted key. Sender authentication and message integrity: we suppose that Alice and Bob don’t care for confidentiality. They will use digital signatures and message digests. Alice applies a hash function H to her message m, obtain a message digest, signs the digest with her private key to create a digital signature, concatenates the original message with the signature to create a package and sends the package to Bob’s e-mail address. Bob uses Alice’s public key to the digest and compares the result fo this operation with his own hash H of the message. Confidentiality, sender authentication and message integrity: the two procedures above can be combined, message and digest are concatenated and the treated as a new message which is encrypted using the first technique.These techniques suppose however that Alice and Bob are able to exchange their public keys. An intruder could in fact send a public key to Bob pretending to be Alice. Certification is needed.Phil Zimmermann and PGPPZ was the creator of PGP. For that he was legally attacked by the US Government, he distributed PGP while it should have stayed a secret weapon in the heads of the defense. The US dropped the case and PGP became the most widely used e-mail encryption software in the world despite the lack of funding, paid staff.8.5.2 PGPPretty Good Privacy (PGP) is an e-mail encryption scheme that has become the De Facto standard.It uses the same design shown above, giving the option of signing, encrypting or both.When PGP is installed, it creates a public key pair for the user, the public key can be posted online while the private key is protected by a password which has to be entered every time the user accesses the private key.A PGP message appears after the MIME header.PGP also provides a mechanism for public key certification. PGP public keys are certified by Web of Trust: Alice can certify any key/username pair when she believes the pair really belong together and, in addition, PGP permits Alice to say that she trusts another user to vouch for the authenticity of more keys. Some PGP users sign each other’s key by holding key-signing parties.8.6 Securing TCP Connections: SSLWe now move to the transport layer. The enhanced version of TCP is called Secure Socket Layer (SSL), a slightly modified version of SSL v3 called Transport Layer Security (TLS) has been standardized by the IETF.Originally developed by Netscape, SSL has enjoyed broad deployment since its origins, providing secure communication between all recent browsers and online services. SSL provides TCP with confidentiality, data integrity, server authentication and client authentication.SSL is often used over HTTP, however, as it secures TCP, it can be employed by any application that runs over TCP. SSL provides a simple Application Programming Interface with sockets, similar to TCP’s API.When an application wants to use SSL, it must include SSL classes/libraries. Technically SSL resides in the application layer but from the developer’s perspective it is a transport layer protocol that provides TCP’s services enhanced with security services.8.6.1 The Big Picture (primitive almost-SSL)Three phases: Handshake: Bob initiates a TCP connection is established (TCP SYN, SYNACK, ACK). Bob sends SSL Hello, Alice responds with her certificate containing her public key (the certificate being certified by a CA, Bob is sure that the key belongs to Alice). Bob generates a master secrect (MS), encrypts it with Alice’s public key to create the Encrypted Master Secret (EMS) and sends it to Alice who will decrypt it with her private key to get the MS which can be used for confidentiality and integrity as seen before. Key Derivation instead of using the MS for integrity and confidentiality, it is safer to use different keys for different functions. Therefore both Alice and Bob use the MS to generate: \t- Eb = session encryption key for data Bob -&gt; Alice Mb = session MAC key for data Bob -&gt; Alice Ea = session encryption key for data Alice -&gt; Bob Ma = session MAC key for data Alice -&gt; BobThe MS could simply be split in four chunks, but real SSL does it differently. Data Transfer TCP is a byte-stream protocol, so where would we put the MAC for the integrity check? SSL breaks the data stream into records, appends a MAC to each record and then encrypts record+MAC. However, in a MITM attack, the order of packets could be reversed as TCP sequence numbers are not encrypted. SSL therefore uses sequence numbers. Bob keeps a sequence number counter which begins at zero and is incremented at each record transmission. He includesthe sequence number in the MAC calculation: MAC = hash(data+Mb+SeqNum). Alice tracks Bob’s sequence numbers so that she can verify the MAC.SSL RecordThe real SSL record: Type: handshake message, data message, connection teardown message Length: used to extract the records out of the TCP byte stream8.6.2 A More Complete PictureSSL allows Alice and Bob to agree on the cryptographic algorithms at the beginning of the SSL session, during handshake. Steps: The client sends a list of cryptographic algorithms it supports, along with a client nonce The server chooses a symmetric algorithm (ex: AES), a public key algorithm (ex RSA) and a MAC algorithm. It sends back to the client its choices as well as a certificate and a server nonce. The client verifies the certificate, extracts the server’s public key, generates a Pre-Master Secret (PMS), encrypts it with the server’s public key and sends the encrypted PMS to server. Using the same key derivation function (specified by SSL standard), client and server independently compute the Master Secret (MS) from the PMS and the nonces. The MS is sliced up to create the two encryption and the two MAC keys. Furthemore when the symmetric cipher employs CBC (ex 3DES or AES) the two Initialization Vectors (IVs), one for each side of the connection, are also obtained from hte MS. Henceforth all messages sent between client and server are encrypted and authenticated (using MAC) The client sends a MAC of all the handshake messages The server sends a MAC of the handshake messages.5 and 6 protect the handshake from tampering: if in the end MAC are not coherent with the previously sent messages, the connection is stopped. (prevents an attacker from impersonating the server and imposing weak algorithms).Nonces are used to avoid connection replay attacks (resending packets sniffed during a previous connection again, using nonces allows to have different MACs and therefore messages at each connection, even if the content of the communication is the same).Connection ClosureTCP FIN segments can be crafted by an attacker (truncation attack), therefore they cannot be used.The type field of SSL records is used for these purpose, even if it sent in the clear, it is authenticated at the receivers using record’s MAC.8.7 Network-Layer Security: IPsec and Virtual Private NetworksThe IP security protocol is called IPsec, it secures IP datagrams between any two network-layer entities (host, routers)8.7.1 IPsec and Virtual Private Networks (VPNs)An institution extending overt multiple geographical regions might want its own IP network so that the machines in it can communicate securely. Such a disjoint network is a private network. A physical private network can be expensive. VPN can be used to deploy and maintain a private network over the existing public Internet. The traffic is sent over the Internet but encrypted before entering the public net.Not all traffic sent into the Internet by the gateway routers or laptops will be IPsec secured (only the portion accessing internal resources)8.7.2 The AH and ESP ProtocolsIn the IPsec protocol suite, there are two principal protocols: the Authentication Header (AH) protocol and the Encapsulation Security Payload (ESP) protocol.When a source IPsec entity (router or host) sends secure datagrams to a destination entity it does so with either ESP or AH. AH provides source authentication and data integrity while ESP provides source authentication, data integrity and confidentiality. Because the latter is often critical for VPNs, ESP is much more widely used AH. We will only study ESP.8.7.3 Security AssociationsBefore sending IPsec datagrams from source entity to destination entity, source and destination create a network-layer logical connection called security association (SA). SA is a simplex (unidirectional from source to destination) logical connection. If both entities want to send datagrams to each other, then two SAs need to be established, one in each direction.The VPN server (headquarters gateway router) will maintain state information about the SA, which will include: 32-bit identifier for the SA, called Security Parameter Index (SPI) The origin interface (client outside) of the SA and its destination (its out facing interface) [IP addresses] Type of the encryption used Encryption key Type of the integrity check Authentication keyAn IPsec entity often maintains state information for many SAs (all outside clients) using its Security Association Database (SAD) which is a data structure in the entity’s OS kernel.8.7.4 The IPsec DatagramIPsec has two different packet forms, one for tunnel mode and one for transport mode, the first one, being more appropriate for VPNs, is more widely deployed than the transport mode, we will therefore only focus on it.The headquarters’s gateway receives an IPv4 datagram from inside the network directed to a VPN client outside. Here is what happens: It appends to the back of the original datagram (which includes the original header fields) in the ESP trailer field It encrypts the result using the algorithm and key specified in the SA Appends to the front of the result a ESP Header creating the “enchilada” Creates an authentication MAC over the whole enchilada using algorithm and key specified in the SA Appends the MAC to the back of the enchilada forming the payload Creates a brand new IP header with all the classic IPv4 header fields which it appends before the payload.The protocol number field is set to 50, designating IPsec. The routers along the path will treat the datagram as a normal one, oblivious that it is an IPsec datagram.To decide whether outgoing packets should be treated as above or simply let through, the gateway maintains a Security Policy Database (SPD) which indicates what types of datagrams (as a function of the source and destination IPs and of the protocol) are to be IPsec processed and, for those that are, which SA should be used.IPsec provides confidentiality, source authentication, data integrity, replay-attack prevention.8.7.5 IKE: Key Management in IPsecWho/What should populate the SAD? For small VPNs this can be done manually. For larger ones there is the Internet Key Exchange (IKE) protocol.IKE is similar to the handshake in SSL. Here are the steps: During the first exchange of messages, the two sides use Diffie-Hellman to create a Bi-Directional IKE SA between the routers, which is entirely different form the IPsec SA discussed above. This IKESA provides an authenticated and encrypted channel between the two routers. Keys are established for encryption and authentication for IKESA. Also established is a master secret. During the second exchange of messages, both sides reveal their identity to each other by signing their messages. However the identities are not revealed to an eventual sniffer, since the messages are sent over the IKE sa channel. The two sides also negotiate the IPsec encryption and authentication algorithms to be employed by the IPsec SA. Finally the two sides create an SA n each direction.We have two phases to reduce computational costs: we don’t need asymmetric cryptography during second phase, allowing IKE to generate many SAs with relatively little computational cost.8.9 Operational Security: Firewalls and Intrusion Detection Systems8.9.1 FirewallsA firewall is a combination of hardware and software that isolates an organization’s internal network from the Internet at large, allowing some packets to pass and blocking others. It has three goals All traffic from outside to inside, and vice versa, passes through the firewall Only authorized traffic, as defined by the local security by the local policy, will be allowed to pass. The firewall itself is immune to penetrationFirewalls can be classified in three categories:1: Traditional Packet FiltersPacket filters examine each datagram in isolation determining whether the datagram should be allowed to pass or should be dropped based on administrator-specific rules.Filtering decisions can be based on IP source/destination, protocol type, TCP/UDP, TCP flags/ ICMP message type, rules for leaving/entering, rules for different router interfaces.The parameters are based on the policy of the organization taking account of user productivity and bandwidth usage as well as security concerns.2: Stateful Packet FiltersDecisions are made on each packet in isolation. Stateful filters track TCP connecions and use this knowledge to make filtering decisions.3: Application GatewaysApplication Gateways look beyond the IP/TCP/UDP headers and make policy decisions based on application data. An Application Gateway is an application-specific server through which all application data must pass. Multiple AG can run on the same host, but each gateway is a separate server with its own processes.8.9.2 Intrusion Detection SystemsAn intrusion detection system (IDS) is a device that alerts when it observes potentially malicious traffic. An intrusion prevention system (IPS) is a device that filters out suspicious traffic. Both types of device perform deep packet inspection: they look beyond the header fields and into the actual application data that the packets carry.An IDS can detect a wide range of attacks, including network mapping, port scans, TCP stack scans, DoS, worms, viruses, OS vulnerability attacks and application vulnerability attacks.An organization can deploy one more IDS sensors in its network. When many are used, they work together, usually coordinated by a central server. More than one is often a good solution as each one compare each passing packet with tens of thousands of signatures. They are usually classified as either signature-based systems or anomaly-based systems.A signature based IDS maintains an extensive database of attack signature, each of which being a set of rules pertaining to an intrusion activity. A signature can be a list of packet characteristics or may relate to a series of packets. They are created by network security engineers researching attacks. The ids sniffs every packet passing by it, comparing it with signatures.Signature based IDS, although widely deployed, have a number of limitations: they require a previous knowledge of the attack to generate an accurate signature, false alarms may be generated, they can be slow and fail to detect attacks if overwhelmed.Anomaly-based packets study normal traffic and looks for statistically unusual events. They don’t rely on previous knowledge of attacks.Chapter 5: The Link Layer: Links, Access Networks and LANs5.1 Introduction to the Link LayerSome terminology: node = any device running a link-layer protocol (hosts, routers, switches…) link = communication channels connecting adjacent nodes along the path. Over a given link, a transmitting node encapsulates the datagram in a link-layer frame and transmits the frame into the link.5.1.1 The Services Provided by The Link LayerPossible services offered by a link-layer protocol include: Framing: all link layer protocols encapsulate each network layer datagram within a link-layer frame before transmission. A frame consists of a data field, containing the datagram, and a number of header fields, whose structure is determined by the protocol. Link access: A Medium Access Control (MAC) protocol specifies the rules by which a frame is transmitted onto the link. Reliable delivery: the protocol guarantees to move each datagram across the link without loss or errors. A reliable delivery protocol is often used for links highly prone to errors (WiFi) so that the error can be corrected locally, where it happens, rather than forcing an end-to-end retransmission. However it can represent a significant overhead for low bit-error links (cable) and therefore many wired link-layer protocols do not provide a reliable delivery service. Error detection and correction: signal attenuation and electromagnetic noise can introduce errors. Because there is no need to forward a datagram that has an error, may link-layer protocols provide a mechanism to detect such bit errors so that they can drop the frames. This can be accomplished transmitting error-detection bits in the frame. Link layer error detection is usually more sophisticated and implemented in hardware.5.1.2 Where Is the Link Layer Implemented?In routers, the link layer is implemented in the line card. Is a host’s link layer implemented in hardware or software?For the most part, the link layer is implemented in a network adapter, sometimes known as network interface card (NIC). At the heart of the NIC is the link-layer controller, usually a single, special purpose chip that implements many of the link-layer services. Thus, much of a link-layer controller’s functionality is implemented in hardware.Part of the link layer is implemented in software that runs on the host’s CPU, this part implement higher-level functionalities.Link-Layer is a combination of hardware and software, the place in the protocol stack where software meets hardware.5.2 Error-Detection and -Correction TechniquesError detection and correction allow the receiver to sometimes, but not always, detect that bit errors have occurred. Even with the use of error-detection bits, there still may be undetected bit errors (the receiver is unaware of the presence of corrupted bits).We want to keep the probability of such an event small. Let’s now consider three techniques for detecting errors in the transmitted data: parity checks, checksumming methods and cyclic redundancy checks5.2.1 Parity ChecksPerhaps the simplest form of error detection is the use of a single parity bit. Suppose that the information to be sent, D, has d bits.In an even parity scheme, the sender simply includes one additional bit and chooses its value such that the total number of 1s in the d+1 bits (original + parity bit) is even. (odd parity scheme, parity bit to one if #1s % 2 != 0).The receiver only needs to count the number of 1s in the d+1 bits. If an odd number of 1 valued bits are found with an even parity scheme, the receiver knows that some odd number of bit error has occurred.If an even number of bit errors occur, this would result in an undetected error.Another approach is to use a two dimensional even parity: the d bits are divided into i rows and j columns. A parity value is computed for each row and for each column. The result i + j + 1 parity bits comprise the error-detection bits.A single bit error in the original d bits will cause the parity of both the column and the row containing the flipped bit to to be in error. The receiver can not only detect the error, but also use the column and row indices of the column and row with parity errors to actually identify the bit that was corrupted and correct the error.This technique also allows to detect an error in the parity bits.The ability of the receiver to both detect and correct errors is known as forward error correction (FEC)5.2.2 Checksumming MethodsThe d bits of data are treated as a sequence of k-bit integers for example the Internet checksum already studied: bytes of data are treated as integers and summed, the 1s complement of this sum forms the Internet checksum carried in the header. The receiver checks the checksum by taking the 1s complement of the sum of the received data (including checksum) and checking whether the result is all 1 bits, if there are any 0, an error is indicated. In TCP and UDP the checksum is computed over all fields (header and data).Checksumming methods require little packet overhead but they provide relatively weak protection against errors.Why is checksumming used in transport layer and cyclic redundancy check used at the link layer?Transport layer is implemented in software (OS) and therefore needs a simple and fast error detection scheme while error detection at link layer is implemented in hardware which can perform the more complex CRC operations.5.2.3 Cyclic Redundancy Check (CRC)Cyclic Redundancy Check (CRC) codes are also known as polynomial codes since it is possible to view the string to be sent as a polynomial whose coefficients are the 0 and 1 values in the bit string with operation interpreted as polynomial arithmetic.Sender and receiver must agree on a r+1 bit pattern know as generator which we’ll denote as G. We require the leftmost bit of G to be a 1. For a given piece of data D the sender will choose r additional bits, R, and append them to D such that the resulting d + r bit pattern, interpreted as a binary number, is exactly divisible by G using modulo-2 arithmetic.Checking is therefore easy: the receiver divides the d + r received by bits by G, if the remainder is nonzero, an error has occurred, otherwise the data is accepted as being correct.All CRC calculations are done in modulo 2 without carries in addition or borrows in subtraction (+ = - = xor).5.3 Multiple Access Links and ProtocolsThere are two types of network links: point-to-point and broadcast links. A point-to-point link consists of a single sender at one end of the link and a single receiver at the other end of the link. A broadcast link can have multiple sending and receiving nodes all connected to the same, single, shared broadcast channel. The term broadcast is used because when any node transmits a frame, the channel broadcasts the frame and each other node receives a copy (ex: ethernet, wireless).The multiple access problem: How to coordinate the access of multiple sending and receiving nodes to a shared broadcast channel?Computer networks have multiple access protocols by which nodes regulate their transmission into the shared broadcast channel.More than two nodes can transmit frames at the same time, which will result in all of the nodes receiving multiple frames at the same time: the frames collide at all of the receivers. Typically in case of collision, none of the receiving nodes can make any sense of any of the frames, they become inextricably tangled together and are therefore lost, the channel being wasted during collision.Thus it is necessary to coordinate the transmission of the active nodes.We can classify multiple access protocols in three categories: channel partitioning protocols, random access protocols, taking-turns protocols.5.3.1 Channel Partitioning ProtocolsTDM and FDM (from circuit switching) are in this category.A third channel partitioning tool is code division multiple access (CDMA) which assigns a different code to each node. Each node then uses its unique code to encode the data bits it sends. If the codes are chosen carefully, then all nodes can transmit simultaneously and yet have their respective receivers correctly receive a sender’s encoded data bits. Originally used in military systems, it’s now widely used for civilian use, particularly in cellular telephony.5.3.2 Random Access ProtocolsA transmitting node always transmits at the full rate of the channel, R bps. When there is a collision, each node involved in the collision repeatedly retransmits its frame until the frame gets through without a collision.But when a node experiences a collision, it waits a random dely before retransmitting the frame. The delay is chosen independently.Here a few of the most commonly used random access protocols:Slotted ALOHAAll frames consist of L bits, time is divided into slots of size L/R seconds, nodes start to transmit frames only at the beginning of slots. Moreover nodes are synchronized so that each node when the slot begins. If two or more frames collide in a slot, then all the nodes detect the collision event before the slot ends.If p is a probability then the operation of slotted ALOHA in each node is simple: each node waits the beginning of the next slot to transmit the entire frame in a slot If no collision occurs, the frame is considered delivered If collision, this is detect before the end of the slot. The node retransmits its frame in each subsequent slot with probability p (probability of retransmission) until the frame is transmitted without a collision.Slotted ALOHA allows transmission at full rate R, is highly decentralized, and is extremely simple.The computed maximal efficiency (successfully used slots in transmission / total slots) of Slotted ALOHA) is 37% thus the effective transmission rate is 0.37R bps.Alohaall nodes synchronize their transmissions to start at the beginning of a slot. The node immediately transmits a frame in its entirety in the channel. In case of collision, the node will then immediately retransmit the frame with probability p otherwise the node waits for a frame transmission time, after which it transmits the frame with probability p or wait for another frame with probability 1-p. The maximum efficiency is 1/(2e) but the protocol is fully decentralized.Carrier Sense Multiple Access (CSMA)CSMA and CSMA/CD (collision detection) embody two rules: carrier sensing: if a node is transmitting, the others wait until they detect no transmission for a short amount of time and begin transmission. collision detection: a transmitting node listens to the channel while it’s transmitting, if it detects that another node is transmitting, it stops transmitting and waits for a random amount of time before repeating the sense-and-transmit-when-idle-cycle.It is evident that the propagation delay of the channel plays a crucial role: the longer, the larger the chance that a carrier sensing node is not yet able to sense a transmission that has already begun.Carrier Sense Multiple Access with Collision Detection (CSMA/CD)When a node detects a collision, it ceases transmission immediately in Collision Detection.A link layer frame is prepared, if the node senses that the channel is idle (no energy is entering the adapter from the channel), it starts to transmit the frame, else it waits until it detects idle. While transmitting, the node monitors the channel for usage from other nodes, if the entire frame is transmitted without detecting usage, then the adapter is finished. If energy is detected from other adapters while transmitting, the node aborts transmission (stops), waits for a random amount of time and then returns to checking for idle.The wait for random amount of time is required in order to avoid the nodes to keep colliding.CSMA/CD EfficiencyIs the long run fraction of time during which frames are being transmitted without collision. If the propagation delay approaches 0, the efficiency approaches 1.Also if the propagation delay becomes very large, efficiency approaches 1.5.3.3 Taking-Turns ProtocolsThere are a lot of them, we’ll cover two of the more important, the first one being the polling protocol. It requires one of the nodes to be designated as a master node which polls each of the nodes in a round-robin fashion.The master tells node 1 that it can transmit up to some maximum number of frames, when node 1 is finished (the master checks for energy in the channel) the master tells the same to node 2 and so on.The polling protocol eliminates the collisions and empty slots that plague random access protocols, resulting in a much higher efficiency.However it introduces a polling delay (the amount of time required to notify a node that it can transmit) [if only one is transmitting, it will have to wait for the master to poll all the others]. Moreover the master node represents a single point of failure.The second protocol is the token-passing protocol in which there is no master method. A small, special purpose frame known as token is exchanged among the nodes in some fixed order. When a node receives a toke, it holds it only if it has some frames to transmit otherwise it immediately forwards it to the next node.If a node has frames to transmit when it receives the token, it sends up to a maximum number of frames and then passes the token. Token passing is decentralized and highly efficient but the failure of one node could crash the entire channel, or a node could neglect to release the token….5.3.4 DOCSIS: The Link-Layer Protocol for Cable Internet AccessThe Data-Over-Cable-Service-Interface-Specifications specifies the cable data network architecture and its protocols. DOCSIS uses FDM to divide the downstream and upstream network segments into multiple frequency channels. Each upstream and downstream channel is a broadcast channel. Several cable modems share the same upstream channel (frequency) to the CMTS and thus collision can potentially occur.Each upstream channel is divided into intervals of time (TDM-like) each containing a sequence of mini-slots during which cable modems can transmit to the CMTS, which explicitly grants permission to individual modems to transmit during specific mini-slots. This is done sending a special control message known as a MAP message on a downstream channel to specify which cable modem can transmit during which mini-slot.Modems send mini-slot-request frames to the CMTS during a special set of interval mini-slots dedicated for this purpose. The requests are transmitted in a random access manner and may collide with each other. The modem cannot detect activity nor collisions: it simply infers that its request experienced collision if it does not receive a response in the next downstream control message.When a collision is inferred, a modem uses binary exponential backoff to defer the transmission to a future slot.5.4 Switched Local Area NetworksSwitched local networks connect hosts using link-layer switches which do not run networks-layer protocols.5.4.1 Link-Layer Addressing and ARPMAC AddressesNetwork interfaces in hosts and routers have link-layer addresses, however link-layer switches do not have link-layer addresses associated with their interfaces so that they can carry datagrams without having routers or hosts having to explicitly address the frame to the intervening switch.A link-layer address is called LAN address, physical address or MAC address, the last name being the most popular. This address is 6 bytes long, typically expressed in hexadecimal notation. They are supposed to be permanent but can be changed via software.No two adapters have the same address: the IEEE manages the MAC address space, usually assigning a 24 prefix to each manufacturer and letting him choose the content of the remaining 24 bits.MAC address have a flat structure (no hierarchy such as in IP) and do not change.When an adapter wants to send a frame to some destination adapter, it inserts the destination adapter’s MAC address into the frame and then sends the frame into the LAN. An adapter might receive a frame that isn’t addressed to it, when this happens, the adapter checks whether the frame’s destination address matches its own, if not it discards the frame. When a sending adapter want to broadcast to the whole network, it inserts a special MAC broadcast address into the destination address field, for 6bytes addresses that is FF-FF-FF-FF-FF-FFAddress Resolution Protocol (ARP)The Address Resolution Protocol (ARP) translates network-layer addresses into link-layer addresses, analogously to DNS, but ARP resolves IP addresses only for hosts and router interfaces on the same subnet.Each host and router has an ARP table which contain mappings of IP addresses to MAC addresses and a time-to-live TTL value which indicates when each mapping will be deleted from the table. A typical TTL is 20 minutes from when an entry is placed in the ARP table.The table does not necessarily contain an entry for every host and router on the subnet.What if a frame has to be sent to an address which does not appear in the table?The sender creates a special packet, an ARP packet, containing the sending and receiving IP and MAC addresses. Both ARP query and response have the same format: the sending forwards the ARP request to the broadcast address (destination address) the frame containing the query is received by all the other adapters in the subnet. Each adapter passes the frame to the ARP module which checks if its IP address matches the destination IP address in the query. The one with a match sends back the response with the desired mapping. The querying can update its table and send the IP datagram encapsulated in a link-layer frame.ARP is plug and play: the table gets build automatically.ARP stands in the boundary between the link and network layers.Sending a Datagram off the SubnetA datagram that has to be sent out of the subnet is first sent to the first-hop router on the path to the final destination (which is outside the subnet). How is its MAC acquired? Using ARP.When the frame reaches the next-hop router of the destination subnet, it has to be moved inside, the router having to decide what interface to use. This is done using the forwarding table: the router extracts the datagram and checks the destination IP. The datagram is encapsulated again and sent into the subnet, this time the MAC address of the frame is indeed the destination MAC address of the ultimate destination, which the router acquire via ARP.5.4.2 EthernetIt has pretty much taken over the wired LAN market. Since its invention in the 70’s, it has grown and become faster.At the beginning the original Ethernet LAN used a coaxial bus to interconnect the nodes, creating a broadcast LAN. By the late 90s, most companies and universities had replaces their LANs with Ethernet installation using a hub-based star topology: hosts and routers are directly connected to a hub with twisted-pair copper wire. A hub is a physical layer device that acts on individual bits rather than frames. When a hub receives a bit, it simply recreates it boosting its energy strength and transmits the bit onto all the other interfaces (it’s still a broadcast LAN). In the early 2000s, the star topology evolved: the hub was replaced with a switch, allowing a collision-less LAN.Ethernet Frame Structure Data fields (46 to 1,500 bytes): carries the IP datagram (or other network-layer datagram). The MTU (maximum transmission unit) is 1500 bytes, compensated with fragmentation. The minimum is 46, is less, the data is “stuffed” and the receiving network layer uses the length field to eliminate the stuffing Destination address (6 bytes) destination MAC address. Source address (6 bytes) Type field (2 bytes) allows to multiplex network layer protocols (if not only IP is used, also ARP has its own type number 0x0806) Cyclic redundant check (CRC) (4 bytes): used for bit error detection Preamble (8 bytes): the first seven have value 10101010, the last has value 10101011. The first seven serve as “wake up” the receiving side and to synchronize their clocks to that of the sender’s clock the two 1s at the end of byte 8 alerts the receiver that the important stuff is about to come.All of the Ethernet technologies provide connectionless service (no handshaking, similar to UDP) and unrealiable service to the network layer (no ACK, drop in case of errors) which help to make Ethernet simple and cheap.If there are gaps due to discarded Ethernet frames, the fact that the application sees the gaps or not depends on the transport layer protocol used: not with TCP (reliable data transfer), yes with UDP.Ethernet TechnologiesThere are many variants and flavors of Ethernet which have been standardized over the years by the IEEE. They vary in speed: 10 Megabit, 100 Megabit, 1000 Megabit, 10 Gigabit…They can also vary in the type of traffic they can transport….5.4.3 Link-Layer SwitchesSwitch receive and forward frames. They are transparent: adapters address each other, without knowing that the switch is sitting in the middle. As they’re output rate might be smaller than the input rate, they also have buffers to queue frames.Forwarding and FilteringFiltering is the switch function that determines whether a frame should be forwarded to some interface or should just be dropped.Forwarding is the switch function that the determines the interfaces to which a frame should be directed and then moves the frame to those interfaces.Switch filtering and forwarding are done with a switch table which contains entries for some (not necessarily all) of the hosts and routers on a LAN. Each entry contains:(MAC address, interface leading toward that MAC, time at which the entry was placed in the table)Switches forward frames based on the MAC addresses rather than on IP addresses.When a switch receives a frame: There is no entry in the table associated with the destination address -&gt; the packet is broadcast through all the interfaces (except the one through which the frame was received) There is an entry in the table that point to the same interface through which the frame was received -&gt; The frame is discarded (filtering) There is an entry in the table that point to an interface different from the one through which the frame was received -&gt; the frame is put in the output buffer preceding the interface discovered thanks to the table (forwarding)Self-LearningThe switch table is build automatically, dynamically and autonomously without any intervention from a network administrator: switches are self learning. The switch table is initially empty For each incoming frame, the switch stores in its table \t1. the MAC address in the frame’s source address field the interface from which the frame arrived the current time The switch deletes an address in the table if no frame are received with that address as the source after some period (aging time) so that to eliminate unused entries from the tableThus switches are plug-and-play devices: they require no human intervention. Switches are also full-duplex, meaning any interface can send and receive at the same time.Properties of Link-Layer SwitchingAdvantages over buses or hubs: Elimination of collisions: the switch buffers frames and never transmit more than one frame on a segment at any one time. The maximum aggregated throughput is the sum of all the switch interface rates Heterogeneous links: The switch providing isolation, different links can operate at different speeds and run over different media. Therefore switches are ideal for mixing legacy equipment with new equipment. Management: A switch can disconnect a malfunctioning adapter and a cut cable isolates only one host. Switches can gather statistics useful for debugging and planning the evolution of the network.Switches Versus RoutersThey are both packet switches but switches are layer-2 packet switches while routers are layer-3 packet switches.Switches are plug-and-play, have relatively high filtering and forwarding rates.However to prevent the cycling of broadcast frames, the active topology of a swtiched network is restricted to a spanning tree. A large network requires large ARP tables in hosts and routers and would generate substantial ARP traffic and processing. Switches are also susceptible to broadcast storms: if one goes crazy and send an endless stream of broadcast frames, the others will forward all of the frames resulting in a network collapse.Routers network addressing is hierarchical, packets do not normally cycle and the topology is not limited to a spanning tree even when the network has redundant paths. Therefore packets can use the best path between source and destination. But routers are not plug-and-play (a host need the IP to connect) and often have a larger per-packet processing time than switches. Finally two pronunciation cause a lot of disputes.PDF Note👇" }, { "title": "Complete Computer Science Study Plan to Become a Software Engineer", "url": "/posts/complete-computer-science-study-plan-to-become-a-software-engineer/", "categories": "Computer Science, Study Plan", "tags": "computer-science, study-plan, software-engineer, developer", "date": "2022-10-25 00:00:00 +0530", "snippet": "Table of ContentsThe Study Plan What is it? Why use it? How to use it Don’t feel you aren’t smart enough A Note About Video Resources Choose a Programming Language Books for Data Structures ...", "content": "Table of ContentsThe Study Plan What is it? Why use it? How to use it Don’t feel you aren’t smart enough A Note About Video Resources Choose a Programming Language Books for Data Structures and Algorithms Interview Prep Books Don’t Make My Mistakes What you Won’t See Covered The Daily Plan Coding Question Practice Coding ProblemsTopics of Study Algorithmic complexity / Big-O / Asymptotic analysis Data Structures Arrays Linked Lists Stack Queue Hash table More Knowledge Binary search Bitwise operations Trees Trees - Intro Binary search trees: BSTs Heap / Priority Queue / Binary Heap balanced search trees (general concept, not details) traversals: preorder, inorder, postorder, BFS, DFS Sorting selection insertion heapsort quicksort merge sort Graphs directed undirected adjacency matrix adjacency list traversals: BFS, DFS Even More Knowledge Recursion Dynamic Programming Design Patterns Combinatorics (n choose k) &amp; Probability NP, NP-Complete and Approximation Algorithms How computers process a program Caches Processes and Threads Testing String searching &amp; manipulations Tries Floating Point Numbers Unicode Endianness Networking Final ReviewGetting the Job Update Your Resume Find a Job Interview Process &amp; General Interview Prep Be thinking of for when the interview comes Have questions for the interviewer Once You’ve Got The Job—————- Everything below this point is optional —————-Optional Extra Topics &amp; Resources Additional Books System Design, Scalability, Data Handling (if you have 4+ years experience) Additional Learning Compilers Emacs and vi(m) Unix command line tools Information theory Parity &amp; Hamming Code Entropy Cryptography Compression Computer Security Garbage collection Parallel Programming Messaging, Serialization, and Queueing Systems A* Fast Fourier Transform Bloom Filter HyperLogLog Locality-Sensitive Hashing van Emde Boas Trees Augmented Data Structures Balanced search trees AVL trees Splay trees Red/black trees 2-3 search trees 2-3-4 Trees (aka 2-4 trees) N-ary (K-ary, M-ary) trees B-Trees k-D Trees Skip lists Network Flows Disjoint Sets &amp; Union Find Math for Fast Processing Treap Linear Programming Geometry, Convex hull Discrete math Additional Detail on Some Subjects Video Series Computer Science Courses PapersWhy use it?If you want to work as a software engineer for a large company, these are the things you have to know.If you missed out on getting a degree in computer science, like I did, this will catch you up and save four years of your life.When I started this project, I didn’t know a stack from a heap, didn’t know Big-O anything, or anything about trees, or how totraverse a graph. If I had to code a sorting algorithm, I can tell ya it would have been terrible.Every data structure I had ever used was built into the language, and I didn’t know how they workedunder the hood at all. I never had to manage memory unless a process I was running would give an “out ofmemory” error, and then I’d have to find a workaround. I used a few multidimensional arrays in my life andthousands of associative arrays, but I never created data structures from scratch.It’s a long plan. It may take you months. If you are familiar with a lot of this already it will take you a lot less time.How to use itEverything below is an outline, and you should tackle the items in order from top to bottom.I’m using GitHub’s special markdown flavor, including tasks lists to track progress. More about GitHub-flavored markdownIf you don’t want to use gitOn this page, click the Code button near the top, then click “Download ZIP”. Unzip the file and you can work with the text files.If you’re open in a code editor that understands markdown, you’ll see everything formatted nicely.If you’re comfortable with gitCreate a new branch so you can check items like this, just put an x in the brackets: [x] Fork the GitHub repo: https://github.com/jwasham/coding-interview-university by clicking on the Fork button. Clone to your local repo: git clone git@github.com:&lt;your_github_username&gt;/coding-interview-university.git cd coding-interview-university git checkout -b progress git remote add jwasham https://github.com/jwasham/coding-interview-university git fetch --all Mark all boxes with X after you completed your changes: git add . git commit -m \"Marked x\" git rebase jwasham/main git push --set-upstream origin progress git push --force Don’t feel you aren’t smart enough Successful software engineers are smart, but many have an insecurity that they aren’t smart enough. Following videos may help you overcome this insecurity: The myth of the Genius Programmer It’s Dangerous to Go Alone: Battling the Invisible Monsters in Tech A Note About Video ResourcesSome videos are available only by enrolling in a Coursera or EdX class. These are called MOOCs.Sometimes the classes are not in session so you have to wait a couple of months, so you have no access.It would be great to replace the online course resources with free and always-available public sources, such as YouTube videos (preferably university lectures), so that you people can study these anytime, not just when a specific online course is in session.Choose a Programming LanguageYou’ll need to choose a programming language for the coding interviews you do, but you’ll also need to find a language that you can use to study computer science concepts.Preferably the language would be the same, so that you only need to be proficient in one.For this Study PlanWhen I did the study plan, I used 2 languages for most of it: C and Python C: Very low level. Allows you to deal with pointers and memory allocation/deallocation, so you feel the data structures and algorithms in your bones. In higher level languages like Python or Java, these are hidden from you. In day to day work, that’s terrific, but when you’re learning how these low-level data structures are built, it’s great to feel close to the metal. C is everywhere. You’ll see examples in books, lectures, videos, everywhere while you’re studying. The C Programming Language, Vol 2 This is a short book, but it will give you a great handle on the C language and if you practice it a little you’ll quickly get proficient. Understanding C helps you understand how programs and memory work. You don’t need to go super deep in the book (or even finish it). Just get to where you’re comfortable reading and writing in C. Answers to questions in the book Python: Modern and very expressive, I learned it because it’s just super useful and also allows me to write less code in an interview.This is my preference. You do what you like, of course.You may not need it, but here are some sites for learning a new language: Exercism Codewars HackerEarth Scaler Topics (Java, C++)For your Coding InterviewYou can use a language you are comfortable in to do the coding part of the interview, but for large companies, these are solid choices: C++ Java PythonYou could also use these, but read around first. There may be caveats: JavaScript RubyHere is an article I wrote about choosing a language for the interview: Pick One Language for the Coding Interview.This is the original article my post was based on: Choosing a Programming Language for InterviewsYou need to be very comfortable in the language and be knowledgeable.Read more about choices: Choose the Right Language for Your Coding InterviewBooks for Data Structures and AlgorithmsThis book will form your foundation for computer science.Just choose one, in a language that you will be comfortable with. You’ll be doing a lot of reading and coding.C Algorithms in C, Parts 1-5 (Bundle), 3rd Edition Fundamentals, Data Structures, Sorting, Searching, and Graph Algorithms Python Data Structures and Algorithms in Python by Goodrich, Tamassia, Goldwasser I loved this book. It covered everything and more. Pythonic code my glowing book report: https://startupnextdoor.com/book-report-data-structures-and-algorithms-in-python/ JavaYour choice: Goodrich, Tamassia, Goldwasser Data Structures and Algorithms in Java Sedgewick and Wayne: Algorithms Free Coursera course that covers the book (taught by the authors!): Algorithms I Algorithms II C++Your choice: Goodrich, Tamassia, and Mount Data Structures and Algorithms in C++, 2nd Edition Sedgewick and Wayne Algorithms in C++, Parts 1-4: Fundamentals, Data Structure, Sorting, Searching Algorithms in C++ Part 5: Graph Algorithms Interview Prep BooksYou don’t need to buy a bunch of these. Honestly “Cracking the Coding Interview” is probably enough, but I bought more to give myself more practice. But I always do too much.I bought both of these. They gave me plenty of practice. Programming Interviews Exposed: Coding Your Way Through the Interview, 4th Edition Answers in C++ and Java This is a good warm-up for Cracking the Coding Interview Not too difficult. Most problems may be easier than what you’ll see in an interview (from what I’ve read) Cracking the Coding Interview, 6th Edition answers in Java If you have tons of extra time:Choose one: Elements of Programming Interviews (C++ version) Elements of Programming Interviews in Python Elements of Programming Interviews (Java version) - Companion Project - Method Stub and Test Cases for Every Problem in the BookDon’t Make My MistakesThis list grew over many months, and yes, it got out of hand.Here are some mistakes I made so you’ll have a better experience. And you’ll save months of time.1. You Won’t Remember it AllI watched hours of videos and took copious notes, and months later there was much I didn’t remember. I spent 3 days goingthrough my notes and making flashcards, so I could review. I didn’t need all of that knowledge.Please, read so you won’t make my mistakes:Retaining Computer Science Knowledge.2. Use FlashcardsTo solve the problem, I made a little flashcards site where I could add flashcards of 2 types: general and code.Each card has different formatting. I made a mobile-first website, so I could review on my phone or tablet, wherever I am.Make your own for free: Flashcards site repoI DON’T RECOMMEND using my flashcards. There are too many and most of them are trivia that you don’t need.But if you don’t want to listen to me, here you go: My flash cards database (1200 cards): My flash cards database (extreme - 1800 cards):Keep in mind I went overboard and have cards covering everything from assembly language and Python trivia to machine learning and statistics. It’s way too much for what’s required.Note on flashcards: The first time you recognize you know the answer, don’t mark it as known. You have to see thesame card and answer it several times correctly before you really know it. Repetition will put that knowledge deeper inyour brain.An alternative to using my flashcard site is Anki, which has been recommended to me numerous times. It uses a repetition system to help you remember. It’s user-friendly, available on all platforms and has a cloud sync system. It costs $25 on iOS but is free on other platforms.My flashcard database in Anki format: https://ankiweb.net/shared/info/25173560 (thanks @xiewenya).Some students have mentioned formatting issues with white space that can be fixed by doing the following: open deck, edit card, click cards, select the “styling” radio button, add the member “white-space: pre;” to the card class.3. Do Coding Interview Questions While You’re LearningTHIS IS VERY IMPORTANT.Start doing coding interview questions while you’re learning data structures and algorithms.You need to apply what you’re learning to solving problems, or you’ll forget. I made this mistake.Once you’ve learned a topic, and feel somewhat comfortable with it, for example, linked lists: Open one of the coding interview books (or coding problem websites, listed below) Do 2 or 3 questions regarding linked lists. Move on to the next learning topic. Later, go back and do another 2 or 3 linked list problems. Do this with each new topic you learn.Keep doing problems while you’re learning all this stuff, not after.You’re not being hired for knowledge, but how you apply the knowledge.There are many resources for this, listed below. Keep going.4. FocusThere are a lot of distractions that can take up valuable time. Focus and concentration are hard. Turn on some musicwithout lyrics and you’ll be able to focus pretty well.What you won’t see coveredThese are prevalent technologies but not part of this study plan: SQL Javascript HTML, CSS, and other front-end technologiesThe Daily PlanThis course goes over a lot of subjects. Each will probably take you a few days, or maybe even a week or more. It depends on your schedule.Each day, take the next subject in the list, watch some videos about that subject, and then write an implementation of that data structure or algorithm in the language you chose for this course.You can see my code here: C C++ PythonYou don’t need to memorize every algorithm. You just need to be able to understand it enough to be able to write your own implementation.Coding Question Practice🤔 Why is this here? I’m not ready to interview.Then go back and read this.Why you need to practice doing programming problems: Problem recognition, and where the right data structures and algorithms fit in Gathering requirements for the problem Talking your way through the problem like you will in the interview Coding on a whiteboard or paper, not a computer Coming up with time and space complexity for your solutions (see Big-O below) Testing your solutionsThere is a great intro for methodical, communicative problem solving in an interview. You’ll get this from the programminginterview books, too, but I found this outstanding:Algorithm design canvasWrite code on a whiteboard or paper, not a computer. Test with some sample inputs. Then type it and test it out on a computer.If you don’t have a whiteboard at home, pick up a large drawing pad from an art store. You can sit on the couch and practice. This is my “sofa whiteboard”. I added the pen in the photo just for scale. If you use a pen, you’ll wish you could erase. Gets messy quick. I use a pencil and eraser.Coding question practice is not about memorizing answers to programming problems.Coding ProblemsDon’t forget your key coding interview books here.Solving Problems: How to Find a Solution How to Dissect a Topcoder Problem StatementCoding Interview Question Videos: IDeserve (88 videos) Tushar Roy (5 playlists) Super for walkthroughs of problem solutions Nick White - LeetCode Solutions (187 Videos) Good explanations of solution and the code You can watch several in a short time FisherCoder - LeetCode SolutionsChallenge/Practice sites: LeetCode My favorite coding problem site. It’s worth the subscription money for the 1-2 months you’ll likely be preparing. See Nick White and FisherCoder Videos above for code walk-throughs. HackerRank TopCoder Codeforces Codility Geeks for Geeks InterviewBit AlgoExpert Created by Google engineers, this is also an excellent resource to hone your skills. Project Euler very math focused, and not really suited for coding interviews Let’s Get StartedAlright, enough talk, let’s learn!But don’t forget to do coding problems from above while you learn!Algorithmic complexity / Big-O / Asymptotic analysis Nothing to implement here, you’re just watching videos and taking notes! Yay! There are a lot of videos here. Just watch enough until you understand it. You can always come back and review. Don’t worry if you don’t understand all the math behind it. You just need to understand how to express the complexity of an algorithm in terms of Big-O. Harvard CS50 - Asymptotic Notation (video) Big O Notations (general quick tutorial) (video) Big O Notation (and Omega and Theta) - best mathematical explanation (video) Skiena (video) UC Berkeley Big O (video) Amortized Analysis (video) TopCoder (includes recurrence relations and master theorem): Computational Complexity: Section 1 Computational Complexity: Section 2 Cheat sheet [Review] Big-O notation in 5 minutes (video)Well, that’s about enough of that.When you go through “Cracking the Coding Interview”, there is a chapter on this, and at the end there is a quiz to see if you can identify the runtime complexity of different algorithms. It’s a super review and test.Data Structures Arrays About Arrays: Arrays (video) UC Berkeley CS61B - Linear and Multi-Dim Arrays (video) (Start watching from 15m 32s) Dynamic Arrays (video) Jagged Arrays (video) Implement a vector (mutable array with automatic resizing): Practice coding using arrays and pointers, and pointer math to jump to an index instead of using indexing. New raw data array with allocated memory can allocate int array under the hood, just not use its features start with 16, or if starting number is greater, use power of 2 - 16, 32, 64, 128 size() - number of items capacity() - number of items it can hold is_empty() at(index) - returns item at given index, blows up if index out of bounds push(item) insert(index, item) - inserts item at index, shifts that index’s value and trailing elements to the right prepend(item) - can use insert above at index 0 pop() - remove from end, return value delete(index) - delete item at index, shifting all trailing elements left remove(item) - looks for value and removes index holding it (even if in multiple places) find(item) - looks for value and returns first index with that value, -1 if not found resize(new_capacity) // private function when you reach capacity, resize to double the size when popping an item, if size is 1/4 of capacity, resize to half Time O(1) to add/remove at end (amortized for allocations for more space), index, or update O(n) to insert/remove elsewhere Space contiguous in memory, so proximity helps performance space needed = (array capacity, which is &gt;= n) * size of item, but even if 2n, still O(n) Linked Lists Description: Singly Linked Lists (video) CS 61B - Linked Lists 1 (video) CS 61B - Linked Lists 2 (video) [Review] Linked lists in 4 minutes (video) C Code (video) - not the whole video, just portions about Node struct and memory allocation Linked List vs Arrays: Core Linked Lists Vs Arrays (video) In The Real World Linked Lists Vs Arrays (video) Why you should avoid linked lists (video) Gotcha: you need pointer to pointer knowledge: (for when you pass a pointer to a function that may change the address where that pointer points) This page is just to get a grasp on ptr to ptr. I don’t recommend this list traversal style. Readability and maintainability suffer due to cleverness. Pointers to Pointers Implement (I did with tail pointer &amp; without): size() - returns number of data elements in list empty() - bool returns true if empty value_at(index) - returns the value of the nth item (starting at 0 for first) push_front(value) - adds an item to the front of the list pop_front() - remove front item and return its value push_back(value) - adds an item at the end pop_back() - removes end item and returns its value front() - get value of front item back() - get value of end item insert(index, value) - insert value at index, so current item at that index is pointed to by new item at index erase(index) - removes node at given index value_n_from_end(n) - returns the value of the node at nth position from the end of the list reverse() - reverses the list remove_value(value) - removes the first item in the list with this value Doubly-linked List Description (video) No need to implement Stack Stacks (video) [Review] Stacks in 3 minutes (video) Will not implement. Implementing with array is trivial Queue Queue (video) Circular buffer/FIFO [Review] Queues in 3 minutes (video) Implement using linked-list, with tail pointer: enqueue(value) - adds value at position at tail dequeue() - returns value and removes least recently added element (front) empty() Implement using fixed-sized array: enqueue(value) - adds item at end of available storage dequeue() - returns value and removes least recently added element empty() full() Cost: a bad implementation using linked list where you enqueue at head and dequeue at tail would be O(n) because you’d need the next to last element, causing a full traversal each dequeue enqueue: O(1) (amortized, linked list and array [probing]) dequeue: O(1) (linked list and array) empty: O(1) (linked list and array) Hash table Videos: Hashing with Chaining (video) Table Doubling, Karp-Rabin (video) Open Addressing, Cryptographic Hashing (video) PyCon 2010: The Mighty Dictionary (video) PyCon 2017: The Dictionary Even Mightier (video) (Advanced) Randomization: Universal &amp; Perfect Hashing (video) (Advanced) Perfect hashing (video) [Review] Hash tables in 4 minutes (video) Online Courses: Core Hash Tables (video) Data Structures (video) Phone Book Problem (video) distributed hash tables: Instant Uploads And Storage Optimization In Dropbox (video) Distributed Hash Tables (video) Implement with array using linear probing hash(k, m) - m is size of hash table add(key, value) - if key already exists, update value exists(key) get(key) remove(key) More Knowledge Binary search Binary Search (video) Binary Search (video) detail blueprint [Review] Binary search in 4 minutes (video) Implement: binary search (on sorted array of integers) binary search using recursion Bitwise operations Bits cheat sheet - you should know many of the powers of 2 from (2^1 to 2^16 and 2^32) [ ] Get a really good understanding of manipulating bits with: &amp;, , ^, ~, », « words Good intro: Bit Manipulation (video) C Programming Tutorial 2-10: Bitwise Operators (video) Bit Manipulation Bitwise Operation Bithacks The Bit Twiddler The Bit Twiddler Interactive Bit Hacks (video) Practice Operations 2s and 1s complement Binary: Plusses &amp; Minuses (Why We Use Two’s Complement) (video) 1s Complement 2s Complement Count set bits 4 ways to count bits in a byte (video) Count Bits How To Count The Number Of Set Bits In a 32 Bit Integer Swap values: Swap Absolute value: Absolute Integer Trees Trees - Intro Intro to Trees (video) Tree Traversal (video) BFS(breadth-first search) and DFS(depth-first search) (video) BFS notes: level order (BFS, using queue) time complexity: O(n) space complexity: best: O(1), worst: O(n/2)=O(n) DFS notes: time complexity: O(n) space complexity: best: O(log n) - avg. height of tree worst: O(n) inorder (DFS: left, self, right) postorder (DFS: left, right, self) preorder (DFS: self, left, right) [Review] Breadth-first search in 4 minutes (video) [Review] Depth-first search in 4 minutes (video) [Review] Tree Traversal (playlist) in 11 minutes (video) Binary search trees: BSTs Binary Search Tree Review (video) Introduction (video) MIT (video) C/C++: Binary search tree - Implementation in C/C++ (video) BST implementation - memory allocation in stack and heap (video) Find min and max element in a binary search tree (video) Find height of a binary tree (video) Binary tree traversal - breadth-first and depth-first strategies (video) Binary tree: Level Order Traversal (video) Binary tree traversal: Preorder, Inorder, Postorder (video) Check if a binary tree is binary search tree or not (video) Delete a node from Binary Search Tree (video) Inorder Successor in a binary search tree (video) Implement: insert // insert value into tree get_node_count // get count of values stored print_values // prints the values in the tree, from min to max delete_tree is_in_tree // returns true if given value exists in the tree get_height // returns the height in nodes (single node’s height is 1) get_min // returns the minimum value stored in the tree get_max // returns the maximum value stored in the tree is_binary_search_tree delete_value get_successor // returns next-highest value in tree after given value, -1 if none Heap / Priority Queue / Binary Heap visualized as a tree, but is usually linear in storage (array, linked list) Heap Introduction (video) Binary Trees (video) Tree Height Remark (video) Basic Operations (video) Complete Binary Trees (video) Pseudocode (video) Heap Sort - jumps to start (video) Heap Sort (video) Building a heap (video) MIT: Heaps and Heap Sort (video) CS 61B Lecture 24: Priority Queues (video) Linear Time BuildHeap (max-heap) [Review] Heap (playlist) in 13 minutes (video) Implement a max-heap: insert sift_up - needed for insert get_max - returns the max item, without removing it get_size() - return number of elements stored is_empty() - returns true if heap contains no elements extract_max - returns the max item, removing it sift_down - needed for extract_max remove(x) - removes item at index x heapify - create a heap from an array of elements, needed for heap_sort heap_sort() - take an unsorted array and turn it into a sorted array in-place using a max heap or min heap Sorting Notes: Implement sorts &amp; know best case/worst case, average complexity of each: no bubble sort - it’s terrible - O(n^2), except when n &lt;= 16 Stability in sorting algorithms (“Is Quicksort stable?”) Sorting Algorithm Stability Stability In Sorting Algorithms Stability In Sorting Algorithms Sorting Algorithms - Stability Which algorithms can be used on linked lists? Which on arrays? Which on both? I wouldn’t recommend sorting a linked list, but merge sort is doable. Merge Sort For Linked List For heapsort, see Heap data structure above. Heap sort is great, but not stable Sedgewick - Mergesort (5 videos) 1. Mergesort 2. Bottom up Mergesort 3. Sorting Complexity 4. Comparators 5. Stability Sedgewick - Quicksort (4 videos) 1. Quicksort 2. Selection 3. Duplicate Keys 4. System Sorts UC Berkeley: CS 61B Lecture 29: Sorting I (video) CS 61B Lecture 30: Sorting II (video) CS 61B Lecture 32: Sorting III (video) CS 61B Lecture 33: Sorting V (video) CS 61B 2014-04-21: Radix Sort(video) Bubble Sort (video) Analyzing Bubble Sort (video) Insertion Sort, Merge Sort (video) Insertion Sort (video) Merge Sort (video) Quicksort (video) Selection Sort (video) Merge sort code: Using output array (C) Using output array (Python) In-place (C++) Quick sort code: Implementation (C) Implementation (C) Implementation (Python) [Review] Sorting (playlist) in 18 minutes Quick sort in 4 minutes (video) Heap sort in 4 minutes (video) Merge sort in 3 minutes (video) Bubble sort in 2 minutes (video) Selection sort in 3 minutes (video) Insertion sort in 2 minutes (video) Implement: Mergesort: O(n log n) average and worst case Quicksort O(n log n) average case Selection sort and insertion sort are both O(n^2) average and worst case For heapsort, see Heap data structure above Not required, but I recommended them: Sedgewick - Radix Sorts (6 videos) 1. Strings in Java 2. Key Indexed Counting 3. Least Significant Digit First String Radix Sort 4. Most Significant Digit First String Radix Sort 5. 3 Way Radix Quicksort 6. Suffix Arrays Radix Sort Radix Sort (video) Radix Sort, Counting Sort (linear time given constraints) (video) Randomization: Matrix Multiply, Quicksort, Freivalds’ algorithm (video) Sorting in Linear Time (video) As a summary, here is a visual representation of 15 sorting algorithms.If you need more detail on this subject, see “Sorting” section in Additional Detail on Some SubjectsGraphsGraphs can be used to represent many problems in computer science, so this section is long, like trees and sorting were. Notes: There are 4 basic ways to represent a graph in memory: objects and pointers adjacency matrix adjacency list adjacency map Familiarize yourself with each representation and its pros &amp; cons BFS and DFS - know their computational complexity, their trade offs, and how to implement them in real code When asked a question, look for a graph-based solution first, then move on if none MIT(videos): Breadth-First Search Depth-First Search Skiena Lectures - great intro: CSE373 2020 - Lecture 10 - Graph Data Structures (video) CSE373 2020 - Lecture 11 - Graph Traversal (video) CSE373 2020 - Lecture 12 - Depth First Search (video) CSE373 2020 - Lecture 13 - Minimum Spanning Trees (video) CSE373 2020 - Lecture 14 - Minimum Spanning Trees (con’t) (video) CSE373 2020 - Lecture 15 - Graph Algorithms (con’t 2) (video) Graphs (review and more): 6.006 Single-Source Shortest Paths Problem (video) 6.006 Dijkstra (video) 6.006 Bellman-Ford (video) 6.006 Speeding Up Dijkstra (video) Aduni: Graph Algorithms I - Topological Sorting, Minimum Spanning Trees, Prim’s Algorithm - Lecture 6 (video) Aduni: Graph Algorithms II - DFS, BFS, Kruskal’s Algorithm, Union Find Data Structure - Lecture 7 (video) Aduni: Graph Algorithms III: Shortest Path - Lecture 8 (video) Aduni: Graph Alg. IV: Intro to geometric algorithms - Lecture 9 (video) CS 61B 2014: Weighted graphs (video) Greedy Algorithms: Minimum Spanning Tree (video) Strongly Connected Components Kosaraju’s Algorithm Graph Algorithm (video) [Review] Shortest Path Algorithms (playlist) in 16 minutes (video) [Review] Minimum Spanning Trees (playlist) in 4 minutes (video) Full Coursera Course: Algorithms on Graphs (video) I’ll implement: DFS with adjacency list (recursive) DFS with adjacency list (iterative with stack) DFS with adjacency matrix (recursive) DFS with adjacency matrix (iterative with stack) BFS with adjacency list BFS with adjacency matrix single-source shortest path (Dijkstra) minimum spanning tree DFS-based algorithms (see Aduni videos above): check for cycle (needed for topological sort, since we’ll check for cycle before starting) topological sort count connected components in a graph list strongly connected components check for bipartite graph Even More Knowledge Recursion Stanford lectures on recursion &amp; backtracking: [ ] [Lecture 8 Programming Abstractions (video)](https://www.youtube.com/watch?v=gl3emqCuueQ&amp;list=PLFE6E58F856038C69&amp;index=8) [ ] [Lecture 9 Programming Abstractions (video)](https://www.youtube.com/watch?v=uFJhEPrbycQ&amp;list=PLFE6E58F856038C69&amp;index=9) [ ] [Lecture 10 Programming Abstractions (video)](https://www.youtube.com/watch?v=NdF1QDTRkck&amp;index=10&amp;list=PLFE6E58F856038C69) [ ] [Lecture 11 Programming Abstractions (video)](https://www.youtube.com/watch?v=p-gpaIGRCQI&amp;list=PLFE6E58F856038C69&amp;index=11) When it is appropriate to use it? How is tail recursion better than not? What Is Tail Recursion Why Is It So Bad? Tail Recursion (video) 5 Simple Steps for Solving Any Recursive Problem(video) Backtracking Blueprint: Java Python Dynamic Programming You probably won’t see any dynamic programming problems in your interview, but it’s worth being able to recognize a problem as being a candidate for dynamic programming. This subject can be pretty difficult, as each DP soluble problem must be defined as a recursion relation, and coming up with it can be tricky. I suggest looking at many examples of DP problems until you have a solid understanding of the pattern involved. Videos: Skiena: CSE373 2020 - Lecture 19 - Introduction to Dynamic Programming (video) Skiena: CSE373 2020 - Lecture 20 - Edit Distance (video) Skiena: CSE373 2020 - Lecture 20 - Edit Distance (continued) (video) Skiena: CSE373 2020 - Lecture 21 - Dynamic Programming (video) Skiena: CSE373 2020 - Lecture 21 - Dynamic Programming and Review (video) Simonson: Dynamic Programming 0 (starts at 59:18) (video) Simonson: Dynamic Programming I - Lecture 11 (video) Simonson: Dynamic programming II - Lecture 12 (video) List of individual DP problems (each is short): Dynamic Programming (video) Yale Lecture notes: Dynamic Programming Coursera: The RNA secondary structure problem (video) A dynamic programming algorithm (video) Illustrating the DP algorithm (video) Running time of the DP algorithm (video) DP vs. recursive implementation (video) Global pairwise sequence alignment (video) Local pairwise sequence alignment (video) Design patterns Quick UML review (video) Learn these patterns: strategy singleton adapter prototype decorator visitor factory, abstract factory facade observer proxy delegate command state memento iterator composite flyweight Series of videos (27 videos) Book: Head First Design Patterns I know the canonical book is “Design Patterns: Elements of Reusable Object-Oriented Software”, but Head First is great for beginners to OO. Handy reference: 101 Design Patterns &amp; Tips for Developers Combinatorics (n choose k) &amp; Probability Math Skills: How to find Factorial, Permutation and Combination (Choose) (video) Make School: Probability (video) Make School: More Probability and Markov Chains (video) Khan Academy: Course layout: Basic Theoretical Probability Just the videos - 41 (each are simple and each are short): Probability Explained (video) NP, NP-Complete and Approximation Algorithms Know about the most famous classes of NP-complete problems, such as traveling salesman and the knapsack problem, and be able to recognize them when an interviewer asks you them in disguise. Know what NP-complete means. Computational Complexity (video) Simonson: Greedy Algs. II &amp; Intro to NP Completeness (video) NP Completeness II &amp; Reductions (video) NP Completeness III (Video) NP Completeness IV (video) Skiena: CSE373 2020 - Lecture 23 - NP-Completeness (video) CSE373 2020 - Lecture 24 - Satisfiability (video) CSE373 2020 - Lecture 25 - More NP-Completeness (video) CSE373 2020 - Lecture 26 - NP-Completeness Challenge (video) Complexity: P, NP, NP-completeness, Reductions (video) Complexity: Approximation Algorithms (video) Complexity: Fixed-Parameter Algorithms (video) Peter Norvig discusses near-optimal solutions to traveling salesman problem: Jupyter Notebook Pages 1048 - 1140 in CLRS if you have it. How computers process a program How CPU executes a program (video) How computers calculate - ALU (video) Registers and RAM (video) The Central Processing Unit (CPU) (video) Instructions and Programs (video) Caches LRU cache: The Magic of LRU Cache (100 Days of Google Dev) (video) Implementing LRU (video) LeetCode - 146 LRU Cache (C++) (video) CPU cache: MIT 6.004 L15: The Memory Hierarchy (video) MIT 6.004 L16: Cache Issues (video) Processes and Threads Computer Science 162 - Operating Systems (25 videos): for processes and threads see videos 1-11 Operating Systems and System Programming (video) What Is The Difference Between A Process And A Thread? Covers: Processes, Threads, Concurrency issues Difference between processes and threads Processes Threads Locks Mutexes Semaphores Monitors How they work? Deadlock Livelock CPU activity, interrupts, context switching Modern concurrency constructs with multicore processors Paging, segmentation and virtual memory (video) Interrupts (video) Process resource needs (memory: code, static storage, stack, heap, and also file descriptors, i/o) Thread resource needs (shares above (minus stack) with other threads in the same process but each has its own pc, stack counter, registers, and stack) Forking is really copy on write (read-only) until the new process writes to memory, then it does a full copy. Context switching How context switching is initiated by the operating system and underlying hardware? threads in C++ (series - 10 videos) CS 377 Spring ‘14: Operating Systems from University of Massachusetts concurrency in Python (videos): Short series on threads Python Threads Understanding the Python GIL (2010) reference David Beazley - Python Concurrency From the Ground Up: LIVE! - PyCon 2015 Keynote David Beazley - Topics of Interest (Python Asyncio) Mutex in Python Testing To cover: how unit testing works what are mock objects what is integration testing what is dependency injection Agile Software Testing with James Bach (video) Open Lecture by James Bach on Software Testing (video) Steve Freeman - Test-Driven Development (that’s not what we meant) (video) slides Dependency injection: video Tao Of Testing How to write tests String searching &amp; manipulations Sedgewick - Suffix Arrays (video) Sedgewick - Substring Search (videos) 1. Introduction to Substring Search 2. Brute-Force Substring Search 3. Knuth-Morris Pratt 4. Boyer-Moore 5. Rabin-Karp Search pattern in text (video) If you need more detail on this subject, see “String Matching” section in Additional Detail on Some Subjects. Tries Note there are different kinds of tries. Some have prefixes, some don’t, and some use string instead of bits to track the path I read through code, but will not implement Sedgewick - Tries (3 videos) 1. R Way Tries 2. Ternary Search Tries 3. Character Based Operations Notes on Data Structures and Programming Techniques Short course videos: Introduction To Tries (video) Performance Of Tries (video) Implementing A Trie (video) The Trie: A Neglected Data Structure TopCoder - Using Tries Stanford Lecture (real world use case) (video) MIT, Advanced Data Structures, Strings (can get pretty obscure about halfway through) (video) Floating Point Numbers simple 8-bit: Representation of Floating Point Numbers - 1 (video - there is an error in calculations - see video description) Unicode The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text Endianness Big And Little Endian Big Endian Vs Little Endian (video) Big And Little Endian Inside/Out (video) Very technical talk for kernel devs. Don’t worry if most is over your head. The first half is enough. Networking If you have networking experience or want to be a reliability engineer or operations engineer, expect questions Otherwise, this is just good to know Khan Academy UDP and TCP: Comparison of Transport Protocols (video) TCP/IP and the OSI Model Explained! (video) Packet Transmission across the Internet. Networking &amp; TCP/IP tutorial. (video) HTTP (video) SSL and HTTPS (video) SSL/TLS (video) HTTP 2.0 (video) Video Series (21 videos) (video) Subnetting Demystified - Part 5 CIDR Notation (video) Sockets: Java - Sockets - Introduction (video) Socket Programming (video) Final Review This section will have shorter videos that you can watch pretty quickly to review most of the important concepts. It’s nice if you want a refresher often. Series of 2-3 minutes short subject videos (23 videos) Videos Series of 2-5 minutes short subject videos - Michael Sambol (38 videos): Videos Sedgewick Videos - Algorithms I Sedgewick Videos - Algorithms IIUpdate Your Resume See Resume prep information in the books: “Cracking The Coding Interview” and “Programming Interviews Exposed” I don’t know how important this is (you can do your own research) but here is an article on making your resume ATS Compliant: How to Create or Check if your Resume is ATS Compliant “This Is What A GOOD Resume Should Look Like” by Gayle McDowell (author of Cracking the Coding Interview), Note by the author: “This is for a US-focused resume. CVs for India and other countries have different expectations, although many of the points will be the same.” “Step-by-step resume guide” by Tech Interview Handbook Detailed guide on how to set up your resume from scratch, write effective resume content, optimize it, and test your resume Find a Job Sites for Finding JobsInterview Process &amp; General Interview Prep How to Pass the Engineering Interview in 2021 Demystifying Tech Recruiting How to Get a Job at the Big 4: How to Get a Job at the Big 4 - Amazon, Facebook, Google &amp; Microsoft (video) How to Get a Job at the Big 4.1 (Follow-up video) Cracking The Coding Interview Set 1: Gayle L McDowell - Cracking The Coding Interview (video) Cracking the Coding Interview with Author Gayle Laakmann McDowell (video) Cracking the Facebook Coding Interview: The Approach Problem Walkthrough Prep Courses: Software Engineer Interview Unleashed (paid course): Learn how to make yourself ready for software engineer interviews from a former Google interviewer. Python for Data Structures, Algorithms, and Interviews (paid course): A Python centric interview prep course which covers data structures, algorithms, mock interviews and much more. Intro to Data Structures and Algorithms using Python (Udacity free course): A free Python centric data structures and algorithms course. Data Structures and Algorithms Nanodegree! (Udacity paid Nanodegree): Get hands-on practice with over 100 data structures and algorithm exercises and guidance from a dedicated mentor to help prepare you for interviews and on-the-job scenarios. Grokking the Behavioral Interview (Educative free course): Many times, it’s not your technical competency that holds you back from landing your dream job, it’s how you perform on the behavioral interview. Mock Interviews: Gainlo.co: Mock interviewers from big companies - I used this and it helped me relax for the phone screen and on-site interview Pramp: Mock interviews from/with peers - peer-to-peer model of practice interviews interviewing.io: Practice mock interview with senior engineers - anonymous algorithmic/systems design interviews with senior engineers from FAANG anonymouslyBe thinking of for when the interview comesThink of about 20 interview questions you’ll get, along with the lines of the items below. Have at least one answer for each.Have a story, not just data, about something you accomplished. Why do you want this job? What’s a tough problem you’ve solved? Biggest challenges faced? Best/worst designs seen? Ideas for improving an existing product How do you work best, as an individual and as part of a team? Which of your skills or experiences would be assets in the role and why? What did you most enjoy at [job x / project y]? What was the biggest challenge you faced at [job x / project y]? What was the hardest bug you faced at [job x / project y]? What did you learn at [job x / project y]? What would you have done better at [job x / project y]? If you find it hard to come up with good answers of these types of interview questions, here are some ideas: General Interview Questions and their Answers Have questions for the interviewerSome of mine (I already may know the answers, but want their opinion or team perspective): How large is your team? What does your dev cycle look like? Do you do waterfall/sprints/agile? Are rushes to deadlines common? Or is there flexibility? How are decisions made in your team? How many meetings do you have per week? Do you feel your work environment helps you concentrate? What are you working on? What do you like about it? What is the work life like? How is the work/life balance?Once You’ve Got The JobCongratulations!Keep learning.You’re never really done.Everything below this point is optional. It is NOT needed for an entry-level interview.However, by studying these, you’ll get greater exposure to more CS concepts, and will be better prepared forany software engineering job. You’ll be a much more well-rounded software engineer.Additional Books📚 These are here so you can dive into a topic you find interesting. The Unix Programming Environment An oldie but a goodie The Linux Command Line: A Complete Introduction A modern option TCP/IP Illustrated Series Head First Design Patterns A gentle introduction to design patterns Design Patterns: Elements of Reusable Object-Oriente​d Software AKA the “Gang Of Four” book, or GOF The canonical design patterns book Algorithm Design Manual (Skiena) As a review and problem recognition The algorithm catalog portion is well beyond the scope of difficulty you’ll get in an interview This book has 2 parts: Class textbook on data structures and algorithms Pros: Is a good review as any algorithms textbook would be Nice stories from his experiences solving problems in industry and academia Code examples in C Cons: Can be as dense or impenetrable as CLRS, and in some cases, CLRS may be a better alternative for some subjects Chapters 7, 8, 9 can be painful to try to follow, as some items are not explained well or require more brain than I have Don’t get me wrong: I like Skiena, his teaching style, and mannerisms, but I may not be Stony Brook material Algorithm catalog: This is the real reason you buy this book. This book is better as an algorithm reference, and not something you read cover to cover. Can rent it on Kindle Answers: Solutions Errata Write Great Code: Volume 1: Understanding the Machine The book was published in 2004, and is somewhat outdated, but it’s a terrific resource for understanding a computer in brief The author invented HLA, so take mentions and examples in HLA with a grain of salt. Not widely used, but decent examples of what assembly looks like These chapters are worth the read to give you a nice foundation: Chapter 2 - Numeric Representation Chapter 3 - Binary Arithmetic and Bit Operations Chapter 4 - Floating-Point Representation Chapter 5 - Character Representation Chapter 6 - Memory Organization and Access Chapter 7 - Composite Data Types and Memory Objects Chapter 9 - CPU Architecture Chapter 10 - Instruction Set Architecture Chapter 11 - Memory Architecture and Organization Introduction to Algorithms Important: Reading this book will only have limited value. This book is a great review of algorithms and data structures, but won’t teach you how to write good code. You have to be able to code a decent solution efficiently AKA CLR, sometimes CLRS, because Stein was late to the game Computer Architecture, Sixth Edition: A Quantitative Approach For a richer, more up-to-date (2017), but longer treatment System Design, Scalability, Data HandlingYou can expect system design questions if you have 4+ years of experience. Scalability and System Design are very large topics with many topics and resources, since there is a lot to consider when designing a software/hardware system that can scale. Expect to spend quite a bit of time on this Considerations: Scalability Distill large data sets to single values Transform one data set to another Handling obscenely large amounts of data System design features sets interfaces class hierarchies designing a system under certain constraints simplicity and robustness tradeoffs performance analysis and optimization START HERE: The System Design Primer System Design from HiredInTech How Do I Prepare To Answer Design Questions In A Technical Interview? 8 Things You Need to Know Before a System Design Interview Database Normalization - 1NF, 2NF, 3NF and 4NF (video) System Design Interview - There are a lot of resources in this one. Look through the articles and examples. I put some of them below How to ace a systems design interview Numbers Everyone Should Know How long does it take to make a context switch? Transactions Across Datacenters (video) A plain English introduction to CAP Theorem MIT 6.824: Distributed Systems, Spring 2020 (20 videos) Consensus Algorithms: Paxos - Paxos Agreement - Computerphile (video) Raft - An Introduction to the Raft Distributed Consensus Algorithm (video) Easy-to-read paper Infographic Consistent Hashing NoSQL Patterns Scalability: You don’t need all of these. Just pick a few that interest you. Great overview (video) Short series: Clones Database Cache Asynchronism Scalable Web Architecture and Distributed Systems Fallacies of Distributed Computing Explained Jeff Dean - Building Software Systems At Google and Lessons Learned (video) Introduction to Architecting Systems for Scale Scaling mobile games to a global audience using App Engine and Cloud Datastore (video) How Google Does Planet-Scale Engineering for Planet-Scale Infra (video) The Importance of Algorithms Sharding Engineering for the Long Game - Astrid Atkinson Keynote(video) 7 Years Of YouTube Scalability Lessons In 30 Minutes video How PayPal Scaled To Billions Of Transactions Daily Using Just 8VMs How to Remove Duplicates in Large Datasets A look inside Etsy’s scale and engineering culture with Jon Cowie (video) What Led Amazon to its Own Microservices Architecture To Compress Or Not To Compress, That Was Uber’s Question When Should Approximate Query Processing Be Used? Google’s Transition From Single Datacenter, To Failover, To A Native Multihomed Architecture The Image Optimization Technology That Serves Millions Of Requests Per Day A Patreon Architecture Short Tinder: How Does One Of The Largest Recommendation Engines Decide Who You’ll See Next? Design Of A Modern Cache Live Video Streaming At Facebook Scale A Beginner’s Guide To Scaling To 11 Million+ Users On Amazon’s AWS A 360 Degree View Of The Entire Netflix Stack Latency Is Everywhere And It Costs You Sales - How To Crush It What Powers Instagram: Hundreds of Instances, Dozens of Technologies Salesforce Architecture - How They Handle 1.3 Billion Transactions A Day ESPN’s Architecture At Scale - Operating At 100,000 Duh Nuh Nuhs Per Second See “Messaging, Serialization, and Queueing Systems” way below for info on some of the technologies that can glue services together Twitter: O’Reilly MySQL CE 2011: Jeremy Cole, “Big and Small Data at @Twitter” (video) Timelines at Scale For even more, see “Mining Massive Datasets” video series in the Video Series section Practicing the system design process: Here are some ideas to try working through on paper, each with some documentation on how it was handled in the real world: review: The System Design Primer System Design from HiredInTech cheat sheet flow: Understand the problem and scope: Define the use cases, with interviewer’s help Suggest additional features Remove items that interviewer deems out of scope Assume high availability is required, add as a use case Think about constraints: Ask how many requests per month Ask how many requests per second (they may volunteer it or make you do the math) Estimate reads vs. writes percentage Keep 80/20 rule in mind when estimating How much data written per second Total storage required over 5 years How much data read per second Abstract design: Layers (service, data, caching) Infrastructure: load balancing, messaging Rough overview of any key algorithm that drives the service Consider bottlenecks and determine solutions Exercises: Design a random unique ID generation system Design a key-value database Design a picture sharing system Design a recommendation system Design a URL-shortener system: copied from above Design a cache system Additional LearningI added them to help you become a well-rounded software engineer, and to be aware of certaintechnologies and algorithms, so you’ll have a bigger toolbox. Compilers How a Compiler Works in ~1 minute (video) Harvard CS50 - Compilers (video) C++ (video) Understanding Compiler Optimization (C++) (video) Emacs and vi(m) Familiarize yourself with a unix-based code editor vi(m): Editing With vim 01 - Installation, Setup, and The Modes (video) VIM Adventures set of 4 videos: The vi/vim editor - Lesson 1 The vi/vim editor - Lesson 2 The vi/vim editor - Lesson 3 The vi/vim editor - Lesson 4 Using Vi Instead of Emacs emacs: Basics Emacs Tutorial (video) set of 3 (videos): Emacs Tutorial (Beginners) -Part 1- File commands, cut/copy/paste, cursor commands Emacs Tutorial (Beginners) -Part 2- Buffer management, search, M-x grep and rgrep modes Emacs Tutorial (Beginners) -Part 3- Expressions, Statements, ~/.emacs file and packages Evil Mode: Or, How I Learned to Stop Worrying and Love Emacs (video) Writing C Programs With Emacs The Absolute Beginner’s Guide to Emacs (video by David Wilson) The Absolute Beginner’s Guide to Emacs (notes by David Wilson) Unix command line tools I filled in the list below from good tools. bash cat grep sed awk curl or wget sort tr uniq strace tcpdump Information theory (videos) Khan Academy More about Markov processes: Core Markov Text Generation Core Implementing Markov Text Generation Project = Markov Text Generation Walk Through See more in MIT 6.050J Information and Entropy series below Parity &amp; Hamming Code (videos) Intro Parity Hamming Code: Error detection Error correction Error Checking Entropy Also see videos below Make sure to watch information theory videos first Information Theory, Claude Shannon, Entropy, Redundancy, Data Compression &amp; Bits (video) Cryptography Also see videos below Make sure to watch information theory videos first Khan Academy Series Cryptography: Hash Functions Cryptography: Encryption Compression Make sure to watch information theory videos first Computerphile (videos): Compression Entropy in Compression Upside Down Trees (Huffman Trees) EXTRA BITS/TRITS - Huffman Trees Elegant Compression in Text (The LZ 77 Method) Text Compression Meets Probabilities Compressor Head videos (optional) Google Developers Live: GZIP is not enough! Computer Security MIT (23 videos) Introduction, Threat Models Control Hijacking Attacks Buffer Overflow Exploits and Defenses Privilege Separation Capabilities Sandboxing Native Code Web Security Model Securing Web Applications Symbolic Execution Network Security Network Protocols Side-Channel Attacks Garbage collection GC in Python (video) Deep Dive Java: Garbage Collection is Good! Deep Dive Python: Garbage Collection in CPython (video) Parallel Programming Coursera (Scala) Efficient Python for High Performance Parallel Computing (video) Messaging, Serialization, and Queueing Systems Thrift Tutorial Protocol Buffers Tutorials gRPC gRPC 101 for Java Developers (video) Redis Tutorial Amazon SQS (queue) Amazon SNS (pub-sub) RabbitMQ Get Started Celery First Steps With Celery ZeroMQ Intro - Read The Manual ActiveMQ Kafka MessagePack Avro A* A Search Algorithm A* Pathfinding (E01: algorithm explanation) (video) Fast Fourier Transform An Interactive Guide To The Fourier Transform What is a Fourier transform? What is it used for? What is the Fourier Transform? (video) Divide &amp; Conquer: FFT (video) Understanding The FFT Bloom Filter Given a Bloom filter with m bits and k hashing functions, both insertion and membership testing are O(k) Bloom Filters (video) [Bloom Filters Mining of Massive Datasets Stanford University (video)](https://www.youtube.com/watch?v=qBTdukbzc78) Tutorial How To Write A Bloom Filter App HyperLogLog How To Count A Billion Distinct Objects Using Only 1.5KB Of Memory Locality-Sensitive Hashing Used to determine the similarity of documents The opposite of MD5 or SHA which are used to determine if 2 documents/strings are exactly the same Simhashing (hopefully) made simple van Emde Boas Trees Divide &amp; Conquer: van Emde Boas Trees (video) MIT Lecture Notes Augmented Data Structures CS 61B Lecture 39: Augmenting Data Structures Balanced search trees Know at least one type of balanced binary tree (and know how it’s implemented): “Among balanced search trees, AVL and 2/3 trees are now passé, and red-black trees seem to be more popular. A particularly interesting self-organizing data structure is the splay tree, which uses rotations to move any accessed key to the root.” - Skiena Of these, I chose to implement a splay tree. From what I’ve read, you won’t implement a balanced search tree in your interview. But I wanted exposure to coding one up and let’s face it, splay trees are the bee’s knees. I did read a lot of red-black tree code Splay tree: insert, search, delete functions If you end up implementing red/black tree try just these: Search and insertion functions, skipping delete I want to learn more about B-Tree since it’s used so widely with very large data sets Self-balancing binary search tree AVL trees In practice: From what I can tell, these aren’t used much in practice, but I could see where they would be: The AVL tree is another structure supporting O(log n) search, insertion, and removal. It is more rigidly balanced than red–black trees, leading to slower insertion and removal but faster retrieval. This makes it attractive for data structures that may be built once and loaded without reconstruction, such as language dictionaries (or program dictionaries, such as the opcodes of an assembler or interpreter) MIT AVL Trees / AVL Sort (video) AVL Trees (video) AVL Tree Implementation (video) Split And Merge Splay trees In practice: Splay trees are typically used in the implementation of caches, memory allocators, routers, garbage collectors, data compression, ropes (replacement of string used for long text strings), in Windows NT (in the virtual memory, networking and file system code) etc CS 61B: Splay Trees (video) MIT Lecture: Splay Trees: Gets very mathy, but watch the last 10 minutes for sure. Video Red/black trees These are a translation of a 2-3 tree (see below). In practice: Red–black trees offer worst-case guarantees for insertion time, deletion time, and search time. Not only does this make them valuable in time-sensitive applications such as real-time applications, but it makes them valuable building blocks in other data structures which provide worst-case guarantees; for example, many data structures used in computational geometry can be based on red–black trees, and the Completely Fair Scheduler used in current Linux kernels uses red–black trees. In the version 8 of Java, the Collection HashMap has been modified such that instead of using a LinkedList to store identical elements with poor hashcodes, a Red-Black tree is used Aduni - Algorithms - Lecture 4 (link jumps to starting point) (video) Aduni - Algorithms - Lecture 5 (video) Red-Black Tree An Introduction To Binary Search And Red Black Tree [Review] Red-Black Trees (playlist) in 30 minutes (video) 2-3 search trees In practice: 2-3 trees have faster inserts at the expense of slower searches (since height is more compared to AVL trees). You would use 2-3 tree very rarely because its implementation involves different types of nodes. Instead, people use Red Black trees. 23-Tree Intuition and Definition (video) Binary View of 23-Tree 2-3 Trees (student recitation) (video) 2-3-4 Trees (aka 2-4 trees) In practice: For every 2-4 tree, there are corresponding red–black trees with data elements in the same order. The insertion and deletion operations on 2-4 trees are also equivalent to color-flipping and rotations in red–black trees. This makes 2-4 trees an important tool for understanding the logic behind red–black trees, and this is why many introductory algorithm texts introduce 2-4 trees just before red–black trees, even though 2-4 trees are not often used in practice. CS 61B Lecture 26: Balanced Search Trees (video) Bottom Up 234-Trees (video) Top Down 234-Trees (video) N-ary (K-ary, M-ary) trees note: the N or K is the branching factor (max branches) binary trees are a 2-ary tree, with branching factor = 2 2-3 trees are 3-ary K-Ary Tree B-Trees Fun fact: it’s a mystery, but the B could stand for Boeing, Balanced, or Bayer (co-inventor). In Practice: B-Trees are widely used in databases. Most modern filesystems use B-trees (or Variants). In addition to its use in databases, the B-tree is also used in filesystems to allow quick random access to an arbitrary block in a particular file. The basic problem is turning the file block i address into a disk block (or perhaps to a cylinder-head-sector) address B-Tree B-Tree Datastructure Introduction to B-Trees (video) B-Tree Definition and Insertion (video) B-Tree Deletion (video) MIT 6.851 - Memory Hierarchy Models (video) - covers cache-oblivious B-Trees, very interesting data structures - the first 37 minutes are very technical, may be skipped (B is block size, cache line size) [Review] B-Trees (playlist) in 26 minutes (video) k-D Trees Great for finding number of points in a rectangle or higher dimension object A good fit for k-nearest neighbors kNN K-d tree algorithm (video) Skip lists “These are somewhat of a cult data structure” - Skiena Randomization: Skip Lists (video) For animations and a little more detail Network Flows Ford-Fulkerson in 5 minutes — Step by step example (video) Ford-Fulkerson Algorithm (video) Network Flows (video) Disjoint Sets &amp; Union Find UCB 61B - Disjoint Sets; Sorting &amp; selection (video) Sedgewick Algorithms - Union-Find (6 videos) Math for Fast Processing Integer Arithmetic, Karatsuba Multiplication (video) The Chinese Remainder Theorem (used in cryptography) (video) Treap Combination of a binary search tree and a heap Treap Data Structures: Treaps explained (video) Applications in set operations Linear Programming (videos) Linear Programming Finding minimum cost Finding maximum value Solve Linear Equations with Python - Simplex Algorithm Geometry, Convex hull (videos) Graph Alg. IV: Intro to geometric algorithms - Lecture 9 Geometric Algorithms: Graham &amp; Jarvis - Lecture 10 Divide &amp; Conquer: Convex Hull, Median Finding Discrete math Computer Science 70, 001 - Spring 2015 - Discrete Mathematics and Probability Theory Discrete Mathematics by Shai Simonson (19 videos) Discrete Mathematics By IIT Ropar NPTEL Additional Detail on Some Subjects I added these to reinforce some ideas already presented above, but didn’t want to include themabove because it’s just too much. It’s easy to overdo it on a subject.You want to get hired in this century, right? SOLID Bob Martin SOLID Principles of Object Oriented and Agile Design (video) [ ] S - Single Responsibility Principle Single responsibility to each Object more flavor [ ] O - Open/Closed Principle On production level Objects are ready for extension but not for modification more flavor [ ] L - Liskov Substitution Principle Base Class and Derived class follow ‘IS A’ Principle more flavor [ ] I - Interface segregation principle clients should not be forced to implement interfaces they don’t use Interface Segregation Principle in 5 minutes (video) more flavor [ ] D -Dependency Inversion principle Reduce the dependency In composition of objects. Why Is The Dependency Inversion Principle And Why Is It Important more flavor Union-Find Overview Naive Implementation Trees Union By Rank Path Compression Analysis Options More Dynamic Programming (videos) 6.006: Dynamic Programming I: Fibonacci, Shortest Paths 6.006: Dynamic Programming II: Text Justification, Blackjack 6.006: DP III: Parenthesization, Edit Distance, Knapsack 6.006: DP IV: Guitar Fingering, Tetris, Super Mario Bros. 6.046: Dynamic Programming &amp; Advanced DP 6.046: Dynamic Programming: All-Pairs Shortest Paths 6.046: Dynamic Programming (student recitation) Advanced Graph Processing (videos) Synchronous Distributed Algorithms: Symmetry-Breaking. Shortest-Paths Spanning Trees Asynchronous Distributed Algorithms: Shortest-Paths Spanning Trees MIT Probability (mathy, and go slowly, which is good for mathy things) (videos): MIT 6.042J - Probability Introduction MIT 6.042J - Conditional Probability MIT 6.042J - Independence MIT 6.042J - Random Variables MIT 6.042J - Expectation I MIT 6.042J - Expectation II MIT 6.042J - Large Deviations MIT 6.042J - Random Walks Simonson: Approximation Algorithms (video) String Matching Rabin-Karp (videos): Rabin Karps Algorithm Precomputing Optimization: Implementation and Analysis Table Doubling, Karp-Rabin Rolling Hashes, Amortized Analysis Knuth-Morris-Pratt (KMP): TThe Knuth-Morris-Pratt (KMP) String Matching Algorithm Boyer–Moore string search algorithm Boyer-Moore String Search Algorithm Advanced String Searching Boyer-Moore-Horspool Algorithms (video) Coursera: Algorithms on Strings starts off great, but by the time it gets past KMP it gets more complicated than it needs to be nice explanation of tries can be skipped Sorting Stanford lectures on sorting: [Lecture 15 Programming Abstractions (video)](https://www.youtube.com/watch?v=ENp00xylP7c&amp;index=15&amp;list=PLFE6E58F856038C69) [Lecture 16 Programming Abstractions (video)](https://www.youtube.com/watch?v=y4M9IVgrVKo&amp;index=16&amp;list=PLFE6E58F856038C69) Shai Simonson, Aduni.org: Algorithms - Sorting - Lecture 2 (video) Algorithms - Sorting II - Lecture 3 (video) Steven Skiena lectures on sorting: CSE373 2020 - Mergesort/Quicksort (video) CSE373 2020 - Linear Sorting (video) Video SeriesSit back and enjoy. List of individual Dynamic Programming problems (each is short) x86 Architecture, Assembly, Applications (11 videos) MIT 18.06 Linear Algebra, Spring 2005 (35 videos) Excellent - MIT Calculus Revisited: Single Variable Calculus Skiena lectures from Algorithm Design Manual - CSE373 2020 - Analysis of Algorithms (26 videos) UC Berkeley 61B (Spring 2014): Data Structures (25 videos) UC Berkeley 61B (Fall 2006): Data Structures (39 videos) UC Berkeley 61C: Machine Structures (26 videos) OOSE: Software Dev Using UML and Java (21 videos) MIT 6.004: Computation Structures (49 videos) Carnegie Mellon - Computer Architecture Lectures (39 videos) MIT 6.006: Intro to Algorithms (47 videos) MIT 6.033: Computer System Engineering (22 videos) MIT 6.034 Artificial Intelligence, Fall 2010 (30 videos) MIT 6.042J: Mathematics for Computer Science, Fall 2010 (25 videos) MIT 6.046: Design and Analysis of Algorithms (34 videos) MIT 6.824: Distributed Systems, Spring 2020 (20 videos) MIT 6.851: Advanced Data Structures (22 videos) MIT 6.854: Advanced Algorithms, Spring 2016 (24 videos) Harvard COMPSCI 224: Advanced Algorithms (25 videos) MIT 6.858 Computer Systems Security, Fall 2014 Stanford: Programming Paradigms (27 videos) Introduction to Cryptography by Christof Paar Course Website along with Slides and Problem Sets Mining Massive Datasets - Stanford University (94 videos) Graph Theory by Sarada Herke (67 videos)Computer Science Courses Directory of Online CS Courses Directory of CS Courses (many with online lectures)Algorithms implementation Multiple Algorithms implementation by Princeton UniversityPapers Love classic papers? 1978: Communicating Sequential Processes implemented in Go 2003: The Google File System replaced by Colossus in 2012 2004: MapReduce: Simplified Data Processing on Large Clusters mostly replaced by Cloud Dataflow? 2006: Bigtable: A Distributed Storage System for Structured Data 2006: The Chubby Lock Service for Loosely-Coupled Distributed Systems 2007: Dynamo: Amazon’s Highly Available Key-value Store The Dynamo paper kicked off the NoSQL revolution 2007: What Every Programmer Should Know About Memory (very long, and the author encourages skipping of some sections) 2012: AddressSanitizer: A Fast Address Sanity Checker: paper video 2013: Spanner: Google’s Globally-Distributed Database: paper video 2015: Continuous Pipelines at Google 2015: High-Availability at Massive Scale: Building Google’s Data Infrastructure for Ads 2015: How Developers Search for Code: A Case Study More papers: 1,000 papers" } ]
